{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steady-state Analysis of lDE20 (with lineage Dataframe ready)\n",
    "\n",
    "- Note that there are fluctuations in the illumination intensity which may be resulting in pathological behavior from the reporter\n",
    "\n",
    "- Consider either normalizing this out or fixing the underlying problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paulssonlab.deaton.trenchripper.trenchripper as tr\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import sklearn as skl\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "from sklearn.metrics.pairwise import (\n",
    "    euclidean_distances,\n",
    "    manhattan_distances,\n",
    "    cosine_distances,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy.stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import ast\n",
    "\n",
    "\n",
    "import pylab\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "warnings.filterwarnings(action=\"once\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timepoint_values(\n",
    "    df,\n",
    "    label,\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    time_label=\"final cell timepoints list\",\n",
    "    flatten_vals=True,\n",
    "):\n",
    "    masked_label_series = df.apply(\n",
    "        lambda x: np.array(x[label])[\n",
    "            (np.array(x[time_label]) >= min_timepoint)\n",
    "            * (np.array(x[time_label]) <= max_timepoint)\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    if flatten_vals:\n",
    "        flattened_vals = [val for item in masked_label_series.tolist() for val in item]\n",
    "        return flattened_vals\n",
    "    else:\n",
    "        return masked_label_series\n",
    "\n",
    "\n",
    "def get_feature_stats(df, feature_label, min_timepoint, max_timepoint):\n",
    "    feature_vals = get_timepoint_values(df, feature_label, min_timepoint, max_timepoint)\n",
    "    feature_median = np.median(feature_vals)\n",
    "    feature_iqr = sp.stats.iqr(feature_vals)\n",
    "    return feature_median, feature_iqr\n",
    "\n",
    "\n",
    "def get_feature_median_bytrench(df, feature_label, min_timepoint, max_timepoint):\n",
    "    masked_label_series = get_timepoint_values(\n",
    "        final_output_df_pd_filtered,\n",
    "        feature_label,\n",
    "        min_timepoint,\n",
    "        max_timepoint,\n",
    "        flatten_vals=False,\n",
    "    )\n",
    "    trench_median_series = masked_label_series.apply(lambda x: np.nanmedian(x))\n",
    "    return trench_median_series\n",
    "\n",
    "\n",
    "def get_feature_scores(\n",
    "    df,\n",
    "    feature_label,\n",
    "    trench_median_series,\n",
    "    feature_median,\n",
    "    feature_iqr,\n",
    "    time_label=\"final cell timepoints list\",\n",
    "    timepoint_range=None,\n",
    "):\n",
    "    scaling_factor = 1.35 * (feature_median / feature_iqr)\n",
    "\n",
    "    if timepoint_range == None:\n",
    "        feature_scores = (\n",
    "            (df[feature_label].apply(lambda x: np.array(x))) / trench_median_series\n",
    "        ) - 1.0\n",
    "    else:\n",
    "        feature_scores = (\n",
    "            (\n",
    "                df[feature_label].apply(\n",
    "                    lambda x: np.array(x)[\n",
    "                        (np.array(x[time_label]) >= timepoint_range[0])\n",
    "                        * (np.array(x[time_label]) <= timepoint_range[1])\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            / trench_median_series\n",
    "        ) - 1.0\n",
    "    feature_scores = scaling_factor * feature_scores\n",
    "    return feature_scores\n",
    "\n",
    "\n",
    "def get_avg_feature_score(\n",
    "    df,\n",
    "    feature_label,\n",
    "    init_timepoint_range=(0, 20),\n",
    "    time_label=\"final cell timepoints list\",\n",
    "    timepoint_range=None,\n",
    "):\n",
    "    feature_median, feature_iqr = get_feature_stats(\n",
    "        df, feature_label, init_timepoint_range[0], init_timepoint_range[1]\n",
    "    )\n",
    "    trench_median_series = get_feature_median_bytrench(\n",
    "        df, feature_label, init_timepoint_range[0], init_timepoint_range[1]\n",
    "    )\n",
    "    feature_scores = get_feature_scores(\n",
    "        df,\n",
    "        feature_label,\n",
    "        trench_median_series,\n",
    "        feature_median,\n",
    "        feature_iqr,\n",
    "        time_label=time_label,\n",
    "        timepoint_range=timepoint_range,\n",
    "    )\n",
    "    avg_feature_scores = feature_scores.apply(lambda x: np.nanmean(x))\n",
    "    return avg_feature_scores\n",
    "\n",
    "\n",
    "def get_all_avg_feature_scores(\n",
    "    df,\n",
    "    feature_labels,\n",
    "    init_timepoint_range=(0, 20),\n",
    "    time_label=\"final cell timepoints list\",\n",
    "    timepoint_range=None,\n",
    "):\n",
    "\n",
    "    for feature_label in feature_labels:\n",
    "        print(feature_label)\n",
    "        avg_feature_scores = get_avg_feature_score(\n",
    "            df,\n",
    "            feature_label,\n",
    "            init_timepoint_range=init_timepoint_range,\n",
    "            time_label=time_label,\n",
    "            timepoint_range=timepoint_range,\n",
    "        )\n",
    "        df[feature_label + \": score\"] = avg_feature_scores\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_sgrnadf_from_scoredf(\n",
    "    scoredf, feature_labels, score_agg=np.nanmedian, score_agg_name=\"median\"\n",
    "):\n",
    "    scoredf_groupby = scoredf.groupby(\"sgRNA\")\n",
    "    sgrnadf = (\n",
    "        scoredf_groupby.apply(lambda x: x[\"phenotype trenchid\"].tolist())\n",
    "        .to_frame()\n",
    "        .rename(columns={0: \"phenotype trenchid\"})\n",
    "    )\n",
    "\n",
    "    for feature_label in feature_labels:\n",
    "        sgrnadf[feature_label + \": score \" + score_agg_name] = scoredf_groupby.apply(\n",
    "            lambda x: score_agg(np.array(x[feature_label + \": score\"].tolist()))\n",
    "        )\n",
    "\n",
    "    sgrnadf[\"Gene\"] = scoredf_groupby.apply(lambda x: x[\"Gene\"].iloc[0])\n",
    "    sgrnadf[\"TargetID\"] = scoredf_groupby.apply(lambda x: x[\"TargetID\"].iloc[0])\n",
    "    sgrnadf[\"N Mismatch\"] = scoredf_groupby.apply(lambda x: x[\"N Mismatch\"].iloc[0])\n",
    "    sgrnadf[\"N Observations\"] = scoredf_groupby.apply(\n",
    "        lambda x: len(x[\"phenotype trenchid\"].tolist())\n",
    "    )\n",
    "    sgrnadf[\"Category\"] = scoredf_groupby.apply(lambda x: x[\"Category\"].iloc[0])\n",
    "\n",
    "    return sgrnadf\n",
    "\n",
    "\n",
    "# No longer using this\n",
    "# def filter_strong_KOs(df,sampling_thr = 4, n_strongest=2):\n",
    "\n",
    "#     for i in range(sampling_thr,0,-1):\n",
    "#         sampling_mask = df[\"N Observations\"]>=sampling_thr\n",
    "#         mismatch_series = df[sampling_mask][\"N Mismatch\"]\n",
    "\n",
    "#         for n in range(n_strongest,0,-1):\n",
    "#             if len(mismatch_series)>=n:\n",
    "#                 keep_indices = np.argsort(mismatch_series)[:n]\n",
    "#                 out_df = df[sampling_mask].iloc[keep_indices]\n",
    "\n",
    "#                 return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Processing\n",
    "\n",
    "Here, I am going to try and replicate (to some extant) the corrections from \"Genomewide phenotypic analysis of growth, cell morphogenesis, and cell cycle events in Escherichia coli\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = (\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Barcodes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=10,\n",
    "    memory=\"16GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_output_df_pd = pd.read_pickle(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/2021-07-26_lDE20_Lineage_Analysis.pkl\"\n",
    ")\n",
    "final_output_df_pd = final_output_df_pd[\n",
    "    ~final_output_df_pd[\"final cell timepoints list\"].isna()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter for \"Normal\" Sizes at Start\n",
    "\n",
    "1) Fit a gaussian model to each of the specified feature params during the first t timepoints of the experiment (using a subsample for speed) \n",
    "2) Compute a normalized probability trenchwise for these features under the gaussian model, during the first t timepoints of the experiment\n",
    "3) Eliminate trenches that are under some p percentile value of this probability for each feature\n",
    "4) Display histograms for each property as well as the resulting theshold\n",
    "\n",
    "Note that these features should be the only features examined in the resulting analysis. For the notebook, I am looking at:\n",
    "- Birth length (Lb)\n",
    "- Division length (Ld)\n",
    "- Mean Area Increment\n",
    "- Mean Length Increment\n",
    "- Mean Width\n",
    "- Cell cycle duration (Delta t)\n",
    "- Mean mCherry Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_timepoint_cutoff = 30\n",
    "gaussian_subsample = 0.2\n",
    "percentile_threshold = 10\n",
    "\n",
    "filter_params = [\n",
    "    \"Lb list\",\n",
    "    \"Ld list\",\n",
    "    \"Mean Area Increment list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    \"Mean Width list\",\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Delta t list\",\n",
    "]\n",
    "\n",
    "final_output_df_pd_dask = dd.from_pandas(final_output_df_pd, npartitions=100).persist()\n",
    "dask.distributed.wait(final_output_df_pd_dask)\n",
    "final_output_df_pd_dask[\"Early Timepoint Mask\"] = final_output_df_pd_dask[\n",
    "    \"cell timepoints list\"\n",
    "].apply(\n",
    "    lambda x: np.array([item if (type(item) is int) else 10000000 for item in x])\n",
    "    < early_timepoint_cutoff,\n",
    "    meta=(None, \"object\"),\n",
    ")\n",
    "\n",
    "for filter_param in filter_params:\n",
    "    early_param_series = final_output_df_pd_dask.apply(\n",
    "        lambda x: np.array(x[filter_param])[x[\"Early Timepoint Mask\"]]\n",
    "        if type(x[filter_param]) is list\n",
    "        else np.array([]),\n",
    "        axis=1,\n",
    "        meta=(None, \"object\"),\n",
    "    )\n",
    "    all_param_values = [\n",
    "        val\n",
    "        for item in early_param_series.sample(frac=gaussian_subsample)\n",
    "        .compute()\n",
    "        .tolist()\n",
    "        for val in item\n",
    "    ]\n",
    "    gaussian_fit = sp.stats.norm.fit(all_param_values)\n",
    "    gaussian_fit = sp.stats.norm(loc=gaussian_fit[0], scale=gaussian_fit[1])\n",
    "\n",
    "    final_output_df_pd[filter_param + \": Probability\"] = early_param_series.apply(\n",
    "        lambda x: np.exp(np.sum(gaussian_fit.logpdf(x)) / len(x)), meta=float\n",
    "    ).persist()\n",
    "\n",
    "plt.figure(figsize=(22, 16))\n",
    "query_list = []\n",
    "for i, filter_param in enumerate(filter_params):\n",
    "    prob_threshold = np.nanpercentile(\n",
    "        final_output_df_pd[filter_param + \": Probability\"].tolist(),\n",
    "        percentile_threshold,\n",
    "    )\n",
    "    query = \"`\" + filter_param + \": Probability` > \" + str(prob_threshold)\n",
    "    query_list.append(query)\n",
    "\n",
    "    min_v, max_v = np.min(final_output_df_pd[filter_param + \": Probability\"]), np.max(\n",
    "        final_output_df_pd[filter_param + \": Probability\"]\n",
    "    )\n",
    "\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.title(filter_param)\n",
    "    plt.hist(\n",
    "        final_output_df_pd[\n",
    "            final_output_df_pd[filter_param + \": Probability\"] < prob_threshold\n",
    "        ][filter_param + \": Probability\"].tolist(),\n",
    "        bins=50,\n",
    "        range=(min_v, max_v),\n",
    "    )\n",
    "    plt.hist(\n",
    "        final_output_df_pd[\n",
    "            final_output_df_pd[filter_param + \": Probability\"] >= prob_threshold\n",
    "        ][filter_param + \": Probability\"].tolist(),\n",
    "        bins=50,\n",
    "        range=(min_v, max_v),\n",
    "    )\n",
    "plt.show()\n",
    "\n",
    "compiled_query = \" and \".join(query_list)\n",
    "final_output_df_pd_filtered = final_output_df_pd.query(compiled_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_output_df_pd_filtered) / len(final_output_df_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert properties to z-scores\n",
    "\n",
    "1) Apply Yeo-Johnson transform to all properties to stabalize ranges and make distributions more gaussian\n",
    "2) Convert transformed values to z-scores using the following formula:\n",
    "\n",
    "$$ z = 1.35 \\times \\frac{median_{t\\in \\tau}(F_{i,t})}{iqr_{t\\in \\tau}(F_{i,t})}\\Bigg(\\frac{mean_{t\\in T}(F_{i,k,t})}{median_{t\\in \\tau}(F_{i,k,t})} - 1\\Bigg) $$\n",
    "\n",
    "where $F_{i,k,t}$ are the yeo-johnson transformed features values for feature i, trench k at time t. $\\tau$ are the initial pre-induction timepoints while $T$ are the timepoints from the whole timeseries. \n",
    "\n",
    "Essentially this is a z-score using the more outlier robust median and interquartile range to define the differences from normal bahavior. The 1.35 factor scales the values such that z-scores represent number of standard deviations from the mean for a normal distribution. Finally the values are normalized by initial behaviors trenchwise by the $median_{t\\in \\tau}(F_{i,k,t})$ factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_transform = [\n",
    "    \"Lb list\",\n",
    "    \"Ld list\",\n",
    "    \"Mean Area Increment list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    \"Mean Width list\",\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Delta t list\",\n",
    "]\n",
    "yeo_subsample = 0.1\n",
    "\n",
    "final_output_df_pd_filtered_dask = dd.from_pandas(\n",
    "    final_output_df_pd_filtered, npartitions=100\n",
    ").persist()\n",
    "dask.distributed.wait(final_output_df_pd_filtered_dask)\n",
    "\n",
    "for i, param in enumerate(params_to_transform):\n",
    "    all_param_values = [\n",
    "        float(val)\n",
    "        for item in final_output_df_pd_filtered_dask[param]\n",
    "        .sample(frac=yeo_subsample)\n",
    "        .compute()\n",
    "        .tolist()\n",
    "        for val in item\n",
    "    ]\n",
    "    l_norm = sp.stats.yeojohnson_normmax(all_param_values)\n",
    "    final_output_df_pd_filtered_dask[param + \": Yeo-Johnson\"] = (\n",
    "        final_output_df_pd_filtered_dask[param]\n",
    "        .apply(\n",
    "            lambda x: sp.stats.yeojohnson(np.array(x).astype(float), lmbda=l_norm),\n",
    "            meta=\"object\",\n",
    "        )\n",
    "        .persist()\n",
    "    )\n",
    "final_output_df_pd_filtered = final_output_df_pd_filtered_dask.compute()\n",
    "\n",
    "scoredf = get_all_avg_feature_scores(\n",
    "    final_output_df_pd_filtered,\n",
    "    [param + \": Yeo-Johnson\" for param in params_to_transform],\n",
    ")\n",
    "sgrnadf = get_sgrnadf_from_scoredf(\n",
    "    scoredf, [param + \": Yeo-Johnson\" for param in params_to_transform]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sgRNA Effect Size Filtering (within Gene groups)\n",
    "\n",
    "1) Threshold sgRNAs to include by number of observations\n",
    "2) Vectorize feature z scores and apply a euclidean norm to measure effect size (this can also be done with a manhattan norm)\n",
    "3) Thrshold sgRNAs for strong effects by applying a threshold to the euclidean norm that will be displayed with histogram\n",
    "4) Display a histogram for the sgRNA number per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_thr = 4\n",
    "strong_effect_threshold = 1.75\n",
    "\n",
    "sgrnadf_wellsampled = sgrnadf[sgrnadf[\"N Observations\"] >= sampling_thr]\n",
    "\n",
    "feature_vector_series = sgrnadf_wellsampled.apply(\n",
    "    lambda x: x[sgrnadf_wellsampled.columns[1:8]].values, axis=1\n",
    ")\n",
    "sgrnadf_wellsampled[\"Feature Vector\"] = feature_vector_series\n",
    "zero_vector = np.zeros((1, feature_vector_series.iloc[0].shape[0]))\n",
    "sgrnadf_wellsampled[\"Euclidean Norm\"] = euclidean_distances(\n",
    "    np.array(feature_vector_series.tolist()), zero_vector\n",
    ")[:, 0]\n",
    "\n",
    "\n",
    "sgrnadf_strong_effect = sgrnadf_wellsampled[\n",
    "    sgrnadf_wellsampled[\"Euclidean Norm\"] >= strong_effect_threshold\n",
    "]\n",
    "min_v, max_v = np.min(sgrnadf_wellsampled[\"Euclidean Norm\"]), np.max(\n",
    "    sgrnadf_wellsampled[\"Euclidean Norm\"]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Euclidean Norm\")\n",
    "plt.hist(\n",
    "    sgrnadf_wellsampled[\n",
    "        sgrnadf_wellsampled[\"Euclidean Norm\"] < strong_effect_threshold\n",
    "    ][\"Euclidean Norm\"].tolist(),\n",
    "    bins=50,\n",
    "    range=(min_v, max_v),\n",
    ")\n",
    "plt.hist(\n",
    "    sgrnadf_wellsampled[\n",
    "        sgrnadf_wellsampled[\"Euclidean Norm\"] >= strong_effect_threshold\n",
    "    ][\"Euclidean Norm\"].tolist(),\n",
    "    bins=50,\n",
    "    range=(min_v, max_v),\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "unique_genes, gene_counts = np.unique(sgrnadf_strong_effect[\"Gene\"], return_counts=True)\n",
    "plt.title(\"sgRNAs per Gene\")\n",
    "plt.xticks(range(0, 20, 2), labels=range(0, 20, 2))\n",
    "plt.hist(gene_counts, bins=np.arange(20) - 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick Representative Effect per TargetID\n",
    "~~1) For each target, pick the sgRNA that is most representative of the set by cosine distance (i.e. minimizes the sum of the distances to the sgRNAs in the group)~~\n",
    "1) For each target, pick the sgRNA that has the strongest phenotype (highest euclidean norm)\n",
    "2) Additionally identify any targets with titration information by saving a dataframe with targetIDs that posess at least N sgRNAs\n",
    "    - this is in a preliminary form; transfer to a full notebook later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgrnadf_strong_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "most_rep_example_series = (\n",
    "    sgrnadf_strong_effect.reset_index(drop=False)\n",
    "    .groupby(\"TargetID\")\n",
    "    .apply(lambda x: x.iloc[np.argmax(x[\"Euclidean Norm\"])])\n",
    "    .reset_index(drop=True)\n",
    "    .set_index(\"sgRNA\", drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_rep_example_series = sgrnadf_strong_effect.reset_index(drop=False).groupby(\"TargetID\").apply(lambda x:  \\\n",
    "# x.iloc[np.argmin(np.sum(cosine_distances(np.array(x[\"Feature Vector\"].tolist())),axis=0))]).reset_index(drop=True).set_index(\"sgRNA\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_stat_correlations(df, stat_list):\n",
    "    stat_correlations = []\n",
    "    for stat in stat_list:\n",
    "        mismatch_series = df[\"N Mismatch\"]\n",
    "        stat_series = df[stat]\n",
    "        pearson_r = sp.stats.pearsonr(mismatch_series, stat_series)[0]\n",
    "        stat_correlations.append(pearson_r)\n",
    "    return stat_correlations\n",
    "\n",
    "\n",
    "def get_genes_with_titration(df, stat_list, N_sgRNAs_thr, correlation_magnitude):\n",
    "    n_sgRNA_per_TargetID = (\n",
    "        df.reset_index(drop=False).groupby(\"TargetID\").apply(lambda x: len(x))\n",
    "    )\n",
    "    well_sampled_TargetID_mask = n_sgRNA_per_TargetID >= N_sgRNAs_thr\n",
    "    well_sampled_TargetID_list = n_sgRNA_per_TargetID[\n",
    "        well_sampled_TargetID_mask\n",
    "    ].index.tolist()\n",
    "    sgrnadf_titrations_df = df[df[\"TargetID\"].isin(well_sampled_TargetID_list)]\n",
    "\n",
    "    pearson_r_series = (\n",
    "        sgrnadf_titrations_df.reset_index(drop=False)\n",
    "        .groupby(\"TargetID\")\n",
    "        .apply(lambda x: get_all_stat_correlations(x, stat_list))\n",
    "    )\n",
    "    max_abs_pearson_r_series = pearson_r_series.apply(\n",
    "        lambda x: np.max(abs(np.array(x)))\n",
    "    )\n",
    "    titrations_strong_correlation = pearson_r_series[\n",
    "        max_abs_pearson_r_series > correlation_magnitude\n",
    "    ].index.tolist()\n",
    "    strong_titration_df = sgrnadf_titrations_df[\n",
    "        sgrnadf_titrations_df[\"TargetID\"].isin(titrations_strong_correlation)\n",
    "    ]\n",
    "    return strong_titration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sgRNAs_thr = 4\n",
    "correlation_magnitude = 0.9\n",
    "\n",
    "strong_titration_df = get_genes_with_titration(\n",
    "    sgrnadf_strong_effect,\n",
    "    [\"Mean Width list: Yeo-Johnson: score median\"],\n",
    "    N_sgRNAs_thr,\n",
    "    correlation_magnitude,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect Distance Metrics\n",
    "\n",
    "Now, I want to evaluate the performance of different distance metrics on the data wrt seperating it maximally while also preserving similarity within replicates\n",
    "\n",
    "- manhattan distance\n",
    "- cosine similarity (same as pearson for z-scores)\n",
    "- euclidean distance\n",
    "\n",
    "In the end cosine similarity was chosen as it produced superior silhouette scores for sets of targets from genes with different phenotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrnadf_examples_for_distance_metric = most_rep_example_series[\n",
    "    most_rep_example_series[\"Gene\"].isin([\"ftsN\", \"rplA\", \"mreB\", \"tufB\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_silhouette = silhouette_score(\n",
    "    np.array(sgrnadf_examples_for_distance_metric[\"Feature Vector\"].tolist()),\n",
    "    sgrnadf_examples_for_distance_metric[\"Gene\"].tolist(),\n",
    "    metric=\"euclidean\",\n",
    ")\n",
    "\n",
    "print(\"euclidean_silhouette : \" + str(euclidean_silhouette))\n",
    "\n",
    "manhattan_silhouette = silhouette_score(\n",
    "    np.array(sgrnadf_examples_for_distance_metric[\"Feature Vector\"].tolist()),\n",
    "    sgrnadf_examples_for_distance_metric[\"Gene\"].tolist(),\n",
    "    metric=\"manhattan\",\n",
    ")\n",
    "\n",
    "print(\"manhattan_silhouette : \" + str(manhattan_silhouette))\n",
    "\n",
    "cosine_silhouette = silhouette_score(\n",
    "    np.array(sgrnadf_examples_for_distance_metric[\"Feature Vector\"].tolist()),\n",
    "    sgrnadf_examples_for_distance_metric[\"Gene\"].tolist(),\n",
    "    metric=\"cosine\",\n",
    ")\n",
    "\n",
    "print(\"cosine_silhouette : \" + str(cosine_silhouette))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting different effects against single genes\n",
    "\n",
    "1) Plot a histogram of minimum cosine similarity within groups of TargetIDs against the same genes (for genes with more than one targetID)\n",
    "2) Use affinity propagation to select the number of phenotype clusters to use per gene (preference set to 0.6 based on toy examples)\n",
    "3) Among each cluster, represent the final effect as the strongest effect (euc norm) of the members of the cluster\n",
    "\n",
    "~~3) Among each cluster, represent the final effect as the median of the members of the cluster~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_right_vals(a):\n",
    "    upper_tri = np.triu(a, k=1)\n",
    "    upper_tri[upper_tri == 0.0] = np.NaN\n",
    "    return upper_tri\n",
    "\n",
    "\n",
    "def get_sgRNA_clusters(df, preference=0.6):\n",
    "    gene_indexed_df = (\n",
    "        df.reset_index(drop=False)\n",
    "        .set_index(\"Gene\")[[\"sgRNA\", \"Feature Vector\", \"TargetID\"]]\n",
    "        .sort_index()\n",
    "    )\n",
    "    gene_indexed_df[\"sgRNA Cluster\"] = pd.Series(\n",
    "        np.zeros(len(gene_indexed_df), dtype=int), dtype=int\n",
    "    )\n",
    "    gene_df_list = []\n",
    "    for gene in gene_indexed_df.index.tolist():\n",
    "        gene_df = gene_indexed_df.loc[[gene]]\n",
    "        if len(gene_df) > 1:\n",
    "            gene_feature_vector = gene_df[\"Feature Vector\"]\n",
    "            X = np.array(gene_feature_vector.tolist()).astype(float)\n",
    "            X_sim = 1.0 - cosine_distances(X)\n",
    "            af_labels = (\n",
    "                AffinityPropagation(\n",
    "                    affinity=\"precomputed\", preference=0.6, random_state=42\n",
    "                )\n",
    "                .fit_predict(X_sim)\n",
    "                .astype(int)\n",
    "            )\n",
    "            gene_indexed_df.loc[gene, \"sgRNA Cluster\"] = af_labels\n",
    "        else:\n",
    "            gene_indexed_df.loc[gene, \"sgRNA Cluster\"] = 0\n",
    "    gene_indexed_df[\"sgRNA Cluster\"] = gene_indexed_df[\"sgRNA Cluster\"].astype(int)\n",
    "    return gene_indexed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "most_rep_example_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_sgrna_replicate_thr = 2\n",
    "\n",
    "gene_list, counts_list = np.unique(most_rep_example_series[\"Gene\"], return_counts=True)\n",
    "genes_with_many_replicate_sgRNAs = gene_list[counts_list >= n_sgrna_replicate_thr]\n",
    "sgrnadf_many_copies_per_gene = most_rep_example_series[\n",
    "    most_rep_example_series[\"Gene\"].isin(genes_with_many_replicate_sgRNAs)\n",
    "]\n",
    "\n",
    "min_similarity_within_gene = sgrnadf_many_copies_per_gene.groupby(\"Gene\").apply(\n",
    "    lambda x: np.nanmin(\n",
    "        get_upper_right_vals(\n",
    "            1.0 - cosine_distances(np.array(x[\"Feature Vector\"].tolist()))\n",
    "        )\n",
    "    )\n",
    ")\n",
    "plt.title(\"Minimum Cosine Similarity per Gene\")\n",
    "plt.hist(min_similarity_within_gene, bins=50)\n",
    "plt.show()\n",
    "\n",
    "gene_df = get_sgRNA_clusters(most_rep_example_series)\n",
    "most_rep_example_series[\"sgRNA Cluster\"] = gene_df.set_index(\"sgRNA\")[\"sgRNA Cluster\"]\n",
    "most_rep_example_series[\"sgRNA Cluster Label\"] = most_rep_example_series.apply(\n",
    "    lambda x: str(x[\"Gene\"]) + \"-\" + str(x[\"sgRNA Cluster\"]), axis=1\n",
    ")\n",
    "gene_cluster_df = most_rep_example_series[\n",
    "    [\"sgRNA Cluster Label\", \"Feature Vector\", \"Gene\", \"Euclidean Norm\"]\n",
    "    + [param + \": Yeo-Johnson: score median\" for param in params_to_transform]\n",
    "].reset_index(drop=True)\n",
    "gene_cluster_groupby = gene_cluster_df.groupby(\"sgRNA Cluster Label\")\n",
    "# median_feature_series = gene_cluster_groupby.apply(lambda x: np.median(np.stack(x[\"Feature Vector\"]).astype(float), axis=0)).to_frame().rename(columns={0:\"Feature Vector\"})\n",
    "feature_series = (\n",
    "    gene_cluster_groupby.apply(\n",
    "        lambda x: x.iloc[np.argmax(x[\"Euclidean Norm\"])][\"Feature Vector\"]\n",
    "    )\n",
    "    .to_frame()\n",
    "    .rename(columns={0: \"Feature Vector\"})\n",
    ")\n",
    "\n",
    "gene_cluster_df = gene_cluster_groupby.apply(\n",
    "    lambda x: x.iloc[0][\n",
    "        [\"Gene\"]\n",
    "        + [param + \": Yeo-Johnson: score median\" for param in params_to_transform]\n",
    "    ]\n",
    ")\n",
    "gene_cluster_df = gene_cluster_df.join(feature_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering: TSNE and Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(gene_cluster_df[\"Feature Vector\"].tolist())\n",
    "X_sim = 1.0 - cosine_distances(X)\n",
    "\n",
    "X_embedded = TSNE(\n",
    "    n_components=2, init=\"pca\", perplexity=5.0, early_exaggeration=50.0, metric=\"cosine\"\n",
    ").fit_transform(X)\n",
    "gene_cluster_df[\"TSNE Coords\"] = [X_embedded[i] for i in range(X_embedded.shape[0])]\n",
    "\n",
    "af_labels = (\n",
    "    AffinityPropagation(affinity=\"precomputed\", preference=0.0)\n",
    "    .fit_predict(X_sim)\n",
    "    .astype(int)\n",
    ")\n",
    "gene_cluster_df[\"Affinity Clusts\"] = af_labels\n",
    "\n",
    "plt.scatter(\n",
    "    X_embedded[:, 0],\n",
    "    X_embedded[:, 1],\n",
    "    s=3,\n",
    "    alpha=1,\n",
    "    c=gene_cluster_df[\"Affinity Clusts\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_cluster_df = pd.read_csv(\n",
    "    \"2021-07-31_for_ethan/2021-07-31_Steady_State_Analysis.csv\"\n",
    ")\n",
    "gene_cluster_df[\"Feature Vector\"] = gene_cluster_df[\"Feature Vector\"].apply(\n",
    "    lambda x: np.array(ast.literal_eval(x.replace(\"\\n\", \"\").replace(\" \", \",\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_labels = [\n",
    "    \"Birth Length\",\n",
    "    \"Division Length\",\n",
    "    \"Area Growth Rate\",\n",
    "    \"Length Growth Rate\",\n",
    "    \"Average Width\",\n",
    "    \"mCherry Intensity\",\n",
    "    \"Cell Cycle Duration\",\n",
    "]\n",
    "\n",
    "hierarchical_labels = gene_cluster_df.index.tolist()\n",
    "\n",
    "\n",
    "def get_leaf_children(tree, leaf_id):\n",
    "    cluster_node = tree[leaf_id]\n",
    "    leaf_children = cluster_node.pre_order(lambda x: x.id)\n",
    "    return leaf_children\n",
    "\n",
    "\n",
    "def assign_dendro_clusts(df, children_labels):\n",
    "    df_out = copy.deepcopy(df)\n",
    "    df_out[\"Dendrogram Clusters\"] = pd.Series(len(df), dtype=int)\n",
    "    for clust_i, indices in enumerate(children_labels):\n",
    "        df_out[\"Dendrogram Clusters\"].iloc[indices] = clust_i\n",
    "    df_out[\"Dendrogram Clusters\"] = df_out[\"Dendrogram Clusters\"].astype(int)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "suppress_thr = 15\n",
    "min_zscore = -2\n",
    "max_zscore = 2\n",
    "\n",
    "\n",
    "def compute_and_plot_dendrogram(\n",
    "    df, feature_labels, suppress_thr, min_zscore, max_zscore, cmap=mpl.cm.coolwarm\n",
    "):\n",
    "\n",
    "    norm = mpl.colors.Normalize(vmin=min_zscore, vmax=max_zscore)\n",
    "\n",
    "    hierarchical_labels = df.index.tolist()\n",
    "    X = np.array(df[\"Feature Vector\"].tolist())\n",
    "\n",
    "    # Compute and plot dendrogram.\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(20, 10))\n",
    "    gs = fig.add_gridspec(2, suppress_thr)\n",
    "    dendro_ax = fig.add_subplot(gs[0, :])\n",
    "\n",
    "    Y = sch.linkage(X, method=\"weighted\", metric=\"cosine\", optimal_ordering=True)\n",
    "    cluster_tree = sch.to_tree(Y, rd=True)[1]\n",
    "\n",
    "    Z = sch.dendrogram(\n",
    "        Y,\n",
    "        orientation=\"top\",\n",
    "        show_leaf_counts=True,\n",
    "        leaf_rotation=90.0,\n",
    "        leaf_font_size=12.0,\n",
    "        truncate_mode=\"lastp\",\n",
    "        show_contracted=True,\n",
    "        p=suppress_thr,\n",
    "        ax=dendro_ax,\n",
    "        no_labels=True,\n",
    "    )\n",
    "    children_labels = [get_leaf_children(cluster_tree, leaf) for leaf in Z[\"leaves\"]]\n",
    "\n",
    "    fig.colorbar(\n",
    "        mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "        ax=dendro_ax,\n",
    "        orientation=\"vertical\",\n",
    "        label=\"Z-score\",\n",
    "        use_gridspec=True,\n",
    "        location=\"left\",\n",
    "        pad=-0.05,\n",
    "        aspect=10,\n",
    "    )\n",
    "\n",
    "    for i, children in enumerate(children_labels):\n",
    "        children_arr = np.array(\n",
    "            df.iloc[children][\"Feature Vector\"].tolist(), dtype=float\n",
    "        )\n",
    "        mean_vector = np.mean(children_arr, axis=0).reshape(-1, 1)\n",
    "\n",
    "        #     imshow_ax = fig.add_subplot(gs[1, i])\n",
    "        #     imshow_ax.imshow(mean_vector,cmap=cmap,norm=norm)\n",
    "        if i == 0:\n",
    "            imshow_first_ax = fig.add_subplot(gs[1, i])\n",
    "            imshow_first_ax.imshow(mean_vector, cmap=cmap, norm=norm)\n",
    "\n",
    "            imshow_first_ax.tick_params(\n",
    "                axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False\n",
    "            )\n",
    "            imshow_first_ax.tick_params(\n",
    "                axis=\"y\", which=\"both\", left=False, right=False, labelbottom=False\n",
    "            )\n",
    "            imshow_first_ax.set_xlabel(str(i), fontsize=18)\n",
    "\n",
    "            imshow_first_ax.set_yticks(range(len(feature_labels)))\n",
    "            imshow_first_ax.set_yticklabels(\n",
    "                feature_labels,\n",
    "                fontsize=18,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            imshow_ax = fig.add_subplot(gs[1, i], sharey=imshow_first_ax)\n",
    "            imshow_ax.imshow(mean_vector, cmap=cmap, norm=norm)\n",
    "            plt.setp(imshow_ax.get_yticklabels(), visible=False)\n",
    "\n",
    "            imshow_ax.tick_params(\n",
    "                axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False\n",
    "            )\n",
    "            imshow_ax.tick_params(\n",
    "                axis=\"y\", which=\"both\", left=False, right=False, labelbottom=False\n",
    "            )\n",
    "            imshow_ax.set_xlabel(str(i), fontsize=18)\n",
    "\n",
    "    return children_labels\n",
    "\n",
    "\n",
    "def plot_subset(\n",
    "    df_subset,\n",
    "    min_zscore=min_zscore,\n",
    "    max_zscore=max_zscore,\n",
    "    feature_labels=feature_labels,\n",
    "    figsize=(10, 10),\n",
    "    wspace=1.5,\n",
    "):\n",
    "\n",
    "    df_clusts = (\n",
    "        df_subset.sort_index()\n",
    "        .reset_index(drop=False)\n",
    "        .set_index(\"Dendrogram Clusters\")[[\"sgRNA Cluster Label\", \"Feature Vector\"]]\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    cmap = mpl.cm.coolwarm\n",
    "    norm = mpl.colors.Normalize(vmin=min_zscore, vmax=max_zscore)\n",
    "\n",
    "    # Compute and plot dendrogram.\n",
    "    fig = plt.figure(constrained_layout=True, figsize=figsize)\n",
    "    gs = fig.add_gridspec(1, len(df_clusts), wspace=wspace)\n",
    "\n",
    "    for i in range(len(df_clusts)):\n",
    "\n",
    "        if i == 0:\n",
    "            imshow_first_ax = fig.add_subplot(gs[0, i])\n",
    "            imshow_first_ax.imshow(\n",
    "                df_clusts[\"Feature Vector\"].iloc[i].astype(float).reshape(-1, 1),\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "            )\n",
    "\n",
    "            imshow_first_ax.tick_params(\n",
    "                axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False\n",
    "            )\n",
    "            imshow_first_ax.tick_params(\n",
    "                axis=\"y\", which=\"both\", left=False, right=False, labelbottom=False\n",
    "            )\n",
    "            imshow_first_ax.set_xlabel(\n",
    "                df_clusts[\"sgRNA Cluster Label\"].iloc[i]\n",
    "                + \"\\n Cluster \"\n",
    "                + str(df_clusts.index[i]),\n",
    "                fontsize=14,\n",
    "            )\n",
    "\n",
    "            imshow_first_ax.set_yticks(range(len(feature_labels)))\n",
    "            imshow_first_ax.set_yticklabels(\n",
    "                feature_labels,\n",
    "                fontsize=18,\n",
    "            )\n",
    "        else:\n",
    "            imshow_ax = fig.add_subplot(gs[0, i], sharey=imshow_first_ax)\n",
    "            imshow_ax.imshow(\n",
    "                df_clusts[\"Feature Vector\"].iloc[i].astype(float).reshape(-1, 1),\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "            )\n",
    "\n",
    "            plt.setp(imshow_ax.get_yticklabels(), visible=False)\n",
    "\n",
    "            imshow_ax.tick_params(\n",
    "                axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False\n",
    "            )\n",
    "            imshow_ax.tick_params(\n",
    "                axis=\"y\", which=\"both\", left=False, right=False, labelbottom=False\n",
    "            )\n",
    "            imshow_ax.set_xlabel(\n",
    "                df_clusts[\"sgRNA Cluster Label\"].iloc[i]\n",
    "                + \"\\n Cluster \"\n",
    "                + str(df_clusts.index[i]),\n",
    "                fontsize=14,\n",
    "            )\n",
    "\n",
    "\n",
    "def make_subset_dendrogram(\n",
    "    sub_df,\n",
    "    title,\n",
    "    feature_labels=feature_labels,\n",
    "    min_zscore=min_zscore,\n",
    "    max_zscore=max_zscore,\n",
    "    figsize=(10, 10),\n",
    "    fontsize=18,\n",
    "):\n",
    "    X = np.array(sub_df[\"Feature Vector\"].tolist())\n",
    "\n",
    "    # Compute and plot dendrogram.\n",
    "    fig = plt.figure(constrained_layout=True, figsize=figsize)\n",
    "    gs = fig.add_gridspec(2, len(sub_df))\n",
    "    dendro_ax = fig.add_subplot(gs[0, :])\n",
    "\n",
    "    Y = sch.linkage(X, method=\"weighted\", metric=\"cosine\", optimal_ordering=True)\n",
    "    cluster_tree = sch.to_tree(Y, rd=True)[1]\n",
    "\n",
    "    Z = sch.dendrogram(\n",
    "        Y,\n",
    "        orientation=\"top\",\n",
    "        show_leaf_counts=True,\n",
    "        leaf_rotation=90.0,\n",
    "        leaf_font_size=12.0,\n",
    "        show_contracted=True,\n",
    "        ax=dendro_ax,\n",
    "        no_labels=True,\n",
    "    )\n",
    "\n",
    "    cmap = mpl.cm.coolwarm\n",
    "    norm = mpl.colors.Normalize(vmin=min_zscore, vmax=max_zscore)\n",
    "\n",
    "    fig.colorbar(\n",
    "        mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "        ax=dendro_ax,\n",
    "        orientation=\"vertical\",\n",
    "        label=\"Z-score\",\n",
    "        use_gridspec=True,\n",
    "        location=\"left\",\n",
    "        pad=-0.0,\n",
    "        aspect=10,\n",
    "    )\n",
    "\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "\n",
    "    for i, leaf in enumerate(Z[\"leaves\"]):\n",
    "        leaf_arr = np.array(\n",
    "            sub_df.iloc[leaf][\"Feature Vector\"].tolist(), dtype=float\n",
    "        ).reshape(-1, 1)\n",
    "        #         imshow_ax = fig.add_subplot(gs[1, i])\n",
    "        #         imshow_ax.imshow(leaf_arr,cmap=cmap,norm=norm)\n",
    "        if i == 0:\n",
    "            imshow_first_ax = fig.add_subplot(gs[1, i])\n",
    "            imshow_first_ax.imshow(leaf_arr, cmap=cmap, norm=norm)\n",
    "\n",
    "            imshow_first_ax.tick_params(\n",
    "                axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False\n",
    "            )\n",
    "            imshow_first_ax.tick_params(\n",
    "                axis=\"y\", which=\"both\", left=False, right=False, labelbottom=False\n",
    "            )\n",
    "            imshow_first_ax.set_xlabel(\n",
    "                sub_df.index[leaf], fontsize=fontsize, rotation=90\n",
    "            )\n",
    "\n",
    "            imshow_first_ax.set_yticks(range(len(feature_labels)))\n",
    "            imshow_first_ax.set_yticklabels(\n",
    "                feature_labels,\n",
    "                fontsize=fontsize,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            imshow_ax = fig.add_subplot(gs[1, i], sharey=imshow_first_ax)\n",
    "            imshow_ax.imshow(leaf_arr, cmap=cmap, norm=norm)\n",
    "            plt.setp(imshow_ax.get_yticklabels(), visible=False)\n",
    "\n",
    "            imshow_ax.tick_params(\n",
    "                axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False\n",
    "            )\n",
    "            imshow_ax.tick_params(\n",
    "                axis=\"y\", which=\"both\", left=False, right=False, labelbottom=False\n",
    "            )\n",
    "            imshow_ax.set_xlabel(sub_df.index[leaf], fontsize=fontsize, rotation=90)\n",
    "\n",
    "\n",
    "#         imshow_ax.tick_params(axis='x',which='both',bottom=False,top=False,labelbottom=False)\n",
    "#         imshow_ax.tick_params(axis='y',which='both',left=False,right=False,labelbottom=False)\n",
    "\n",
    "#         imshow_ax.set_xlabel(sub_df.index[leaf], fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children_labels = compute_and_plot_dendrogram(\n",
    "    gene_cluster_df,\n",
    "    feature_labels,\n",
    "    suppress_thr,\n",
    "    min_zscore,\n",
    "    max_zscore,\n",
    "    cmap=mpl.cm.coolwarm,\n",
    ")\n",
    "plt.savefig(\"./Dendrograms/Global_Dendrogram.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gene_cluster_df = assign_dendro_clusts(gene_cluster_df, children_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    X_embedded[:, 0],\n",
    "    X_embedded[:, 1],\n",
    "    s=3,\n",
    "    alpha=1,\n",
    "    c=gene_cluster_df[\"Affinity Clusts\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Major System Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"fts\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(fts_subset)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"./Gene_Groups/fts.png\",dpi=200,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpl_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"rpl\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(rpl_subset, figsize=(30, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/rpl.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"rpm\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(rpm_subset, figsize=(30, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/rpm.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"rps\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(rps_subset, figsize=(30, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/rps.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_subset = gene_cluster_df[gene_cluster_df.apply(lambda x: \"rr\" in x[\"Gene\"], axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(rr_subset, figsize=(30, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"tff\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(tff_subset, figsize=(30, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/tff.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpo_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"rpo\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(rpo_subset, figsize=(10, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/rpo.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"min\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(min_subset, figsize=(6, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/min.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"dna\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(dna_subset, figsize=(6, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/dna.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fol_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"fol\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(fol_subset, figsize=(6, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/fol.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muk_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"muk\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(muk_subset, figsize=(6, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/muk.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mre_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"mre\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(mre_subset, figsize=(6, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/mre.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mur_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"mur\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(mur_subset, figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/mur.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nus_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"nus\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(nus_subset, figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/nus.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"sec\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(sec_subset, figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/sec.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"bam\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(bam_subset, figsize=(6, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/bam.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hol_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"hol\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(hol_subset, figsize=(6, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/hol.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hda_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"hda\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(hda_subset, figsize=(6, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/hda.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodZ_subset = gene_cluster_df[\n",
    "    gene_cluster_df.apply(lambda x: \"rodZ\" in x[\"Gene\"], axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_subset(rodZ_subset, figsize=(6, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Gene_Groups/rodz.png\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, cluster_counts = np.unique(\n",
    "    gene_cluster_df[\"Dendrogram Clusters\"], return_counts=True\n",
    ")\n",
    "singleton_clusters = clusters[cluster_counts == 1]\n",
    "small_clusters = clusters[cluster_counts <= 40]\n",
    "big_clusters = clusters[cluster_counts > 40]\n",
    "print(singleton_clusters)\n",
    "print(small_clusters)\n",
    "print(big_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_6to8 = gene_cluster_df[gene_cluster_df[\"Dendrogram Clusters\"].isin([6, 7, 8])]\n",
    "cluster_9to10 = gene_cluster_df[gene_cluster_df[\"Dendrogram Clusters\"].isin([9, 10])]\n",
    "cluster_1 = gene_cluster_df[gene_cluster_df[\"Dendrogram Clusters\"].isin([1])]\n",
    "cluster_13 = gene_cluster_df[gene_cluster_df[\"Dendrogram Clusters\"].isin([13])]\n",
    "cluster_14 = gene_cluster_df[gene_cluster_df[\"Dendrogram Clusters\"].isin([14])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_small_clusters = list(set(small_clusters) - set([6, 7, 8, 9, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_small_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in remaining_small_clusters:\n",
    "    cluster_df = gene_cluster_df[gene_cluster_df[\"Dendrogram Clusters\"].isin([i])]\n",
    "    make_subset_dendrogram(\n",
    "        cluster_df,\n",
    "        \"Cluster \" + str(i) + \" Dendrogram\",\n",
    "        figsize=(int(len(cluster_df) * 1.75), 12),\n",
    "        fontsize=16 + int(len(cluster_df) * 0.75),\n",
    "    )\n",
    "    plt.savefig(\"./Dendrograms/Cluster_\" + str(i) + \".png\", dpi=200)\n",
    "\n",
    "make_subset_dendrogram(\n",
    "    cluster_6to8,\n",
    "    \"Cluster 6 to 8 Dendrogram\",\n",
    "    figsize=(int(len(cluster_6to8) * 1.75), 10),\n",
    "    fontsize=16 + int(len(cluster_6to8) * 0.75),\n",
    ")\n",
    "plt.savefig(\"./Dendrograms/Cluster_6to8.png\", dpi=200)\n",
    "\n",
    "make_subset_dendrogram(\n",
    "    cluster_9to10,\n",
    "    \"Cluster 9 to 10 Dendrogram\",\n",
    "    figsize=(int(len(cluster_9to10) * 1.75), 10),\n",
    "    fontsize=16 + int(len(cluster_9to10) * 0.75),\n",
    ")\n",
    "plt.savefig(\"./Dendrograms/Cluster_9to10.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_subset_dendrogram(\n",
    "    cluster_1,\n",
    "    \"Cluster 1 Dendrogram\",\n",
    "    figsize=(int(len(cluster_1) * 1.75), 30),\n",
    "    fontsize=16 + int(len(cluster_1) * 0.75),\n",
    ")\n",
    "plt.savefig(\"./Dendrograms/Cluster_1.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_subset_dendrogram(\n",
    "    cluster_13,\n",
    "    \"Cluster 13 Dendrogram\",\n",
    "    figsize=(int(len(cluster_13) * 1.75), 30),\n",
    "    fontsize=16 + int(len(cluster_13) * 0.75),\n",
    ")\n",
    "plt.savefig(\"./Dendrograms/Cluster_13.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_subset_dendrogram(\n",
    "    cluster_14,\n",
    "    \"Cluster 14 Dendrogram\",\n",
    "    figsize=(int(len(cluster_14) * 1.75), 30),\n",
    "    fontsize=16 + int(len(cluster_14) * 0.75),\n",
    ")\n",
    "plt.savefig(\"./Dendrograms/Cluster_14.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_cluster_df.to_csv(\"2021-07-31_Steady_State_Analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Cluster Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_transform = [\n",
    "    \"Lb list\",\n",
    "    \"Ld list\",\n",
    "    \"delL list\",\n",
    "    \"Mean Area Increment list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    \"Mean Width list\",\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Delta t list\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_sgrnadf_from_df(df, feature_labels, time_label=\"final cell timepoints list\"):\n",
    "    df_groupby = df.groupby(\"sgRNA\")\n",
    "    sgrnadf = (\n",
    "        df_groupby.apply(lambda x: x[\"phenotype trenchid\"].tolist())\n",
    "        .to_frame()\n",
    "        .rename(columns={0: \"phenotype trenchid\"})\n",
    "    )\n",
    "\n",
    "    for feature_label in feature_labels:\n",
    "        sgrnadf[feature_label] = df_groupby.apply(\n",
    "            lambda x: np.array(\n",
    "                [val for item in x[feature_label].tolist() for val in item]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    sgrnadf[time_label] = df_groupby.apply(\n",
    "        lambda x: np.array([val for item in x[time_label].tolist() for val in item])\n",
    "    )\n",
    "    sgrnadf[\"Gene\"] = df_groupby.apply(lambda x: x[\"Gene\"].iloc[0])\n",
    "    sgrnadf[\"TargetID\"] = df_groupby.apply(lambda x: x[\"TargetID\"].iloc[0])\n",
    "    sgrnadf[\"N Mismatch\"] = df_groupby.apply(lambda x: x[\"N Mismatch\"].iloc[0])\n",
    "    sgrnadf[\"N Observations\"] = df_groupby.apply(\n",
    "        lambda x: len(x[\"phenotype trenchid\"].tolist())\n",
    "    )\n",
    "    sgrnadf[\"Category\"] = df_groupby.apply(lambda x: x[\"Category\"].iloc[0])\n",
    "\n",
    "    return sgrnadf\n",
    "\n",
    "\n",
    "def get_timepoint_values(\n",
    "    df,\n",
    "    label,\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    time_label=\"final cell timepoints list\",\n",
    "    flatten_vals=True,\n",
    "):\n",
    "    masked_label_series = df.apply(\n",
    "        lambda x: np.array(x[label])[\n",
    "            (np.array(x[time_label]) >= min_timepoint)\n",
    "            * (np.array(x[time_label]) <= max_timepoint)\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    if flatten_vals:\n",
    "        flattened_vals = [val for item in masked_label_series.tolist() for val in item]\n",
    "        return flattened_vals\n",
    "    else:\n",
    "        return masked_label_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrnadf_nontrasformed_vals = get_sgrnadf_from_df(\n",
    "    final_output_df_pd, params_to_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = sgrnadf_nontrasformed_vals[sgrnadf_nontrasformed_vals[\"Gene\"] == \"ftsN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 14\n",
    "t = selected_df[\"final cell timepoints list\"][idx]\n",
    "y = selected_df[\"delL list\"][idx]\n",
    "plt.ylim(0, 8)\n",
    "plt.scatter(t, y, s=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 14\n",
    "t = selected_df[\"final cell timepoints list\"][idx]\n",
    "y = selected_df[\"Mean Area Increment list\"][idx]\n",
    "plt.ylim(0, 1)\n",
    "plt.scatter(t, y, s=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 14\n",
    "t = selected_df[\"final cell timepoints list\"][idx]\n",
    "y = selected_df[\"Delta t list\"][idx]\n",
    "plt.ylim(0, 20)\n",
    "plt.scatter(t, y, s=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 90\n",
    "max_timepoint = 144\n",
    "for i in range(len(selected_df)):\n",
    "    Lb = get_timepoint_values(\n",
    "        selected_df[i : i + 1], \"Lb list\", min_timepoint, max_timepoint\n",
    "    )\n",
    "    delL = get_timepoint_values(\n",
    "        selected_df[i : i + 1], \"delL list\", min_timepoint, max_timepoint\n",
    "    )\n",
    "    t = get_timepoint_values(\n",
    "        selected_df[i : i + 1],\n",
    "        \"final cell timepoints list\",\n",
    "        min_timepoint,\n",
    "        max_timepoint,\n",
    "    )\n",
    "    r = sp.stats.pearsonr(Lb, delL)\n",
    "    print(r[0])\n",
    "    plt.scatter(Lb, delL, s=3, c=t)\n",
    "    plt.xlim(1, 8)\n",
    "    plt.ylim(1, 8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_output_df_pd.groupby(\"sgRNA\").apply(lambda x: x.iloc[0])\n",
    "df[\"phenotype trenchids\"] = final_output_df_pd.groupby(\"sgRNA\").apply(\n",
    "    lambda x: x[\"phenotype trenchid\"].tolist()\n",
    ")\n",
    "df = df[\n",
    "    [\n",
    "        \"Gene\",\n",
    "        \"Target Sequence\",\n",
    "        \"phenotype trenchids\",\n",
    "        \"N Mismatch\",\n",
    "        \"N Target Sites\",\n",
    "        \"Category\",\n",
    "        \"Strand\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kymo_xarr = tr.kymo_xarr(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Growth_Division\"\n",
    ")\n",
    "wrapped_kymo_xarr = tr.kymo_xarr(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Growth_Division\",\n",
    "    unwrap=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gene_table_layout,\n",
    "    select_gene,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid,\n",
    ") = tr.linked_gene_table(\n",
    "    df, trenchids_as_list=True, trenchid_column=\"phenotype trenchids\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gene_table_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_display, save_button = tr.linked_kymograph_for_gene_table(\n",
    "    kymo_xarr,\n",
    "    wrapped_kymo_xarr,\n",
    "    df,\n",
    "    select_gene,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid=select_unpacked_trenchid,\n",
    "    trenchid_column=\"phenotype trenchids\",\n",
    "    y_scale=3,\n",
    "    x_window_size=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_button  ## NEED OPTION WHETHER OR NOT TO NORM SIGNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
