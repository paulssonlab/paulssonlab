{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finds all PAMs on a strand of a sequence record\n",
    "## strand specifies the strand (1,-1) that the search is being conducted on\n",
    "## startcoord specifies the beginning coordinate of the seqrecord on the underlying reference genome\n",
    "def find_strand_pams(seqrecord, strand, startcoord=0):\n",
    "    if strand == 1:\n",
    "        seq = str(seqrecord.seq)\n",
    "    else:\n",
    "        seq = str(seqrecord.seq.reverse_complement())\n",
    "\n",
    "    pam_reg = re.compile(\"CC\")\n",
    "    pam_starts = [item.start(0) for item in re.finditer(pam_reg, str(seq))]\n",
    "\n",
    "    pam_list = []\n",
    "\n",
    "    if strand == 1:\n",
    "        for item in pam_starts:\n",
    "            if len(seq[item + 3 : item + 23]) == 20:\n",
    "                start = startcoord + item + 3\n",
    "                end = startcoord + item + 23\n",
    "                sequence = seq[item + 3 : item + 23]\n",
    "                pam_list.append([start, end, sequence, strand])\n",
    "    else:\n",
    "        for item in pam_starts:\n",
    "            if len(seq[item + 3 : item + 23]) == 20:\n",
    "                start = startcoord + len(seq) - item - 23\n",
    "                end = startcoord + len(seq) - item - 3\n",
    "                sequence = seq[item + 3 : item + 23]\n",
    "                pam_list.append([start, end, sequence, strand])\n",
    "    return pam_list\n",
    "\n",
    "\n",
    "## Finds all PAMs in target sequence record\n",
    "## startcoord specifies the beginning coordinate of the seqrecord on the underlying reference genome\n",
    "## target_strand specifies the strand (1,-1) that the seq record is on\n",
    "def find_pams(seqrecord, startcoord=0, target_strand=1):\n",
    "    fwd_pams = find_strand_pams(seqrecord, 1, startcoord=startcoord)\n",
    "    rev_pams = find_strand_pams(seqrecord, -1, startcoord=startcoord)\n",
    "    pam_df = pd.DataFrame(\n",
    "        fwd_pams + rev_pams, columns=[\"start\", \"end\", \"sequence\", \"ref_strand\"]\n",
    "    )\n",
    "    if target_strand == 1:\n",
    "        pam_df[\"target_strand\"] = 1\n",
    "    else:\n",
    "        pam_df[\"target_strand\"] = -pam_df[\"ref_strand\"]\n",
    "    pam_df = pam_df.reset_index()\n",
    "    pam_df[\"targetid\"] = pam_df[\"index\"]\n",
    "    del pam_df[\"index\"]\n",
    "    return pam_df\n",
    "\n",
    "\n",
    "## Uses a reference csv of bad seeds to eliminate bad seeds from the PAM DataFrame\n",
    "def remove_bad_seeds(pam_df, bad_seed_path):\n",
    "    bad_seed_df = pd.read_csv(bad_seed_path)\n",
    "    bad_seed_list = bad_seed_df[\"seeds\"].tolist()\n",
    "    ## reverse complement to match target sequence\n",
    "    bad_seed_list = [\n",
    "        str(Seq(item.upper()).reverse_complement()) for item in bad_seed_list\n",
    "    ]\n",
    "\n",
    "    pam_df = pam_df[pam_df[\"sequence\"].apply(lambda x: x[:5] not in bad_seed_list)]\n",
    "    return pam_df\n",
    "\n",
    "\n",
    "## Converts a string to an integer representation\n",
    "def str_to_int(string):\n",
    "    code = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "    conv_str = np.array(list(map(lambda x: code[x], string)))\n",
    "    return conv_str\n",
    "\n",
    "\n",
    "## Determines the maximum matching (minimum edit distance) of each target sequence\n",
    "## to sequences in the reference\n",
    "## subseq_range can be set to subset the sequences to a region of interest (i.e. the PAM adjacent region)\n",
    "## remove_matching_starts can be set to eliminate sequences from consideration when they are at the same location\n",
    "def compare_seqs(\n",
    "    target_df, reference_df, subseq_range=None, remove_matching_starts=True\n",
    "):\n",
    "    target_arr = target_df[\"sequence\"].values\n",
    "    reference_arr = reference_df[\"sequence\"].values\n",
    "    target_int_arr = np.array(list(map(str_to_int, target_arr)), dtype=\"uint8\")\n",
    "    reference_int_arr = np.array(list(map(str_to_int, reference_arr)), dtype=\"uint8\")\n",
    "\n",
    "    if subseq_range != None:\n",
    "        target_int_arr = target_int_arr[:, subseq_range]\n",
    "        reference_int_arr = reference_int_arr[:, subseq_range]\n",
    "\n",
    "    bool_arr = target_int_arr[:, np.newaxis, :] == reference_int_arr[np.newaxis, :, :]\n",
    "    agreement_arr = np.sum(bool_arr, axis=2, dtype=int)\n",
    "\n",
    "    if remove_matching_starts:\n",
    "        matching_starts = np.where(\n",
    "            target_df[\"start\"].values[:, np.newaxis]\n",
    "            == reference_df[\"start\"].values[np.newaxis, :]\n",
    "        )[1]\n",
    "        agreement_arr[:, matching_starts] = 0\n",
    "    most_agreement = np.max(agreement_arr, axis=1)\n",
    "    return most_agreement\n",
    "\n",
    "\n",
    "### Exhaustively generate mismatched versions of the query with num_mismatch substitutions starting from the PAM distal end\n",
    "def generate_all_mismatchs(in_str, num_mismatch):\n",
    "    flip_dict = {\n",
    "        \"A\": [\"T\", \"C\", \"G\"],\n",
    "        \"T\": [\"A\", \"C\", \"G\"],\n",
    "        \"C\": [\"T\", \"A\", \"G\"],\n",
    "        \"G\": [\"T\", \"C\", \"A\"],\n",
    "    }\n",
    "    in_str_len = len(in_str)\n",
    "    prod = list(\n",
    "        itertools.product(\n",
    "            *[flip_dict[in_str[in_str_len - i - 1]] for i in range(num_mismatch)][::-1]\n",
    "        )\n",
    "    )\n",
    "    new_strs = [in_str[: in_str_len - num_mismatch] + \"\".join(item) for item in prod]\n",
    "    return new_strs\n",
    "\n",
    "\n",
    "### Randomly (with replacement) generate mismatched versions of the query with num_mismatch substitutions\n",
    "def generate_mismatch(in_str, num_mismatch):\n",
    "    flip_dict = {\n",
    "        \"A\": [\"T\", \"C\", \"G\"],\n",
    "        \"T\": [\"A\", \"C\", \"G\"],\n",
    "        \"C\": [\"T\", \"A\", \"G\"],\n",
    "        \"G\": [\"T\", \"C\", \"A\"],\n",
    "    }\n",
    "    in_str_len = len(in_str)\n",
    "    list_str = list(in_str)\n",
    "    new_str = copy.copy(list_str)\n",
    "    for i in range(num_mismatch):\n",
    "        new_char = np.random.choice(flip_dict[list_str[in_str_len - i - 1]])\n",
    "        new_str[in_str_len - i - 1] = new_char\n",
    "    new_str = \"\".join(new_str)\n",
    "    return new_str\n",
    "\n",
    "\n",
    "### Generate a mismatch DataFrame with PAMs containing k[i] mismatches, taking n_samples for each k[i]\n",
    "### If k[i]<max_exhaustive, then this is done exhaustively\n",
    "def generate_mismatch_df(pam_df, ks=[1, 2, 4, 8, 10], n_samples=50, max_exhaustive=5):\n",
    "    mismatch_df = []\n",
    "    for i, row in pam_df.iterrows():\n",
    "        seq = row[\"sequence\"]\n",
    "        start = row[\"start\"]\n",
    "        end = row[\"end\"]\n",
    "        ref_strand = row[\"ref_strand\"]\n",
    "        target_strand = row[\"target_strand\"]\n",
    "        target_id = row[\"targetid\"]\n",
    "        mismatch_df.append(\n",
    "            [target_id, start, end, seq, ref_strand, target_strand, 0, \"Target\"]\n",
    "        )\n",
    "        for k in ks:\n",
    "            if k <= max_exhaustive:\n",
    "                mismatch_list = generate_all_mismatchs(seq, k)\n",
    "                random.shuffle(mismatch_list)\n",
    "                mismatch_list = mismatch_list[:n_samples]\n",
    "            else:\n",
    "                mismatch_list = list(\n",
    "                    set([generate_mismatch(seq, k) for i in range(n_samples)])\n",
    "                )\n",
    "            mismatch_df += [\n",
    "                [target_id, start, end, item, ref_strand, target_strand, k, \"Target\"]\n",
    "                for item in mismatch_list\n",
    "            ]\n",
    "\n",
    "    mismatch_df = pd.DataFrame(\n",
    "        mismatch_df,\n",
    "        columns=[\n",
    "            \"targetid\",\n",
    "            \"start\",\n",
    "            \"end\",\n",
    "            \"sequence\",\n",
    "            \"ref_strand\",\n",
    "            \"target_strand\",\n",
    "            \"num_mismatch\",\n",
    "            \"category\",\n",
    "        ],\n",
    "    )\n",
    "    return mismatch_df\n",
    "\n",
    "\n",
    "### Convert a target sequence to a spacer sequence\n",
    "def target_to_spacer(target_str):\n",
    "    target = Seq(target_str.upper())\n",
    "    spacer = target.reverse_complement()\n",
    "    spacer = str(spacer)\n",
    "    return spacer\n",
    "\n",
    "\n",
    "### Add bsai sites and primer sequences to the side for cloning\n",
    "def add_bsaI_sites(spacer):  ##make more general later\n",
    "    site_1 = \"AGGCACTTGCTCGTACGACGGAAGACATTAGT\"\n",
    "    site_2 = \"GTTTTCGTCTTCTTAAGGTGCCGGGCCCACAT\"\n",
    "    output_seq = site_1 + spacer + site_2\n",
    "    return output_seq\n",
    "\n",
    "\n",
    "### Convert a target sequence to a spacer with bsai sites and basic PCR primers\n",
    "def target_to_padded_spacer(target_str):\n",
    "    spacer = target_to_spacer(target_str)\n",
    "    padded_spacer = add_bsaI_sites(spacer)\n",
    "    return padded_spacer\n",
    "\n",
    "\n",
    "def check_restriction_site(in_str, rest_str=\"GGTCTC\"):\n",
    "    test_str = Seq(in_str.upper())\n",
    "    rc_test_str = test_str.reverse_complement()\n",
    "    if (rest_str in test_str) or (rest_str in rc_test_str):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_output_seqs(sgRNA_df, remove_guides=False):\n",
    "    output_df = copy.deepcopy(sgRNA_df)\n",
    "    output_df[\"sequence_to_order\"] = output_df[\"sequence\"].apply(\n",
    "        target_to_padded_spacer\n",
    "    )\n",
    "    output_df[\"bbsi site\"] = output_df[\"sequence_to_order\"].apply(\n",
    "        lambda x: check_restriction_site(x[28:56], rest_str=\"GAAGAC\")\n",
    "    )\n",
    "    output_df[\"bsai site\"] = output_df[\"sequence_to_order\"].apply(\n",
    "        check_restriction_site, rest_str=\"GGTCTC\"\n",
    "    )\n",
    "    if remove_guides:\n",
    "        no_internal_sites = ~output_df[\"bbsi site\"] & ~output_df[\"bsai site\"]\n",
    "        output_df = output_df[no_internal_sites]\n",
    "        print(\n",
    "            \"Percent Recovered: \"\n",
    "            + str(np.sum(no_internal_sites) / len(no_internal_sites))\n",
    "        )\n",
    "    return output_df\n",
    "\n",
    "\n",
    "def generate_random_sequences(num_seqs, str_len=20, init_targetid=0):\n",
    "    str_arr = np.random.choice([\"A\", \"C\", \"G\", \"T\"], size=(num_seqs, str_len))\n",
    "    str_list = np.apply_along_axis(\"\".join, 1, str_arr).tolist()\n",
    "    df_out = [\n",
    "        [init_targetid + k, -1, -1, item, 1, 1, 0, \"Dummy\"]\n",
    "        for k, item in enumerate(str_list)\n",
    "    ]\n",
    "\n",
    "    df_out = pd.DataFrame(\n",
    "        df_out,\n",
    "        columns=[\n",
    "            \"targetid\",\n",
    "            \"start\",\n",
    "            \"end\",\n",
    "            \"sequence\",\n",
    "            \"ref_strand\",\n",
    "            \"target_strand\",\n",
    "            \"num_mismatch\",\n",
    "            \"category\",\n",
    "        ],\n",
    "    )\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = SeqIO.read(\"./DE161_reference.gb\", \"gb\")\n",
    "\n",
    "ref_start = 807758\n",
    "ref_end = 808585\n",
    "target = genome[ref_start:ref_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pam_df = find_pams(target, startcoord=ref_start, target_strand=-1)\n",
    "genome_pam_df = find_pams(genome)\n",
    "\n",
    "target_pam_df = remove_bad_seeds(target_pam_df, \"./bad_seed_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pam_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_sequence_size = 10\n",
    "most_agreement = compare_seqs(\n",
    "    target_pam_df, genome_pam_df, range(0, seed_sequence_size)\n",
    ")\n",
    "past_threshold = most_agreement < seed_sequence_size\n",
    "target_pam_df_nooff = target_pam_df[past_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percent Past Threshold: \" + str(np.sum(past_threshold) / len(past_threshold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_df = generate_mismatch_df(\n",
    "    target_pam_df_nooff, ks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], n_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CDS site used previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_df = mismatch_df[mismatch_df[\"target_strand\"] == 1].reset_index(drop=True)\n",
    "site_df = guides_df[guides_df[\"start\"] == 808416].reset_index(drop=True)\n",
    "site_subsample = site_df.groupby(\"num_mismatch\").sample(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_subsample = get_output_seqs(site_subsample, remove_guides=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_subsample[\"sequence_to_order\"].apply(lambda x: x[32:52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_subsample.to_csv(\"test_guide_reorder.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add random sequences to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_df = pd.concat(\n",
    "    [\n",
    "        mismatch_df,\n",
    "        generate_random_sequences(50, init_targetid=max(mismatch_df[\"targetid\"])),\n",
    "    ]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate pool for library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_dummy_seqs = 20\n",
    "ttl_replicates = 3\n",
    "\n",
    "output_df = get_output_seqs(library_df)\n",
    "bad_targetids = (\n",
    "    output_df[output_df[\"bbsi site\"] & (output_df[\"num_mismatch\"] == 0)][\n",
    "        \"targetid\"\n",
    "    ].tolist()\n",
    "    + output_df[output_df[\"bsai site\"] & (output_df[\"num_mismatch\"] == 0)][\n",
    "        \"targetid\"\n",
    "    ].tolist()\n",
    ")\n",
    "bad_targetids = sorted(bad_targetids)\n",
    "nobadtarget_df = output_df[~output_df[\"targetid\"].isin(bad_targetids)]\n",
    "norestsite_df = nobadtarget_df[\n",
    "    ~nobadtarget_df[\"bbsi site\"] & ~nobadtarget_df[\"bsai site\"]\n",
    "].reset_index(drop=True)\n",
    "output_mismatch_df = (\n",
    "    norestsite_df[norestsite_df[\"num_mismatch\"] != 0]\n",
    "    .groupby([\"targetid\", \"num_mismatch\"])\n",
    "    .apply(lambda x: x[:ttl_replicates])\n",
    ")\n",
    "output_mismatch_df = output_mismatch_df.reset_index(level=2, drop=True)\n",
    "\n",
    "output_match_df = norestsite_df[norestsite_df[\"num_mismatch\"] == 0]\n",
    "final_library_df = pd.concat([output_match_df, output_mismatch_df])\n",
    "final_library_df = (\n",
    "    final_library_df.set_index([\"targetid\", \"num_mismatch\"]).sort_index().reset_index()\n",
    ")\n",
    "final_dummy_targetids = final_library_df[final_library_df[\"category\"] == \"Dummy\"][\n",
    "    \"targetid\"\n",
    "].tolist()[:ttl_dummy_seqs]\n",
    "final_library_df = final_library_df[\n",
    "    (final_library_df[\"category\"] == \"Target\")\n",
    "    | (final_library_df[\"targetid\"].isin(final_dummy_targetids))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_library_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_library_df.to_csv(\"2020-11-01_mVenus_library_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_series = final_library_df.groupby([\"targetid\", \"num_mismatch\"]).size()\n",
    "size_df = pd.DataFrame(size_seriescolumns=[\"size\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(size_df[size_df[\"num_mismatch\"] == 1][\"size\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
