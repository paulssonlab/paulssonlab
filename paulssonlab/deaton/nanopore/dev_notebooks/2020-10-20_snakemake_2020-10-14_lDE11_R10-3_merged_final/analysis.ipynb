{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def align_read(querystr,cigarstr,pattern=re.compile(\"[0-9]{0,10}[MDI]\")):\n",
    "#     result = pattern.finditer(cigarstr)\n",
    "#     cigar_seq = [(item.group(0)[-1],int(item.group(0)[:-1])) for item in result]\n",
    "# #     output_str = \"\".join([\"-\" for i in range(cigar[1])])\n",
    "#     output_str = \"\"\n",
    "#     current_idx = 0\n",
    "#     for item in cigar_seq:\n",
    "#         if item[0]==\"M\":\n",
    "#             added_str = querystr[current_idx:current_idx+item[1]]\n",
    "#             output_str += added_str\n",
    "#             current_idx += item[1]\n",
    "#         elif item[0]==\"D\":\n",
    "#             added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "#             output_str += added_str\n",
    "#         elif item[0]==\"I\":\n",
    "#             current_idx += item[1]\n",
    "#     return output_str\n",
    "\n",
    "\n",
    "def cigarsfromsam(samfilepath):\n",
    "    cigars = {}\n",
    "    with open(samfilepath, \"r\") as samfile:\n",
    "        for line in samfile:\n",
    "            if line[0] == \"@\":\n",
    "                next(samfile)\n",
    "            else:\n",
    "                splitline = line.split(\"\\t\")\n",
    "                cigars[splitline[0]] = splitline[5]\n",
    "    return cigars\n",
    "\n",
    "\n",
    "def strsfromfasta(fastafilepath):\n",
    "    queries = SeqIO.to_dict(SeqIO.parse(fastafilepath, \"fasta\"))\n",
    "    queries = {key: str(val.seq) for key, val in queries.items()}\n",
    "    return queries\n",
    "\n",
    "\n",
    "def make_seg_dict(gfafile):\n",
    "    segment_dict = {}\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                segment_dict[splitline[1]] = splitline[2][:-1]\n",
    "    return segment_dict\n",
    "\n",
    "\n",
    "def get_ref_intervals(gfafile):\n",
    "    segment_dict = {}\n",
    "    current_idx = 0\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                if \"OFF\" not in splitline[1]:\n",
    "                    refstr = splitline[2][:-1]\n",
    "                    strlen = len(refstr)\n",
    "                    name = splitline[1]\n",
    "                    if \"ON\" in name:\n",
    "                        name = name[:-2]\n",
    "                    segment_dict[name] = tuple((current_idx, current_idx + strlen))\n",
    "                    current_idx += strlen\n",
    "    return segment_dict\n",
    "\n",
    "\n",
    "def align_read(\n",
    "    querystr, refstr, cigarstr, startpos=1, pattern=re.compile(\"[0-9]{0,10}[MDI]\")\n",
    "):\n",
    "    start_pos = startpos - 1  ##comes as 1 indexed from minimap\n",
    "    result = pattern.finditer(cigarstr)\n",
    "    cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]\n",
    "    #     output_str = \"\".join([\"-\" for i in range(cigar[1])])\n",
    "    output_str = \"\"\n",
    "    if start_pos > 0:\n",
    "        output_str += \"\".join([\"-\" for i in range(start_pos)])\n",
    "    current_idx = 0\n",
    "    for item in cigar_seq:\n",
    "        if item[0] == \"M\":\n",
    "            added_str = querystr[current_idx : current_idx + item[1]]\n",
    "            output_str += added_str\n",
    "            current_idx += item[1]\n",
    "        elif item[0] == \"D\":\n",
    "            added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "            output_str += added_str\n",
    "        elif item[0] == \"I\":\n",
    "            current_idx += item[1]\n",
    "    remaining_len = len(refstr) - len(output_str)\n",
    "    if remaining_len > 0:\n",
    "        output_str += \"\".join([\"-\" for i in range(remaining_len)])\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def splitstr(instr, ref_intervals):\n",
    "    strassign = {key: instr[val[0] : val[1]] for key, val in ref_intervals.items()}\n",
    "    return strassign\n",
    "\n",
    "\n",
    "def slow_hamming_distance(s1, s2):\n",
    "    if len(s1) != len(s2):\n",
    "        print(s1, s2)\n",
    "        raise ValueError(\"Strand lengths are not equal!\")\n",
    "    term_list = []\n",
    "    for ch1, ch2 in zip(s1, s2):\n",
    "        if ch1 == \"N\" or ch2 == \"N\":\n",
    "            term_list.append(False)\n",
    "        else:\n",
    "            term_list.append(ch1 != ch2)\n",
    "    result = sum(term_list)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_dict_dist(dict1, dict2):\n",
    "    hamming_dict = {\n",
    "        key: slow_hamming_distance(dict1[key], dict2[key]) for key in dict1.keys()\n",
    "    }\n",
    "    return hamming_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-10-20_snakemake_2020-10-14_lDE11_R10-3_merged_final/output.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    ")\n",
    "ref_intervals = get_ref_intervals(\n",
    "    \"/home/de64/scratch/de64/2020-10-20_snakemake_2020-10-14_lDE11_R10-3_merged_final/ref.gfa\"\n",
    ")\n",
    "R10_barcodes = set(R10_data[\"barcode\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_arr = np.array([list(item) for item in R10_barcodes]).astype(int)\n",
    "bit_freq = np.mean(bit_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bit_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x=list(range(27)), y=bit_freq, color=\"grey\")\n",
    "plt.xlabel(\"Bit Number\", fontsize=20)\n",
    "plt.ylabel(\"Percent Positive\", fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.savefig(\"./figure_1.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_on = bit_arr @ bit_arr.T\n",
    "both_off = (-bit_arr + 1) @ (-bit_arr.T + 1)\n",
    "ttl_match = both_on + both_off\n",
    "np.fill_diagonal(ttl_match, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_match = np.min(ttl_match, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(closest_match, range=(0, 10))\n",
    "plt.xlabel(\"Closest Hamming Distance\", fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.savefig(\"./figure_2.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(closest_match, range=(0, 2), bins=3)\n",
    "plt.xlabel(\"Closest Hamming Distance\", fontsize=20)\n",
    "plt.xticks([0.25, 1.0, 1.75], [0, 1, 2], fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.savefig(\"./figure_3.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(closest_match == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    np.random.choice(ttl_match.flatten(), 50000, replace=False), range=(0, 27), bins=27\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_cons = R10_data.apply(\n",
    "    lambda x: align_read(\n",
    "        x[\"consensus\"], x[\"reference\"], x[\"cigar\"], startpos=x[\"alignmentstart\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "R10_data[\"aligned_cons\"] = aligned_cons\n",
    "\n",
    "split_ref = R10_data.apply(lambda x: splitstr(x[\"reference\"], ref_intervals), axis=1)\n",
    "split_align = R10_data.apply(\n",
    "    lambda x: splitstr(x[\"aligned_cons\"], ref_intervals), axis=1\n",
    ")\n",
    "R10_data[\"split_ref\"] = split_ref\n",
    "R10_data[\"split_align\"] = split_align\n",
    "\n",
    "hamm_ref = R10_data.apply(\n",
    "    lambda x: get_dict_dist(x[\"split_align\"], x[\"split_ref\"]), axis=1\n",
    ")\n",
    "R10_data[\"hamm_ref\"] = hamm_ref\n",
    "\n",
    "dark_gfp = (\n",
    "    R10_data.apply(\n",
    "        lambda x: slow_hamming_distance(\n",
    "            x[\"split_align\"][\"GFP\"][623:625], x[\"split_ref\"][\"GFP\"][623:625]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    > 0\n",
    ")\n",
    "R10_data[\"dark_gfp\"] = dark_gfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_data.to_csv(\"./lDE11_final_df.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanger Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "record = SeqIO.read(\"./ab1_files/lDE11_validation_sample_1-oDE154.ab1\", \"abi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sanger(seq_record, start=0, end=-1, figsize=(18, 8)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    channels = [\"DATA9\", \"DATA10\", \"DATA11\", \"DATA12\"]\n",
    "    trace = {}\n",
    "    for c in channels:\n",
    "        trace[c] = seq_record.annotations[\"abif_raw\"][c]\n",
    "\n",
    "    plt.plot(trace[\"DATA9\"][start * 10 : end * 10], color=\"blue\")\n",
    "    plt.plot(trace[\"DATA10\"][start * 10 : end * 10], color=\"red\")\n",
    "    plt.plot(trace[\"DATA11\"][start * 10 : end * 10], color=\"green\")\n",
    "    plt.plot(trace[\"DATA12\"][start * 10 : end * 10], color=\"yellow\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sanger(record, 50, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to fastq and group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ab1_files/merged.fastq\", \"w\") as outfile:\n",
    "    for i in range(1, 97):\n",
    "        filepath1 = \"./ab1_files/lDE11_validation_sample_\" + str(i) + \"-oDE154.ab1\"\n",
    "        filepath2 = \"./ab1_files/lDE11_validation_sample_\" + str(i) + \"-oDE201.ab1\"\n",
    "\n",
    "        record1 = SeqIO.read(filepath1, \"abi\")\n",
    "        record2 = SeqIO.read(filepath2, \"abi\")\n",
    "\n",
    "        SeqIO.write(record1, outfile, \"fastq\")\n",
    "        SeqIO.write(record2, outfile, \"fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!GraphAligner -g ./ref.gfa -f ./ab1_files/merged.fastq -a ./ab1_files/aligned.gaf -x dbg --high-memory -b 20 -B 35 -C -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "cigar_dict = {}\n",
    "with open(\"./ab1_files/aligned.gaf\", \"r\") as infile:\n",
    "    for line in infile:\n",
    "        data = line.split(\"\\t\")\n",
    "        read_id = data[0].split(\" \")[0]\n",
    "        if \">\" in data[5]:\n",
    "            cigar_dict[read_id] = (\n",
    "                \"+\",\n",
    "                int(data[7]),\n",
    "                int(data[8]),\n",
    "                data[5],\n",
    "                data[15].split(\":\")[-1][:-1],\n",
    "            )\n",
    "        else:\n",
    "            cigar_dict[read_id] = (\n",
    "                \"-\",\n",
    "                int(data[7]),\n",
    "                int(data[8]),\n",
    "                data[5],\n",
    "                data[15].split(\":\")[-1][:-1],\n",
    "            )\n",
    "\n",
    "barcode_dict = {}\n",
    "for key in cigar_dict.keys():\n",
    "    cigar = cigar_dict[key]\n",
    "    if \"oDE201\" in key:\n",
    "        barcode = cigar[3].split(\"<\")\n",
    "        barcode = barcode[::-1]\n",
    "        barcode = barcode[:-1]\n",
    "        barcode = (\n",
    "            np.array([\"ON\" in item for item in barcode if \"BIT\" in item])\n",
    "            .astype(int)\n",
    "            .astype(str)\n",
    "            .tolist()\n",
    "        )\n",
    "        barcode = \"\".join(barcode)\n",
    "        index = key.split(\"_\")[3].split(\"-\")[0]\n",
    "        barcode_dict[int(index)] = barcode\n",
    "\n",
    "with open(\"./ab1_files/merged.fastq\", \"r\") as infile:\n",
    "    read_dict = SeqIO.parse(infile, \"fastq\")\n",
    "    read_dict = SeqIO.to_dict(read_dict)\n",
    "\n",
    "# barcode_dict = [\n",
    "#     {\"readname\": key, \"barcode\": val, \"cigar\": cigar_dict[key]}\n",
    "#     for key, val in barcode_dict.items()\n",
    "# ]\n",
    "\n",
    "# keys = [\"readname\", \"barcode\", \"cigar\"]\n",
    "# with open(snakemake.output[0], \"w\") as outfile:\n",
    "#     dict_writer = csv.DictWriter(outfile, keys, delimiter=\"\\t\")\n",
    "#     dict_writer.writeheader()\n",
    "#     dict_writer.writerows(barcode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar_dict[\"lDE11_validation_sample_1-oDE154\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_data = pd.read_csv(\"./lDE11_final_df.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_data[R10_data[\"barcode\"] == barcode_dict[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snp_hamming = []\n",
    "for i in range(1, 97):\n",
    "    if np.sum(R10_data[\"barcode\"] == barcode_dict[i]) == 1:\n",
    "        gfp_read_name = \"lDE11_validation_sample_\" + str(i) + \"-oDE154\"\n",
    "        aligned = align_read(\n",
    "            read_dict[gfp_read_name],\n",
    "            R10_data[R10_data[\"barcode\"] == barcode_dict[i]][\"reference\"].iloc[0],\n",
    "            cigar_dict[gfp_read_name][4],\n",
    "            startpos=cigar_dict[gfp_read_name][1] + 1,\n",
    "        )\n",
    "        ref_intervals = get_ref_intervals(\"./ref.gfa\")\n",
    "        split_ref = splitstr(\n",
    "            R10_data[R10_data[\"barcode\"] == barcode_dict[i]][\"reference\"].iloc[0],\n",
    "            ref_intervals,\n",
    "        )\n",
    "        split_consensus = splitstr(\n",
    "            R10_data[R10_data[\"barcode\"] == barcode_dict[i]][\"consensus\"].iloc[0],\n",
    "            ref_intervals,\n",
    "        )\n",
    "        split_align = splitstr(str(aligned.seq), ref_intervals)\n",
    "        snp_hamming = slow_hamming_distance(\n",
    "            split_align[\"GFP\"][623:625], split_consensus[\"GFP\"][623:625]\n",
    "        )\n",
    "        all_snp_hamming.append(snp_hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_snp_hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_bc = []\n",
    "for i in range(1, 97):\n",
    "    ttl_bc.append(np.sum(R10_data[\"barcode\"] == barcode_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(ttl_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ttl_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_data[R10_data[\"barcode\"] == barcode_dict[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"011101000101100111101100001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_align[\"GFP\"][623:625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ref[\"GFP\"][623:625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_consensus[\"GFP\"][623:625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_hamming_distance(split_align[\"GFP\"][623:625], split_consensus[\"GFP\"][623:625])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
