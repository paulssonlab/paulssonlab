{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paulssonlab.deaton.trenchripper.trenchripper as trenchripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import scipy.signal\n",
    "import shutil\n",
    "import skimage as sk\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import h5py_cache\n",
    "import copy\n",
    "from parse import compile\n",
    "\n",
    "from skimage import filters\n",
    "from paulssonlab.deaton.trenchripper.trenchripper.trcluster import hdf5lock\n",
    "from paulssonlab.deaton.trenchripper.trenchripper.utils import (\n",
    "    multifov,\n",
    "    pandas_hdf5_handler,\n",
    "    writedir,\n",
    ")\n",
    "from tifffile import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = \"/n/scratch2/de64/2019-05-31_validation_data\"\n",
    "nd2file = \"/n/scratch2/de64/2019-05-31_validation_data/Main_Experiment.nd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kymograph_cluster:\n",
    "    def __init__(\n",
    "        self,\n",
    "        headpath=\"\",\n",
    "        trenches_per_file=20,\n",
    "        paramfile=False,\n",
    "        all_channels=[\"\"],\n",
    "        trench_len_y=270,\n",
    "        padding_y=20,\n",
    "        trench_width_x=30,\n",
    "        t_range=(0, None),\n",
    "        invert=False,\n",
    "        y_percentile=85,\n",
    "        y_min_edge_dist=50,\n",
    "        smoothing_kernel_y=(1, 9),\n",
    "        y_percentile_threshold=0.2,\n",
    "        top_orientation=0,\n",
    "        expected_num_rows=None,\n",
    "        orientation_on_fail=None,\n",
    "        x_percentile=85,\n",
    "        background_kernel_x=(1, 21),\n",
    "        smoothing_kernel_x=(1, 9),\n",
    "        otsu_nbins=50,\n",
    "        otsu_scaling=1.0,\n",
    "        trench_present_thr=0.0,\n",
    "    ):\n",
    "\n",
    "        if paramfile:\n",
    "            parampath = headpath + \"/kymograph.par\"\n",
    "            with open(parampath, \"rb\") as infile:\n",
    "                param_dict = pickle.load(infile)\n",
    "\n",
    "            all_channels = param_dict[\"All Channels\"]\n",
    "            trench_len_y = param_dict[\"Trench Length\"]\n",
    "            padding_y = param_dict[\"Y Padding\"]\n",
    "            trench_width_x = param_dict[\"Trench Width\"]\n",
    "            t_range = param_dict[\"Time Range\"]\n",
    "            invert = param_dict[\"Invert\"]\n",
    "            y_percentile = param_dict[\"Y Percentile\"]\n",
    "            y_min_edge_dist = param_dict[\"Minimum Trench Length\"]\n",
    "            smoothing_kernel_y = (1, param_dict[\"Y Smoothing Kernel\"])\n",
    "            y_percentile_threshold = param_dict[\"Y Percentile Threshold\"]\n",
    "            top_orientation = param_dict[\"Orientation Detection Method\"]\n",
    "            expected_num_rows = param_dict[\n",
    "                \"Expected Number of Rows (Manual Orientation Detection)\"\n",
    "            ]\n",
    "            orientation_on_fail = param_dict[\n",
    "                \"Top Orientation when Row Drifts Out (Manual Orientation Detection)\"\n",
    "            ]\n",
    "            x_percentile = param_dict[\"X Percentile\"]\n",
    "            background_kernel_x = (1, param_dict[\"X Background Kernel\"])\n",
    "            smoothing_kernel_x = (1, param_dict[\"X Smoothing Kernel\"])\n",
    "            otsu_nbins = param_dict[\"Otsu Threshold Bins\"]\n",
    "            otsu_scaling = param_dict[\"Otsu Threshold Scaling\"]\n",
    "            trench_present_thr = param_dict[\"Trench Presence Threshold\"]\n",
    "\n",
    "        self.headpath = headpath\n",
    "        self.kymographpath = self.headpath + \"/kymograph\"\n",
    "        self.hdf5path = self.headpath + \"/hdf5\"\n",
    "        self.all_channels = all_channels\n",
    "        self.seg_channel = self.all_channels[0]\n",
    "        self.metapath = self.headpath + \"/metadata.hdf5\"\n",
    "        self.meta_handle = pandas_hdf5_handler(self.metapath)\n",
    "        self.trenches_per_file = trenches_per_file\n",
    "\n",
    "        self.t_range = t_range\n",
    "        self.invert = invert\n",
    "\n",
    "        #### important paramaters to set\n",
    "        self.trench_len_y = trench_len_y\n",
    "        self.padding_y = padding_y\n",
    "        ttl_len_y = trench_len_y + padding_y\n",
    "        self.ttl_len_y = ttl_len_y\n",
    "        self.trench_width_x = trench_width_x\n",
    "\n",
    "        #### params for y\n",
    "        ## parameter for reducing signal to one dim\n",
    "        self.y_percentile = y_percentile\n",
    "        self.y_min_edge_dist = y_min_edge_dist\n",
    "        ## parameters for threshold finding\n",
    "        self.smoothing_kernel_y = smoothing_kernel_y\n",
    "        self.y_percentile_threshold = y_percentile_threshold\n",
    "        ###\n",
    "        self.top_orientation = top_orientation\n",
    "        self.expected_num_rows = expected_num_rows\n",
    "        self.orientation_on_fail = orientation_on_fail\n",
    "        #### params for x\n",
    "        ## parameter for reducing signal to one dim\n",
    "        self.x_percentile = x_percentile\n",
    "        ## parameters for midpoint finding\n",
    "        self.background_kernel_x = background_kernel_x\n",
    "        self.smoothing_kernel_x = smoothing_kernel_x\n",
    "        ## parameters for threshold finding\n",
    "        self.otsu_nbins = otsu_nbins\n",
    "        self.otsu_scaling = otsu_scaling\n",
    "        ## New\n",
    "        self.trench_present_thr = trench_present_thr\n",
    "\n",
    "        self.output_chunk_shape = (1, 1, self.ttl_len_y, (self.trench_width_x // 2) * 2)\n",
    "        self.output_chunk_bytes = (\n",
    "            2 * np.multiply.accumulate(np.array(self.output_chunk_shape))[-1]\n",
    "        )\n",
    "        self.output_chunk_cache_mem_size = 2 * self.output_chunk_bytes\n",
    "\n",
    "        self.kymograph_params = {\n",
    "            \"trench_len_y\": trench_len_y,\n",
    "            \"padding_y\": padding_y,\n",
    "            \"ttl_len_y\": ttl_len_y,\n",
    "            \"trench_width_x\": trench_width_x,\n",
    "            \"y_percentile\": y_percentile,\n",
    "            \"invert\": invert,\n",
    "            \"y_min_edge_dist\": y_min_edge_dist,\n",
    "            \"smoothing_kernel_y\": smoothing_kernel_y,\n",
    "            \"y_percentile_threshold\": y_percentile_threshold,\n",
    "            \"top_orientation\": top_orientation,\n",
    "            \"expected_num_rows\": expected_num_rows,\n",
    "            \"orientation_on_fail\": orientation_on_fail,\n",
    "            \"x_percentile\": x_percentile,\n",
    "            \"background_kernel_x\": background_kernel_x,\n",
    "            \"smoothing_kernel_x\": smoothing_kernel_x,\n",
    "            \"otsu_nbins\": otsu_nbins,\n",
    "            \"otsu_scaling\": otsu_scaling,\n",
    "            \"trench_present_thr\": trench_present_thr,\n",
    "        }\n",
    "\n",
    "    def median_filter_2d(self, array, smoothing_kernel):\n",
    "        \"\"\"Two-dimensional median filter, with average smoothing at the signal\n",
    "        edges in the second dimension (the non-time dimension).\n",
    "        Args:\n",
    "            array_list (list): List containing a single array of 2 dimensional signal to be smoothed.\n",
    "            smoothing_kernel (tuple): A tuple of ints specifying the kernel under which\n",
    "            the median will be taken.\n",
    "        Returns:\n",
    "            array: Median-filtered 2 dimensional signal.\n",
    "        \"\"\"\n",
    "        kernel = np.array(smoothing_kernel)  # 1,9\n",
    "        kernel_pad = kernel // 2 + 1  # 1,5\n",
    "        med_filter = scipy.signal.medfilt(array, kernel_size=kernel)\n",
    "        start_edge = np.mean(med_filter[:, kernel_pad[1] : kernel[1]])\n",
    "        end_edge = np.mean(med_filter[:, -kernel[1] : -kernel_pad[1]])\n",
    "        med_filter[:, : kernel_pad[1]] = start_edge\n",
    "        med_filter[:, -kernel_pad[1] :] = end_edge\n",
    "        return med_filter\n",
    "\n",
    "    def get_smoothed_y_percentiles(self, file_idx, y_percentile, smoothing_kernel_y):\n",
    "        \"\"\"For each imported array, computes the percentile along the x-axis of\n",
    "        the segmentation channel, generating a (y,t) array. Then performs\n",
    "        median filtering of this array for smoothing.\n",
    "        Args:\n",
    "            imported_hdf5_handle (h5py.File): Hdf5 file handle corresponding to the input hdf5 dataset\n",
    "            \"data\" of shape (channel,y,x,t).\n",
    "            y_percentile (int): Percentile to apply along the x-axis.\n",
    "            smoothing_kernel_y (tuple): Kernel to use for median filtering.\n",
    "        Returns:\n",
    "            h5py.File: Hdf5 file handle corresponding to the output hdf5 dataset \"data\", a smoothed\n",
    "            percentile array of shape (y,t).\n",
    "        \"\"\"\n",
    "        with h5py_cache.File(\n",
    "            self.hdf5path + \"/hdf5_\" + str(file_idx) + \".hdf5\",\n",
    "            \"r\",\n",
    "            chunk_cache_mem_size=self.metadata[\"chunk_cache_mem_size\"],\n",
    "        ) as imported_hdf5_handle:\n",
    "            img_arr = imported_hdf5_handle[self.seg_channel][:]  # t x y\n",
    "            if self.invert:\n",
    "                img_arr = sk.util.invert(img_arr)\n",
    "            perc_arr = np.percentile(\n",
    "                img_arr, y_percentile, axis=2, interpolation=\"lower\"\n",
    "            )\n",
    "            y_percentiles_smoothed = self.median_filter_2d(perc_arr, smoothing_kernel_y)\n",
    "\n",
    "            min_qth_percentile = y_percentiles_smoothed.min(axis=1)[:, np.newaxis]\n",
    "            max_qth_percentile = y_percentiles_smoothed.max(axis=1)[:, np.newaxis]\n",
    "            y_percentiles_smoothed = (y_percentiles_smoothed - min_qth_percentile) / (\n",
    "                max_qth_percentile - min_qth_percentile\n",
    "            )\n",
    "\n",
    "        return y_percentiles_smoothed\n",
    "\n",
    "    def get_edges_from_mask(self, mask):\n",
    "        \"\"\"Finds edges from a boolean mask of shape (t,y). Filters out rows of\n",
    "        length smaller than y_min_edge_dist.\n",
    "        Args:\n",
    "            mask (array): Boolean of shape (y,t) resulting from triangle thresholding.\n",
    "            y_min_edge_dist (int): Minimum row length necessary for detection.\n",
    "        Returns:\n",
    "            list: List containing arrays of edges for each timepoint, filtered for rows that are too small.\n",
    "        \"\"\"\n",
    "        edges_list = []\n",
    "        start_above_list = []\n",
    "        end_above_list = []\n",
    "        for t in range(mask.shape[0]):\n",
    "            edge_mask = mask[t, 1:] != mask[t, :-1]\n",
    "            start_above, end_above = (mask[t, 0] == True, mask[t, -1] == True)\n",
    "            edges = np.where(edge_mask)[0]\n",
    "            edges_list.append(edges)\n",
    "            start_above_list.append(start_above)\n",
    "            end_above_list.append(end_above)\n",
    "        return edges_list, start_above_list, end_above_list\n",
    "\n",
    "    def get_trench_edges_y(\n",
    "        self, y_percentiles_smoothed_array, y_percentile_threshold, y_min_edge_dist\n",
    "    ):\n",
    "        \"\"\"Detects edges in the shape (t,y) smoothed percentile arrays for each\n",
    "        input array.\n",
    "        Args:\n",
    "            y_percentiles_smoothed_array (array): A shape (y,t) smoothed percentile array.\n",
    "            triangle_nbins (int): Number of bins to be used to construct the thresholding histogram.\n",
    "            triangle_scaling (float): Factor by which to scale the threshold.\n",
    "            y_min_edge_dist (int): Minimum row length necessary for detection.\n",
    "        Returns:\n",
    "            list: List containing arrays of edges for each timepoint, filtered for rows that are too small.\n",
    "        \"\"\"\n",
    "\n",
    "        trench_mask_y = y_percentiles_smoothed_array > y_percentile_threshold\n",
    "        edges_list, start_above_list, end_above_list = self.get_edges_from_mask(\n",
    "            trench_mask_y\n",
    "        )\n",
    "        return edges_list, start_above_list, end_above_list\n",
    "\n",
    "    def repair_out_of_frame(self, trench_edges_y, start_above, end_above):\n",
    "        if start_above:\n",
    "            trench_edges_y = np.array([0] + trench_edges_y.tolist())\n",
    "        if end_above:\n",
    "            trench_edges_y = np.array(\n",
    "                trench_edges_y.tolist() + [int(self.metadata[\"height\"])]\n",
    "            )\n",
    "        return trench_edges_y\n",
    "\n",
    "    def remove_small_rows(self, edges, min_edge_dist):\n",
    "        \"\"\"Filters out small rows when performing automated row detection.\n",
    "        Args:\n",
    "            edges (array): Array of edges along y-axis.\n",
    "            min_edge_dist (int): Minimum row length necessary for detection.\n",
    "        Returns:\n",
    "            array: Array of edges, filtered for rows that are too small.\n",
    "        \"\"\"\n",
    "        grouped_edges = edges.reshape(-1, 2)\n",
    "        row_lens = np.diff(grouped_edges, axis=1)\n",
    "        row_mask = (row_lens > min_edge_dist).flatten()\n",
    "        filtered_edges = grouped_edges[row_mask]\n",
    "        return filtered_edges.flatten()\n",
    "\n",
    "    def remove_out_of_frame(\n",
    "        self, orientations, repaired_trench_edges_y, start_above, end_above\n",
    "    ):\n",
    "        \"\"\"Takes an array of trench row edges and removes the first/last edge,\n",
    "        if that edge does not have a proper partner (i.e. trench row mask takes\n",
    "        value True at boundaries of image).\n",
    "        Args:\n",
    "            edges (array): Array of edges along y-axis.\n",
    "            start_above (bool): True if the trench row mask takes value True at the\n",
    "            starting edge of the mask.\n",
    "            end_above (bool): True if the trench row mask takes value True at the\n",
    "            ending edge of the mask.\n",
    "        Returns:\n",
    "            array: Array of edges along y-axis, corrected for edge pairs that\n",
    "            are out of frame.\n",
    "        \"\"\"\n",
    "        drop_first_row, drop_last_row = (False, False)\n",
    "        if start_above and orientations[0] == 0:  # if the top is facing down and is cut\n",
    "            drop_first_row = True\n",
    "            orientations = orientations[1:]\n",
    "            repaired_trench_edges_y = repaired_trench_edges_y[2:]\n",
    "        if end_above and orientations[-1] == 1:  # if the bottom is facing up and is cut\n",
    "            drop_last_row = True\n",
    "            orientations = orientations[:-1]\n",
    "            repaired_trench_edges_y = repaired_trench_edges_y[:-2]\n",
    "        return orientations, drop_first_row, drop_last_row, repaired_trench_edges_y\n",
    "\n",
    "    def get_manual_orientations(\n",
    "        self,\n",
    "        trench_edges_y_list,\n",
    "        start_above_list,\n",
    "        end_above_list,\n",
    "        expected_num_rows,\n",
    "        top_orientation,\n",
    "        orientation_on_fail,\n",
    "        y_min_edge_dist,\n",
    "    ):\n",
    "        trench_edges_y = trench_edges_y_list[0]\n",
    "        start_above = start_above_list[0]\n",
    "        end_above = end_above_list[0]\n",
    "        orientations = []\n",
    "\n",
    "        repaired_trench_edges_y = self.repair_out_of_frame(\n",
    "            trench_edges_y, start_above, end_above\n",
    "        )\n",
    "        repaired_trench_edges_y = self.remove_small_rows(\n",
    "            repaired_trench_edges_y, y_min_edge_dist\n",
    "        )\n",
    "\n",
    "        if repaired_trench_edges_y.shape[0] // 2 == expected_num_rows:\n",
    "            orientation = top_orientation\n",
    "            for row in range(repaired_trench_edges_y.shape[0] // 2):\n",
    "                orientations.append(orientation)\n",
    "                orientation = (orientation + 1) % 2\n",
    "            (\n",
    "                orientations,\n",
    "                drop_first_row,\n",
    "                drop_last_row,\n",
    "                repaired_trench_edges_y,\n",
    "            ) = self.remove_out_of_frame(\n",
    "                orientations, repaired_trench_edges_y, start_above, end_above\n",
    "            )\n",
    "\n",
    "        elif (\n",
    "            repaired_trench_edges_y.shape[0] // 2 < expected_num_rows\n",
    "        ) and orientation_on_fail is not None:\n",
    "            orientation = orientation_on_fail\n",
    "            for row in range(repaired_trench_edges_y.shape[0] // 2):\n",
    "                orientations.append(orientation)\n",
    "                orientation = (orientation + 1) % 2\n",
    "            (\n",
    "                orientations,\n",
    "                drop_first_row,\n",
    "                drop_last_row,\n",
    "                repaired_trench_edges_y,\n",
    "            ) = self.remove_out_of_frame(\n",
    "                orientations, repaired_trench_edges_y, start_above, end_above\n",
    "            )\n",
    "        else:\n",
    "            print(\"Start frame does not have expected number of rows!\")\n",
    "\n",
    "        return orientations, drop_first_row, drop_last_row\n",
    "\n",
    "    def get_trench_ends(\n",
    "        self,\n",
    "        trench_edges_y_list,\n",
    "        start_above_list,\n",
    "        end_above_list,\n",
    "        orientations,\n",
    "        drop_first_row,\n",
    "        drop_last_row,\n",
    "        y_min_edge_dist,\n",
    "    ):\n",
    "        top_orientation = orientations[0]\n",
    "\n",
    "        y_ends_list = []\n",
    "\n",
    "        for t, trench_edges_y in enumerate(trench_edges_y_list):\n",
    "            start_above = start_above_list[t]\n",
    "            end_above = end_above_list[t]\n",
    "\n",
    "            repaired_trench_edges_y = self.repair_out_of_frame(\n",
    "                trench_edges_y, start_above, end_above\n",
    "            )\n",
    "            repaired_trench_edges_y = self.remove_small_rows(\n",
    "                repaired_trench_edges_y, y_min_edge_dist\n",
    "            )\n",
    "\n",
    "            if (\n",
    "                repaired_trench_edges_y.shape[0] // 2 > len(orientations)\n",
    "            ) and drop_first_row:\n",
    "                repaired_trench_edges_y = repaired_trench_edges_y[2:]\n",
    "            if (\n",
    "                repaired_trench_edges_y.shape[0] // 2 > len(orientations)\n",
    "            ) and drop_last_row:\n",
    "                repaired_trench_edges_y = repaired_trench_edges_y[:-2]\n",
    "            grouped_edges = repaired_trench_edges_y.reshape(-1, 2)  # or,2\n",
    "            y_ends = []\n",
    "            for edges, orientation in enumerate(orientations):\n",
    "                y_ends.append(grouped_edges[edges, orientation])\n",
    "            y_ends = np.array(y_ends)\n",
    "            y_ends_list.append(y_ends)\n",
    "        return y_ends_list\n",
    "\n",
    "    def get_y_drift(self, y_ends_list):\n",
    "        \"\"\"Given a list of midpoints, computes the average drift in y for every\n",
    "        timepoint.\n",
    "        Args:\n",
    "            y_midpoints_list (list): A list containing, for each fov, a list of the form [time_list,[midpoint_array]]\n",
    "            containing the trench row midpoints.\n",
    "        Returns:\n",
    "            list: A nested list of the form [time_list,[y_drift_int]] for fov i.\n",
    "        \"\"\"\n",
    "        y_drift = []\n",
    "        for t in range(len(y_ends_list) - 1):\n",
    "            diff_mat = np.subtract.outer(y_ends_list[t + 1], y_ends_list[t])\n",
    "            if len(diff_mat) > 0:\n",
    "                min_dist_idx = np.argmin(abs(diff_mat), axis=0)\n",
    "                min_dists = []\n",
    "                for row in range(diff_mat.shape[0]):\n",
    "                    min_dists.append(diff_mat[row, min_dist_idx[row]])\n",
    "                min_dists = np.array(min_dists)\n",
    "                median_translation = np.median(min_dists)\n",
    "            else:\n",
    "                median_translation = 0\n",
    "            y_drift.append(median_translation)\n",
    "        net_y_drift = np.append(np.array([0]), np.add.accumulate(y_drift)).astype(int)\n",
    "        return net_y_drift\n",
    "\n",
    "    def keep_in_frame_kernels(\n",
    "        self, y_ends_list, y_drift, orientations, padding_y, trench_len_y\n",
    "    ):\n",
    "        \"\"\"Removes those kernels which drift out of the image during any timepoint.\n",
    "        Args:\n",
    "            trench_edges_y_lists (list): A list containing, for each fov, a time-ordered list of trench edge arrays.\n",
    "            y_drift_list (list): A list containing, for each fov, a nested list of the form [time_list,[y_drift_int]].\n",
    "            imported_array_list (int): A numpy array containing the hdf5 file image data.\n",
    "            padding_y (int): Y-dimensional padding for cropping.\n",
    "        Returns:\n",
    "            list: Time-ordered list of trench edge arrays, filtered for images which\n",
    "            stay in frame for all timepoints, for fov i.\n",
    "        \"\"\"\n",
    "\n",
    "        init_y_ends = y_ends_list[0]\n",
    "        max_y_dim = self.metadata[\"height\"]\n",
    "        max_drift, min_drift = np.max(y_drift), np.min(y_drift)\n",
    "\n",
    "        valid_y_ends_list = []\n",
    "        valid_orientations = []\n",
    "        for j, orientation in enumerate(orientations):\n",
    "            y_end = init_y_ends[j]\n",
    "            if orientation == 0:\n",
    "                bottom_edge = y_end + trench_len_y + max_drift\n",
    "                top_edge = y_end - padding_y + min_drift\n",
    "                edge_under_max = bottom_edge < max_y_dim\n",
    "                edge_over_min = top_edge >= 0\n",
    "            else:\n",
    "                bottom_edge = y_end + padding_y + max_drift\n",
    "                top_edge = y_end - trench_len_y + min_drift\n",
    "                edge_under_max = bottom_edge < max_y_dim\n",
    "                edge_over_min = top_edge >= 0\n",
    "\n",
    "            edge_in_bounds = edge_under_max * edge_over_min\n",
    "\n",
    "            if edge_in_bounds:\n",
    "                valid_y_ends_list.append([y_end[j] for y_end in y_ends_list])\n",
    "                valid_orientations.append(orientation)\n",
    "\n",
    "        valid_y_ends = np.array(valid_y_ends_list).T  # t,edge\n",
    "\n",
    "        return valid_y_ends, valid_orientations\n",
    "\n",
    "    def get_ends_and_orientations(\n",
    "        self,\n",
    "        fov_idx,\n",
    "        edges_futures,\n",
    "        expected_num_rows,\n",
    "        top_orientation,\n",
    "        orientation_on_fail,\n",
    "        y_min_edge_dist,\n",
    "        padding_y,\n",
    "        trench_len_y,\n",
    "    ):\n",
    "\n",
    "        fovdf = self.meta_handle.read_df(\"global\", read_metadata=False)\n",
    "        fovdf = fovdf.loc[(slice(None), slice(self.t_range[0], self.t_range[1])), :]\n",
    "        working_fovdf = fovdf.loc[fov_idx]\n",
    "\n",
    "        trench_edges_y_list = []\n",
    "        start_above_list = []\n",
    "        end_above_list = []\n",
    "\n",
    "        for j, file_idx in enumerate(working_fovdf[\"File Index\"].unique().tolist()):\n",
    "            working_filedf = working_fovdf[working_fovdf[\"File Index\"] == file_idx]\n",
    "            img_indices = working_filedf[\"Image Index\"].unique()\n",
    "            first_idx, last_idx = (img_indices[0], img_indices[-1])\n",
    "            trench_edges_y_list += edges_futures[j][0][first_idx : last_idx + 1]\n",
    "            start_above_list += edges_futures[j][1][first_idx : last_idx + 1]\n",
    "            end_above_list += edges_futures[j][2][first_idx : last_idx + 1]\n",
    "\n",
    "        orientations, drop_first_row, drop_last_row = self.get_manual_orientations(\n",
    "            trench_edges_y_list,\n",
    "            start_above_list,\n",
    "            end_above_list,\n",
    "            expected_num_rows,\n",
    "            top_orientation,\n",
    "            orientation_on_fail,\n",
    "            y_min_edge_dist,\n",
    "        )\n",
    "        y_ends_list = self.get_trench_ends(\n",
    "            trench_edges_y_list,\n",
    "            start_above_list,\n",
    "            end_above_list,\n",
    "            orientations,\n",
    "            drop_first_row,\n",
    "            drop_last_row,\n",
    "            y_min_edge_dist,\n",
    "        )\n",
    "        y_drift = self.get_y_drift(y_ends_list)\n",
    "        valid_y_ends, valid_orientations = self.keep_in_frame_kernels(\n",
    "            y_ends_list, y_drift, orientations, padding_y, trench_len_y\n",
    "        )\n",
    "\n",
    "        return y_drift, valid_orientations, valid_y_ends\n",
    "\n",
    "    def crop_y(\n",
    "        self, file_idx, drift_orientation_and_initend_future, padding_y, trench_len_y\n",
    "    ):\n",
    "        \"\"\"Performs cropping of the images in the y-dimension.\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            trench_edges_y_list (list): List containing, for each fov entry, a list of time-sorted edge arrays.\n",
    "            row_num_list (list): List containing The number of trench rows detected in each fov.\n",
    "            imported_array_list (list): A list containing numpy arrays containing the hdf5 file image\n",
    "            data of shape (channel,y,x,t).\n",
    "            padding_y (int): Padding to be used when cropping in the y-dimension.\n",
    "            trench_len_y (int): Length from the end of the tenches to be used when cropping in the\n",
    "            y-dimension.\n",
    "            top_orientation (int, optional): The orientation of the top-most row where 0 corresponds to a trench with\n",
    "            a downward-oriented trench opening and 1 corresponds to a trench with an upward-oriented trench opening.\n",
    "        Returns:\n",
    "            array: A y-cropped array of shape (rows,channels,x,y,t).\n",
    "        \"\"\"\n",
    "        fovdf = self.meta_handle.read_df(\"global\", read_metadata=False)\n",
    "        fovdf = fovdf.loc[(slice(None), slice(self.t_range[0], self.t_range[1])), :]\n",
    "\n",
    "        filedf = fovdf.reset_index(inplace=False)\n",
    "        filedf = filedf.set_index(\n",
    "            [\"File Index\", \"Image Index\"], drop=True, append=False, inplace=False\n",
    "        )\n",
    "        filedf = filedf.sort_index()\n",
    "        working_filedf = filedf.loc[file_idx]\n",
    "\n",
    "        timepoint_indices = working_filedf[\"timepoints\"].unique().tolist()\n",
    "        image_indices = (\n",
    "            working_filedf.index.get_level_values(\"Image Index\").unique().tolist()\n",
    "        )\n",
    "\n",
    "        first_idx, last_idx = (\n",
    "            timepoint_indices[0] - self.t_range[0],\n",
    "            timepoint_indices[-1] - self.t_range[0],\n",
    "        )  # CHANGED\n",
    "\n",
    "        y_drift = drift_orientation_and_initend_future[0][first_idx : last_idx + 1]\n",
    "\n",
    "        valid_orientations, valid_y_ends = drift_orientation_and_initend_future[1:]\n",
    "\n",
    "        drift_corrected_edges = np.add.outer(y_drift, valid_y_ends[0])\n",
    "\n",
    "        channel_arr_list = []\n",
    "        for c, channel in enumerate(self.all_channels):\n",
    "            with h5py_cache.File(\n",
    "                self.hdf5path + \"/hdf5_\" + str(file_idx) + \".hdf5\",\n",
    "                \"r\",\n",
    "                chunk_cache_mem_size=self.metadata[\"chunk_cache_mem_size\"],\n",
    "            ) as imported_hdf5_handle:\n",
    "                img_arr = imported_hdf5_handle[channel][\n",
    "                    image_indices[0] : image_indices[-1] + 1\n",
    "                ]\n",
    "            time_list = []\n",
    "            lane_y_coords_list = []\n",
    "            for t in range(len(drift_corrected_edges)):\n",
    "                trench_ends_y = drift_corrected_edges[t]\n",
    "                row_list = []\n",
    "                lane_y_coords = []\n",
    "                for r, orientation in enumerate(valid_orientations):\n",
    "                    trench_end = trench_ends_y[r]\n",
    "                    if orientation == 0:\n",
    "                        upper = max(trench_end - padding_y, 0)\n",
    "                        lower = min(trench_end + trench_len_y, img_arr.shape[1])\n",
    "                    else:\n",
    "                        upper = max(trench_end - trench_len_y, 0)\n",
    "                        lower = min(trench_end + padding_y, img_arr.shape[1])\n",
    "                    lane_y_coords.append(upper)\n",
    "                    output_array = img_arr[t, upper:lower, :]\n",
    "                    row_list.append(output_array)\n",
    "                time_list.append(row_list)\n",
    "                lane_y_coords_list.append(lane_y_coords)\n",
    "            cropped_in_y = np.array(time_list)  # t x row x y x x\n",
    "            if len(cropped_in_y.shape) != 4:\n",
    "                print(\"Error in crop_y\")\n",
    "                raise\n",
    "            else:\n",
    "                channel_arr_list.append(cropped_in_y)\n",
    "        return channel_arr_list, lane_y_coords_list\n",
    "\n",
    "    def get_smoothed_x_percentiles(\n",
    "        self,\n",
    "        file_idx,\n",
    "        drift_orientation_and_initend_future,\n",
    "        padding_y,\n",
    "        trench_len_y,\n",
    "        x_percentile,\n",
    "        background_kernel_x,\n",
    "        smoothing_kernel_x,\n",
    "    ):\n",
    "\n",
    "        \"\"\"Summary.\n",
    "        Args:\n",
    "            array_tuple (tuple): A singleton tuple containing the y-cropped hdf5 array of shape (rows,x,y,t).\n",
    "            background_kernel_x (tuple): Two-entry tuple specifying a kernel size for performing background subtraction\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "            smoothing_kernel_x (tuple): Two-entry tuple specifying a kernel size for performing smoothing\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "        Returns:\n",
    "            array: A smoothed and background subtracted percentile array of shape (rows,x,t)\n",
    "        \"\"\"\n",
    "        channel_arr_list, _ = self.crop_y(\n",
    "            file_idx, drift_orientation_and_initend_future, padding_y, trench_len_y\n",
    "        )\n",
    "        cropped_in_y = channel_arr_list[0]\n",
    "\n",
    "        if self.invert:\n",
    "            cropped_in_y = sk.util.invert(cropped_in_y)\n",
    "        #         cropped_in_y = y_crop_future[0][0] # t x row x y x x     # (24, 1, 330, 2048)\n",
    "\n",
    "        x_percentiles_smoothed = []\n",
    "        for row_num in range(cropped_in_y.shape[1]):\n",
    "            cropped_in_y_seg = cropped_in_y[:, row_num]  # t x y x x\n",
    "            x_percentiles = np.percentile(\n",
    "                cropped_in_y_seg, x_percentile, axis=1\n",
    "            )  # t x x\n",
    "            x_background_filtered = x_percentiles - self.median_filter_2d(\n",
    "                x_percentiles, background_kernel_x\n",
    "            )\n",
    "            x_smooth_filtered = self.median_filter_2d(\n",
    "                x_background_filtered, smoothing_kernel_x\n",
    "            )\n",
    "            x_smooth_filtered[x_smooth_filtered < 0.0] = 0.0\n",
    "            x_percentiles_smoothed.append(x_smooth_filtered)\n",
    "        x_percentiles_smoothed = np.array(x_percentiles_smoothed)  # row x t x x\n",
    "        return x_percentiles_smoothed\n",
    "\n",
    "    def get_midpoints_from_mask(self, mask):\n",
    "        \"\"\"Using a boolean x mask, computes the positions of trench midpoints.\n",
    "        Args:\n",
    "            mask (array): x boolean array, specifying where trenches are present.\n",
    "        Returns:\n",
    "            array: array of trench midpoint x positions.\n",
    "        \"\"\"\n",
    "        transitions = mask[:-1].astype(int) - mask[1:].astype(int)\n",
    "\n",
    "        trans_up = np.where((transitions == -1))[0]\n",
    "        trans_dn = np.where((transitions == 1))[0]\n",
    "\n",
    "        if len(np.where(trans_dn > trans_up[0])[0]) > 0:\n",
    "            first_dn = np.where(trans_dn > trans_up[0])[0][0]\n",
    "            trans_dn = trans_dn[first_dn:]\n",
    "            trans_up = trans_up[: len(trans_dn)]\n",
    "            midpoints = (trans_dn + trans_up) // 2\n",
    "        else:\n",
    "            midpoints = []\n",
    "        return midpoints\n",
    "\n",
    "    def get_x_row_midpoints(self, x_percentiles_t, otsu_nbins, otsu_scaling):\n",
    "        \"\"\"Given an array of signal in x, determines the position of trench\n",
    "        midpoints.\n",
    "        Args:\n",
    "            x_percentiles_t (array): array of trench intensities in x, at time t.\n",
    "            otsu_nbins (int): Number of bins to use when applying Otsu's method to x-dimension signal.\n",
    "            otsu_scaling (float): Threshold scaling factor for Otsu's method thresholding.\n",
    "        Returns:\n",
    "            array: array of trench midpoint x positions.\n",
    "        \"\"\"\n",
    "\n",
    "        otsu_threshold = (\n",
    "            sk.filters.threshold_otsu(x_percentiles_t[:, np.newaxis], nbins=otsu_nbins)\n",
    "            * otsu_scaling\n",
    "        )\n",
    "\n",
    "        x_mask = x_percentiles_t > otsu_threshold\n",
    "        midpoints = self.get_midpoints_from_mask(x_mask)\n",
    "        return midpoints\n",
    "\n",
    "    def get_x_midpoints(self, x_percentiles_smoothed, otsu_nbins, otsu_scaling):\n",
    "        \"\"\"Given an x percentile array of shape (rows,t,x), determines the\n",
    "        trench midpoints of each row array at each time t.\n",
    "        Args:\n",
    "            x_percentiles_smoothed_array (array): A smoothed and background subtracted percentile array of shape (rows,x,t)\n",
    "            otsu_nbins (int): Number of bins to use when applying Otsu's method to x-dimension signal.\n",
    "            otsu_scaling (float): Threshold scaling factor for Otsu's method thresholding.\n",
    "        Returns:\n",
    "            list: A nested list of the form [row_list,[time_list,[midpoint_array]]].\n",
    "        \"\"\"\n",
    "        all_midpoints_list = []\n",
    "        for row in range(x_percentiles_smoothed.shape[0]):\n",
    "            row_x_percentiles = x_percentiles_smoothed[row]\n",
    "            all_midpoints = []\n",
    "            midpoints = self.get_x_row_midpoints(\n",
    "                row_x_percentiles[0], otsu_nbins, otsu_scaling\n",
    "            )\n",
    "            if len(midpoints) == 0:\n",
    "                return None\n",
    "            all_midpoints.append(midpoints)\n",
    "\n",
    "            for t in range(1, row_x_percentiles.shape[0]):\n",
    "                midpoints = self.get_x_row_midpoints(\n",
    "                    row_x_percentiles[t], otsu_nbins, otsu_scaling\n",
    "                )\n",
    "                if len(midpoints) / (len(all_midpoints[-1]) + 1) < 0.5:\n",
    "                    all_midpoints.append(all_midpoints[-1])\n",
    "                else:\n",
    "                    all_midpoints.append(midpoints)\n",
    "            all_midpoints_list.append(all_midpoints)\n",
    "        return all_midpoints_list\n",
    "\n",
    "    def compile_midpoint_futures(self, midpoint_futures):\n",
    "        num_rows = len(midpoint_futures[0])\n",
    "        all_midpoints_list = []\n",
    "        for row in range(num_rows):\n",
    "            row_midpoints_list = []\n",
    "            for midpoint_future in midpoint_futures:\n",
    "                row_midpoints_list += midpoint_future[row]\n",
    "            all_midpoints_list.append(row_midpoints_list)\n",
    "        return all_midpoints_list\n",
    "\n",
    "    def get_x_drift(self, midpoint_futures):\n",
    "        \"\"\"Given a list of midpoints, computes the average drift in x for every\n",
    "        timepoint.\n",
    "        Args:\n",
    "            all_midpoints_list (list): A nested list of the form [row_list,[time_list,[midpoint_array]]] containing\n",
    "            the trench midpoints.\n",
    "        Returns:\n",
    "            list: A nested list of the form [row_list,[time_list,[x_drift_int]]].\n",
    "        \"\"\"\n",
    "        all_midpoints_list = self.compile_midpoint_futures(midpoint_futures)\n",
    "\n",
    "        x_drift_list = []\n",
    "        for all_midpoints in all_midpoints_list:\n",
    "            x_drift = []\n",
    "            for t in range(len(all_midpoints) - 1):\n",
    "                diff_mat = np.subtract.outer(all_midpoints[t + 1], all_midpoints[t])\n",
    "                min_dist_idx = np.argmin(abs(diff_mat), axis=0)\n",
    "                min_dists = diff_mat[min_dist_idx]\n",
    "                median_translation = int(np.median(min_dists))\n",
    "                x_drift.append(median_translation)\n",
    "            net_x_drift = np.append(np.array([0]), np.add.accumulate(x_drift))\n",
    "            x_drift_list.append(net_x_drift)\n",
    "        return x_drift_list\n",
    "\n",
    "    def filter_midpoints(\n",
    "        self, all_midpoints, x_drift, trench_width_x, trench_present_thr\n",
    "    ):\n",
    "\n",
    "        drift_corrected_midpoints = []\n",
    "        for t in range(len(x_drift)):\n",
    "            drift_corrected_t = all_midpoints[t] - x_drift[t]\n",
    "            drift_corrected_midpoints.append(drift_corrected_t)\n",
    "        midpoints_up, midpoints_dn = (\n",
    "            all_midpoints[0] - trench_width_x // 2,\n",
    "            all_midpoints[0] + trench_width_x // 2 + 1,\n",
    "        )\n",
    "\n",
    "        trench_present_t = []\n",
    "        for t in range(len(drift_corrected_midpoints)):\n",
    "            above_mask = np.greater.outer(drift_corrected_midpoints[t], midpoints_up)\n",
    "            below_mask = np.less.outer(drift_corrected_midpoints[t], midpoints_dn)\n",
    "            in_bound_mask = above_mask * below_mask\n",
    "            trench_present = np.any(in_bound_mask, axis=0)\n",
    "            trench_present_t.append(trench_present)\n",
    "        trench_present_t = np.array(trench_present_t)\n",
    "        trench_present_perc = (\n",
    "            np.sum(trench_present_t, axis=0) / trench_present_t.shape[0]\n",
    "        )\n",
    "\n",
    "        presence_filter_mask = trench_present_perc >= trench_present_thr\n",
    "\n",
    "        midpoint_seeds = all_midpoints[0][presence_filter_mask]\n",
    "        return midpoint_seeds\n",
    "\n",
    "    def get_in_bounds(self, all_midpoints, x_drift, trench_width_x, trench_present_thr):\n",
    "        \"\"\"Produces and writes a trench mask of shape (y_dim,t_dim,x_dim). This\n",
    "        will be used to mask out trenches from the reshaped \"cropped_in_y\"\n",
    "        array at a later step.\n",
    "        Args:\n",
    "            cropped_in_y (array): A y-cropped hdf5 array of shape (rows,y,x,t) containing y-cropped image data.\n",
    "            all_midpoints (list): A list containing, for each time t, an array of trench midpoints.\n",
    "            x_drift (list): A list containing, for each time t, an int corresponding to the drift of the midpoints in x.\n",
    "            trench_width_x (int): Width to be used when cropping in the x-dimension.\n",
    "        Returns:\n",
    "            h5py.File: Hdf5 file handle corresponding to the trench mask hdf5 dataset\n",
    "            \"data\" of shape (y_dim,t_dim,x_dim).\n",
    "            int: Total number of trenches detected in the image.\n",
    "        \"\"\"\n",
    "\n",
    "        midpoint_seeds = self.filter_midpoints(\n",
    "            all_midpoints, x_drift, trench_width_x, trench_present_thr\n",
    "        )\n",
    "        corrected_midpoints = x_drift[:, np.newaxis] + midpoint_seeds[np.newaxis, :]\n",
    "\n",
    "        midpoints_up, midpoints_dn = (\n",
    "            corrected_midpoints - trench_width_x // 2,\n",
    "            corrected_midpoints + trench_width_x // 2 + 1,\n",
    "        )\n",
    "        stays_in_frame = np.all(midpoints_up >= 0, axis=0) * np.all(\n",
    "            midpoints_dn <= self.metadata[\"width\"], axis=0\n",
    "        )  # filters out midpoints that stay in the frame for the whole time...\n",
    "        no_overlap = np.append(\n",
    "            np.array([True]),\n",
    "            (corrected_midpoints[0, 1:] - corrected_midpoints[0, :-1])\n",
    "            >= (trench_width_x + 1),\n",
    "        )  # corrects for overlap\n",
    "        if np.sum(no_overlap) / len(no_overlap) < 0.9:\n",
    "            print(\"Trench overlap issue!!!\")\n",
    "\n",
    "        valid_mask = stays_in_frame * no_overlap\n",
    "        in_bounds = np.array([midpoints_up[:, valid_mask], midpoints_dn[:, valid_mask]])\n",
    "        k_tot = in_bounds.shape[2]\n",
    "\n",
    "        x_coords = in_bounds[0].T\n",
    "        return in_bounds, x_coords, k_tot\n",
    "\n",
    "    def get_all_in_bounds(\n",
    "        self, midpoint_futures, x_drift_future, trench_width_x, trench_present_thr\n",
    "    ):\n",
    "        \"\"\"Generates complete kymograph arrays for all trenches in the fov in\n",
    "        every channel listed in 'self.all_channels'. Writes hdf5 files\n",
    "        containing datasets of shape (trench_num,y_dim,x_dim,t_dim) for each\n",
    "        row,channel combination. Dataset keys follow the convention.\n",
    "        [\"[row_number]/[channel_name]\"].\n",
    "        Args:\n",
    "            cropped_in_y_handle (h5py.File): Hdf5 file handle corresponding to the y-cropped hdf5 dataset\n",
    "            \"data\" of shape (rows,channels,x,y,t).\n",
    "            all_midpoints_list (list): A nested list of the form [row_list,[time_list,[midpoint_array]]] containing\n",
    "            the trench midpoints.\n",
    "            x_drift_list (list): A nested list of the form [row_list,[time_list,[x_drift_int]]] containing the computed\n",
    "            drift in the x dimension.\n",
    "            trench_width_x (int): Width to be used when cropping in the x-dimension.\n",
    "        \"\"\"\n",
    "        all_midpoints_list = self.compile_midpoint_futures(midpoint_futures)\n",
    "\n",
    "        in_bounds_list = []\n",
    "        x_coords_list = []\n",
    "        k_tot_list = []\n",
    "\n",
    "        for row_num, all_midpoints in enumerate(all_midpoints_list):\n",
    "            x_drift = x_drift_future[row_num]\n",
    "            in_bounds, x_coords, k_tot = self.get_in_bounds(\n",
    "                all_midpoints, x_drift, trench_width_x, trench_present_thr\n",
    "            )\n",
    "\n",
    "            in_bounds_list.append(in_bounds)\n",
    "            x_coords_list.append(x_coords)\n",
    "            k_tot_list.append(k_tot)\n",
    "\n",
    "        return in_bounds_list, x_coords_list, k_tot_list\n",
    "\n",
    "    def init_counting_arr(self, x_dim):\n",
    "        \"\"\"Initializes a counting array of shape (x_dim,) which counts from 0\n",
    "        to x_dim on axis 0.\n",
    "        Args:\n",
    "            x_dim (int): Size of x axis to use.\n",
    "        Returns:\n",
    "            array: Counting array to be used for masking out trenches in x.\n",
    "        \"\"\"\n",
    "        ones_arr = np.ones(x_dim)\n",
    "        counting_arr = np.add.accumulate(np.ones(x_dim)).astype(int) - 1\n",
    "        return counting_arr\n",
    "\n",
    "    def get_trench_mask(self, in_bounds, counting_arr):\n",
    "        \"\"\"Produce a trench mask of shape (y_dim,t_dim,x_dim) which will\n",
    "        correspond to the reshaped \"cropped_in_y\" array that will be made\n",
    "        later.\n",
    "        Args:\n",
    "            array_tuple (tuple): Singleton tuple containing the trench boundary array of shape\n",
    "            (2,t_dim,num_trenches)\n",
    "            cropped_in_y (array): A y-cropped hdf5 array of shape (rows,y,x,t) containing y-cropped image data.\n",
    "            counting_arr (array): Counting array to be used for masking out trenches in x, of shape (x_dim,).\n",
    "        Returns:\n",
    "            array: A trench mask of shape (y_dim,t_dim,x_dim).\n",
    "        \"\"\"\n",
    "        counting_arr_repeated = np.repeat(\n",
    "            counting_arr[:, np.newaxis], in_bounds.shape[1], axis=1\n",
    "        )\n",
    "        masks = []\n",
    "        print(in_bounds.shape)\n",
    "        for k in range(in_bounds.shape[2]):\n",
    "            mask = np.logical_and(\n",
    "                counting_arr_repeated > in_bounds[0, :, k],\n",
    "                counting_arr_repeated < in_bounds[1, :, k],\n",
    "            ).T\n",
    "            masks.append(mask)\n",
    "        all_mask = np.any(np.array(masks), axis=0)\n",
    "        k_mask = np.repeat(all_mask[np.newaxis, :, :], self.ttl_len_y, axis=0)\n",
    "        return k_mask\n",
    "\n",
    "    def apply_kymo_mask(self, k_mask, img_arr, k_tot):\n",
    "        \"\"\"Given a y-cropped image and a boolean trench mask of shape\n",
    "        (y_dim,t_dim,x_dim), masks that image to generate an output kymograph\n",
    "        of shape (trench_num,y_dim,x_dim,t_dim). Masked trenches must be a\n",
    "        fized size, so this only detects trenches that are totally in frame for\n",
    "        the whole timelapse.\n",
    "        Args:\n",
    "            array_tuple (tuple): Tuple containing the y-cropped hdf5 array of shape (t,y,x), and\n",
    "            the boolean trench mask of shape (y_dim,t_dim,x_dim).\n",
    "            row_num (int): Int specifying the current row.\n",
    "            k_tot (int): Int specifying the total number of detected trenches in the fov.\n",
    "        Returns:\n",
    "            array: Kymograph array of shape (trench_num,y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "\n",
    "        img_arr_swap = np.moveaxis(img_arr, (0, 1, 2), (1, 0, 2))\n",
    "        cropped_img_arr = img_arr_swap[k_mask]\n",
    "        cropped_img_arr = cropped_img_arr.reshape(\n",
    "            img_arr_swap.shape[0], img_arr_swap.shape[1], -1\n",
    "        )\n",
    "        cropped_img_arr = np.moveaxis(\n",
    "            cropped_img_arr, (0, 1, 2), (1, 0, 2)\n",
    "        )  # t x y x x\n",
    "        kymo_out = np.stack(\n",
    "            np.split(cropped_img_arr, k_tot, axis=2), axis=0\n",
    "        )  # k x t x y x x\n",
    "        return kymo_out\n",
    "\n",
    "    def crop_with_k_masks(\n",
    "        self, output_kymograph, cropped_in_y_list, kymo_mask, k_tot, row_num\n",
    "    ):\n",
    "        \"\"\"Generates and writes kymographs of a single row from the already\n",
    "        y-cropped image data, using a pregenerated kymograph mask of shape\n",
    "        (y_dim,t_dim,x_dim).\n",
    "        Args:\n",
    "            cropped_in_y_handle (h5py.File): Hdf5 file handle corresponding to the y-cropped hdf5 dataset\n",
    "            \"data\" of shape (rows,channels,x,y,t).\n",
    "            k_mask_handle (h5py.File): Hdf5 file handle corresponding to the trench mask hdf5 dataset\n",
    "            \"data\" of shape (y_dim,t_dim,x_dim).\n",
    "            row_num (int): The row number to crop kymographs from.\n",
    "            k_tot (int): Int specifying the total number of detected trenches in the fov.\n",
    "        \"\"\"\n",
    "\n",
    "        for c, channel in enumerate(self.all_channels):\n",
    "            dataset_name = str(row_num) + \"/\" + str(channel)\n",
    "            cropped_in_y = cropped_in_y_list[c][:, row_num]\n",
    "            kymo_out = self.apply_kymo_mask(\n",
    "                kymo_mask, cropped_in_y, k_tot\n",
    "            )  # k x t x y x x\n",
    "\n",
    "            hdf5_dataset = output_kymograph.create_dataset(\n",
    "                dataset_name,\n",
    "                data=kymo_out,\n",
    "                chunks=self.output_chunk_shape,\n",
    "                dtype=\"uint16\",\n",
    "            )\n",
    "\n",
    "    def crop_x(\n",
    "        self,\n",
    "        file_idx,\n",
    "        drift_orientation_and_initend_future,\n",
    "        in_bounds_future,\n",
    "        padding_y,\n",
    "        trench_len_y,\n",
    "    ):\n",
    "        \"\"\"Generates complete kymograph arrays for all trenches in the fov in\n",
    "        every channel listed in 'self.all_channels'. Writes hdf5 files\n",
    "        containing datasets of shape (trench_num,y_dim,x_dim,t_dim) for each\n",
    "        row,channel combination. Dataset keys follow the convention.\n",
    "        [\"[row_number]/[channel_name]\"].\n",
    "        Args:\n",
    "            cropped_in_y_handle (h5py.File): Hdf5 file handle corresponding to the y-cropped hdf5 dataset\n",
    "            \"data\" of shape (rows,channels,x,y,t).\n",
    "            all_midpoints_list (list): A nested list of the form [row_list,[time_list,[midpoint_array]]] containing\n",
    "            the trench midpoints.\n",
    "            x_drift_list (list): A nested list of the form [row_list,[time_list,[x_drift_int]]] containing the computed\n",
    "            drift in the x dimension.\n",
    "            trench_width_x (int): Width to be used when cropping in the x-dimension.\n",
    "        \"\"\"\n",
    "        fovdf = self.meta_handle.read_df(\"global\", read_metadata=False)\n",
    "        fovdf = fovdf.loc[(slice(None), slice(self.t_range[0], self.t_range[1])), :]\n",
    "        filedf = fovdf.reset_index(inplace=False)\n",
    "        filedf = filedf.set_index(\n",
    "            [\"File Index\", \"Image Index\"], drop=True, append=False, inplace=False\n",
    "        )\n",
    "        filedf = filedf.sort_index()\n",
    "        working_filedf = filedf.loc[file_idx]\n",
    "\n",
    "        timepoint_indices = working_filedf[\"timepoints\"].unique().tolist()\n",
    "        image_indices = (\n",
    "            working_filedf.index.get_level_values(\"Image Index\").unique().tolist()\n",
    "        )\n",
    "        first_idx, last_idx = (\n",
    "            timepoint_indices[0] - self.t_range[0],\n",
    "            timepoint_indices[-1] - self.t_range[0],\n",
    "        )  # CHANGED\n",
    "\n",
    "        channel_arr_list, lane_y_coords_list = self.crop_y(\n",
    "            file_idx, drift_orientation_and_initend_future, padding_y, trench_len_y\n",
    "        )\n",
    "        num_rows = channel_arr_list[0].shape[1]\n",
    "\n",
    "        in_bounds_list, x_coords_list, k_tot_list = in_bounds_future\n",
    "        counting_arr = self.init_counting_arr(self.metadata[\"width\"])\n",
    "\n",
    "        with h5py_cache.File(\n",
    "            self.kymographpath + \"/kymograph_processed_\" + str(file_idx) + \".hdf5\",\n",
    "            \"w\",\n",
    "            chunk_cache_mem_size=self.output_chunk_cache_mem_size,\n",
    "        ) as output_kymograph:\n",
    "            for row_num in range(num_rows):\n",
    "                in_bounds, k_tot = (in_bounds_list[row_num], k_tot_list[row_num])\n",
    "                kymo_mask = self.get_trench_mask(\n",
    "                    in_bounds[:, first_idx : last_idx + 1], counting_arr\n",
    "                )\n",
    "\n",
    "                self.crop_with_k_masks(\n",
    "                    output_kymograph, channel_arr_list, kymo_mask, k_tot, row_num\n",
    "                )\n",
    "\n",
    "        return lane_y_coords_list\n",
    "\n",
    "    def save_coords(\n",
    "        self,\n",
    "        fov_idx,\n",
    "        x_crop_futures,\n",
    "        in_bounds_future,\n",
    "        drift_orientation_and_initend_future,\n",
    "    ):\n",
    "        fovdf = self.meta_handle.read_df(\"global\", read_metadata=False)\n",
    "        fovdf = fovdf.loc[(slice(None), slice(self.t_range[0], self.t_range[1])), :]\n",
    "        fovdf = fovdf.loc[fov_idx]\n",
    "\n",
    "        x_coords_list = in_bounds_future[1]\n",
    "        orientations = drift_orientation_and_initend_future[1]\n",
    "\n",
    "        y_coords_list = []\n",
    "        for j, file_idx in enumerate(fovdf[\"File Index\"].unique().tolist()):\n",
    "            working_filedf = fovdf[fovdf[\"File Index\"] == file_idx]\n",
    "            img_indices = working_filedf[\"Image Index\"].unique()\n",
    "            #             first_idx,last_idx = (img_indices[0],img_indices[-1])  CHANGE\n",
    "\n",
    "            #             [ 4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n",
    "            #  28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]\n",
    "            # 46\n",
    "            # [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
    "            # 21\n",
    "            y_coords_list += x_crop_futures[j]  # CHANGE\n",
    "        #             y_coords_list += x_crop_futures[j][first_idx:last_idx+1] # t x row list  # CHANGE\n",
    "\n",
    "        pixel_microns = self.metadata[\"pixel_microns\"]\n",
    "        y_coords = np.array(y_coords_list)  # t x row array\n",
    "        scaled_y_coords = y_coords * pixel_microns\n",
    "        t_len = scaled_y_coords.shape[0]\n",
    "        fs = np.repeat([fov_idx], t_len)\n",
    "        orit_dict = {0: \"top\", 1: \"bottom\"}\n",
    "        tpts = np.array(range(t_len))\n",
    "\n",
    "        missing_metadata = \"x\" not in fovdf.columns\n",
    "\n",
    "        if not missing_metadata:\n",
    "            global_x, global_y, ts, file_indices, img_indices = (\n",
    "                fovdf[\"x\"].values,\n",
    "                fovdf[\"y\"].values,\n",
    "                fovdf[\"t\"].values,\n",
    "                fovdf[\"File Index\"].values,\n",
    "                fovdf[\"Image Index\"].values,\n",
    "            )\n",
    "        else:\n",
    "            file_indices, img_indices = (\n",
    "                fovdf[\"File Index\"].values,\n",
    "                fovdf[\"Image Index\"].values,\n",
    "            )\n",
    "\n",
    "        pd_output = []\n",
    "\n",
    "        for l, x_coord in enumerate(x_coords_list):\n",
    "            scaled_x_coord = x_coord * pixel_microns\n",
    "            yt = scaled_y_coords[:, l]\n",
    "            orit = np.repeat([orit_dict[orientations[l]]], t_len)\n",
    "            if not missing_metadata:\n",
    "                global_yt = yt + global_y\n",
    "            ls = np.repeat([l], t_len)\n",
    "            for k in range(scaled_x_coord.shape[0]):\n",
    "                xt = scaled_x_coord[k]\n",
    "                if not missing_metadata:\n",
    "                    global_xt = xt + global_x\n",
    "                ks = np.repeat([k], t_len)\n",
    "                if not missing_metadata:\n",
    "                    pd_output.append(\n",
    "                        np.array(\n",
    "                            [\n",
    "                                fs,\n",
    "                                ls,\n",
    "                                ks,\n",
    "                                tpts,\n",
    "                                file_indices,\n",
    "                                img_indices,\n",
    "                                ts,\n",
    "                                orit,\n",
    "                                yt,\n",
    "                                xt,\n",
    "                                global_yt,\n",
    "                                global_xt,\n",
    "                            ]\n",
    "                        ).T\n",
    "                    )\n",
    "                else:\n",
    "                    pd_output.append(\n",
    "                        np.array(\n",
    "                            [fs, ls, ks, tpts, file_indices, img_indices, orit, yt, xt]\n",
    "                        ).T\n",
    "                    )\n",
    "\n",
    "        pd_output = np.concatenate(pd_output, axis=0)\n",
    "        if not missing_metadata:\n",
    "            df = pd.DataFrame(\n",
    "                pd_output,\n",
    "                columns=[\n",
    "                    \"fov\",\n",
    "                    \"row\",\n",
    "                    \"trench\",\n",
    "                    \"timepoints\",\n",
    "                    \"File Index\",\n",
    "                    \"Image Index\",\n",
    "                    \"time (s)\",\n",
    "                    \"lane orientation\",\n",
    "                    \"y (local)\",\n",
    "                    \"x (local)\",\n",
    "                    \"y (global)\",\n",
    "                    \"x (global)\",\n",
    "                ],\n",
    "            )\n",
    "            df = df.astype(\n",
    "                {\n",
    "                    \"fov\": int,\n",
    "                    \"row\": int,\n",
    "                    \"trench\": int,\n",
    "                    \"timepoints\": int,\n",
    "                    \"File Index\": int,\n",
    "                    \"Image Index\": int,\n",
    "                    \"time (s)\": float,\n",
    "                    \"lane orientation\": str,\n",
    "                    \"y (local)\": float,\n",
    "                    \"x (local)\": float,\n",
    "                    \"y (global)\": float,\n",
    "                    \"x (global)\": float,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            df = pd.DataFrame(\n",
    "                pd_output,\n",
    "                columns=[\n",
    "                    \"fov\",\n",
    "                    \"row\",\n",
    "                    \"trench\",\n",
    "                    \"timepoints\",\n",
    "                    \"File Index\",\n",
    "                    \"Image Index\",\n",
    "                    \"lane orientation\",\n",
    "                    \"y (local)\",\n",
    "                    \"x (local)\",\n",
    "                ],\n",
    "            )\n",
    "            df = df.astype(\n",
    "                {\n",
    "                    \"fov\": int,\n",
    "                    \"row\": int,\n",
    "                    \"trench\": int,\n",
    "                    \"timepoints\": int,\n",
    "                    \"File Index\": int,\n",
    "                    \"Image Index\": int,\n",
    "                    \"lane orientation\": str,\n",
    "                    \"y (local)\": float,\n",
    "                    \"x (local)\": float,\n",
    "                }\n",
    "            )\n",
    "        temp_meta_handle = pandas_hdf5_handler(\n",
    "            self.kymographpath + \"/temp_metadata_\" + str(fov_idx) + \".hdf5\"\n",
    "        )\n",
    "        temp_meta_handle.write_df(\"temp\", df)\n",
    "\n",
    "    def generate_kymographs(self, dask_controller):\n",
    "        writedir(self.kymographpath, overwrite=True)\n",
    "\n",
    "        dask_controller.futures = {}\n",
    "        fovdf = self.meta_handle.read_df(\"global\", read_metadata=True)\n",
    "        self.metadata = fovdf.metadata\n",
    "        fovdf = fovdf.loc[(slice(None), slice(self.t_range[0], self.t_range[1])), :]\n",
    "\n",
    "        filedf = fovdf.reset_index(inplace=False)\n",
    "        filedf = filedf.set_index(\n",
    "            [\"File Index\", \"Image Index\"], drop=True, append=False, inplace=False\n",
    "        )\n",
    "        filedf = filedf.sort_index()\n",
    "\n",
    "        file_list = filedf.index.get_level_values(\"File Index\").unique().values\n",
    "        fov_list = fovdf.index.get_level_values(\"fov\").unique().values\n",
    "        num_file_jobs = len(file_list)\n",
    "        num_fov_jobs = len(fov_list)\n",
    "\n",
    "        ### smoothed y percentiles ###\n",
    "\n",
    "        for k, file_idx in enumerate(file_list):\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.get_smoothed_y_percentiles,\n",
    "                file_idx,\n",
    "                self.y_percentile,\n",
    "                self.smoothing_kernel_y,\n",
    "                retries=1,\n",
    "            )\n",
    "            dask_controller.futures[\"Smoothed Y Percentiles: \" + str(file_idx)] = future\n",
    "\n",
    "        ### get trench row edges, y midpoints ###\n",
    "\n",
    "        for k, file_idx in enumerate(file_list):\n",
    "            smoothed_y_future = dask_controller.futures[\n",
    "                \"Smoothed Y Percentiles: \" + str(file_idx)\n",
    "            ]\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.get_trench_edges_y,\n",
    "                smoothed_y_future,\n",
    "                self.y_percentile_threshold,\n",
    "                self.y_min_edge_dist,\n",
    "                retries=1,\n",
    "            )\n",
    "\n",
    "            dask_controller.futures[\"Y Trench Edges: \" + str(file_idx)] = future\n",
    "\n",
    "        ### get y drift, orientations, init edges ###\n",
    "\n",
    "        for k, fov_idx in enumerate(fov_list):\n",
    "            working_fovdf = fovdf.loc[fov_idx]\n",
    "            working_files = working_fovdf[\"File Index\"].unique().tolist()\n",
    "            edges_futures = [\n",
    "                dask_controller.futures[\"Y Trench Edges: \" + str(file_idx)]\n",
    "                for file_idx in working_files\n",
    "            ]\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.get_ends_and_orientations,\n",
    "                fov_idx,\n",
    "                edges_futures,\n",
    "                self.expected_num_rows,\n",
    "                self.top_orientation,\n",
    "                self.orientation_on_fail,\n",
    "                self.y_min_edge_dist,\n",
    "                self.padding_y,\n",
    "                self.trench_len_y,\n",
    "                retries=1,\n",
    "            )\n",
    "            dask_controller.futures[\n",
    "                \"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(fov_idx)\n",
    "            ] = future\n",
    "\n",
    "        ### smoothed x percentiles ###\n",
    "\n",
    "        for k, file_idx in enumerate(file_list):\n",
    "            working_filedf = filedf.loc[file_idx]\n",
    "            fov_idx = working_filedf[\"fov\"].unique().tolist()[0]\n",
    "            drift_orientation_and_initend_future = dask_controller.futures[\n",
    "                \"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(fov_idx)\n",
    "            ]\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.get_smoothed_x_percentiles,\n",
    "                file_idx,\n",
    "                drift_orientation_and_initend_future,\n",
    "                self.padding_y,\n",
    "                self.trench_len_y,\n",
    "                self.x_percentile,\n",
    "                self.background_kernel_x,\n",
    "                self.smoothing_kernel_x,\n",
    "                retries=1,\n",
    "            )\n",
    "            dask_controller.futures[\"Smoothed X Percentiles: \" + str(file_idx)] = future\n",
    "\n",
    "        ### get x midpoints ###\n",
    "\n",
    "        for k, file_idx in enumerate(file_list):\n",
    "            smoothed_x_future = dask_controller.futures[\n",
    "                \"Smoothed X Percentiles: \" + str(file_idx)\n",
    "            ]\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.get_x_midpoints,\n",
    "                smoothed_x_future,\n",
    "                self.otsu_nbins,\n",
    "                self.otsu_scaling,\n",
    "                retries=1,\n",
    "            )\n",
    "            dask_controller.futures[\"X Midpoints: \" + str(file_idx)] = future\n",
    "\n",
    "        ### get x drift ###\n",
    "\n",
    "        for k, fov_idx in enumerate(fov_list):\n",
    "            working_fovdf = fovdf.loc[fov_idx]\n",
    "            working_files = working_fovdf[\"File Index\"].unique().tolist()\n",
    "            midpoint_futures = [\n",
    "                dask_controller.futures[\"X Midpoints: \" + str(file_idx)]\n",
    "                for file_idx in working_files\n",
    "            ]\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.get_x_drift, midpoint_futures, retries=1\n",
    "            )\n",
    "            dask_controller.futures[\"X Drift: \" + str(fov_idx)] = future\n",
    "\n",
    "        ### get kymograph masks ###\n",
    "\n",
    "        for k, fov_idx in enumerate(fov_list):\n",
    "            working_fovdf = fovdf.loc[fov_idx]\n",
    "            working_files = working_fovdf[\"File Index\"].unique().tolist()\n",
    "            midpoint_futures = [\n",
    "                dask_controller.futures[\"X Midpoints: \" + str(file_idx)]\n",
    "                for file_idx in working_files\n",
    "            ]\n",
    "            x_drift_future = dask_controller.futures[\"X Drift: \" + str(fov_idx)]\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.get_all_in_bounds,\n",
    "                midpoint_futures,\n",
    "                x_drift_future,\n",
    "                self.trench_width_x,\n",
    "                self.trench_present_thr,\n",
    "                retries=1,\n",
    "            )\n",
    "            dask_controller.futures[\"X In Bounds: \" + str(fov_idx)] = future\n",
    "\n",
    "        ### crop in x ###\n",
    "\n",
    "        for k, file_idx in enumerate(file_list):\n",
    "            working_filedf = filedf.loc[file_idx]\n",
    "            fov_idx = working_filedf[\"fov\"].unique().tolist()[0]\n",
    "            drift_orientation_and_initend_future = dask_controller.futures[\n",
    "                \"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(fov_idx)\n",
    "            ]\n",
    "            in_bounds_future = dask_controller.futures[\"X In Bounds: \" + str(fov_idx)]\n",
    "\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.crop_x,\n",
    "                file_idx,\n",
    "                drift_orientation_and_initend_future,\n",
    "                in_bounds_future,\n",
    "                self.padding_y,\n",
    "                self.trench_len_y,\n",
    "                retries=0,\n",
    "            )\n",
    "            dask_controller.futures[\"X Crop: \" + str(file_idx)] = future\n",
    "\n",
    "        ### get coords ###\n",
    "\n",
    "        for k, fov_idx in enumerate(fov_list):\n",
    "            working_fovdf = fovdf.loc[fov_idx]\n",
    "            working_files = working_fovdf[\"File Index\"].unique().tolist()\n",
    "            x_crop_futures = [\n",
    "                dask_controller.futures[\"X Crop: \" + str(file_idx)]\n",
    "                for file_idx in working_files\n",
    "            ]\n",
    "            in_bounds_future = dask_controller.futures[\"X In Bounds: \" + str(fov_idx)]\n",
    "            drift_orientation_and_initend_future = dask_controller.futures[\n",
    "                \"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(fov_idx)\n",
    "            ]\n",
    "\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.save_coords,\n",
    "                fov_idx,\n",
    "                x_crop_futures,\n",
    "                in_bounds_future,\n",
    "                drift_orientation_and_initend_future,\n",
    "                retries=1,\n",
    "            )  # ,priority=priority)\n",
    "            dask_controller.futures[\"Coords: \" + str(fov_idx)] = future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust.t_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust = kymograph_cluster(headpath=headpath, trenches_per_file=25, paramfile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writedir(kymoclust.kymographpath, overwrite=True)\n",
    "fovdf = kymoclust.meta_handle.read_df(\"global\", read_metadata=True)\n",
    "kymoclust.metadata = fovdf.metadata\n",
    "fovdf = fovdf.loc[(slice(4, 4), slice(kymoclust.t_range[0], kymoclust.t_range[1])), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedf = fovdf.reset_index(inplace=False)\n",
    "filedf = filedf.set_index(\n",
    "    [\"File Index\", \"Image Index\"], drop=True, append=False, inplace=False\n",
    ")\n",
    "filedf = filedf.sort_index()\n",
    "\n",
    "file_list = filedf.index.get_level_values(\"File Index\").unique().values\n",
    "fov_list = fovdf.index.get_level_values(\"fov\").unique().values\n",
    "num_file_jobs = len(file_list)\n",
    "num_fov_jobs = len(fov_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fovdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = {}\n",
    "### smoothed y percentiles ###\n",
    "\n",
    "for k, file_idx in enumerate(file_list):\n",
    "    future = kymoclust.get_smoothed_y_percentiles(\n",
    "        file_idx, kymoclust.y_percentile, kymoclust.smoothing_kernel_y\n",
    "    )\n",
    "    futures[\"Smoothed Y Percentiles: \" + str(file_idx)] = future\n",
    "\n",
    "### get trench row edges, y midpoints ###\n",
    "\n",
    "for k, file_idx in enumerate(file_list):\n",
    "    smoothed_y_future = futures[\"Smoothed Y Percentiles: \" + str(file_idx)]\n",
    "\n",
    "    future = kymoclust.get_trench_edges_y(\n",
    "        smoothed_y_future, kymoclust.y_percentile_threshold, kymoclust.y_min_edge_dist\n",
    "    )\n",
    "\n",
    "    futures[\"Y Trench Edges: \" + str(file_idx)] = future\n",
    "\n",
    "### get y drift, orientations, init edges ###\n",
    "\n",
    "for k, fov_idx in enumerate(fov_list):\n",
    "    working_fovdf = fovdf.loc[fov_idx]\n",
    "    working_files = working_fovdf[\"File Index\"].unique().tolist()\n",
    "    edges_futures = [\n",
    "        futures[\"Y Trench Edges: \" + str(file_idx)] for file_idx in working_files\n",
    "    ]\n",
    "    future = kymoclust.get_ends_and_orientations(\n",
    "        fov_idx,\n",
    "        edges_futures,\n",
    "        kymoclust.expected_num_rows,\n",
    "        kymoclust.top_orientation,\n",
    "        kymoclust.orientation_on_fail,\n",
    "        kymoclust.y_min_edge_dist,\n",
    "        kymoclust.padding_y,\n",
    "        kymoclust.trench_len_y,\n",
    "    )\n",
    "    futures[\n",
    "        \"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(fov_idx)\n",
    "    ] = future\n",
    "\n",
    "for k, file_idx in enumerate(file_list):\n",
    "    working_filedf = filedf.loc[file_idx]\n",
    "    fov_idx = working_filedf[\"fov\"].unique().tolist()[0]\n",
    "    drift_orientation_and_initend_future = futures[\n",
    "        \"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(fov_idx)\n",
    "    ]\n",
    "    future = kymoclust.get_smoothed_x_percentiles(\n",
    "        file_idx,\n",
    "        drift_orientation_and_initend_future,\n",
    "        kymoclust.padding_y,\n",
    "        kymoclust.trench_len_y,\n",
    "        kymoclust.x_percentile,\n",
    "        kymoclust.background_kernel_x,\n",
    "        kymoclust.smoothing_kernel_x,\n",
    "    )\n",
    "    futures[\"Smoothed X Percentiles: \" + str(file_idx)] = future\n",
    "\n",
    "\n",
    "### get x midpoints ###\n",
    "\n",
    "for k, file_idx in enumerate(file_list):\n",
    "    smoothed_x_future = futures[\"Smoothed X Percentiles: \" + str(file_idx)]\n",
    "    future = kymoclust.get_x_midpoints(\n",
    "        smoothed_x_future, kymoclust.otsu_nbins, kymoclust.otsu_scaling\n",
    "    )\n",
    "    futures[\"X Midpoints: \" + str(file_idx)] = future\n",
    "\n",
    "### get x drift ###\n",
    "\n",
    "for k, fov_idx in enumerate(fov_list):\n",
    "    working_fovdf = fovdf.loc[fov_idx]\n",
    "    working_files = working_fovdf[\"File Index\"].unique().tolist()\n",
    "    midpoint_futures = [\n",
    "        futures[\"X Midpoints: \" + str(file_idx)] for file_idx in working_files\n",
    "    ]\n",
    "    future = kymoclust.get_x_drift(midpoint_futures)\n",
    "    futures[\"X Drift: \" + str(fov_idx)] = future\n",
    "\n",
    "### get kymograph masks ###\n",
    "\n",
    "for k, fov_idx in enumerate(fov_list):\n",
    "    working_fovdf = fovdf.loc[fov_idx]\n",
    "    working_files = working_fovdf[\"File Index\"].unique().tolist()\n",
    "    midpoint_futures = [\n",
    "        futures[\"X Midpoints: \" + str(file_idx)] for file_idx in working_files\n",
    "    ]\n",
    "    x_drift_future = futures[\"X Drift: \" + str(fov_idx)]\n",
    "    future = kymoclust.get_all_in_bounds(\n",
    "        midpoint_futures,\n",
    "        x_drift_future,\n",
    "        kymoclust.trench_width_x,\n",
    "        kymoclust.trench_present_thr,\n",
    "    )\n",
    "    futures[\"X In Bounds: \" + str(fov_idx)] = future\n",
    "\n",
    "### crop in x ###\n",
    "\n",
    "\n",
    "for k, file_idx in enumerate(file_list):\n",
    "    working_filedf = filedf.loc[file_idx]\n",
    "    fov_idx = working_filedf[\"fov\"].unique().tolist()[0]\n",
    "    drift_orientation_and_initend_future = futures[\n",
    "        \"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(fov_idx)\n",
    "    ]\n",
    "    in_bounds_future = futures[\"X In Bounds: \" + str(fov_idx)]\n",
    "    future = kymoclust.crop_x(\n",
    "        file_idx,\n",
    "        drift_orientation_and_initend_future,\n",
    "        in_bounds_future,\n",
    "        kymoclust.padding_y,\n",
    "        kymoclust.trench_len_y,\n",
    "    )\n",
    "    futures[\"X Crop: \" + str(file_idx)] = future\n",
    "\n",
    "#         ### get coords ###\n",
    "\n",
    "for k, fov_idx in enumerate(fov_list):\n",
    "    working_fovdf = fovdf.loc[fov_idx]\n",
    "    working_files = working_fovdf[\"File Index\"].unique().tolist()\n",
    "    x_crop_futures = [futures[\"X Crop: \" + str(file_idx)] for file_idx in working_files]\n",
    "    in_bounds_future = futures[\"X In Bounds: \" + str(fov_idx)]\n",
    "    drift_orientation_and_initend_future = futures[\n",
    "        \"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(fov_idx)\n",
    "    ]\n",
    "\n",
    "    future = kymoclust.save_coords(\n",
    "        fov_idx, x_crop_futures, in_bounds_future, drift_orientation_and_initend_future\n",
    "    )\n",
    "    futures[\"Coords: \" + str(fov_idx)] = future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures[\"Coords: \" + str(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pandas_hdf5_handler(\n",
    "    \"/n/scratch2/de64/2019-05-31_validation_data/kymograph/temp_metadata_4.hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.read_df(\"temp\")[0:100:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "temp_list = []\n",
    "with h5py.File(\n",
    "    \"/n/scratch2/de64/2019-05-31_validation_data/kymograph/kymograph_processed_8.hdf5\",\n",
    "    \"r\",\n",
    ") as infile:\n",
    "    temp_list.append(infile[\"0/Phase\"][41])\n",
    "with h5py.File(\n",
    "    \"/n/scratch2/de64/2019-05-31_validation_data/kymograph/kymograph_processed_9.hdf5\",\n",
    "    \"r\",\n",
    ") as infile:\n",
    "    temp_list.append(infile[\"0/Phase\"][41])\n",
    "\n",
    "kymoboi = trenchripper.utils.kymo_handle()\n",
    "kymoboi.import_wrap(np.concatenate(temp_list, axis=0))\n",
    "plt.imshow(kymoboi.return_unwrap())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(futures[\"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(4)][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures[\"Y Trench Drift, Orientations and Initial Trench Ends: \" + str(4)][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        ### smoothed y percentiles ###\n",
    "\n",
    "        for k,file_idx in enumerate(file_list):\n",
    "            future = dask_controller.daskclient.submit(self.get_smoothed_y_percentiles,file_idx,\\\n",
    "                                        self.y_percentile,self.smoothing_kernel_y,retries=1)\n",
    "            dask_controller.futures[\"Smoothed Y Percentiles: \" + str(file_idx)] = future\n",
    "\n",
    "        ### get trench row edges, y midpoints ###\n",
    "\n",
    "        for k,file_idx in enumerate(file_list):\n",
    "            smoothed_y_future = dask_controller.futures[\"Smoothed Y Percentiles: \" + str(file_idx)]\n",
    "            future = dask_controller.daskclient.submit(self.get_trench_edges_y,smoothed_y_future,self.y_percentile_threshold,\\\n",
    "                                                       self.y_min_edge_dist,retries=1)\n",
    "\n",
    "            dask_controller.futures[\"Y Trench Edges: \" + str(file_idx)] = future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
