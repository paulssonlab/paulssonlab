{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "from ipywidgets import (\n",
    "    interact,\n",
    "    interactive,\n",
    "    fixed,\n",
    "    interact_manual,\n",
    "    FloatSlider,\n",
    "    IntSlider,\n",
    "    Dropdown,\n",
    "    IntText,\n",
    "    SelectMultiple,\n",
    "    Select,\n",
    "    IntRangeSlider,\n",
    "    FloatRangeSlider,\n",
    ")\n",
    "from skimage import filters, transform\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from paulssonlab.deaton.trenchripper.trenchripper.kymograph import kymograph_cluster\n",
    "from paulssonlab.deaton.trenchripper.trenchripper.segment import fluo_segmentation\n",
    "from paulssonlab.deaton.trenchripper.trenchripper.utils import (\n",
    "    kymo_handle,\n",
    "    pandas_hdf5_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_handle = pandas_hdf5_handler(\n",
    "    \"/n/scratch2/de64/2019-05-31_validation_data/metadata.hdf5\"\n",
    ")\n",
    "test = meta_handle.read_df(\"global\", read_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[pd.IndexSlice[[2, 36], 0:5], :]\n",
    "# df.loc[idx[:,[3,4]],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kymograph_interactive(kymograph_cluster):\n",
    "    def __init__(self, headpath):\n",
    "        \"\"\"The kymograph class is used to generate and visualize kymographs.\n",
    "        The central function of this class is the method 'generate_kymograph',\n",
    "        which takes an hdf5 file of images from a single fov and outputs an\n",
    "        hdf5 file containing kymographs from all detected trenches.\n",
    "\n",
    "        NOTE: I need to revisit the row detection, must ensure there can be no overlap...\n",
    "\n",
    "        Args:\n",
    "        \"\"\"\n",
    "        # break all_channels,fov_list,t_subsample_step=t_subsample_step\n",
    "        super(kymograph_interactive, self).__init__(headpath=headpath)\n",
    "\n",
    "        self.metadf = self.meta_handle.read_df(\"global\", read_metadata=True)\n",
    "        self.metadata = self.metadf.metadata\n",
    "        self.fov_list = self.metadf.index.get_level_values(\"fov\").unique().values\n",
    "        self.channels = self.metadata[\"channels\"]\n",
    "        self.timepoints_len = self.metadata[\"num_frames\"]\n",
    "\n",
    "        self.final_params = {}\n",
    "\n",
    "    def view_image(self, fov_idx, t, channel, invert):\n",
    "        img_entry = self.metadf.loc[fov_idx, t]\n",
    "        file_idx = int(img_entry[\"File Index\"])\n",
    "        img_idx = int(img_entry[\"Image Index\"])\n",
    "\n",
    "        with h5py.File(\n",
    "            self.headpath + \"/hdf5/hdf5_\" + str(file_idx) + \".hdf5\", \"r\"\n",
    "        ) as infile:\n",
    "            img_arr = infile[channel][img_idx, :, :]\n",
    "        if invert:\n",
    "            img_arr = sk.util.invert(img_arr)\n",
    "        plt.imshow(img_arr, cmap=\"Greys_r\")\n",
    "\n",
    "    def view_image_interactive(self):\n",
    "\n",
    "        interact(\n",
    "            self.view_image,\n",
    "            fov_idx=Select(description=\"FOV number:\", options=self.fov_list),\n",
    "            t=IntSlider(\n",
    "                value=0,\n",
    "                min=0,\n",
    "                max=self.timepoints_len - 1,\n",
    "                step=1,\n",
    "                continuous_update=False,\n",
    "            ),\n",
    "            channel=Dropdown(\n",
    "                options=self.channels,\n",
    "                value=self.channels[0],\n",
    "                description=\"Channel:\",\n",
    "                disabled=False,\n",
    "            ),\n",
    "            invert=Dropdown(options=[True, False], value=False),\n",
    "        )\n",
    "\n",
    "    #     def import_hdf5(self,i):\n",
    "    #         \"\"\"Performs initial import of the hdf5 file to be processed. Converts\n",
    "    #         the input hdf5 file's \"channel\" datasets into the first dimension of\n",
    "    #         the array, ordered as specified by 'self.all_channels'. Outputs a numpy\n",
    "    #         array.\n",
    "\n",
    "    #         Args:\n",
    "    #             i (int): Specifies the current fov index.\n",
    "\n",
    "    #         Returns:\n",
    "    #             array: A numpy array containing the hdf5 file image data.\n",
    "    #         \"\"\"\n",
    "    #         fov = self.fov_list[i]\n",
    "    #         fovdf = self.metadf.loc[fov]\n",
    "    #         last_idx = fovdf.index.get_level_values(0).unique().tolist()[-1]\n",
    "    #         fovdf = fovdf.loc[slice(0,last_idx,self.t_subsample_step),:]\n",
    "    #         file_indices = fovdf[\"File Index\"].unique().tolist()\n",
    "\n",
    "    #         channel_list = []\n",
    "    #         for channel in self.all_channels:\n",
    "    #             file_list = []\n",
    "    #             for j,file_idx in enumerate(file_indices):\n",
    "    #                 filedf = fovdf[fovdf[\"File Index\"]==file_idx]\n",
    "    #                 img_indices = filedf[\"Image Index\"].unique().tolist()\n",
    "    #                 with h5py.File(self.headpath + \"/hdf5/hdf5_\" + str(file_idx) + \".hdf5\", \"r\") as infile:\n",
    "    #                     file_list += [infile[channel][idx][:,:,np.newaxis] for idx in img_indices]\n",
    "    #             channel_list.append(np.concatenate(file_list,axis=2))\n",
    "    #         channel_array = np.array(channel_list)\n",
    "    #         if self.invert:\n",
    "    #             channel_array = sk.util.invert(channel_array)\n",
    "    #         return channel_array\n",
    "\n",
    "    #         writedir(self.kymographpath,overwrite=True)\n",
    "    #         ### smoothed y percentiles ###\n",
    "\n",
    "    #         self.fovdf = self.meta_handle.read_df(\"global\",read_metadata=True)\n",
    "    #         self.metadata = self.fovdf.metadata\n",
    "    #         self.filedf = self.fovdf.reset_index(inplace=False)\n",
    "    #         self.filedf = self.filedf.set_index([\"File Index\",\"Image Index\"], drop=True, append=False, inplace=False)\n",
    "    #         self.filedf = self.filedf.sort_index()\n",
    "    #         self.file_list = self.filedf.index.get_level_values(\"File Index\").unique().values\n",
    "    #         self.fov_list = self.fovdf.index.get_level_values(\"fov\").unique().values\n",
    "\n",
    "    def import_hdf5_files(\n",
    "        self, all_channels, seg_channel, invert, fov_list, t_subsample_step\n",
    "    ):\n",
    "        seg_channel_idx = all_channels.index(seg_channel)\n",
    "        all_channels.insert(0, all_channels.pop(seg_channel_idx))\n",
    "        self.all_channels = all_channels\n",
    "        self.seg_channel = all_channels[0]\n",
    "        self.fov_list = fov_list\n",
    "        self.t_subsample_step = t_subsample_step\n",
    "        self.invert = invert\n",
    "\n",
    "        self.fovdf = self.meta_handle.read_df(\"global\", read_metadata=True)\n",
    "        self.fovdf = self.fovdf.loc[\n",
    "            pd.IndexSlice[self.fov_list, :: self.t_subsample_step], :\n",
    "        ]\n",
    "\n",
    "        self.filedf = self.fovdf.reset_index(inplace=False)\n",
    "        self.filedf = self.filedf.set_index(\n",
    "            [\"File Index\", \"Image Index\"], drop=True, append=False, inplace=False\n",
    "        )\n",
    "        self.filedf = self.filedf.sort_index()\n",
    "        self.file_list = (\n",
    "            self.filedf.index.get_level_values(\"File Index\").unique().values\n",
    "        )\n",
    "\n",
    "    def import_hdf5_interactive(self):\n",
    "        import_hdf5 = interactive(\n",
    "            self.import_hdf5_files,\n",
    "            {\"manual\": True},\n",
    "            all_channels=fixed(self.channels),\n",
    "            seg_channel=Dropdown(options=self.channels, value=self.channels[0]),\n",
    "            invert=Dropdown(options=[True, False], value=False),\n",
    "            fov_list=SelectMultiple(options=self.fov_list),\n",
    "            t_subsample_step=IntSlider(value=10, min=0, max=200, step=1),\n",
    "        )\n",
    "        display(import_hdf5)\n",
    "\n",
    "    #         for k,file_idx in enumerate(file_list):\n",
    "    #             future = dask_controller.daskclient.submit(self.get_smoothed_y_percentiles,file_idx,\\\n",
    "    #                                         self.y_percentile,self.smoothing_kernel_y,retries=1)\n",
    "    #             dask_controller.futures[\"Smoothed Y Percentiles: \" + str(file_idx)] = future\n",
    "\n",
    "    #             def get_smoothed_y_percentiles(self,file_idx,y_percentile,smoothing_kernel_y):\n",
    "    #         \"\"\"For each imported array, computes the percentile along the x-axis of\n",
    "    #         the segmentation channel, generating a (y,t) array. Then performs\n",
    "    #         median filtering of this array for smoothing.\n",
    "\n",
    "    #         Args:\n",
    "    #             imported_hdf5_handle (h5py.File): Hdf5 file handle corresponding to the input hdf5 dataset\n",
    "    #             \"data\" of shape (channel,y,x,t).\n",
    "    #             y_percentile (int): Percentile to apply along the x-axis.\n",
    "    #             smoothing_kernel_y (tuple): Kernel to use for median filtering.\n",
    "\n",
    "    #         Returns:\n",
    "    #             h5py.File: Hdf5 file handle corresponding to the output hdf5 dataset \"data\", a smoothed\n",
    "    #             percentile array of shape (y,t).\n",
    "    #         \"\"\"\n",
    "    #         with h5py_cache.File(self.hdf5path+\"/hdf5_\"+str(file_idx)+\".hdf5\",\"r\",chunk_cache_mem_size=self.metadata[\"chunk_cache_mem_size\"]) as imported_hdf5_handle:\n",
    "    #             img_arr = imported_hdf5_handle[self.seg_channel][:] #t x y\n",
    "    #             if self.invert:\n",
    "    #                 img_arr = sk.util.invert(img_arr)\n",
    "    #             perc_arr = np.percentile(img_arr,y_percentile,axis=2,interpolation='lower')\n",
    "    #             y_percentiles_smoothed = self.median_filter_2d(perc_arr,smoothing_kernel_y)\n",
    "\n",
    "    #             min_qth_percentile = y_percentiles_smoothed.min(axis=1)[:, np.newaxis]\n",
    "    #             max_qth_percentile = y_percentiles_smoothed.max(axis=1)[:, np.newaxis]\n",
    "    #             y_percentiles_smoothed = (y_percentiles_smoothed - min_qth_percentile)/(max_qth_percentile - min_qth_percentile)\n",
    "\n",
    "    #         return y_percentiles_smoothed\n",
    "\n",
    "    def preview_y_precentiles(\n",
    "        self, y_percentile, smoothing_kernel_y_dim_0, y_percentile_threshold\n",
    "    ):\n",
    "\n",
    "        self.final_params[\"Y Percentile\"] = y_percentile\n",
    "        self.final_params[\"Y Smoothing Kernel\"] = smoothing_kernel_y_dim_0\n",
    "        self.final_params[\"Y Percentile Threshold\"] = y_percentile_threshold\n",
    "\n",
    "        y_percentiles_smoothed_list = []\n",
    "        for i, file_idx in enumerate(self.file_list):\n",
    "            y_percentiles_smoothed_list.append(\n",
    "                self.get_smoothed_y_percentiles(\n",
    "                    file_idx, y_percentile, smoothing_kernel_y_dim_0\n",
    "                )\n",
    "            )\n",
    "\n",
    "        y_percentiles_smoothed_list = self.map_to_fovs(\n",
    "            self.get_smoothed_y_percentiles,\n",
    "            imported_array_list,\n",
    "            y_percentile,\n",
    "            (smoothing_kernel_y_dim_0, 1),\n",
    "        )\n",
    "\n",
    "        self.plot_y_precentiles(\n",
    "            y_percentiles_smoothed_list, self.fov_list, y_percentile_threshold\n",
    "        )\n",
    "\n",
    "        self.y_percentiles_smoothed_list = y_percentiles_smoothed_list\n",
    "\n",
    "        return y_percentiles_smoothed_list\n",
    "\n",
    "    def preview_y_precentiles_interactive(self):\n",
    "        row_detection = interactive(\n",
    "            self.preview_y_precentiles,\n",
    "            {\"manual\": True},\n",
    "            imported_array_list=fixed(self.imported_array_list),\n",
    "            y_percentile=IntSlider(value=99, min=0, max=100, step=1),\n",
    "            smoothing_kernel_y_dim_0=IntSlider(value=29, min=1, max=200, step=2),\n",
    "            y_percentile_threshold=FloatSlider(value=0.2, min=0.0, max=1.0, step=0.01),\n",
    "        )\n",
    "        display(row_detection)\n",
    "\n",
    "    def plot_y_precentiles(\n",
    "        self, y_percentiles_smoothed_list, fov_list, y_percentile_threshold\n",
    "    ):\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ### Subplot dimensions of plot\n",
    "        root_list_len = np.ceil(np.sqrt(len(y_percentiles_smoothed_list)))\n",
    "\n",
    "        ### Looping through each fov\n",
    "        idx = 0\n",
    "        for j, y_percentiles_smoothed in enumerate(y_percentiles_smoothed_list):\n",
    "            ### Managing Subplots\n",
    "            idx += 1\n",
    "            ax = fig.add_subplot(root_list_len, root_list_len, idx, projection=\"3d\")\n",
    "\n",
    "            ### Making list of vertices (tuples) for use with PolyCollection\n",
    "            vert_arr = np.array(\n",
    "                [\n",
    "                    np.add.accumulate(\n",
    "                        np.ones(y_percentiles_smoothed.shape, dtype=int), axis=0\n",
    "                    ),\n",
    "                    y_percentiles_smoothed,\n",
    "                ]\n",
    "            )\n",
    "            verts = []\n",
    "            for t in range(vert_arr.shape[2]):\n",
    "                w_vert = vert_arr[:, :, t]\n",
    "                verts.append(\n",
    "                    [\n",
    "                        (w_vert[0, i], w_vert[1, i])\n",
    "                        for i in range(0, w_vert.shape[1], 10)\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            ### Making counting array for y position\n",
    "            zs = np.add.accumulate(np.ones(len(verts)))\n",
    "\n",
    "            ### Creating PolyCollection and add to plot\n",
    "            poly = PolyCollection(verts, facecolors=[\"b\"])\n",
    "            poly.set_alpha(0.5)\n",
    "            ax.add_collection3d(poly, zs=zs, zdir=\"y\")\n",
    "\n",
    "            ### Depecting thresholds as straight lines\n",
    "            x_len = y_percentiles_smoothed.shape[0]\n",
    "            y_len = y_percentiles_smoothed.shape[1]\n",
    "            thr_x = np.repeat(\n",
    "                np.add.accumulate(np.ones(x_len, dtype=int))[:, np.newaxis],\n",
    "                y_len,\n",
    "                axis=1,\n",
    "            ).T.flatten()\n",
    "            thr_y = np.repeat(np.add.accumulate(np.ones(y_len, dtype=int)), x_len)\n",
    "            thr_z = np.repeat(y_percentile_threshold, x_len * y_len)\n",
    "\n",
    "            for i in range(0, x_len * y_len, x_len):\n",
    "                ax.plot(\n",
    "                    thr_x[i : i + x_len],\n",
    "                    thr_y[i : i + x_len],\n",
    "                    thr_z[i : i + x_len],\n",
    "                    c=\"r\",\n",
    "                )\n",
    "\n",
    "            ### Plot lebels\n",
    "            ax.set_title(\"FOV: \" + str(fov_list[j]))\n",
    "            ax.set_xlabel(\"y position\")\n",
    "            ax.set_xlim3d(0, vert_arr[0, -1, 0])\n",
    "            ax.set_ylabel(\"time (s)\")\n",
    "            ax.set_ylim3d(0, len(verts))\n",
    "            ax.set_zlabel(\"intensity\")\n",
    "            ax.set_zlim3d(0, np.max(vert_arr[1]))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def preview_y_crop(\n",
    "        self,\n",
    "        y_percentiles_smoothed_list,\n",
    "        imported_array_list,\n",
    "        y_min_edge_dist,\n",
    "        padding_y,\n",
    "        trench_len_y,\n",
    "        expected_num_rows,\n",
    "        alternate_orientation,\n",
    "        orientation_detection,\n",
    "        orientation_on_fail,\n",
    "        images_per_row,\n",
    "    ):\n",
    "\n",
    "        self.final_params[\"Minimum Trench Length\"] = y_min_edge_dist\n",
    "        self.final_params[\"Y Padding\"] = padding_y\n",
    "        self.final_params[\"Trench Length\"] = trench_len_y\n",
    "        self.final_params[\"Orientation Detection Method\"] = orientation_detection\n",
    "        self.final_params[\n",
    "            \"Expected Number of Rows (Manual Orientation Detection)\"\n",
    "        ] = expected_num_rows\n",
    "        self.final_params[\"Alternate Orientation\"] = alternate_orientation\n",
    "        self.final_params[\n",
    "            \"Top Orientation when Row Drifts Out (Manual Orientation Detection)\"\n",
    "        ] = orientation_on_fail\n",
    "\n",
    "        y_percentile_threshold = self.final_params[\"Y Percentile Threshold\"]\n",
    "\n",
    "        get_trench_edges_y_output = self.map_to_fovs(\n",
    "            self.get_trench_edges_y, y_percentiles_smoothed_list, y_percentile_threshold\n",
    "        )\n",
    "        trench_edges_y_lists = [item[0] for item in get_trench_edges_y_output]\n",
    "        start_above_lists = [item[1] for item in get_trench_edges_y_output]\n",
    "        end_above_lists = [item[2] for item in get_trench_edges_y_output]\n",
    "\n",
    "        get_manual_orientations_output = self.map_to_fovs(\n",
    "            self.get_manual_orientations,\n",
    "            trench_edges_y_lists,\n",
    "            start_above_lists,\n",
    "            end_above_lists,\n",
    "            alternate_orientation,\n",
    "            expected_num_rows,\n",
    "            orientation_detection,\n",
    "            orientation_on_fail,\n",
    "            y_min_edge_dist,\n",
    "        )\n",
    "\n",
    "        orientations_list = [item[0] for item in get_manual_orientations_output]\n",
    "        drop_first_row_list = [item[1] for item in get_manual_orientations_output]\n",
    "        drop_last_row_list = [item[2] for item in get_manual_orientations_output]\n",
    "\n",
    "        y_ends_lists = self.map_to_fovs(\n",
    "            self.get_trench_ends,\n",
    "            trench_edges_y_lists,\n",
    "            start_above_lists,\n",
    "            end_above_lists,\n",
    "            orientations_list,\n",
    "            drop_first_row_list,\n",
    "            drop_last_row_list,\n",
    "            y_min_edge_dist,\n",
    "        )\n",
    "        y_drift_list = self.map_to_fovs(self.get_y_drift, y_ends_lists)\n",
    "\n",
    "        keep_in_frame_kernels_output = self.map_to_fovs(\n",
    "            self.keep_in_frame_kernels,\n",
    "            y_ends_lists,\n",
    "            y_drift_list,\n",
    "            imported_array_list,\n",
    "            orientations_list,\n",
    "            padding_y,\n",
    "            trench_len_y,\n",
    "        )\n",
    "        valid_y_ends_list = [item[0] for item in keep_in_frame_kernels_output]\n",
    "        valid_orientations_list = [item[1] for item in keep_in_frame_kernels_output]\n",
    "        cropped_in_y_list = self.map_to_fovs(\n",
    "            self.crop_y,\n",
    "            imported_array_list,\n",
    "            y_drift_list,\n",
    "            valid_y_ends_list,\n",
    "            valid_orientations_list,\n",
    "            padding_y,\n",
    "            trench_len_y,\n",
    "        )\n",
    "\n",
    "        self.plot_y_crop(\n",
    "            cropped_in_y_list,\n",
    "            imported_array_list,\n",
    "            self.fov_list,\n",
    "            valid_orientations_list,\n",
    "            images_per_row,\n",
    "        )\n",
    "\n",
    "        self.cropped_in_y_list = cropped_in_y_list\n",
    "\n",
    "        return cropped_in_y_list\n",
    "\n",
    "    def preview_y_crop_interactive(self):\n",
    "\n",
    "        y_cropping = interactive(\n",
    "            self.preview_y_crop,\n",
    "            {\"manual\": True},\n",
    "            y_percentiles_smoothed_list=fixed(self.y_percentiles_smoothed_list),\n",
    "            imported_array_list=fixed(self.imported_array_list),\n",
    "            y_min_edge_dist=IntSlider(value=50, min=5, max=1000, step=5),\n",
    "            padding_y=IntSlider(value=20, min=0, max=500, step=5),\n",
    "            trench_len_y=IntSlider(value=270, min=0, max=1000, step=5),\n",
    "            expected_num_rows=IntText(\n",
    "                value=2, description=\"Number of Rows:\", disabled=False\n",
    "            ),\n",
    "            alternate_orientation=Dropdown(\n",
    "                options=[True, False],\n",
    "                value=True,\n",
    "                description=\"Alternate Orientation?:\",\n",
    "                disabled=False,\n",
    "            ),\n",
    "            orientation_detection=Dropdown(\n",
    "                options=[0, 1, \"phase\"],\n",
    "                value=0,\n",
    "                description=\"Orientation:\",\n",
    "                disabled=False,\n",
    "            ),\n",
    "            orientation_on_fail=Dropdown(\n",
    "                options=[None, 0, 1],\n",
    "                value=0,\n",
    "                description=\"Orientation when < expected rows:\",\n",
    "                disabled=False,\n",
    "            ),\n",
    "            images_per_row=IntSlider(value=3, min=1, max=10, step=1),\n",
    "        )\n",
    "\n",
    "        display(y_cropping)\n",
    "\n",
    "    def plot_y_crop(\n",
    "        self,\n",
    "        cropped_in_y_list,\n",
    "        imported_array_list,\n",
    "        fov_list,\n",
    "        valid_orientations_list,\n",
    "        images_per_row,\n",
    "    ):\n",
    "\n",
    "        time_list = range(1, imported_array_list[0].shape[3] + 1)\n",
    "        time_per_img = len(time_list)\n",
    "        ttl_lanes = np.sum([len(item) for item in valid_orientations_list])\n",
    "        ttl_imgs = ttl_lanes * time_per_img\n",
    "\n",
    "        remaining_imgs = time_per_img % images_per_row\n",
    "        if remaining_imgs == 0:\n",
    "            rows_per_lane = time_per_img // images_per_row\n",
    "        else:\n",
    "            rows_per_lane = (time_per_img // images_per_row) + 1\n",
    "\n",
    "        nrows = rows_per_lane * ttl_lanes\n",
    "        ncols = images_per_row\n",
    "\n",
    "        fig, _ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "        idx = 0\n",
    "        for i, cropped_in_y in enumerate(cropped_in_y_list):\n",
    "            num_rows = len(valid_orientations_list[i])\n",
    "            for j in range(num_rows):\n",
    "                for k, t in enumerate(time_list):\n",
    "                    idx += 1\n",
    "                    ax = plt.subplot(nrows, ncols, idx)\n",
    "                    ax.axis(\"off\")\n",
    "                    ax.set_title(\n",
    "                        \"row=\" + str(j) + \",fov=\" + str(fov_list[i]) + \",t=\" + str(t)\n",
    "                    )\n",
    "                    ax.imshow(cropped_in_y[j, 0, :, :, k], cmap=\"Greys_r\")\n",
    "                if remaining_imgs != 0:\n",
    "                    for t in range(0, (images_per_row - remaining_imgs)):\n",
    "                        idx += 1\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.show()\n",
    "\n",
    "    def preview_x_percentiles(\n",
    "        self,\n",
    "        cropped_in_y_list,\n",
    "        t,\n",
    "        x_percentile,\n",
    "        background_kernel_x,\n",
    "        smoothing_kernel_x,\n",
    "        otsu_scaling,\n",
    "        min_threshold,\n",
    "    ):\n",
    "\n",
    "        self.final_params[\"X Percentile\"] = x_percentile\n",
    "        self.final_params[\"X Background Kernel\"] = background_kernel_x\n",
    "        self.final_params[\"X Smoothing Kernel\"] = smoothing_kernel_x\n",
    "        self.final_params[\"Otsu Threshold Scaling\"] = otsu_scaling\n",
    "        self.final_params[\"Minimum X Threshold\"] = min_threshold\n",
    "\n",
    "        smoothed_x_percentiles_list = self.map_to_fovs(\n",
    "            self.get_smoothed_x_percentiles,\n",
    "            cropped_in_y_list,\n",
    "            x_percentile,\n",
    "            (background_kernel_x, 1),\n",
    "            (smoothing_kernel_x, 1),\n",
    "        )\n",
    "        thresholds = []\n",
    "        for smoothed_x_percentiles_row in smoothed_x_percentiles_list:\n",
    "            for smoothed_x_percentiles in smoothed_x_percentiles_row:\n",
    "                x_percentiles_t = smoothed_x_percentiles[:, t]\n",
    "                thresholds.append(\n",
    "                    self.get_midpoints(x_percentiles_t, otsu_scaling, min_threshold)[1]\n",
    "                )\n",
    "        self.plot_x_percentiles(\n",
    "            smoothed_x_percentiles_list, self.fov_list, t, thresholds\n",
    "        )\n",
    "\n",
    "        self.smoothed_x_percentiles_list = smoothed_x_percentiles_list\n",
    "        all_midpoints_list, x_drift_list = self.preview_midpoints(\n",
    "            self.smoothed_x_percentiles_list\n",
    "        )\n",
    "\n",
    "        return smoothed_x_percentiles_list, all_midpoints_list, x_drift_list\n",
    "\n",
    "    def preview_midpoints(self, smoothed_x_percentiles_list):\n",
    "        otsu_scaling = self.final_params[\"Otsu Threshold Scaling\"]\n",
    "        min_threshold = self.final_params[\"Minimum X Threshold\"]\n",
    "\n",
    "        all_midpoints_list = self.map_to_fovs(\n",
    "            self.get_all_midpoints,\n",
    "            self.smoothed_x_percentiles_list,\n",
    "            otsu_scaling,\n",
    "            min_threshold,\n",
    "        )\n",
    "        self.plot_midpoints(all_midpoints_list, self.fov_list)\n",
    "        x_drift_list = self.map_to_fovs(self.get_x_drift, all_midpoints_list)\n",
    "\n",
    "        self.all_midpoints_list, self.x_drift_list = (all_midpoints_list, x_drift_list)\n",
    "\n",
    "        return all_midpoints_list, x_drift_list\n",
    "\n",
    "    def preview_x_percentiles_interactive(self):\n",
    "        trench_detection = interactive(\n",
    "            self.preview_x_percentiles,\n",
    "            {\"manual\": True},\n",
    "            cropped_in_y_list=fixed(self.cropped_in_y_list),\n",
    "            t=IntSlider(\n",
    "                value=0, min=0, max=self.cropped_in_y_list[0].shape[4] - 1, step=1\n",
    "            ),\n",
    "            x_percentile=IntSlider(value=85, min=50, max=100, step=1),\n",
    "            background_kernel_x=IntSlider(value=21, min=1, max=601, step=20),\n",
    "            smoothing_kernel_x=IntSlider(value=9, min=1, max=31, step=2),\n",
    "            otsu_scaling=FloatSlider(value=0.25, min=0.0, max=2.0, step=0.01),\n",
    "            min_threshold=IntSlider(value=0, min=0.0, max=65535, step=1),\n",
    "        )\n",
    "\n",
    "        display(trench_detection)\n",
    "\n",
    "    def plot_x_percentiles(self, smoothed_x_percentiles_list, fov_list, t, thresholds):\n",
    "        fig = plt.figure()\n",
    "        nrow = len(self.cropped_in_y_list)  # fovs\n",
    "        ncol = (sum([len(item) for item in self.cropped_in_y_list]) // nrow) + 1\n",
    "\n",
    "        idx = 0\n",
    "        for i, smoothed_x_percentiles_lanes in enumerate(smoothed_x_percentiles_list):\n",
    "            for j, smoothed_x_percentiles in enumerate(smoothed_x_percentiles_lanes):\n",
    "                idx += 1\n",
    "                data = smoothed_x_percentiles[:, t]\n",
    "                ax = fig.add_subplot(ncol, nrow, idx)\n",
    "                ax.plot(data)\n",
    "\n",
    "                current_threshold = thresholds[idx - 1]\n",
    "                threshold_data = np.repeat(current_threshold, len(data))\n",
    "                ax.plot(threshold_data, c=\"r\")\n",
    "                ax.set_title(\"FOV: \" + str(fov_list[i]) + \" Lane: \" + str(j))\n",
    "                ax.set_xlabel(\"x position\")\n",
    "                ax.set_ylabel(\"intensity\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def plot_midpoints(self, all_midpoints_list, fov_list):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca()\n",
    "\n",
    "        nrows = 2 * len(fov_list)\n",
    "        ncols = 2\n",
    "\n",
    "        idx = 0\n",
    "        for i, top_bottom_list in enumerate(all_midpoints_list):\n",
    "            for j, all_midpoints in enumerate(top_bottom_list):\n",
    "                idx += 1\n",
    "                ax = plt.subplot(nrows, ncols, idx)\n",
    "                ax.set_title(\"row=\" + str(j) + \",fov=\" + str(fov_list[i]))\n",
    "                data = np.concatenate(\n",
    "                    [\n",
    "                        np.array([item, np.ones(item.shape, dtype=int) * k]).T\n",
    "                        for k, item in enumerate(all_midpoints)\n",
    "                    ]\n",
    "                )\n",
    "                ax.scatter(data[:, 0], data[:, 1], alpha=0.7)\n",
    "                ax.set_xlabel(\"x position\")\n",
    "                ax.set_ylabel(\"time\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def preview_kymographs(\n",
    "        self,\n",
    "        cropped_in_y_list,\n",
    "        all_midpoints_list,\n",
    "        x_drift_list,\n",
    "        trench_width_x,\n",
    "        trench_present_thr,\n",
    "    ):\n",
    "        self.final_params[\"Trench Width\"] = trench_width_x\n",
    "        self.final_params[\"Trench Presence Threshold\"] = trench_present_thr\n",
    "\n",
    "        cropped_in_x_list = self.map_to_fovs(\n",
    "            self.get_crop_in_x,\n",
    "            cropped_in_y_list,\n",
    "            all_midpoints_list,\n",
    "            x_drift_list,\n",
    "            trench_width_x,\n",
    "            trench_present_thr,\n",
    "        )\n",
    "        corrected_midpoints_list = self.map_to_fovs(\n",
    "            self.get_corrected_midpoints,\n",
    "            all_midpoints_list,\n",
    "            x_drift_list,\n",
    "            trench_width_x,\n",
    "            trench_present_thr,\n",
    "        )\n",
    "\n",
    "        self.plot_kymographs(cropped_in_x_list, self.fov_list)\n",
    "        self.plot_midpoints(corrected_midpoints_list, self.fov_list)\n",
    "\n",
    "    def preview_kymographs_interactive(self):\n",
    "        interact_manual(\n",
    "            self.preview_kymographs,\n",
    "            cropped_in_y_list=fixed(self.cropped_in_y_list),\n",
    "            all_midpoints_list=fixed(self.all_midpoints_list),\n",
    "            x_drift_list=fixed(self.x_drift_list),\n",
    "            trench_width_x=IntSlider(value=30, min=2, max=1000, step=2),\n",
    "            trench_present_thr=FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05),\n",
    "        )\n",
    "\n",
    "    def plot_kymographs(self, cropped_in_x_list, fov_list, num_rows=2):\n",
    "        plt.figure()\n",
    "        idx = 0\n",
    "        ncol = num_rows\n",
    "        nrow = len(fov_list) * num_rows\n",
    "\n",
    "        for i, row_list in enumerate(cropped_in_x_list):\n",
    "            for j, channel in enumerate(row_list):\n",
    "                seg_channel = channel[0]\n",
    "                idx += 1\n",
    "                rand_k = np.random.randint(0, seg_channel.shape[0])\n",
    "                ax = plt.subplot(ncol, nrow, idx)\n",
    "                ex_kymo = seg_channel[rand_k]\n",
    "                self.plot_kymograph(ax, ex_kymo)\n",
    "                ax.set_title(\n",
    "                    \"row=\"\n",
    "                    + str(j)\n",
    "                    + \",fov=\"\n",
    "                    + str(fov_list[i])\n",
    "                    + \",trench=\"\n",
    "                    + str(rand_k)\n",
    "                )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_kymograph(self, ax, kymograph):\n",
    "        \"\"\"Helper function for plotting kymographs. Takes a kymograph array of\n",
    "        shape (y_dim,x_dim,t_dim).\n",
    "\n",
    "        Args:\n",
    "            kymograph (array): kymograph array of shape (y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        list_in_t = [kymograph[:, :, t] for t in range(kymograph.shape[2])]\n",
    "        img_arr = np.concatenate(list_in_t, axis=1)\n",
    "        ax.imshow(img_arr, cmap=\"Greys_r\")\n",
    "\n",
    "    def process_results(self):\n",
    "        self.final_params[\"All Channels\"] = self.all_channels\n",
    "        self.final_params[\"Invert\"] = self.invert\n",
    "\n",
    "        for key, value in self.final_params.items():\n",
    "            print(key + \" \" + str(value))\n",
    "\n",
    "    def write_param_file(self):\n",
    "        with open(self.headpath + \"/kymograph.par\", \"wb\") as outfile:\n",
    "            pickle.dump(self.final_params, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
