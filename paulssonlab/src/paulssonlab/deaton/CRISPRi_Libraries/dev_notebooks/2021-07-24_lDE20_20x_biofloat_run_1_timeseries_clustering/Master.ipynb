{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Timeseries Analysis of lDE20 (with lineage Dataframe ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import paulssonlab.deaton.trenchripper.trenchripper as tr\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_strong_KOs(df, sampling_thr=3, n_strongest=2):\n",
    "    for i in range(sampling_thr, 0, -1):\n",
    "        sampling_mask = df[\"N Observations\"] >= sampling_thr\n",
    "        mismatch_series = df[sampling_mask][\"N Mismatch\"]\n",
    "\n",
    "        for n in range(n_strongest, 0, -1):\n",
    "            if len(mismatch_series) >= n:\n",
    "                keep_indices = np.argsort(mismatch_series)[:n]\n",
    "                out_df = df[sampling_mask].iloc[keep_indices]\n",
    "\n",
    "                return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Initial Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = (\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Barcodes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=10,\n",
    "    memory=\"16GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df_pd = pd.read_pickle(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/lDE20_Lineage_Analysis_with_time_delt_filt.pkl\"\n",
    ")\n",
    "final_output_df_pd = final_output_df_pd[\n",
    "    ~final_output_df_pd[\"final cell timepoints list\"].isna()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Filter for \"Normal\" Sizes at Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lb_values = [\n",
    "    val\n",
    "    for item in final_output_df_pd.sample(frac=0.1)[\"Lb list\"].tolist()\n",
    "    for val in item\n",
    "]\n",
    "\n",
    "normal_fit = sp.stats.norm.fit(all_lb_values)\n",
    "normal_fit = sp.stats.norm(loc=normal_fit[0], scale=normal_fit[1])\n",
    "\n",
    "final_output_df_pd[\"Lb Log Likelihood\"] = final_output_df_pd[\"Lb list\"].apply(\n",
    "    lambda x: np.sum(normal_fit.logpdf(x)) / len(x)\n",
    ")\n",
    "final_output_df_pd[\"Lb Probability\"] = final_output_df_pd[\"Lb list\"].apply(\n",
    "    lambda x: np.exp(np.sum(normal_fit.logpdf(x)) / len(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_threshold = 10\n",
    "\n",
    "prob_threshold = np.nanpercentile(\n",
    "    final_output_df_pd[\"Lb Probability\"].tolist(), percentile_threshold\n",
    ")\n",
    "final_output_df_pd_filtered = final_output_df_pd[\n",
    "    final_output_df_pd[\"Lb Probability\"] > prob_threshold\n",
    "]\n",
    "print(prob_threshold)\n",
    "\n",
    "plt.hist(\n",
    "    final_output_df_pd[final_output_df_pd[\"Lb Probability\"] < prob_threshold][\n",
    "        \"Lb Probability\"\n",
    "    ].tolist(),\n",
    "    bins=50,\n",
    "    range=(0, 0.7),\n",
    ")\n",
    "plt.hist(\n",
    "    final_output_df_pd[final_output_df_pd[\"Lb Probability\"] >= prob_threshold][\n",
    "        \"Lb Probability\"\n",
    "    ].tolist(),\n",
    "    bins=50,\n",
    "    range=(0, 0.7),\n",
    ")\n",
    "# plt.hist(final_output_df_pd[\"Lb Probability\"].tolist(),bins=50,log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Pool Results by sgRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df_pd_groupby = final_output_df_pd_filtered.groupby(\"sgRNA\")\n",
    "\n",
    "merged_timeseries_df = (\n",
    "    final_output_df_pd_groupby.apply(\n",
    "        lambda x: np.array(\n",
    "            [val for item in x[\"final cell timepoints list\"].tolist() for val in item]\n",
    "        )\n",
    "    )\n",
    "    .to_frame()\n",
    "    .rename(columns={0: \"final cell timepoints\"})\n",
    ")\n",
    "merged_timeseries_df[\"init cell timepoints\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"cell timepoints list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Delta t list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Delta t list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Mean mCherry Intensity list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"Mean mCherry Intensity list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Mean Width list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Mean Width list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\"\n",
    "] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            val\n",
    "            for item in x[\"Mean mCherry Promoter Activity list (area normed)\"].tolist()\n",
    "            for val in item\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\"\n",
    "] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            val\n",
    "            for item in x[\n",
    "                \"Mean mCherry Promoter Activity list (length normed)\"\n",
    "            ].tolist()\n",
    "            for val in item\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Mean Area Increment list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"Mean Area Increment list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Mean Length Increment list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"Mean Length Increment list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "\n",
    "merged_timeseries_df[\"Sb list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Sb list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Sd list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Sd list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"delS list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"delS list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Lb list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Lb list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Ld list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Ld list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"delL list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"delL list\"].tolist() for val in item])\n",
    ")\n",
    "\n",
    "merged_timeseries_df[\"phenotype trenchids\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"phenotype trenchid\"].tolist()\n",
    ")\n",
    "merged_timeseries_df[\"Gene\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"Gene\"].iloc[0]\n",
    ")\n",
    "merged_timeseries_df[\"TargetID\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"TargetID\"].iloc[0]\n",
    ")\n",
    "merged_timeseries_df[\"N Mismatch\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"N Mismatch\"].iloc[0]\n",
    ")\n",
    "merged_timeseries_df[\"N Observations\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: len(x[\"phenotype trenchid\"].tolist())\n",
    ")\n",
    "merged_timeseries_df[\"Category\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"Category\"].iloc[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Filter sgRNAs for Strongest + All Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_timeseries_index_df = merged_timeseries_df.reset_index(drop=False)\n",
    "merged_timeseries_index_df_best_KO = (\n",
    "    merged_timeseries_index_df.groupby([\"TargetID\"])\n",
    "    .apply(lambda x: filter_strong_KOs(x))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "no_nan_mask = merged_timeseries_index_df_best_KO[\"sgRNA\"].apply(\n",
    "    lambda x: type(x) == str\n",
    ")\n",
    "merged_timeseries_index_df_best_KO = merged_timeseries_index_df_best_KO[no_nan_mask]\n",
    "merged_timeseries_index_df_best_KO = pd.concat(\n",
    "    [\n",
    "        merged_timeseries_index_df_best_KO,\n",
    "        merged_timeseries_df[merged_timeseries_df[\"Category\"] != \"Target\"].reset_index(\n",
    "            drop=False\n",
    "        ),\n",
    "    ]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_timeseries_index_df_nofilter = merged_timeseries_index_df.reset_index(drop=True)\n",
    "no_nan_mask_nofilter = merged_timeseries_index_df_nofilter[\"sgRNA\"].apply(\n",
    "    lambda x: type(x) == str\n",
    ")\n",
    "merged_timeseries_index_df_nofilter = merged_timeseries_index_df_nofilter[\n",
    "    no_nan_mask_nofilter\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### LOWESS Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "\n",
    "def timeseries_lowess_reg(df, t_label, y_label, min_tpt, max_tpt, bins, frac=0.33):\n",
    "    del_tpt = max_tpt - min_tpt\n",
    "    intervals = np.linspace(min_tpt, max_tpt, num=bins, dtype=float)\n",
    "\n",
    "    def lowess_reg(x_arr, y_arr, start=min_tpt, end=max_tpt, bins=bins, frac=frac):\n",
    "        intervals = np.linspace(start, end, num=bins, dtype=float)\n",
    "        w = lowess(y_arr, x_arr, frac=frac, xvals=intervals, it=1)\n",
    "        reg_x, reg_y = (intervals, w)\n",
    "        return reg_x, reg_y\n",
    "\n",
    "    lowess_result = df.apply(\n",
    "        lambda x: lowess_reg(x[t_label], x[y_label])[1], axis=1, meta=float\n",
    "    )\n",
    "\n",
    "    df[\"LOWESS Trace: \" + y_label] = lowess_result\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_timeseries_df_dask = dd.from_pandas(\n",
    "    merged_timeseries_index_df_best_KO, chunksize=50\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_tpt, max_tpt = 0, 143\n",
    "bins = 20\n",
    "intervals = np.linspace(min_tpt, max_tpt, num=bins, dtype=float)\n",
    "frac = 0.2\n",
    "\n",
    "merged_timeseries_df_dask = timeseries_lowess_reg(\n",
    "    merged_timeseries_df_dask,\n",
    "    \"final cell timepoints\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    "    frac=frac,\n",
    ")\n",
    "merged_timeseries_df_dask = timeseries_lowess_reg(\n",
    "    merged_timeseries_df_dask,\n",
    "    \"final cell timepoints\",\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    "    frac=frac,\n",
    ")\n",
    "merged_timeseries_df_dask = timeseries_lowess_reg(\n",
    "    merged_timeseries_df_dask,\n",
    "    \"final cell timepoints\",\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    "    frac=frac,\n",
    ")\n",
    "merged_timeseries_df_dask = timeseries_lowess_reg(\n",
    "    merged_timeseries_df_dask,\n",
    "    \"final cell timepoints\",\n",
    "    \"Mean Width list\",\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    "    frac=frac,\n",
    ")\n",
    "merged_timeseries_df_dask = timeseries_lowess_reg(\n",
    "    merged_timeseries_df_dask,\n",
    "    \"final cell timepoints\",\n",
    "    \"Delta t list\",\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    "    frac=frac,\n",
    ")\n",
    "\n",
    "merged_timeseries_df_dask = timeseries_lowess_reg(\n",
    "    merged_timeseries_df_dask,\n",
    "    \"final cell timepoints\",\n",
    "    \"Lb list\",\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    "    frac=frac,\n",
    ")\n",
    "merged_timeseries_df_dask = timeseries_lowess_reg(\n",
    "    merged_timeseries_df_dask,\n",
    "    \"final cell timepoints\",\n",
    "    \"Ld list\",\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    "    frac=frac,\n",
    ")\n",
    "merged_timeseries_df_dask = timeseries_lowess_reg(\n",
    "    merged_timeseries_df_dask,\n",
    "    \"final cell timepoints\",\n",
    "    \"delL list\",\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    "    frac=frac,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_timeseries_df_final = merged_timeseries_df_dask.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_timeseries_df_final = merged_timeseries_df_final[\n",
    "    merged_timeseries_df_final[\"LOWESS Trace: Lb list\"].apply(\n",
    "        lambda x: np.all(np.isfinite(x))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "controldf = merged_timeseries_df_final[\n",
    "    merged_timeseries_df_final[\"Category\"] == \"NoTarget\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_timeseries_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df = merged_timeseries_df_final[\n",
    "    merged_timeseries_df_final[\"Gene\"].apply(lambda x: \"ubiJ esrE\" in str(x))\n",
    "]\n",
    "rand_variant_df = filtered_df.sample(n=1)\n",
    "lowess_intervals = np.linspace(min_tpt, max_tpt, bins)\n",
    "plt.plot(lowess_intervals, rand_variant_df[\"LOWESS Trace: Lb list\"].iloc[0])\n",
    "plt.ylim(0, 8)\n",
    "plt.scatter(\n",
    "    rand_variant_df[\"final cell timepoints\"].iloc[0], rand_variant_df[\"Lb list\"].iloc[0]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    ",rand_variant_df[\"Lb list\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = rand_variant_df[\"Lb list\"].iloc[0][\n",
    "    rand_variant_df[\"final cell timepoints\"].apply(lambda x: x > 100).iloc[0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std((test - np.mean(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_variant_df[\"Gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lowess_intervals, rand_variant_df[\"LOWESS Trace: delL list\"].iloc[0])\n",
    "plt.ylim(0, 8)\n",
    "plt.scatter(\n",
    "    rand_variant_df[\"final cell timepoints\"].iloc[0],\n",
    "    rand_variant_df[\"delL list\"].iloc[0],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lowess_intervals, rand_variant_df[\"LOWESS Trace: Delta t list\"].iloc[0])\n",
    "plt.ylim(0, 16)\n",
    "plt.scatter(\n",
    "    rand_variant_df[\"final cell timepoints\"].iloc[0],\n",
    "    rand_variant_df[\"Delta t list\"].iloc[0],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# controldf = timeseries_bin_df_output[timeseries_bin_df_output[\"Category\"]==\"NoTarget\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Euclidian Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "\n",
    "lowess_arr = np.array(merged_timeseries_df_final[\"LOWESS Trace: Delta t list\"].tolist())\n",
    "kmeans_lowess = skl.cluster.KMeans(n_clusters=40, random_state=0)\n",
    "kmeans_lowess.fit(lowess_arr)\n",
    "dist_to_center_lowess = kmeans_lowess.transform(lowess_arr)\n",
    "dist_to_center_lowess = np.min(dist_to_center_lowess, axis=1)\n",
    "predicted_lowess_clust = kmeans_lowess.predict(lowess_arr)\n",
    "unique_lowess, counts_lowess = np.unique(predicted_lowess_clust, return_counts=True)\n",
    "\n",
    "merged_timeseries_df_final[\n",
    "    \"LOWESS Trace: Delta t list Cluster Assignment\"\n",
    "] = predicted_lowess_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(16, 32))\n",
    "\n",
    "for i in range(kmeans_lowess.n_clusters):\n",
    "    ax[0].plot(\n",
    "        intervals,\n",
    "        kmeans_lowess.cluster_centers_.T[:, i],\n",
    "        label=\"Cluster \" + str(i),\n",
    "        linewidth=2,\n",
    "    )  # ,color=\"#56B4E9\")\n",
    "# ax[0].plot(intervals,kmeans_lowess.cluster_centers_.T[:,1],label=\"Cluster 1\",linewidth=2,color=\"#E69F00\")\n",
    "# ax[0].plot(intervals,kmeans_lowess.cluster_centers_.T[:,2],label=\"Cluster 2\",linewidth=2,color=\"#009E73\")\n",
    "# ax[0].plot(kmeans_area.cluster_centers_.T[:,3],label=\"Cluster 3\",linewidth=2,color=\"#CC79A7\")\n",
    "# ax[0].set_xlabel(\"Time ($\\Delta$ t = 4 mins)\",fontsize=20)\n",
    "ax[0].tick_params(labelsize=20)\n",
    "# ax[0].set_ylabel(\"Average Cell Size ($\\mu^2$)\",fontsize=20)\n",
    "ax[0].legend(fontsize=20)\n",
    "# ax[0].set_ylim(0.7,1.5)\n",
    "# ax[0].set_xlim(0.7,1.5)\n",
    "\n",
    "ax[1].bar(\n",
    "    [str(i) for i in range(0, kmeans_lowess.n_clusters)],\n",
    "    counts_lowess,\n",
    "    bottom=range(0, kmeans_lowess.n_clusters),\n",
    "    linewidth=1,\n",
    ")  # color=[\"#56B4E9\",\"#E69F00\",\"#009E73\"])\n",
    "# ax[1].set_xlabel(\"Cluster #\",fontsize=20)\n",
    "ax[1].tick_params(labelsize=20)\n",
    "# ax[1].set_ylabel(\"N sgRNAs\",fontsize=20)\n",
    "# ax[1].set_ylabel(\"N sgRNAs\",fontsize=20)\n",
    "# plt.savefig(\"2021-07-13_cluster_fig.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Correlations in Null Distribution (early timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_binned_vars(\n",
    "    ax,\n",
    "    df,\n",
    "    label_x,\n",
    "    label_y,\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    unwrap_list_items=False,\n",
    "    **scatterkwargs,\n",
    "):\n",
    "    timepoints = range(min_timepoint, max_timepoint)\n",
    "    df_sub = df[df[\"Timepoint Bin\"].isin(timepoints)]\n",
    "\n",
    "    x_list = df_sub[label_x].tolist()\n",
    "    y_list = df_sub[label_y].tolist()\n",
    "\n",
    "    if unwrap_list_items:\n",
    "        x_list = [val for item in x_list for val in item]\n",
    "        y_list = [val for item in y_list for val in item]\n",
    "\n",
    "    ax.scatter(x_list, y_list, **scatterkwargs)\n",
    "\n",
    "\n",
    "def scatter_means_and_binned_vals(\n",
    "    df,\n",
    "    control_df,\n",
    "    x_label,\n",
    "    y_label,\n",
    "    min_time=0,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 10),\n",
    "    ylim=(0, 10),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    "):\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "\n",
    "    scatter_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Bin Values\",\n",
    "        y_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=True,\n",
    "        alpha=alpha_list[0],\n",
    "        s=s_list[0],\n",
    "    )\n",
    "    ax.set_title(\"All Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "\n",
    "    scatter_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Mean\",\n",
    "        y_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        alpha=alpha_list[1],\n",
    "        s=s_list[1],\n",
    "    )\n",
    "    ax.set_title(\"sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Mean\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "\n",
    "    scatter_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": Bin Values\",\n",
    "        y_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=True,\n",
    "        alpha=alpha_list[2],\n",
    "        s=s_list[2],\n",
    "    )\n",
    "    ax.set_title(\"All Control Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 4)\n",
    "\n",
    "    scatter_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": Mean\",\n",
    "        y_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        alpha=alpha_list[3],\n",
    "        s=s_list[3],\n",
    "    )\n",
    "    ax.set_title(\"Control sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Mean\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def barchart_binned_vars(\n",
    "    ax,\n",
    "    df,\n",
    "    label_x,\n",
    "    label_y,\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    min_xval,\n",
    "    max_xval,\n",
    "    bins=10,\n",
    "    unwrap_list_items=False,\n",
    "    bar_width=0.1,\n",
    "    **scatterkwargs,\n",
    "):\n",
    "    timepoints = range(min_timepoint, max_timepoint)\n",
    "    df_sub = df[df[\"Timepoint Bin\"].isin(timepoints)]\n",
    "\n",
    "    x_list = df_sub[label_x].tolist()\n",
    "    y_list = df_sub[label_y].tolist()\n",
    "\n",
    "    if unwrap_list_items:\n",
    "        x_list = [val for item in x_list for val in item]\n",
    "        y_list = [val for item in y_list for val in item]\n",
    "\n",
    "    x_arr = np.array(x_list)\n",
    "    y_arr = np.array(y_list)\n",
    "\n",
    "    intervals = np.linspace(min_xval, max_xval, num=bins, dtype=float)\n",
    "\n",
    "    spacing = (max_xval - min_xval) / (bins - 1)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    err = []\n",
    "    for i in intervals:\n",
    "        selection = y_arr[(x_arr >= i) & (x_arr < (i + spacing))]\n",
    "        avg = np.mean(selection)\n",
    "        sem = sp.stats.sem(selection)\n",
    "        middle_point = i + (spacing / 2)\n",
    "\n",
    "        x.append(middle_point)\n",
    "        y.append(avg)\n",
    "        err.append(sem)\n",
    "\n",
    "    ax.bar(x, y, yerr=err, width=bar_width)\n",
    "\n",
    "\n",
    "def barchart_means_and_binned_vals(\n",
    "    df,\n",
    "    control_df,\n",
    "    x_label,\n",
    "    y_label,\n",
    "    min_xval,\n",
    "    max_xval,\n",
    "    bins=10,\n",
    "    min_time=0,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 10),\n",
    "    ylim=(0, 10),\n",
    "):\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "\n",
    "    barchart_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Bin Values\",\n",
    "        y_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        min_xval,\n",
    "        max_xval,\n",
    "        unwrap_list_items=True,\n",
    "    )\n",
    "    ax.set_title(\"All Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "\n",
    "    barchart_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Mean\",\n",
    "        y_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        min_xval,\n",
    "        max_xval,\n",
    "        unwrap_list_items=False,\n",
    "    )\n",
    "    ax.set_title(\"sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Mean\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "\n",
    "    barchart_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": Bin Values\",\n",
    "        y_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        min_xval,\n",
    "        max_xval,\n",
    "        unwrap_list_items=True,\n",
    "    )\n",
    "    ax.set_title(\"All Control Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 4)\n",
    "\n",
    "    barchart_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": Mean\",\n",
    "        y_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        min_xval,\n",
    "        max_xval,\n",
    "        unwrap_list_items=False,\n",
    "    )\n",
    "    ax.set_title(\"Control sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Mean\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def filter_binned_timeseries_df(\n",
    "    df, label, min_timepoint, max_timepoint, value_min, value_max, n_timepoints_min\n",
    "):\n",
    "    timepoint_mask = (df[\"Timepoint Bin\"] >= min_timepoint) & (\n",
    "        df[\"Timepoint Bin\"] <= max_timepoint\n",
    "    )\n",
    "    masked_df = df[timepoint_mask]\n",
    "    value_mask = masked_df.groupby(\"sgRNA\").apply(\n",
    "        lambda x: np.sum((x[label] >= value_min) & (x[label] <= value_max))\n",
    "        >= n_timepoints_min\n",
    "    )\n",
    "    sg_RNA_hits = masked_df[value_mask].index.tolist()\n",
    "    output_df = df.loc[sg_RNA_hits]\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "#### mCherry (Ribosome synthesis) and Growth\n",
    "\n",
    "Here, I note a correlation between the incremental growth rate and the mCherry promoter activity. This is a little fraught to interpret because part of the promoter activity measurement included a growth correction. \n",
    "\n",
    "The extra cluster of high mCherry activity may be a segmentation artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "##### mCherry Promoter Activity vs Added Length over cell cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"log\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1, 10000),\n",
    "    ylim=(0, 12),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "##### mCherry Intensity vs Added Length over cell cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"log\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(100, 100000),\n",
    "    ylim=(0, 12),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "##### mCherry Promoter Activity vs Average Length Increment (over cell cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"log\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1, 10000),\n",
    "    ylim=(0, 4),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 250),\n",
    "    ylim=(0.0, 0.6),\n",
    "    alpha_list=[0.01, 0.1, 0.3, 0.3],\n",
    "    s_list=[1, 2, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "##### mCherry Intensity vs Average Length Increment (over cell cycle)\n",
    "\n",
    "Here we see that the cluster in the promoter synthesis rate is being inherited from the incremental length measurements. This does not entirely seem to be a misassignment issue (one would expect some negative incremental values). Must be some kind of error given how large the values are through..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"log\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(100, 10000),\n",
    "    ylim=(0, 6),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"log\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(100, 10000),\n",
    "    ylim=(0, 1),\n",
    "    alpha_list=[0.01, 0.1, 0.3, 0.3],\n",
    "    s_list=[1, 2, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 5000),\n",
    "    ylim=(0, 0.6),\n",
    "    alpha_list=[0.01, 0.1, 0.3, 0.3],\n",
    "    s_list=[1, 2, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "#### mCherry (Ribosome synthesis) and Division\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    \"Delta t list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 300),\n",
    "    ylim=(0, 15),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "#### Growth and Division\n",
    "\n",
    "Here, we see that the abnormal length increment cluster is coming from cells annotated as singletons (dividing in a single timepoint)\n",
    "\n",
    "Probably a reasonable idea to filter cells as having to exist for at least 3 timepoints (12 mins) to be considered legitimate\n",
    "\n",
    "This is fixed in the current version, so the weird cluster will not appear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Length Increment list\",\n",
    "    \"Delta t list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 0.7),\n",
    "    ylim=(0, 12),\n",
    "    alpha_list=[0.1, 0.2, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "#### Width vs Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Length Increment list\",\n",
    "    \"Mean Width list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 0.7),\n",
    "    ylim=(0, 2),\n",
    "    alpha_list=[0.1, 0.2, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "#### Width vs Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    \"Mean Width list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 12),\n",
    "    ylim=(0, 2),\n",
    "    alpha_list=[0.1, 0.2, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "#### Added Size vs Birth Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 6),\n",
    "    ylim=(0, 6),\n",
    "    alpha_list=[0.1, 0.2, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    \"delL list\",\n",
    "    2,\n",
    "    4,\n",
    "    bins=10,\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1.9, 4.4),\n",
    "    ylim=(0, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### Histograms of Single Variables and Outlier Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_binned_vars(\n",
    "    ax, df, label_x, min_timepoint, max_timepoint, unwrap_list_items=False, **histkwargs\n",
    "):\n",
    "    timepoints = range(min_timepoint, max_timepoint)\n",
    "    df_sub = df[df[\"Timepoint Bin\"].isin(timepoints)]\n",
    "\n",
    "    x_list = df_sub[label_x].tolist()\n",
    "\n",
    "    if unwrap_list_items:\n",
    "        x_list = [val for item in x_list for val in item]\n",
    "\n",
    "    ax.hist(x_list, **histkwargs)\n",
    "\n",
    "\n",
    "def hist_means_and_binned_vals(\n",
    "    df,\n",
    "    control_df,\n",
    "    x_label,\n",
    "    min_time=0,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 10),\n",
    "    bins=25,\n",
    "    **histkwargs,\n",
    "):\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "\n",
    "    if xscale == \"log\":\n",
    "        bins = np.logspace(np.log10(xlim[0]), np.log10(xlim[1]), num=bins)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=True,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"All Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=True,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"All Control Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 4)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"Control sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "\n",
    "\n",
    "def hist_CV(\n",
    "    df,\n",
    "    control_df,\n",
    "    x_label,\n",
    "    min_time=0,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 10),\n",
    "    bins=25,\n",
    "    **histkwargs,\n",
    "):\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "\n",
    "    if xscale == \"log\":\n",
    "        bins = np.logspace(np.log10(xlim[0]), np.log10(xlim[1]), num=bins)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": CV\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"sgRNA CV\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": CV\")\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": CV\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"Control sgRNA CV\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": CV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "#### mCherry Intensity and Synthesis\n",
    "\n",
    "Note that repression of rne (Ribonuclease E) significantly decreases the amount of ribosome synthesis. Seems to do so in somewhat tunable manner (since many hits mapped to it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(500, 5000),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(500, 5000),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 1000),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 1000),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 2500\n",
    "value_max = 30000\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Intensity list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "high_mean_intensity_genes = set(unique)\n",
    "high_mean_intensity_sgRNA = hits.index.unique().tolist()\n",
    "\n",
    "print(\"High Mean Intensity Genes\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0\n",
    "value_max = 1200\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Intensity list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "low_mean_intensity_genes = set(unique)\n",
    "low_mean_intensity_sgRNA = hits.index.unique().tolist()\n",
    "\n",
    "print(\"Low Mean Intensity Genes\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(hits[hits[\"Gene\"] == \"rne\"][\"TargetID\"], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 200\n",
    "value_max = 5000\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Promoter Activity list (length normed): Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "high_promoter_syn_genes = set(unique)\n",
    "high_promoter_syn_sgRNA = hits.index.unique().tolist()\n",
    "\n",
    "print(\"High Promoter Synthesis Genes\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "#### Growth Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 2),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 2),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0.65\n",
    "value_max = 2.0\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean Length Increment list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "high_growth_genes = set(unique)\n",
    "high_growth_sgRNA = hits.index.unique().tolist()\n",
    "print(\"High Growth Rate (Length)\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0.0\n",
    "value_max = 0.15\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean Length Increment list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Low Growth Rate (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "\n",
    "low_growth_genes = set(unique)\n",
    "low_growth_sgRNA = hits.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "#### Division Rate\n",
    "\n",
    "Something is strange here...ftsZ is not coming through even through it comes through with the size analysis...\n",
    "\n",
    "Oh, wait of course its not here. It effects cell size not division rate (which is basically coupled to growth rate if we have homeostatic cell size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Delta t list\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 100),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Delta t list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 100),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 15\n",
    "value_max = 200\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Delta t list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "low_div_rate_genes = set(unique)\n",
    "low_div_rate_sgRNA = hits.index.unique().tolist()\n",
    "print(\"Low Division Rate\")\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "#### Added Size (Length units)\n",
    "\n",
    "This is where most of the division related genes come up in a consistent way\n",
    "\n",
    "At some point a manual check of the ribosome and RNA pol may be worth it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 5),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"delL list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 5),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 10\n",
    "value_min = 3.5\n",
    "value_max = 50\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"delL list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Large Added Size (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "large_delL_genes = set(unique)\n",
    "large_delL_sgRNA = hits.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0\n",
    "value_max = 2.5\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"delL list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Small Added Size (Length)\")\n",
    "print(unique)\n",
    "small_delL_genes = set(unique)\n",
    "small_delL_sgRNA = hits.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(list(large_cell_genes.intersection(small_cell_genes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "#### Birth Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 5),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    min_time=8,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 5),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 9\n",
    "value_min = 3.7\n",
    "value_max = 50\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Lb list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Large Birth Size (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "large_Lb_genes = set(unique)\n",
    "large_Lb_sgRNA = hits.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "#### Division Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Ld list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(2, 10),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Ld list\",\n",
    "    min_time=8,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(2, 10),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 9\n",
    "value_min = 7\n",
    "value_max = 50\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Ld list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Large Birth Size (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "large_Ld_genes = set(unique)\n",
    "large_Ld_sgRNA = hits.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "#### Wide Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Width list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0.5, 1.7),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Width list\",\n",
    "    min_time=8,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0.5, 1.7),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    densit
y=True,\n",
    "    log=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 1.4\n",
    "value_max = 2\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean Width list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Wide Cells\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "wide_cell_genes = set(unique)\n",
    "wide_cell_sgRNA = hits.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "#### Variability in Added Size (Length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "hist_CV(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0.0, 2.0),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_CV(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"delL list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0.0, 2.0),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0.75\n",
    "value_max = 2.0\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"delL list: CV\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"High CV delL Cells\")\n",
    "print(unique)\n",
    "variable_delL_genes = set(unique)\n",
    "variable_delL_sgRNA = hits.index.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "#### Variability in Birth Size (Length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "hist_CV(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0.0, 2.0),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_CV(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0.0, 2.0),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0.5\n",
    "value_max = 2.0\n",
    "n_timepoints_min = 3\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Lb list: CV\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"High CV Lb Cells\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "variable_Lb_genes = set(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output[\"Fano Test\"] = timeseries_bin_df_output[\n",
    "    \"Lb list: Bin Values\"\n",
    "].apply(lambda x: np.var(x) / np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(timeseries_bin_df_output[\"Fano Test\"], range=(0, 2), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 1.75\n",
    "value_max = 100.0\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Fano Test\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"High Fano Lb Cells\")\n",
    "print(unique[counts > 100])\n",
    "print(counts)\n",
    "variable_Lb_genes = set(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "### Major Phenotypic Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_mean_intensity_genes\n",
    "low_mean_intensity_genes\n",
    "high_growth_genes\n",
    "low_growth_genes\n",
    "low_div_rate_genes\n",
    "large_cell_genes\n",
    "small_cell_genes\n",
    "wide_cell_genes\n",
    "variable_delL_genes\n",
    "variable_Lb_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "#### Filtering for putative division/replication proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(large_cell_genes - high_mean_intensity_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(large_cell_genes - high_mean_intensity_genes - wide_cell_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    sorted(\n",
    "        list(\n",
    "            large_cell_genes\n",
    "            - high_mean_intensity_genes\n",
    "            - wide_cell_genes\n",
    "            - low_div_rate_genes\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(\n",
    "    list(\n",
    "        large_cell_genes\n",
    "        - high_mean_intensity_genes\n",
    "        - wide_cell_genes\n",
    "        - low_div_rate_genes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "#### Filtering for Genes Perturbing Ribosome Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = sorted(list(large_cell_genes.intersection(high_mean_intensity_genes)))\n",
    "[\"yagH\", \"ycgB\", \"yghJ\", \"yhcN\", \"ypaB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filter_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {},
   "source": [
    "### Adder Measurement for Genes of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df = timeseries_bin_df_output[timeseries_bin_df_output[\"Gene\"].isin([\"ypaB\"])]\n",
    "# filtered_df = timeseries_bin_df_output[timeseries_bin_df_output[\"Gene\"].isin([gene for gene in filter_list if \"thyA\" in gene])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart_means_and_binned_vals(\n",
    "    filtered_df,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    \"delL list\",\n",
    "    2,\n",
    "    4,\n",
    "    bins=10,\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1.9, 4.4),\n",
    "    ylim=(0, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "### PCA on Major Metrics\n",
    "\n",
    "Doesn't seem to be a good direction with the current data; maybe with additional sampling this will improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "### Genes of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "### Gene Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"yejM\" \"yghJ\" \"ypaB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_output_df_pd.groupby(\"sgRNA\").apply(lambda x: x.iloc[0])\n",
    "df[\"phenotype trenchids\"] = final_output_df_pd.groupby(\"sgRNA\").apply(\n",
    "    lambda x: x[\"phenotype trenchid\"].tolist()\n",
    ")\n",
    "df = df[\n",
    "    [\n",
    "        \"Gene\",\n",
    "        \"Target Sequence\",\n",
    "        \"phenotype trenchids\",\n",
    "        \"N Mismatch\",\n",
    "        \"N Target Sites\",\n",
    "        \"Category\",\n",
    "        \"Strand\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kymo_xarr = tr.kymo_xarr(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Growth_Division\"\n",
    ")\n",
    "wrapped_kymo_xarr = tr.kymo_xarr(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Growth_Division\",\n",
    "    unwrap=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gene_table_layout,\n",
    "    select_gene,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid,\n",
    ") = tr.linked_gene_table(\n",
    "    df, trenchids_as_list=True, trenchid_column=\"phenotype trenchids\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gene_table_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_display, save_button = tr.linked_kymograph_for_gene_table(\n",
    "    kymo_xarr,\n",
    "    wrapped_kymo_xarr,\n",
    "    df,\n",
    "    select_gene,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid=select_unpacked_trenchid,\n",
    "    trenchid_column=\"phenotype trenchids\",\n",
    "    y_scale=3,\n",
    "    x_window_size=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_button  ## NEED OPTION WHETHER OR NOT TO NORM SIGNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"log\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(100, 100000),\n",
    "    ylim=(0, 12),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output[\"Timepoint Bin\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 4\n",
    "max_timepoint = 8\n",
    "value_min = 4\n",
    "value_max = 12\n",
    "n_timepoints_min = 2\n",
    "\n",
    "\n",
    "def filter_binned_timeseries_df(\n",
    "    df, label, min_timepoint, max_timepoint, value_min, value_max, n_timepoints_min\n",
    "):\n",
    "    timepoint_mask = (df[\"Timepoint Bin\"] >= min_timepoint) & (\n",
    "        df[\"Timepoint Bin\"] <= max_timepoint\n",
    "    )\n",
    "    masked_df = df[timepoint_mask]\n",
    "    value_mask = masked_df.groupby(\"sgRNA\").apply(\n",
    "        lambda x: np.sum((x[label] >= value_min) & (x[label] <= value_max))\n",
    "        >= n_timepoints_min\n",
    "    )\n",
    "    sg_RNA_hits = masked_df[value_mask].index.tolist()\n",
    "    output_df = df.loc[sg_RNA_hits]\n",
    "    return output_df\n",
    "\n",
    "\n",
    "# hits = violin_bins.groupby(\"sgRNA\").apply(lambda x: (np.sum(x[x[\"Timepoint Bin\"]<7][\"Mean\"]>4)>1)&(np.sum(x[x[\"Timepoint Bin\"]>=7][\"Mean\"]<3)>1))\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Lb list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "filamenting_genes = unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = range(0, 3)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 6)\n",
    "timeseries_bin_df_output_sub = timeseries_bin_df_output[\n",
    "    timeseries_bin_df_output[\"Timepoint Bin\"].isin(timepoints)\n",
    "]\n",
    "fractional_increment = (\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"]\n",
    "    / timeseries_bin_df_output_sub[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"], fractional_increment, alpha=0.5, s=4\n",
    ")\n",
    "plt.show()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\n",
    "        \"Mean mCherry Promoter Activity list (area normed): Mean\"\n",
    "    ],\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(-1, 3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\n",
    "        \"Mean mCherry Promoter Activity list (area normed): Mean\"\n",
    "    ],\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_output_df_og = dd.read_parquet(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/lDE20_Final_Analysis\"\n",
    ")\n",
    "final_output_df = final_output_df_og[\n",
    "    [\"sgRNA\", \"timepoints\", \"area\", \"mean_intensity_wo_bkd\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_output_df_og[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oscillaty_boi = final_output_df_og[\n",
    "    final_output_df_og[\"sgRNA\"] == \"CACTTTGAGTACGATGGTGT\"\n",
    "].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(oscillaty_boi.groupby(\"timepoints\")[\"area\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(oscillaty_boi.groupby(\"timepoints\")[\"mean_intensity\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "mean_series_area = (\n",
    "    final_output_df.groupby([\"sgRNA\", \"timepoints\"])[\"area\"].mean().persist()\n",
    ")\n",
    "mean_series_intensity = (\n",
    "    final_output_df.groupby([\"sgRNA\", \"timepoints\"])[\"mean_intensity_wo_bkd\"]\n",
    "    .mean()\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "time_vectors_area = (\n",
    "    mean_series_area.compute().groupby(\"sgRNA\").apply(lambda x: np.array(x))\n",
    ")\n",
    "valid_time_vectors_area = time_vectors_area[time_vectors_area.apply(len) == 143]\n",
    "\n",
    "time_vectors_intensity = (\n",
    "    mean_series_intensity.compute().groupby(\"sgRNA\").apply(lambda x: np.array(x))\n",
    ")\n",
    "valid_time_vectors_intensity = time_vectors_intensity[\n",
    "    time_vectors_intensity.apply(len) == 143\n",
    "]\n",
    "\n",
    "time_vectors_area_X = np.array(valid_time_vectors_area.tolist())\n",
    "time_vectors_area_X_filtered = sp.signal.medfilt(\n",
    "    time_vectors_area_X, kernel_size=(1, 11)\n",
    ")\n",
    "\n",
    "time_vectors_intensity_X = np.array(valid_time_vectors_intensity.tolist())\n",
    "time_vectors_intensity_X_filtered = sp.signal.medfilt(\n",
    "    time_vectors_intensity_X, kernel_size=(1, 11)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_area = skl.cluster.KMeans(n_clusters=4, random_state=0)\n",
    "kmeans_area.fit(time_vectors_area_X_filtered[:, :-10])\n",
    "\n",
    "kmeans_intensity = skl.cluster.KMeans(n_clusters=4, random_state=0)\n",
    "kmeans_intensity.fit(time_vectors_intensity_X_filtered[:, :-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_to_center_area = kmeans_area.transform(time_vectors_area_X_filtered[:, :-10])\n",
    "dist_to_center_area = np.min(dist_to_center_area, axis=1)\n",
    "predicted_area_clust = kmeans_area.predict(time_vectors_area_X_filtered[:, :-10])\n",
    "\n",
    "dist_to_center_intensity = kmeans_intensity.transform(\n",
    "    time_vectors_intensity_X_filtered[:, :-10]\n",
    ")\n",
    "predicted_intensity_clust = kmeans_intensity.predict(\n",
    "    time_vectors_intensity_X_filtered[:, :-10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_area, counts_area = np.unique(predicted_area_clust, return_counts=True)\n",
    "unique_intensity, counts_intensity = np.unique(\n",
    "    predicted_intensity_clust, return_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 16))\n",
    "\n",
    "ax[0].plot(\n",
    "    kmeans_area.cluster_centers_.T[:, 0],\n",
    "    label=\"Cluster 0\",\n",
    "    linewidth=2,\n",
    "    color=\"#56B4E9\",\n",
    ")\n",
    "ax[0].plot(\n",
    "    kmeans_area.cluster_centers_.T[:, 1],\n",
    "    label=\"Cluster 1\",\n",
    "    linewidth=2,\n",
    "    color=\"#E69F00\",\n",
    ")\n",
    "ax[0].plot(\n",
    "    kmeans_area.cluster_centers_.T[:, 2],\n",
    "    label=\"Cluster 2\",\n",
    "    linewidth=2,\n",
    "    color=\"#009E73\",\n",
    ")\n",
    "ax[0].plot(\n",
    "    kmeans_area.cluster_centers_.T[:, 3],\n",
    "    label=\"Cluster 3\",\n",
    "    linewidth=2,\n",
    "    color=\"#CC79A7\",\n",
    ")\n",
    "ax[0].set_xlabel(\"Time ($\\Delta$ t = 4 mins)\", fontsize=20)\n",
    "ax[0].tick_params(labelsize=20)\n",
    "ax[0].set_ylabel(\"Average Cell Size ($\\mu^2$)\", fontsize=20)\n",
    "ax[0].legend(fontsize=20)\n",
    "\n",
    "ax[1].bar(\n",
    "    [\"0\", \"1\", \"2\", \"3\"],\n",
    "    counts_area,\n",
    "    bottom=[0, 1, 2, 3],\n",
    "    linewidth=1,\n",
    "    color=[\"#56B4E9\", \"#E69F00\", \"#009E73\", \"#CC79A7\"],\n",
    ")\n",
    "ax[1].set_xlabel(\"Cluster #\", fontsize=20)\n",
    "ax[1].tick_params(labelsize=20)\n",
    "ax[1].set_ylabel(\"N sgRNAs\", fontsize=20)\n",
    "ax[1].set_ylabel(\"N sgRNAs\", fontsize=20)\n",
    "# plt.savefig(\"2021-07-13_cluster_fig.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 16))\n",
    "\n",
    "ax[0].plot(\n",
    "    kmeans_intensity.cluster_centers_.T[:, 0],\n",
    "    label=\"Cluster 0\",\n",
    "    linewidth=2,\n",
    "    color=\"#56B4E9\",\n",
    ")\n",
    "ax[0].plot(\n",
    "    kmeans_intensity.cluster_centers_.T[:, 1],\n",
    "    label=\"Cluster 1\",\n",
    "    linewidth=2,\n",
    "    color=\"#E69F00\",\n",
    ")\n",
    "ax[0].plot(\n",
    "    kmeans_intensity.cluster_centers_.T[:, 2],\n",
    "    label=\"Cluster 2\",\n",
    "    linewidth=2,\n",
    "    color=\"#009E73\",\n",
    ")\n",
    "ax[0].plot(\n",
    "    kmeans_intensity.cluster_centers_.T[:, 3],\n",
    "    label=\"Cluster 3\",\n",
    "    linewidth=2,\n",
    "    color=\"#CC79A7\",\n",
    ")\n",
    "ax[0].set_xlabel(\"Time ($\\Delta$ t = 4 mins)\", fontsize=20)\n",
    "ax[0].tick_params(labelsize=20)\n",
    "ax[0].set_ylabel(\"Average Intensity (AU)\", fontsize=20)\n",
    "ax[0].legend(fontsize=20)\n",
    "\n",
    "ax[1].bar(\n",
    "    [\"0\", \"1\", \"2\", \"3\"],\n",
    "    counts_intensity,\n",
    "    bottom=[0, 1, 2, 3],\n",
    "    linewidth=1,\n",
    "    color=[\"#56B4E9\", \"#E69F00\", \"#009E73\", \"#CC79A7\"],\n",
    ")\n",
    "ax[1].set_xlabel(\"Cluster #\", fontsize=20)\n",
    "ax[1].tick_params(labelsize=20)\n",
    "ax[1].set_ylabel(\"N sgRNAs\", fontsize=20)\n",
    "# plt.savefig(\"2021-07-13_cluster_fig.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_mask_area = predicted_area_clust == 3\n",
    "hits_df = valid_time_vectors_area[filter_mask_area].to_frame()\n",
    "hits_df[\"Distance to Centroid\"] = dist_to_center_area[filter_mask_area]\n",
    "hits_df[\"Distance to Stable Intensity Centroid\"] = dist_to_center_intensity[\n",
    "    filter_mask_area, 0\n",
    "]\n",
    "hits_df = hits_df.rename(columns={\"area\": \"avg_area_trace\"})\n",
    "# hits_df = hits_df.sample(n=100)\n",
    "sgRNA_filtered_df = final_output_df_og[\n",
    "    final_output_df_og[\"sgRNA\"].isin(hits_df.index.tolist())\n",
    "]\n",
    "sgRNA_filtered_df_for_hist = sgRNA_filtered_df.groupby(\"phenotype trenchid\").apply(\n",
    "    lambda x: x.iloc[0]\n",
    ")\n",
    "sgRNA_filtered_df_for_hist = sgRNA_filtered_df_for_hist.set_index(\"sgRNA\")\n",
    "sgRNA_filtered_df_for_hist = sgRNA_filtered_df_for_hist.join(hits_df).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgRNA_filtered_df_for_hist.to_pickle(\"./short_cell_cluster_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftsZ_df = final_output_df_og[final_output_df_og[\"Gene\"] == \"ftsZ\"].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftsz_targets = ftsZ_df[\"TargetID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftsZ_df[ftsZ_df[\"TargetID\"] == ftsz_targets[2]][\"N Mismatch\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_df = ftsZ_df[ftsZ_df[\"TargetID\"] == ftsz_targets[2]]\n",
    "target_mean_series = target_df.groupby([\"N Mismatch\", \"timepoints\"])[\"area\"].mean()\n",
    "target_time_vectors = target_mean_series.groupby(\"N Mismatch\").apply(\n",
    "    lambda x: np.array(x)\n",
    ")\n",
    "target_time_vectors_X = np.array(target_time_vectors.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_time_vectors_X[0].T, label=\"N Mismatch = 8\")\n",
    "plt.plot(target_time_vectors_X[1].T, label=\"N Mismatch = 9\")\n",
    "plt.plot(target_time_vectors_X[2].T, label=\"N Mismatch = 10\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftsz_mean_series = ftsZ_df.groupby([\"sgRNA\", \"timepoints\"])[\"area\"].mean()\n",
    "ftsz_time_vectors = ftsz_mean_series.groupby(\"sgRNA\").apply(lambda x: np.array(x))\n",
    "ftsz_time_vectors_X = np.array(ftsz_time_vectors.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ftsz_time_vectors_X.T)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = ftsZ_df[ftsZ_df[\"TargetID\"] == ftsz_targets[3]]\n",
    "target_mean_series = target_df.groupby([\"N Mismatch\", \"timepoints\"])[\"area\"].mean()\n",
    "target_time_vectors = target_mean_series.groupby(\"N Mismatch\").apply(\n",
    "    lambda x: np.array(x)\n",
    ")\n",
    "target_time_vectors_X = np.array(target_time_vectors.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_time_vectors_X.T)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_series = final_output_df.groupby([\"sgRNA\", \"timepoints\"])[\"area\"].mean().persist()\n",
    "\n",
    "time_vectors = mean_series.compute().groupby(\"sgRNA\").apply(lambda x: np.array(x))\n",
    "valid_time_vectors = time_vectors[time_vectors.apply(len) == 143]\n",
    "\n",
    "time_vectors_X = np.array(valid_time_vectors.tolist())\n",
    "time_vectors_X_filtered = sp.signal.medfilt(time_vectors_X, kernel_size=(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_clust = kmeans.predict(time_vectors_X_filtered[:, :-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_to_center[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.predicted_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_clust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {},
   "source": [
    "#### Remeber kmeans++ good for oscillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = skl.mixture.BayesianGaussianMixture(n_components=5)\n",
    "gmm.fit(time_vectors_X_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gmm.means_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_ml.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vectors = mean_series.groupby(\"sgRNA\").apply(lambda x: np.array(x))\n",
    "time_vectors_X = np.array(time_vectors.tolist())\n",
    "centers, indices = skl.cluster.kmeans_plusplus(\n",
    "    time_vectors_X, n_clusters=3, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centers, indices = skl.cluster.kmeans_plusplus(\n",
    "    time_vectors_X, n_clusters=3, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(centers.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr.unlinked_kymograph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175",
   "metadata": {},
   "source": [
    "### Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import paulssonlab.deaton.trenchripper.trenchripper as tr\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headpath = \"/home/de64/scratch/de64/sync_folder/2021-05-27_lDE18_20x_run_1/Barcodes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"01:00:00\",\n",
    "    local=False,\n",
    "    n_workers=6,\n",
    "    memory=\"64GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kymo_xarr = tr.kymo_xarr(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Growth_Division\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgRNA_filtered_df_for_hist[\"Distance to Centroid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_level = 0.7\n",
    "min_intensity = 500\n",
    "n_trench_min = 3\n",
    "filtered_df = barcode_only_df[\n",
    "    (barcode_only_df[\"mVenus Mean Intensity: Median\"] > min_intensity)\n",
    "    & (\n",
    "        (\n",
    "            barcode_only_df[\"mVenus Fano Factor: SEM\"]\n",
    "            / barcode_only_df[\"mVenus Fano Factor: Mean\"]\n",
    "        )\n",
    "        < filter_level\n",
    "    )\n",
    "    & (\n",
    "        (\n",
    "            barcode_only_df[\"mVenus Mean Intensity: SEM\"]\n",
    "            / barcode_only_df[\"mVenus Mean Intensity: Mean\"]\n",
    "        )\n",
    "        < filter_level\n",
    "    )\n",
    "    & (barcode_only_df[\"N Trenches\"] >= n_trench_min)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kymo_xarr = tr.kymo_xarr(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-05-27_lDE18_20x_run_1/mVenus\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgRNA_filtered_df_for_hist.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = sgRNA_filtered_df_for_hist[\n",
    "    [\n",
    "        \"EcoWG1_id\",\n",
    "        \"Gene\",\n",
    "        \"Target Sites\",\n",
    "        \"N Target Sites\",\n",
    "        \"N Mismatch\",\n",
    "        \"Category\",\n",
    "        \"TargetID\",\n",
    "        \"phenotype trenchid\",\n",
    "        \"avg_area_trace\",\n",
    "        \"Distance to Centroid\",\n",
    "    ]\n",
    "]\n",
    "hist, trenchid_table, edges, select_histcolumn, select_trenchid = tr.linked_histogram(\n",
    "    working_df,\n",
    "    \"Distance to Centroid\",\n",
    "    trenchids_as_list=False,\n",
    "    maxperc=99,\n",
    "    trenchid_column=\"phenotype trenchid\",\n",
    "    height=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trenchid_table.opts(width=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_kymograph_display = tr.linked_kymograph_for_hist(\n",
    "    kymo_xarr,\n",
    "    working_df,\n",
    "    \"Distance to Centroid\",\n",
    "    edges,\n",
    "    select_histcolumn,\n",
    "    select_trenchid,\n",
    "    trenchid_column=\"phenotype trenchid\",\n",
    "    y_scale=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_kymograph_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    scatter,\n",
    "    trenchid_table,\n",
    "    unpack_trenchid_table,\n",
    "    select_scatter,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid,\n",
    ") = tr.linked_scatter(\n",
    "    filtered_df,\n",
    "    \"mVenus Mean Intensity: Median\",\n",
    "    \"mVenus Fano Factor: Median\",\n",
    "    trenchids_as_list=True,\n",
    "    maxperc=99,\n",
    "    trenchid_column=\"phenotype trenchids\",\n",
    "    height=600,\n",
    "    logx=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trenchid_table + unpack_trenchid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter_kymograph_display = tr.linked_kymograph_for_scatter(\n",
    "    kymo_xarr,\n",
    "    filtered_df,\n",
    "    \"mVenus Mean Intensity: Median\",\n",
    "    \"mVenus Fano Factor: Median\",\n",
    "    select_scatter,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid=select_unpacked_trenchid,\n",
    "    trenchid_column=\"phenotype trenchids\",\n",
    "    y_scale=3,\n",
    "    x_window_size=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter_kymograph_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "fano_outlier_percentile = 99\n",
    "\n",
    "filtered_df[\"Log mVenus Mean Intensity\"] = np.log10(\n",
    "    filtered_df[\"mVenus Mean Intensity: Median\"]\n",
    ").values\n",
    "filtered_df[\"Log mVenus Fano Factor\"] = np.log10(\n",
    "    filtered_df[\"mVenus Fano Factor: Median\"]\n",
    ").values\n",
    "is_nan_mask = np.logical_or(\n",
    "    np.isnan(filtered_df[\"Log mVenus Mean Intensity\"]),\n",
    "    np.isnan(filtered_df[\"Log mVenus Fano Factor\"]),\n",
    ")\n",
    "\n",
    "log_intensity = filtered_df[\"Log mVenus Mean Intensity\"][~is_nan_mask].values\n",
    "log_fano = filtered_df[\"Log mVenus Fano Factor\"][~is_nan_mask].values\n",
    "\n",
    "reg = LinearRegression().fit(log_intensity.reshape(-1, 1), log_fano)\n",
    "r = reg.score(log_intensity.reshape(-1, 1), log_fano)\n",
    "print(\"R squared: \" + str(r))\n",
    "\n",
    "corrected_fano = filtered_df[\"Log mVenus Fano Factor\"].values - (\n",
    "    reg.coef_[0] * filtered_df[\"Log mVenus Mean Intensity\"].values + reg.intercept_\n",
    ")\n",
    "perc = np.nanpercentile(corrected_fano, fano_outlier_percentile)\n",
    "high_fano_df = filtered_df[corrected_fano > perc]\n",
    "high_fano_complement_df = filtered_df[corrected_fano <= perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divergence analysis\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ref_seq = \"TTGACGGCTAGCTCAGTCCTAGGTACAGTGCTAGC\"\n",
    "ref_seq = np.array([char for char in ref_seq])\n",
    "\n",
    "filtered_df[\"Promoter Divergence\"] = 35 - filtered_df[\"Promoter\"].apply(\n",
    "    lambda x: np.sum(np.array([char for char in x]) == ref_seq)\n",
    ")\n",
    "filtered_df[\"-10 Divergence\"] = 12 - filtered_df[\"Promoter\"].apply(\n",
    "    lambda x: np.sum(np.array([char for char in x])[-12:] == ref_seq[-12:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_df = filtered_df[filtered_df[\"Promoter Divergence\"] < 5]\n",
    "sns.violinplot(\n",
    "    data=violin_df,\n",
    "    x=\"Promoter Divergence\",\n",
    "    y=\"mVenus Mean Intensity: Median\",\n",
    ")\n",
    "plt.ylim(0, 15000)\n",
    "plt.show()\n",
    "\n",
    "violin_df = filtered_df[filtered_df[\"-10 Divergence\"] < 5]\n",
    "sns.violinplot(\n",
    "    data=violin_df,\n",
    "    x=\"-10 Divergence\",\n",
    "    y=\"mVenus Mean Intensity: Median\",\n",
    ")\n",
    "plt.ylim(0, 15000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowess_arr = np.array(\n",
    "    merged_timeseries_df_final_masked[\"LOWESS Trace: Delta t list\"].tolist()\n",
    ")\n",
    "lowess_arr = TimeSeriesScalerMeanVariance().fit_transform(lowess_arr)\n",
    "km = TimeSeriesKMeans(\n",
    "    n_clusters=3, metric=\"dtw\", max_iter=5, max_iter_barycenter=5, random_state=0\n",
    ").fit(lowess_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(km.cluster_centers_[:, :, 0].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200",
   "metadata": {},
   "source": [
    "### Growth/Div (time dependent with bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import paulssonlab.deaton.trenchripper.trenchripper as tr\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = (\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Barcodes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=25,\n",
    "    memory=\"8GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205",
   "metadata": {},
   "source": [
    "#### Binned Plots for Exemplary Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df_pd = pd.read_pickle(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/lDE20_Lineage_Analysis_with_time.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df_pd_groupby = final_output_df_pd.groupby(\"sgRNA\")\n",
    "\n",
    "merged_timeseries_df = (\n",
    "    final_output_df_pd_groupby.apply(\n",
    "        lambda x: np.array(\n",
    "            [val for item in x[\"final cell timepoints list\"].tolist() for val in item]\n",
    "        )\n",
    "    )\n",
    "    .to_frame()\n",
    "    .rename(columns={0: \"final cell timepoints\"})\n",
    ")\n",
    "merged_timeseries_df[\"init cell timepoints\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"cell timepoints list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Delta t list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Delta t list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Mean mCherry Intensity list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"Mean mCherry Intensity list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Mean Width list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Mean Width list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\"\n",
    "] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            val\n",
    "            for item in x[\"Mean mCherry Promoter Activity list (area normed)\"].tolist()\n",
    "            for val in item\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\"\n",
    "] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            val\n",
    "            for item in x[\n",
    "                \"Mean mCherry Promoter Activity list (length normed)\"\n",
    "            ].tolist()\n",
    "            for val in item\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Mean Area Increment list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"Mean Area Increment list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Mean Length Increment list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"Mean Length Increment list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "\n",
    "merged_timeseries_df[\"Sb list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Sb list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Sd list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Sd list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"delS list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"delS list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Lb list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Lb list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Ld list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Ld list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"delL list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"delL list\"].tolist() for val in item])\n",
    ")\n",
    "\n",
    "merged_timeseries_df[\"phenotype trenchids\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"phenotype trenchid\"].tolist()\n",
    ")\n",
    "merged_timeseries_df[\"Gene\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"Gene\"].iloc[0]\n",
    ")\n",
    "merged_timeseries_df[\"TargetID\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"TargetID\"].iloc[0]\n",
    ")\n",
    "merged_timeseries_df[\"N Mismatch\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"N Mismatch\"].iloc[0]\n",
    ")\n",
    "merged_timeseries_df[\"Category\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"Category\"].iloc[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_timeseries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_bins(df, t_label, y_labels, min_tpt, max_tpt, bins):\n",
    "    del_tpt = max_tpt - min_tpt\n",
    "    intervals = np.linspace(min_tpt, max_tpt, num=bins, dtype=float)\n",
    "\n",
    "    timeseries_bin_dfs = []\n",
    "\n",
    "    for i in range(len(intervals) - 1):\n",
    "        bin_df = {}\n",
    "        bin_df[\"Bin Mean Timepoint\"] = np.mean(intervals[i : i + 2])\n",
    "        bin_df[\"Timepoint Bin\"] = i\n",
    "        for y_label in y_labels:\n",
    "            bin_df[y_label + \": Bin Values\"] = df.apply(\n",
    "                lambda x: x[y_label][\n",
    "                    (x[t_label] >= intervals[i]) & (x[t_label] < intervals[i + 1])\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "            bin_df[y_label + \": Mean\"] = bin_df[y_label + \": Bin Values\"].apply(\n",
    "                lambda x: np.mean(x)\n",
    "            )\n",
    "            bin_df[y_label + \": Standard Deviation\"] = bin_df[\n",
    "                y_label + \": Bin Values\"\n",
    "            ].apply(lambda x: np.std(x))\n",
    "            bin_df[y_label + \": CV\"] = (\n",
    "                bin_df[y_label + \": Standard Deviation\"] / bin_df[y_label + \": Mean\"]\n",
    "            )\n",
    "\n",
    "        timeseries_bin_df = pd.DataFrame(bin_df)\n",
    "        timeseries_bin_df.index = df.index\n",
    "        timeseries_bin_dfs.append(timeseries_bin_df)\n",
    "    timeseries_bin_df_output = (\n",
    "        pd.concat(timeseries_bin_dfs).join(df).set_index(\"sgRNA\").sort_index()\n",
    "    )\n",
    "\n",
    "    return timeseries_bin_df_output\n",
    "\n",
    "\n",
    "def filter_strong_KOs(df, sampling_thr=3, n_strongest=2):\n",
    "    for i in range(sampling_thr, 0, -1):\n",
    "        sampling_mask = df[\"N Mismatch\"] >= sampling_thr\n",
    "        mismatch_series = df[sampling_mask][\"N Mismatch\"]\n",
    "\n",
    "        for n in range(n_strongest + 1, 0, -1):\n",
    "            if len(mismatch_series) >= n_strongest:\n",
    "                keep_indices = np.argsort(mismatch_series)[:n_strongest]\n",
    "                out_df = df.iloc[keep_indices]\n",
    "\n",
    "                return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_timeseries_index_df = merged_timeseries_df.reset_index(drop=False)\n",
    "merged_timeseries_index_df_best_KO = (\n",
    "    merged_timeseries_index_df.groupby([\"TargetID\"])\n",
    "    .apply(lambda x: filter_strong_KOs(x))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "no_nan_mask = merged_timeseries_index_df_best_KO[\"sgRNA\"].apply(\n",
    "    lambda x: type(x) == str\n",
    ")\n",
    "merged_timeseries_index_df_best_KO = merged_timeseries_index_df_best_KO[no_nan_mask]\n",
    "merged_timeseries_index_df_best_KO = pd.concat(\n",
    "    [\n",
    "        merged_timeseries_index_df_best_KO,\n",
    "        merged_timeseries_df[merged_timeseries_df[\"Category\"] != \"Target\"].reset_index(\n",
    "            drop=False\n",
    "        ),\n",
    "    ]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tpt, max_tpt, bins = 0, 143, 10\n",
    "\n",
    "timeseries_bin_df_output = timeseries_bins(\n",
    "    merged_timeseries_index_df_best_KO,\n",
    "    \"final cell timepoints\",\n",
    "    [\n",
    "        \"Lb list\",\n",
    "        \"Delta t list\",\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"Mean Area Increment list\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    ],\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeseries_bin_df_output[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merged_timeseries_index_df_best_KO_sgRNA_sorted = merged_timeseries_index_df_best_KO.set_index(\"sgRNA\")\n",
    "# # indices = merged_timeseries_index_df_best_KO_sgRNA_sorted[merged_timeseries_index_df_best_KO_sgRNA_sorted.apply(lambda x: \"ftsL\" in str(x[\"Gene\"]), axis=1)].index.tolist()\n",
    "# indices = merged_timeseries_index_df_best_KO_sgRNA_sorted.index.tolist()\n",
    "\n",
    "# violin_bins = []\n",
    "# for i in range(bins-1):\n",
    "#     timeseries_bin = timeseries_bin_dfs[i].loc[indices][[\"Lb list: Mean\",'Delta t list: Mean',\"Gene\"]]\n",
    "# #     timeseries_bin = [val for item in timeseries_bin_dfs[i].loc[indices][\"Bin Values\"] for val in item]\n",
    "#     timeseries_bin[\"Timepoint Bin\"] = i\n",
    "\n",
    "#     violin_bins.append(timeseries_bin)\n",
    "# violin_bins = pd.concat(violin_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.violinplot(\n",
    "    data=violin_bins,\n",
    "    x=\"Timepoint Bin\",\n",
    "    y=\"Lb list: Mean\",\n",
    ")\n",
    "# plt.ylim(0,15)\n",
    "# sns.scatterplot(data=violin_bins,x=\"Timepoint Bin\",y=\"Mean\",)\n",
    "# sns.lineplot(data=violin_bins,x=\"Timepoint Bin\",y=\"Mean\",hue=\"Gene\",)\n",
    "# sns.lineplot(data=violin_bins,x=\"Timepoint Bin\",y=\"Mean\",hue=\"sgRNA\")\n",
    "# plt.ylim(0,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(\n",
    "    timeseries_bin_df_output[timeseries_bin_df_output[\"Timepoint Bin\"] == 8][\n",
    "        \"Lb list: Mean\"\n",
    "    ],\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_timepoint = 4\n",
    "max_timepoint = 8\n",
    "value_min = 4\n",
    "value_max = 12\n",
    "n_timepoints_min = 2\n",
    "\n",
    "\n",
    "def filter_binned_timeseries_df(\n",
    "    df, label, min_timepoint, max_timepoint, value_min, value_max, n_timepoints_min\n",
    "):\n",
    "    timepoint_mask = (df[\"Timepoint Bin\"] >= min_timepoint) & (\n",
    "        df[\"Timepoint Bin\"] <= max_timepoint\n",
    "    )\n",
    "    masked_df = df[timepoint_mask]\n",
    "    value_mask = masked_df.groupby(\"sgRNA\").apply(\n",
    "        lambda x: np.sum((x[label] >= value_min) & (x[label] <= value_max))\n",
    "        >= n_timepoints_min\n",
    "    )\n",
    "    sg_RNA_hits = masked_df[value_mask].index.tolist()\n",
    "    output_df = df.loc[sg_RNA_hits]\n",
    "    return output_df\n",
    "\n",
    "\n",
    "# hits = violin_bins.groupby(\"sgRNA\").apply(lambda x: (np.sum(x[x[\"Timepoint Bin\"]<7][\"Mean\"]>4)>1)&(np.sum(x[x[\"Timepoint Bin\"]>=7][\"Mean\"]<3)>1))\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Lb list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "filamenting_genes = unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218",
   "metadata": {},
   "outputs": [],
   "source": [
    "filamenting_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(\n",
    "    timeseries_bin_df_output[timeseries_bin_df_output[\"Timepoint Bin\"] == 8][\n",
    "        \"Delta t list: Mean\"\n",
    "    ],\n",
    "    range=(0, 15),\n",
    "    bins=50,\n",
    ")\n",
    "plt.xlim(0, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 4\n",
    "max_timepoint = 8\n",
    "value_min = 14\n",
    "value_max = 30\n",
    "n_timepoints_min = 2\n",
    "\n",
    "# hits = violin_bins.groupby(\"sgRNA\").apply(lambda x: (np.sum(x[x[\"Timepoint Bin\"]<7][\"Mean\"]>4)>1)&(np.sum(x[x[\"Timepoint Bin\"]>=7][\"Mean\"]<3)>1))\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Delta t list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(\n",
    "    timeseries_bin_df_output[timeseries_bin_df_output[\"Timepoint Bin\"] == 8][\n",
    "        \"Mean mCherry Intensity list: Mean\"\n",
    "    ],\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 4\n",
    "max_timepoint = 8\n",
    "value_min = 2500\n",
    "value_max = 100000\n",
    "n_timepoints_min = 3\n",
    "\n",
    "# hits = violin_bins.groupby(\"sgRNA\").apply(lambda x: (np.sum(x[x[\"Timepoint Bin\"]<7][\"Mean\"]>4)>1)&(np.sum(x[x[\"Timepoint Bin\"]>=7][\"Mean\"]<3)>1))\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Intensity list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "bright_genes = unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output[timeseries_bin_df_output[\"Timepoint Bin\"] == 8][\n",
    "    \"Mean Width list\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(\n",
    "    timeseries_bin_df_output[timeseries_bin_df_output[\"Timepoint Bin\"] == 8][\n",
    "        \"Mean Width list\"\n",
    "    ],\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 4\n",
    "max_timepoint = 8\n",
    "value_min = 2500\n",
    "value_max = 100000\n",
    "n_timepoints_min = 3\n",
    "\n",
    "# hits = violin_bins.groupby(\"sgRNA\").apply(lambda x: (np.sum(x[x[\"Timepoint Bin\"]<7][\"Mean\"]>4)>1)&(np.sum(x[x[\"Timepoint Bin\"]>=7][\"Mean\"]<3)>1))\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Intensity list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "bright_genes = unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sorted(list(set(filamenting_genes) - set(bright_genes))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227",
   "metadata": {},
   "source": [
    "#### Growth vs Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(\n",
    "    timeseries_bin_df_output[timeseries_bin_df_output[\"Timepoint Bin\"] == 8][\n",
    "        \"Lb list: Mean\"\n",
    "    ],\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(\n",
    "    timeseries_bin_df_output[timeseries_bin_df_output[\"Timepoint Bin\"] == 8][\n",
    "        \"Mean Length Increment list: Mean\"\n",
    "    ],\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "control_df = timeseries_bin_df_output[timeseries_bin_df_output[\"Category\"] != \"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "control_df[\"Mean mCherry Intensity list: Mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nan_mask = ~(\n",
    "    np.isnan(control_df[\"Mean mCherry Intensity list: Mean\"])\n",
    "    | np.isnan(control_df[\"Lb list: Mean\"])\n",
    ")\n",
    "zero_mask = (\n",
    "    (control_df[\"Mean mCherry Intensity list: Mean\"] > 0)\n",
    "    & (control_df[\"Lb list: Mean\"] > 0)\n",
    "    & (control_df[\"Mean Length Increment list: Mean\"] > 0)\n",
    ")\n",
    "no_nan_control = control_df[(nan_mask * zero_mask)]\n",
    "fractio
nal_increment = (\n",
    "    no_nan_control[\"Mean Length Increment list: Mean\"] / no_nan_control[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "\n",
    "r, p = sp.stats.pearsonr(\n",
    "    no_nan_control[\"Mean mCherry Intensity list: Mean\"], fractional_increment\n",
    ")\n",
    "print(r)\n",
    "r, p = sp.stats.pearsonr(no_nan_control[\"Lb list: Mean\"], fractional_increment)\n",
    "print(r)\n",
    "r, p = sp.stats.pearsonr(\n",
    "    no_nan_control[\"Mean mCherry Intensity list: Mean\"], no_nan_control[\"Lb list: Mean\"]\n",
    ")\n",
    "print(r)\n",
    "### Strong negative correlations between mchy intensity, birth size and growth rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nan_mask = ~(\n",
    "    np.isnan(timeseries_bin_df_output[\"Mean mCherry Intensity list: Mean\"])\n",
    "    | np.isnan(timeseries_bin_df_output[\"Lb list: Mean\"])\n",
    ")\n",
    "zero_mask = (\n",
    "    (timeseries_bin_df_output[\"Mean mCherry Intensity list: Mean\"] > 0)\n",
    "    & (timeseries_bin_df_output[\"Lb list: Mean\"] > 0)\n",
    "    & (timeseries_bin_df_output[\"Mean Length Increment list: Mean\"] > 0)\n",
    ")\n",
    "no_nan_timeseries_bin_df_output = timeseries_bin_df_output[(nan_mask * zero_mask)]\n",
    "no_nan_timeseries_bin_df_output[\"Fractional Increment Scaled\"] = (\n",
    "    no_nan_timeseries_bin_df_output[\"Mean Length Increment list: Mean\"]\n",
    "    / no_nan_timeseries_bin_df_output[\"Lb list: Mean\"]\n",
    ") * (60 / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson_correlation = no_nan_timeseries_bin_df_output.groupby(\"sgRNA\").apply(lambda x: sp.stats.pearsonr(x['Mean mCherry Intensity list: Mean'],x[\"Lb list: Mean\"])[0] if len(x)>5 else None)\n",
    "pearson_correlation = no_nan_timeseries_bin_df_output.groupby(\"sgRNA\").apply(\n",
    "    lambda x: sp.stats.pearsonr(x[\"Lb list: Mean\"], x[\"Fractional Increment Scaled\"])[0]\n",
    "    if len(x) > 5\n",
    "    else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(\n",
    "    no_nan_timeseries_bin_df_output.loc[\n",
    "        (pearson_correlation[pearson_correlation > 0.85]).index.tolist()\n",
    "    ][\"Gene\"].tolist(),\n",
    "    return_counts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique[counts > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pearson_correlation, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 6)\n",
    "fractional_increment = (\n",
    "    control_df[\"Mean Length Increment list: Mean\"] / control_df[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "plt.scatter(control_df[\"Lb list: Mean\"], fractional_increment, alpha=0.6, s=4)\n",
    "plt.show()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    control_df[\"Mean mCherry Intensity list: Mean\"],\n",
    "    fractional_increment,\n",
    "    alpha=0.6,\n",
    "    s=6,\n",
    ")\n",
    "plt.show()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    control_df[\"Mean mCherry Intensity list: Mean\"],\n",
    "    control_df[\"Lb list: Mean\"],\n",
    "    alpha=0.6,\n",
    "    s=6,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mchy_promoter_activity(df):\n",
    "#     mchy_series = df['Mean mCherry Intensity list: Bin Values']\n",
    "#     length_incr_series = df['Mean Length Increment list: Bin Values']\n",
    "#     birth_len_series = df['Lb list: Bin Values']\n",
    "#     fractional_increment = (length_incr_series/birth_len_series)\n",
    "#     delta_t_series = df['Delta t list: Bin Values']\n",
    "#     del_mchy_i = mchy_series[1:-1]-mchy_series[:-2]\n",
    "#     del_mchy_f = mchy_series[2:]-mchy_series[1:-1]\n",
    "#     del_mchy = (del_mchy_i+del_mchy_f)/2\n",
    "#     promoter_activity = del_mchy + (fractional_increment*delta_t_series*mchy_series)[1:-1]\n",
    "#     return promoter_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = range(0, 3)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 6)\n",
    "timeseries_bin_df_output_sub = timeseries_bin_df_output[\n",
    "    timeseries_bin_df_output[\"Timepoint Bin\"].isin(timepoints)\n",
    "]\n",
    "fractional_increment = (\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"]\n",
    "    / timeseries_bin_df_output_sub[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"], fractional_increment, alpha=0.5, s=4\n",
    ")\n",
    "plt.show()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\n",
    "        \"Mean mCherry Promoter Activity list (area normed): Mean\"\n",
    "    ],\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(-1, 3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\n",
    "        \"Mean mCherry Promoter Activity list (area normed): Mean\"\n",
    "    ],\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = range(7, 10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 6)\n",
    "timeseries_bin_df_output_sub = timeseries_bin_df_output[\n",
    "    timeseries_bin_df_output[\"Timepoint Bin\"].isin(timepoints)\n",
    "]\n",
    "fractional_increment = (\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"]\n",
    "    / timeseries_bin_df_output_sub[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"], fractional_increment, alpha=0.5, s=4\n",
    ")\n",
    "plt.show()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\n",
    "        \"Mean mCherry Promoter Activity list (area normed): Mean\"\n",
    "    ],\n",
    "    fractional_increment,\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\n",
    "        \"Mean mCherry Promoter Activity list (area normed): Mean\"\n",
    "    ],\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output_sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output_sub[\"fractional_increment\"] = (\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"]\n",
    "    / (\n",
    "        (\n",
    "            timeseries_bin_df_output_sub[\"Lb list: Mean\"]\n",
    "            + timeseries_bin_df_output_sub[\"Ld list: Mean\"]\n",
    "        )\n",
    "        / 2\n",
    "    )\n",
    ") * (60 / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\n",
    "        \"Mean mCherry Promoter Activity list (length normed): Mean\"\n",
    "    ],\n",
    "    timeseries_bin_df_output_sub[\"fractional_increment\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(-1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.xlim(0,1000)\n",
    "# plt.ylim(-1,8)\n",
    "(\n",
    "    scatter,\n",
    "    trenchid_table,\n",
    "    unpack_trenchid_table,\n",
    "    select_scatter,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid,\n",
    ") = tr.linked_scatter(\n",
    "    timeseries_bin_df_output_sub,\n",
    "    \"Mean mCherry Promoter Activity list (length normed): Mean\",\n",
    "    \"fractional_increment\",\n",
    "    trenchids_as_list=True,\n",
    "    maxperc=90,\n",
    "    trenchid_column=\"phenotype trenchids\",\n",
    "    height=600,\n",
    "    logx=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trenchid_table + unpack_trenchid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter_kymograph_display = tr.linked_kymograph_for_scatter(\n",
    "    kymo_xarr,\n",
    "    timeseries_bin_df_output_sub,\n",
    "    \"Mean mCherry Promoter Activity list (length normed): Mean\",\n",
    "    \"fractional_increment\",\n",
    "    select_scatter,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid=select_unpacked_trenchid,\n",
    "    trenchid_column=\"phenotype trenchids\",\n",
    "    y_scale=3,\n",
    "    x_window_size=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter_kymograph_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = range(0, 3)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 6)\n",
    "timeseries_bin_df_output_sub = timeseries_bin_df_output[\n",
    "    timeseries_bin_df_output[\"Timepoint Bin\"].isin(timepoints)\n",
    "]\n",
    "fractional_increment = (\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"]\n",
    "    / timeseries_bin_df_output_sub[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"], fractional_increment, alpha=0.5, s=4\n",
    ")\n",
    "plt.show()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Mean mCherry Intensity list: Mean\"],\n",
    "    fractional_increment,\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 6000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Mean mCherry Promoter Activity\"],\n",
    "    fractional_increment,\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 6000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Mean mCherry Intensity list: Mean\"],\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 6000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Mean mCherry Promoter Activity\"],\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(0, 6000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = range(6, 9)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 6)\n",
    "timeseries_bin_df_output_sub = timeseries_bin_df_output[\n",
    "    timeseries_bin_df_output[\"Timepoint Bin\"].isin(timepoints)\n",
    "]\n",
    "timeseries_bin_df_output_sub[\n",
    "    \"Mean mCherry Promoter Activity\"\n",
    "] = timeseries_bin_df_output_sub.apply(\n",
    "    lambda x: np.mean(mchy_promoter_activity(x)), axis=1\n",
    ")\n",
    "fractional_increment = (\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"]\n",
    "    / timeseries_bin_df_output_sub[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"], fractional_increment, alpha=0.5, s=4\n",
    ")\n",
    "plt.show()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Mean mCherry Intensity list: Mean\"],\n",
    "    fractional_increment,\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(-1000, 6000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Mean mCherry Promoter Activity\"],\n",
    "    fractional_increment,\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(-1000, 6000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Mean mCherry Intensity list: Mean\"],\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(-1000, 6000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Mean mCherry Promoter Activity\"],\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"],\n",
    "    alpha=0.5,\n",
    "    s=6,\n",
    ")\n",
    "plt.xlim(-1000, 6000)\n",
    "plt.ylim(-1, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mchy_promoter_activity(df):\n",
    "    mchy_series = df[\"Mean mCherry Intensity list: Bin Values\"]\n",
    "    length_incr_series = df[\"Mean Length Increment list: Bin Values\"][1:]\n",
    "    birth_len_series = df[\"Lb list: Bin Values\"][1:]\n",
    "    fractional_increment = length_incr_series / birth_len_series\n",
    "    delta_t_series = df[\"Delta t list: Bin Values\"][1:]\n",
    "    del_mchy = mchy_series[1:] - mchy_series[:-1]\n",
    "    avg_mchy = (mchy_series[1:] + mchy_series[:-1]) / 2\n",
    "\n",
    "    promoter_activity = del_mchy + fractional_increment * delta_t_series * avg_mchy\n",
    "    return promoter_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"Mean Length Increment list: Mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeseries_bin_df_output_sub[] = timeseries_bin_df_output_sub.apply(lambda x: mchy_promoter_activity(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 6)\n",
    "fractional_increment = (\n",
    "    control_df[\"Mean Length Increment list: Mean\"] / control_df[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "plt.scatter(control_df[\"Lb list: Mean\"], fractional_increment, alpha=0.6, s=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = \"folA\"\n",
    "\n",
    "timepoints = range(0, 5)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 6)\n",
    "timeseries_bin_df_output_sub = timeseries_bin_df_output[\n",
    "    timeseries_bin_df_output[\"Timepoint Bin\"].isin(timepoints)\n",
    "]\n",
    "query = timeseries_bin_df_output_sub[timeseries_bin_df_output_sub[\"Gene\"] == gene]\n",
    "fractional_increment = (\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"]\n",
    "    / timeseries_bin_df_output_sub[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "fractional_increment_query = (\n",
    "    query[\"Mean Length Increment list: Mean\"] / query[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"], fractional_increment, alpha=0.6, s=1\n",
    ")\n",
    "plt.scatter(query[\"Lb list: Mean\"], fractional_increment_query, alpha=0.6, s=4)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "timepoints = range(5, 9)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 6)\n",
    "timeseries_bin_df_output_sub = timeseries_bin_df_output[\n",
    "    timeseries_bin_df_output[\"Timepoint Bin\"].isin(timepoints)\n",
    "]\n",
    "query = timeseries_bin_df_output_sub[timeseries_bin_df_output_sub[\"Gene\"] == gene]\n",
    "fractional_increment = (\n",
    "    timeseries_bin_df_output_sub[\"Mean Length Increment list: Mean\"]\n",
    "    / timeseries_bin_df_output_sub[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "fractional_increment_query = (\n",
    "    query[\"Mean Length Increment list: Mean\"] / query[\"Lb list: Mean\"]\n",
    ") * (60 / 4)\n",
    "plt.scatter(\n",
    "    timeseries_bin_df_output_sub[\"Lb list: Mean\"], fractional_increment, alpha=0.6, s=1\n",
    ")\n",
    "plt.scatter(query[\"Lb list: Mean\"], fractional_increment_query, alpha=0.6, s=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output[\"Mean Length Increment list: Mean\"] / timeseries_bin_df_output[\n",
    "    \"Lb list: Mean\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261",
   "metadata": {},
   "outputs": [],
   "source": [
    "fractional_increment = (\n",
    "    timeseries_bin_df_output[\"Mean Length Increment list: Mean\"]\n",
    "    / timeseries_bin_df_output[\"Lb list: Mean\"]\n",
    ") * (4 / 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
