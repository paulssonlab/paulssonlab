{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_strand_pams(seqrecord, strand, startcoord=0):\n",
    "    if strand == 1:\n",
    "        seq = str(seqrecord.seq)\n",
    "    else:\n",
    "        seq = str(seqrecord.seq.reverse_complement())\n",
    "\n",
    "    pam_reg = re.compile(\"CC\")\n",
    "    pam_starts = [item.start(0) for item in re.finditer(pam_reg, str(seq))]\n",
    "\n",
    "    pam_list = []\n",
    "\n",
    "    if strand == 1:\n",
    "        for item in pam_starts:\n",
    "            if len(seq[item + 3 : item + 23]) == 20:\n",
    "                start = startcoord + item + 3\n",
    "                end = startcoord + item + 23\n",
    "                sequence = seq[item + 3 : item + 23]\n",
    "                pam_list.append([start, end, sequence, strand])\n",
    "    else:\n",
    "        for item in pam_starts:\n",
    "            if len(seq[item + 3 : item + 23]) == 20:\n",
    "                start = startcoord + len(seq) - item - 23\n",
    "                end = startcoord + len(seq) - item - 3\n",
    "                sequence = seq[item + 3 : item + 23]\n",
    "                pam_list.append([start, end, sequence, strand])\n",
    "    return pam_list\n",
    "\n",
    "\n",
    "def find_pams(seqrecord, startcoord=0, target_strand=1):\n",
    "    fwd_pams = find_strand_pams(seqrecord, 1, startcoord=startcoord)\n",
    "    rev_pams = find_strand_pams(seqrecord, -1, startcoord=startcoord)\n",
    "    pam_df = pd.DataFrame(\n",
    "        fwd_pams + rev_pams, columns=[\"start\", \"end\", \"sequence\", \"ref_strand\"]\n",
    "    )\n",
    "    if target_strand == 1:\n",
    "        pam_df[\"target_strand\"] = 1\n",
    "    else:\n",
    "        pam_df[\"target_strand\"] = -pam_df[\"ref_strand\"]\n",
    "    return pam_df\n",
    "\n",
    "\n",
    "def remove_bad_seeds(pam_df, bad_seed_path):\n",
    "    bad_seed_df = pd.read_csv(bad_seed_path)\n",
    "    bad_seed_list = bad_seed_df[\"seeds\"].tolist()\n",
    "    ## reverse complement to match target sequence\n",
    "    bad_seed_list = [\n",
    "        str(Seq(item.upper(), IUPAC.unambiguous_dna).reverse_complement())\n",
    "        for item in bad_seed_list\n",
    "    ]\n",
    "\n",
    "    pam_df = pam_df[pam_df[\"sequence\"].apply(lambda x: x[:5] not in bad_seed_list)]\n",
    "    return pam_df\n",
    "\n",
    "\n",
    "def str_to_int(string):\n",
    "    code = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "    conv_str = np.array(list(map(lambda x: code[x], string)))\n",
    "    return conv_str\n",
    "\n",
    "\n",
    "def compare_seqs(\n",
    "    target_df, reference_df, subseq_range=None, remove_matching_starts=True\n",
    "):\n",
    "    target_arr = target_df[\"sequence\"].values\n",
    "    reference_arr = reference_df[\"sequence\"].values\n",
    "    target_int_arr = np.array(list(map(str_to_int, target_arr)), dtype=\"uint8\")\n",
    "    reference_int_arr = np.array(list(map(str_to_int, reference_arr)), dtype=\"uint8\")\n",
    "\n",
    "    if subseq_range != None:\n",
    "        target_int_arr = target_int_arr[:, subseq_range]\n",
    "        reference_int_arr = reference_int_arr[:, subseq_range]\n",
    "\n",
    "    bool_arr = target_int_arr[:, np.newaxis, :] == reference_int_arr[np.newaxis, :, :]\n",
    "    agreement_arr = np.sum(bool_arr, axis=2, dtype=int)\n",
    "\n",
    "    if remove_matching_starts:\n",
    "        matching_starts = np.where(\n",
    "            target_df[\"start\"].values[:, np.newaxis]\n",
    "            == reference_df[\"start\"].values[np.newaxis, :]\n",
    "        )[1]\n",
    "        agreement_arr[:, matching_starts] = 0\n",
    "    most_agreement = np.max(agreement_arr, axis=1)\n",
    "    return most_agreement\n",
    "\n",
    "\n",
    "def generate_all_mismatchs(in_str, num_mismatch):\n",
    "    flip_dict = {\n",
    "        \"A\": [\"T\", \"C\", \"G\"],\n",
    "        \"T\": [\"A\", \"C\", \"G\"],\n",
    "        \"C\": [\"T\", \"A\", \"G\"],\n",
    "        \"G\": [\"T\", \"C\", \"A\"],\n",
    "    }\n",
    "    prod = list(itertools.product(*[flip_dict[in_str[i]] for i in range(num_mismatch)]))\n",
    "    new_strs = [\"\".join(item) + in_str[num_mismatch:] for item in prod]\n",
    "    return new_strs\n",
    "\n",
    "\n",
    "def generate_mismatch(in_str, num_mismatch):\n",
    "    flip_dict = {\n",
    "        \"A\": [\"T\", \"C\", \"G\"],\n",
    "        \"T\": [\"A\", \"C\", \"G\"],\n",
    "        \"C\": [\"T\", \"A\", \"G\"],\n",
    "        \"G\": [\"T\", \"C\", \"A\"],\n",
    "    }\n",
    "    list_str = list(in_str)\n",
    "    new_str = copy.copy(list_str)\n",
    "    for i in range(num_mismatch):\n",
    "        new_char = np.random.choice(flip_dict[list_str[i]])\n",
    "        new_str[i] = new_char\n",
    "    new_str = \"\".join(new_str)\n",
    "    return new_str\n",
    "\n",
    "\n",
    "def generate_mismatch_df(pam_df, k=[1, 2, 4, 8, 10], n_samples=50):\n",
    "    mismatch_df = []\n",
    "    for i, row in pam_df.iterrows():\n",
    "        seq = row[\"sequence\"]\n",
    "        start = row[\"start\"]\n",
    "        end = row[\"end\"]\n",
    "        ref_strand = row[\"ref_strand\"]\n",
    "        target_strand = row[\"target_strand\"]\n",
    "        for k in [1, 2, 4, 8, 10]:\n",
    "            if k < 5:\n",
    "                mismatch_list = generate_all_mismatchs(seq, k)\n",
    "            else:\n",
    "                mismatch_list = list(\n",
    "                    set([generate_mismatch(seq, k) for i in range(n_samples)])\n",
    "                )\n",
    "            mismatch_df += [\n",
    "                [start, end, item, ref_strand, target_strand, k]\n",
    "                for item in mismatch_list\n",
    "            ]\n",
    "\n",
    "    mismatch_df = pd.DataFrame(\n",
    "        mismatch_df,\n",
    "        columns=[\n",
    "            \"start\",\n",
    "            \"end\",\n",
    "            \"sequence\",\n",
    "            \"ref_strand\",\n",
    "            \"target_strand\",\n",
    "            \"num_mismatch\",\n",
    "        ],\n",
    "    )\n",
    "    return mismatch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### Generate target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = SeqIO.read(\"./CRISPRi_reference_genome.gb\", \"gb\")\n",
    "\n",
    "ref_start = 807859\n",
    "ref_end = 808636\n",
    "target = genome[ref_start:ref_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pam_df = find_pams(target, startcoord=ref_start, target_strand=-1)\n",
    "genome_pam_df = find_pams(genome)\n",
    "\n",
    "target_pam_df = remove_bad_seeds(target_pam_df, \"./bad_seed_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_agreement = compare_seqs(target_pam_df, genome_pam_df, range(0, 9))\n",
    "past_threshold = most_agreement < 9\n",
    "\n",
    "target_pam_df_nooff = target_pam_df[past_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_df = generate_mismatch_df(target_pam_df_nooff, n_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_df = mismatch_df[mismatch_df[\"target_strand\"] == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_1_df = guides_df[guides_df[\"start\"] == 808596].reset_index(drop=True)\n",
    "site_1_subsample = site_1_df.groupby(\"num_mismatch\").sample(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_1_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_2_df = guides_df[guides_df[\"start\"] == 808518].reset_index(drop=True)\n",
    "site_2_subsample = site_2_df.groupby(\"num_mismatch\").sample(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_2_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_guides_df = pd.concat([site_1_subsample, site_2_subsample]).reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_guides_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_to_spacer(target_str):\n",
    "    target = Seq(target_str.upper(), IUPAC.unambiguous_dna)\n",
    "    spacer = target.reverse_complement()\n",
    "    spacer = str(spacer)\n",
    "    return spacer\n",
    "\n",
    "\n",
    "def add_bsaI_sites(spacer):  ##make more general later\n",
    "    site_1 = \"AGGCACTTGCTCGTACGACGGAAGACATTAGT\"\n",
    "    site_2 = \"GTTTTCGTCTTCTTAAGGTGCCGGGCCCACAT\"\n",
    "    output_seq = site_1 + spacer + site_2\n",
    "    return output_seq\n",
    "\n",
    "\n",
    "def target_to_padded_spacer(target_str):\n",
    "    spacer = target_to_spacer(target_str)\n",
    "    padded_spacer = add_bsaI_sites(spacer)\n",
    "    return padded_spacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_guides_df[\"sequence_to_order\"] = selected_guides_df[\"sequence\"].apply(\n",
    "    target_to_padded_spacer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_guides_df[\"sequence_to_order\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Checks out...now fix the reference and order"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
