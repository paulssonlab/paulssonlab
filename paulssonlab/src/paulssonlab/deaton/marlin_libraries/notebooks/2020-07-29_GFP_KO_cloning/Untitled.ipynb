{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Initial Guidelines\n",
    "\n",
    "1.\tTargeting sequences are 20bp long and must be complementary to the target coding strand.\n",
    "    a.\tFor example if the target is AGA…GTT, the cognate sgRNA will be AAC…UCU\n",
    "2.\tTargeted sequences must have a PAM motif (NGG) in the antisense strand at the 5’ end, i.e. they must begin with CCN before the 20-mer target sequence.\n",
    "3.\tTargeting sequences should avoid off-target effects by having less than 9bp of complementarity with any other sites containing a PAM motif.\n",
    "    - This usually cannot be avoided, so an alternative is to loosen the restriction to allow off-target binding to neutral regions (away from regulatory elements and on the template (non-coding) strand of coding regions)\n",
    "4.\tAvoid sequences possessing the following “bad seed” substrings in the last 5 positions of the sgRNA targeting sequence (i.e. the complement of the first 5 positions of the targeted sequence, excluding PAM)\n",
    "    - Bad seeds listed in bad_seed_list.csv\n",
    "5.\tBetween 0 and 10 mismatches can be introduced to accomplish partial repression, should maintain avoidance of off targets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Outline of Algorithm\n",
    "\n",
    "1.\tDownload MG1655 .gb file, modify with any integrated constructs in base strain\n",
    "2.\tEnumerate all strings in target gene which satisfy [C]{2}[ATGC]{21} (regular expression, you will need to use these)\n",
    "3.\tFilter out all strings with bad seeds\n",
    "4.\tMake sure all target strings do not have more than 8bp of matching in the seed sequence (if there are, eliminate both)\n",
    " - This may be merged with the next step\n",
    "5.\tFind off-target sites\n",
    " - determine pam sites for which the 9nt seed sequence is identical\n",
    " - eliminate those in the template strand of a coding region or in non-annotated regions\n",
    " - if there are sill off-target sites, eliminate the guide\n",
    "6.\tFor each light off target site, determine the annotation (CDS-template, CDS-coding, regulatory, no annotation)\n",
    "7.\tEliminate any target sequences with a light off target with the CDS-coding or regulatory annotation\n",
    "8.\tGenerate all possible single bp mismatches for each targeting sequence and repeat the above off-target analysis to determine valid guides\n",
    "9.\tRepeat for 2,3,…,10 mismatches; use random sampling if enumerating all possible combinations is too computationally costly; bottleneck each group to 100 variants if necessary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Implementation (for gfpmut2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO, pairwise2\n",
    "from Bio.Alphabet import IUPAC, generic_dna, generic_protein\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import FeatureLocation, SeqFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = SeqIO.read(\"./CRISPRi_reference_genome.gb\", \"gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_start = 807859\n",
    "ref_end = 808636\n",
    "target = genome[ref_start:ref_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_strand_pams(seqrecord, strand, startcoord=0):\n",
    "    if strand == 1:\n",
    "        seq = str(seqrecord.seq)\n",
    "    else:\n",
    "        seq = str(seqrecord.seq.reverse_complement())\n",
    "\n",
    "    pam_reg = re.compile(\"CC\")\n",
    "    pam_starts = [item.start(0) for item in re.finditer(pam_reg, str(seq))]\n",
    "\n",
    "    pam_list = []\n",
    "\n",
    "    if strand == 1:\n",
    "        for item in pam_starts:\n",
    "            if len(seq[item + 3 : item + 23]) == 20:\n",
    "                start = startcoord + item + 3\n",
    "                end = startcoord + item + 23\n",
    "                sequence = seq[item + 3 : item + 23]\n",
    "                pam_list.append([start, end, sequence, strand])\n",
    "    else:\n",
    "        for item in pam_starts:\n",
    "            if len(seq[item + 3 : item + 23]) == 20:\n",
    "                start = startcoord + len(seq) - item - 23\n",
    "                end = startcoord + len(seq) - item - 3\n",
    "                sequence = seq[item + 3 : item + 23]\n",
    "                pam_list.append([start, end, sequence, strand])\n",
    "    return pam_list\n",
    "\n",
    "\n",
    "def find_pams(seqrecord, startcoord=0):\n",
    "    fwd_pams = find_strand_pams(seqrecord, 1, startcoord=startcoord)\n",
    "    rev_pams = find_strand_pams(seqrecord, -1, startcoord=startcoord)\n",
    "    pam_df = pd.DataFrame(\n",
    "        fwd_pams + rev_pams, columns=[\"start\", \"end\", \"sequence\", \"strand\"]\n",
    "    )\n",
    "    return pam_df\n",
    "\n",
    "\n",
    "def remove_bad_seeds(pam_df, bad_seed_path):\n",
    "    bad_seed_df = pd.read_csv(bad_seed_path)\n",
    "    bad_seed_list = bad_seed_df[\"seeds\"].tolist()\n",
    "    ## reverse complement to match target sequence\n",
    "    bad_seed_list = [\n",
    "        str(Seq(item.upper(), IUPAC.unambiguous_dna).reverse_complement())\n",
    "        for item in bad_seed_list\n",
    "    ]\n",
    "\n",
    "    pam_df = pam_df[pam_df[\"sequence\"].apply(lambda x: x[:5] not in bad_seed_list)]\n",
    "    return pam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pam_df = find_pams(target, startcoord=ref_start)\n",
    "target_pam_df = remove_bad_seeds(target_pam_df, \"./bad_seed_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_pam_df = find_pams(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(string):\n",
    "    code = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "    conv_str = np.array(list(map(lambda x: code[x], string)))\n",
    "    return conv_str\n",
    "\n",
    "\n",
    "def compare_seqs(\n",
    "    target_df, reference_df, subseq_range=None, remove_matching_starts=True\n",
    "):\n",
    "    target_arr = target_df[\"sequence\"].values\n",
    "    reference_arr = reference_df[\"sequence\"].values\n",
    "    target_int_arr = np.array(list(map(str_to_int, target_arr)), dtype=\"uint8\")\n",
    "    reference_int_arr = np.array(list(map(str_to_int, reference_arr)), dtype=\"uint8\")\n",
    "\n",
    "    if subseq_range != None:\n",
    "        target_int_arr = target_int_arr[:, subseq_range]\n",
    "        reference_int_arr = reference_int_arr[:, subseq_range]\n",
    "\n",
    "    bool_arr = target_int_arr[:, np.newaxis, :] == reference_int_arr[np.newaxis, :, :]\n",
    "    agreement_arr = np.sum(bool_arr, axis=2, dtype=int)\n",
    "\n",
    "    if remove_matching_starts:\n",
    "        matching_starts = np.where(\n",
    "            target_df[\"start\"].values[:, np.newaxis]\n",
    "            == reference_df[\"start\"].values[np.newaxis, :]\n",
    "        )[1]\n",
    "        agreement_arr[:, matching_starts] = 0\n",
    "    most_agreement = np.max(agreement_arr, axis=1)\n",
    "    return most_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_agreement = compare_seqs(target_pam_df, genome_pam_df, range(0, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_threshold = most_agreement < 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pam_df_nooff = target_pam_df[past_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_mismatchs(in_str, num_mismatch):\n",
    "    flip_dict = {\n",
    "        \"A\": [\"T\", \"C\", \"G\"],\n",
    "        \"T\": [\"A\", \"C\", \"G\"],\n",
    "        \"C\": [\"T\", \"A\", \"G\"],\n",
    "        \"G\": [\"T\", \"C\", \"A\"],\n",
    "    }\n",
    "    prod = list(itertools.product(*[flip_dict[in_str[i]] for i in range(num_mismatch)]))\n",
    "    new_strs = [\"\".join(item) + in_str[num_mismatch:] for item in prod]\n",
    "    return new_strs\n",
    "\n",
    "\n",
    "def generate_mismatch(in_str, num_mismatch):\n",
    "    flip_dict = {\n",
    "        \"A\": [\"T\", \"C\", \"G\"],\n",
    "        \"T\": [\"A\", \"C\", \"G\"],\n",
    "        \"C\": [\"T\", \"A\", \"G\"],\n",
    "        \"G\": [\"T\", \"C\", \"A\"],\n",
    "    }\n",
    "    list_str = list(in_str)\n",
    "    new_str = copy.copy(list_str)\n",
    "    for i in range(num_mismatch):\n",
    "        new_char = np.random.choice(flip_dict[list_str[i]])\n",
    "        new_str[i] = new_char\n",
    "    new_str = \"\".join(new_str)\n",
    "    return new_str\n",
    "\n",
    "\n",
    "def generate_mismatch_df(pam_df, k=[1, 2, 4, 8, 10]):\n",
    "    mismatch_df = []\n",
    "    for i, row in pam_df.iterrows():\n",
    "        seq = row[\"sequence\"]\n",
    "        start = row[\"start\"]\n",
    "        end = row[\"end\"]\n",
    "        strand = row[\"strand\"]\n",
    "        for k in [1, 2, 4, 8, 10]:\n",
    "            if k < 5:\n",
    "                mismatch_list = generate_all_mismatchs(seq, k)\n",
    "            else:\n",
    "                mismatch_list = list(\n",
    "                    set([generate_mismatch(seq, k) for i in range(50)])\n",
    "                )\n",
    "            mismatch_df += [[start, end, item, strand, k] for item in mismatch_list]\n",
    "\n",
    "    mismatch_df = pd.DataFrame(\n",
    "        mismatch_df, columns=[\"start\", \"end\", \"sequence\", \"strand\", \"num_mismatch\"]\n",
    "    )\n",
    "    return mismatch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_mismatch_df(target_pam_df_nooff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = pams_past_threshold[\"sequence\"][0]\n",
    "start = pams_past_threshold[\"start\"][0]\n",
    "end = pams_past_threshold[\"end\"][0]\n",
    "strand = pams_past_threshold[\"strand\"][0]\n",
    "\n",
    "###eliminate bad seeds\n",
    "bad_seed_df = pd.read_csv(\"./bad_seed_list.csv\")\n",
    "bad_seed_list = bad_seed_df[\"seeds\"].tolist()\n",
    "## reverse complement to match target sequence\n",
    "bad_seed_list = [\n",
    "    str(Seq(item.upper(), IUPAC.unambiguous_dna).reverse_complement())\n",
    "    for item in bad_seed_list\n",
    "]\n",
    "\n",
    "mismatch_df = []\n",
    "for k in [1, 2, 4, 8, 10]:\n",
    "    if k < 5:\n",
    "        mismatch_list = generate_all_mismatchs(test, k)\n",
    "    else:\n",
    "        mismatch_list = list(set([generate_mismatch(test, k) for i in range(100)]))\n",
    "    mismatch_df += [[start, end, item, strand, k] for item in mismatch_list]\n",
    "mismatch_df = pd.DataFrame(\n",
    "    mismatch_df, columns=[\"start\", \"end\", \"sequence\", \"strand\", \"num_mismatch\"]\n",
    ")\n",
    "mismatch_df = mismatch_df[\n",
    "    mismatch_df[\"sequence\"].apply(lambda x: x[:5] not in bad_seed_list)\n",
    "]\n",
    "mismatch_df = mismatch_df[get_query_mask(mismatch_df, all_genome_pams)].reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(most_agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_mismatch_seqs(test, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome[58:78].reverse_complement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = []\n",
    "for feature in genome.features:\n",
    "    start_idx = feature.location.start.real\n",
    "    end_idx = feature.location.end.real\n",
    "    strand = feature.location.strand\n",
    "    category = feature.type\n",
    "    meta = feature.qualifiers\n",
    "    if \"gene\" in meta.keys():\n",
    "        name = meta[\"gene\"][0]\n",
    "    else:\n",
    "        name = \"\"\n",
    "    entry = [start_idx, end_idx, strand, category, name]\n",
    "    features_df.append(entry)\n",
    "features_df = pd.DataFrame(\n",
    "    features_df, columns=[\"start\", \"stop\", \"strand\", \"type\", \"name\"]\n",
    ")  ##stop is inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "CDS_df = features_df[features_df[\"type\"] == \"CDS\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "CDS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### annotate the PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_template(pams_df, CDS_df):\n",
    "    targets_template_list = []\n",
    "    for i, item in pams_df.iterrows():\n",
    "        if item[\"strand\"] == 1:\n",
    "            start_idx = item[\"position\"]\n",
    "            end_idx = start_idx + 20\n",
    "        else:\n",
    "            start_idx = item[\"position\"] - 20\n",
    "            end_idx = item[\"position\"]\n",
    "\n",
    "        start_above = start_idx > (CDS_df[\"start\"])\n",
    "        end_below = end_idx < (CDS_df[\"stop\"])\n",
    "        in_range = start_above & end_below\n",
    "        overlapping_CDSs = CDS_df[in_range]\n",
    "        targets_template = ~np.any(overlapping_CDSs[\"strand\"] == item[\"strand\"])\n",
    "        targets_template_list.append(targets_template)\n",
    "    return targets_template_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_if_template(all_genome_pams[:10], CDS_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genome_pams[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pam_str_arr = all_pams[\"sequence\"].values\n",
    "all_pam_int_arr = np.array(list(map(str_to_int, all_pam_str_arr)), dtype=\"uint8\")\n",
    "all_pam_seed_arr = all_pam_int_arr[:, :8]\n",
    "bool_arr = all_pam_seed_arr[:, np.newaxis, :] == all_pam_seed_arr[np.newaxis, :, :]\n",
    "agreement_arr = np.sum(bool_arr, axis=2, dtype=int)\n",
    "agreement_arr[np.eye(agreement_arr.shape[0], dtype=bool)] = 0\n",
    "most_agreement = np.max(agreement_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pams[\"sequence\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "moo = all_pam[\"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "moo.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pam_int_arr[0] == all_pam_int_arr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(most_agreement)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "?right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(closest_dist > 10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hamming_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_arr = all_pam_int_arr[:, np.newaxis, :] == all_pam_int_arr[np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pam_str_arr = np.array(all_pams)\n",
    "\n",
    "= np.apply_along_axis(''.join,1,np.random.choice([\"A\",\"C\",\"G\",\"T\"],size=(100000,20))) #example array of strings\n",
    "ex_2 = np.apply_along_axis(''.join,1,np.random.choice([\"A\",\"C\",\"G\",\"T\"],size=(100000,20)))# example array of strings\n",
    "ex_1_int = np.array(list(map(str_to_int,ex_1)),dtype=\"uint8\") #conversion to (N, L) array of integers\n",
    "ex_2_int = np.array(list(map(str_to_int,ex_2)),dtype=\"uint8\") #conversion to (N, L) array of integers\n",
    "ex_1_broadcast = np.array(ex_1_int[:,np.newaxis,:]) #reshaping for broadcast operation (N, L) -> (N, 1, L)\n",
    "ex_2_broadcast =  np.array(ex_2_int[np.newaxis,:,:]) #reshaping for broadcast operation (N, L) -> (1, N, L)\n",
    "bool_arr = (ex_1_broadcast==ex_2_broadcast) #broadcast comparison (N, N, L)\n",
    "match_arr = np.sum(bool_arr,axis=2) #summing over L (N, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_seed_df = pd.read_csv(\"./bad_seed_list.csv\")\n",
    "seed_list = bad_seed_df[\"seeds\"].tolist()\n",
    "## reverse complement to match target sequence\n",
    "seed_list = [\n",
    "    str(Seq(item.lower(), IUPAC.unambiguous_dna).reverse_complement())\n",
    "    for item in seed_list\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
