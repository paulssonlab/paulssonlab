{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finds all PAMs on a strand of a sequence record\n",
    "## strand specifies the strand (1,-1) that the search is being conducted on\n",
    "## startcoord specifies the beginning coordinate of the seqrecord on the underlying reference genome\n",
    "def find_strand_pams(seqrecord, strand, startcoord=0):\n",
    "    if strand == 1:\n",
    "        seq = str(seqrecord.seq)\n",
    "    else:\n",
    "        seq = str(seqrecord.seq.reverse_complement())\n",
    "\n",
    "    pam_reg = re.compile(\"CC\")\n",
    "    pam_starts = [item.start(0) for item in re.finditer(pam_reg, str(seq))]\n",
    "\n",
    "    pam_list = []\n",
    "\n",
    "    if strand == 1:\n",
    "        for item in pam_starts:\n",
    "            if len(seq[item + 3 : item + 23]) == 20:\n",
    "                start = startcoord + item + 3\n",
    "                end = startcoord + item + 23\n",
    "                sequence = seq[item + 3 : item + 23]\n",
    "                pam_list.append([start, end, sequence, strand])\n",
    "    else:\n",
    "        for item in pam_starts:\n",
    "            if len(seq[item + 3 : item + 23]) == 20:\n",
    "                start = startcoord + len(seq) - item - 23\n",
    "                end = startcoord + len(seq) - item - 3\n",
    "                sequence = seq[item + 3 : item + 23]\n",
    "                pam_list.append([start, end, sequence, strand])\n",
    "    return pam_list\n",
    "\n",
    "\n",
    "## Finds all PAMs in target sequence record\n",
    "## startcoord specifies the beginning coordinate of the seqrecord on the underlying reference genome\n",
    "## target_strand specifies the strand (1,-1) that the seq record is on\n",
    "def find_pams(seqrecord, startcoord=0, target_strand=1):\n",
    "    fwd_pams = find_strand_pams(seqrecord, 1, startcoord=startcoord)\n",
    "    rev_pams = find_strand_pams(seqrecord, -1, startcoord=startcoord)\n",
    "    pam_df = pd.DataFrame(\n",
    "        fwd_pams + rev_pams, columns=[\"start\", \"end\", \"sequence\", \"ref_strand\"]\n",
    "    )\n",
    "    if target_strand == 1:\n",
    "        pam_df[\"target_strand\"] = 1\n",
    "    else:\n",
    "        pam_df[\"target_strand\"] = -pam_df[\"ref_strand\"]\n",
    "    return pam_df\n",
    "\n",
    "\n",
    "## Uses a reference csv of bad seeds to eliminate bad seeds from the PAM DataFrame\n",
    "def remove_bad_seeds(pam_df, bad_seed_path):\n",
    "    bad_seed_df = pd.read_csv(bad_seed_path)\n",
    "    bad_seed_list = bad_seed_df[\"seeds\"].tolist()\n",
    "    ## reverse complement to match target sequence\n",
    "    bad_seed_list = [\n",
    "        str(Seq(item.upper()).reverse_complement()) for item in bad_seed_list\n",
    "    ]\n",
    "\n",
    "    pam_df = pam_df[pam_df[\"sequence\"].apply(lambda x: x[:5] not in bad_seed_list)]\n",
    "    return pam_df\n",
    "\n",
    "\n",
    "## Converts a string to an integer representation\n",
    "def str_to_int(string):\n",
    "    code = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "    conv_str = np.array(list(map(lambda x: code[x], string)))\n",
    "    return conv_str\n",
    "\n",
    "\n",
    "## Determines the maximum matching (minimum edit distance) of each target sequence\n",
    "## to sequences in the reference\n",
    "## subseq_range can be set to subset the sequences to a region of interest (i.e. the PAM adjacent region)\n",
    "## remove_matching_starts can be set to eliminate sequences from consideration when they are at the same location\n",
    "def compare_seqs(\n",
    "    target_df, reference_df, subseq_range=None, remove_matching_starts=True\n",
    "):\n",
    "    target_arr = target_df[\"sequence\"].values\n",
    "    reference_arr = reference_df[\"sequence\"].values\n",
    "    target_int_arr = np.array(list(map(str_to_int, target_arr)), dtype=\"uint8\")\n",
    "    reference_int_arr = np.array(list(map(str_to_int, reference_arr)), dtype=\"uint8\")\n",
    "\n",
    "    if subseq_range != None:\n",
    "        target_int_arr = target_int_arr[:, subseq_range]\n",
    "        reference_int_arr = reference_int_arr[:, subseq_range]\n",
    "\n",
    "    bool_arr = target_int_arr[:, np.newaxis, :] == reference_int_arr[np.newaxis, :, :]\n",
    "    agreement_arr = np.sum(bool_arr, axis=2, dtype=int)\n",
    "\n",
    "    if remove_matching_starts:\n",
    "        matching_starts = np.where(\n",
    "            target_df[\"start\"].values[:, np.newaxis]\n",
    "            == reference_df[\"start\"].values[np.newaxis, :]\n",
    "        )[1]\n",
    "        agreement_arr[:, matching_starts] = 0\n",
    "    most_agreement = np.max(agreement_arr, axis=1)\n",
    "    return most_agreement\n",
    "\n",
    "\n",
    "### Exhaustively generate mismatched versions of the query with num_mismatch substitutions starting from the PAM distal end\n",
    "def generate_all_mismatchs(in_str, num_mismatch):\n",
    "    flip_dict = {\n",
    "        \"A\": [\"T\", \"C\", \"G\"],\n",
    "        \"T\": [\"A\", \"C\", \"G\"],\n",
    "        \"C\": [\"T\", \"A\", \"G\"],\n",
    "        \"G\": [\"T\", \"C\", \"A\"],\n",
    "    }\n",
    "    in_str_len = len(in_str)\n",
    "    prod = list(\n",
    "        itertools.product(\n",
    "            *[flip_dict[in_str[in_str_len - i - 1]] for i in range(num_mismatch)][::-1]\n",
    "        )\n",
    "    )\n",
    "    new_strs = [in_str[: in_str_len - num_mismatch] + \"\".join(item) for item in prod]\n",
    "    return new_strs\n",
    "\n",
    "\n",
    "### Randomly (with replacement) generate mismatched versions of the query with num_mismatch substitutions\n",
    "def generate_mismatch(in_str, num_mismatch):\n",
    "    flip_dict = {\n",
    "        \"A\": [\"T\", \"C\", \"G\"],\n",
    "        \"T\": [\"A\", \"C\", \"G\"],\n",
    "        \"C\": [\"T\", \"A\", \"G\"],\n",
    "        \"G\": [\"T\", \"C\", \"A\"],\n",
    "    }\n",
    "    in_str_len = len(in_str)\n",
    "    list_str = list(in_str)\n",
    "    new_str = copy.copy(list_str)\n",
    "    for i in range(num_mismatch):\n",
    "        new_char = np.random.choice(flip_dict[list_str[in_str_len - i - 1]])\n",
    "        new_str[in_str_len - i - 1] = new_char\n",
    "    new_str = \"\".join(new_str)\n",
    "    return new_str\n",
    "\n",
    "\n",
    "### Generate a mismatch DataFrame with PAMs containing k[i] mismatches, taking n_samples for each k[i]\n",
    "### If k[i]<max_exhaustive, then this is done exhaustively\n",
    "def generate_mismatch_df(pam_df, k=[1, 2, 4, 8, 10], n_samples=50, max_exhaustive=5):\n",
    "    mismatch_df = []\n",
    "    for i, row in pam_df.iterrows():\n",
    "        seq = row[\"sequence\"]\n",
    "        start = row[\"start\"]\n",
    "        end = row[\"end\"]\n",
    "        ref_strand = row[\"ref_strand\"]\n",
    "        target_strand = row[\"target_strand\"]\n",
    "        mismatch_df.append([start, end, seq, ref_strand, target_strand, 0])\n",
    "        for k in [1, 2, 4, 8, 10]:\n",
    "            if k <= max_exhaustive:\n",
    "                mismatch_list = generate_all_mismatchs(seq, k)\n",
    "            else:\n",
    "                mismatch_list = list(\n",
    "                    set([generate_mismatch(seq, k) for i in range(n_samples)])\n",
    "                )\n",
    "            mismatch_df += [\n",
    "                [start, end, item, ref_strand, target_strand, k]\n",
    "                for item in mismatch_list\n",
    "            ]\n",
    "\n",
    "    mismatch_df = pd.DataFrame(\n",
    "        mismatch_df,\n",
    "        columns=[\n",
    "            \"start\",\n",
    "            \"end\",\n",
    "            \"sequence\",\n",
    "            \"ref_strand\",\n",
    "            \"target_strand\",\n",
    "            \"num_mismatch\",\n",
    "        ],\n",
    "    )\n",
    "    return mismatch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = SeqIO.read(\"./DE161_reference.gb\", \"gb\")\n",
    "\n",
    "ref_start = 807758\n",
    "ref_end = 808585\n",
    "target = genome[ref_start:ref_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pam_df = find_pams(target, startcoord=ref_start, target_strand=-1)\n",
    "genome_pam_df = find_pams(genome)\n",
    "\n",
    "target_pam_df = remove_bad_seeds(target_pam_df, \"./bad_seed_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_pam_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAM_adj_size = 10\n",
    "most_agreement = compare_seqs(target_pam_df, genome_pam_df, range(0, PAM_adj_size))\n",
    "past_threshold = most_agreement < PAM_adj_size\n",
    "target_pam_df_nooff = target_pam_df[past_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percent Past Threshold: \" + str(np.sum(past_threshold) / len(past_threshold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_df = generate_mismatch_df(target_pam_df_nooff, n_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoter_guides_df = mismatch_df[(mismatch_df[\"start\"] > 808496)].reset_index(drop=True)\n",
    "most_agreement = compare_seqs(promoter_guides_df, genome_pam_df, range(0, PAM_adj_size))\n",
    "past_threshold = most_agreement < PAM_adj_size\n",
    "promoter_guides_df_nooff = promoter_guides_df[past_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percent Past Threshold: \" + str(np.sum(past_threshold) / len(past_threshold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoter_guides_df_nooff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_1_df = promoter_guides_df_nooff[\n",
    "    promoter_guides_df_nooff[\"start\"] == 808513\n",
    "].reset_index(drop=True)\n",
    "site_1_subsample = site_1_df.groupby(\"num_mismatch\").sample(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_1_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guides_df = mismatch_df[mismatch_df[\"target_strand\"] == 1].reset_index(drop=True)\n",
    "most_agreement = compare_seqs(guides_df, genome_pam_df, range(0, PAM_adj_size))\n",
    "past_threshold = most_agreement < PAM_adj_size\n",
    "guides_df_nooff = guides_df[past_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percent Past Threshold: \" + str(np.sum(past_threshold) / len(past_threshold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_guides = guides_df[guides_df[\"num_mismatch\"] == 0][2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_2_df = guides_df[guides_df[\"start\"] == 808416].reset_index(drop=True)\n",
    "site_2_subsample = site_2_df.groupby(\"num_mismatch\").sample(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_2_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_guides_df = pd.concat([site_1_subsample, site_2_subsample]).reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_guides_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert a target sequence to a spacer sequence\n",
    "def target_to_spacer(target_str):\n",
    "    target = Seq(target_str.upper())\n",
    "    spacer = target.reverse_complement()\n",
    "    spacer = str(spacer)\n",
    "    return spacer\n",
    "\n",
    "\n",
    "### Add bsai sites and primer sequences to the side for cloning\n",
    "def add_bsaI_sites(spacer):  ##make more general later\n",
    "    site_1 = \"AGGCACTTGCTCGTACGACGGAAGACATTAGT\"\n",
    "    site_2 = \"GTTTTCGTCTTCTTAAGGTGCCGGGCCCACAT\"\n",
    "    output_seq = site_1 + spacer + site_2\n",
    "    return output_seq\n",
    "\n",
    "\n",
    "### Convert a target sequence to a spacer with bsai sites and basic PCR primers\n",
    "def target_to_padded_spacer(target_str):\n",
    "    spacer = target_to_spacer(target_str)\n",
    "    padded_spacer = add_bsaI_sites(spacer)\n",
    "    return padded_spacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_guides_df[\"sequence_to_order\"] = selected_guides_df[\"sequence\"].apply(\n",
    "    target_to_padded_spacer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_guides_df.to_csv(\"DE161_extra_guide_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_guides[\"sequence_to_order\"] = extra_guides[\"sequence\"].apply(\n",
    "    target_to_padded_spacer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_guides.to_csv(\"DE161_extra_guide_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
