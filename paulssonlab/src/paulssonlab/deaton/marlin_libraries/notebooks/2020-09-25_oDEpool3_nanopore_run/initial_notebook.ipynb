{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from Bio import SeqIO, motifs\n",
    "from Bio.Seq import Seq\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = \"/n/scratch3/groups/hms/sysbio/paulsson/de64/2020-09-24_oDEPool3\"\n",
    "fastqpath = (\n",
    "    \"/n/scratch3/groups/hms/sysbio/paulsson/de64/2020-09-24_oDEPool3/data/fastq_pass\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fastq(fastqpath, outputpath, ttl_files=None):\n",
    "    files = 0\n",
    "    output_fastq = \"\"\n",
    "    for filename in glob.iglob(fastqpath + \"/*\", recursive=True):\n",
    "        with open(filename, \"r\") as infile:\n",
    "            output_fastq += infile.read()\n",
    "        if ttl_files != None:\n",
    "            files += 1\n",
    "            print(files)\n",
    "            if files >= ttl_files:\n",
    "                break\n",
    "    with open(outputpath, \"w\") as outfile:\n",
    "        outfile.write(output_fastq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Merge FASTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_fastq(fastqpath, headpath + \"/passed_reads.fastq\", ttl_files=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head '/n/scratch3/groups/hms/sysbio/paulsson/de64/2020-09-24_oDEPool3/passed_reads.fastq'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Run GraphAligner\n",
    "\n",
    "```\n",
    "(base) [de64@compute-e-16-192 ~]$ source activate nanopore\n",
    "(nanopore) [de64@compute-e-16-192 ~]$ GraphAligner -g ~/scratch/de64/2020-09-24_oDEPool3/aDE4.gfa -f ~/scratch/de64/2020-09-24_oDEPool3/FAK31569_pass_b3389333_46.fastq -a ~/scratch/de64/2020-09-24_oDEPool3/output.gaf -x vg\n",
    "GraphAligner bioconda 1.0.12-\n",
    "GraphAligner bioconda 1.0.12-\n",
    "Load graph from /home/de64/scratch/de64/2020-09-24_oDEPool3/aDE4.gfa\n",
    "Build alignment graph\n",
    "118 original nodes\n",
    "150 split nodes\n",
    "2 ambiguous split nodes\n",
    "246 edges\n",
    "99 nodes with in-degree >= 2\n",
    "Build minimizer seeder from the graph\n",
    "Minimizer seeds, length 15, window size 20, density 10\n",
    "Seed cluster size 1\n",
    "Initial bandwidth 10\n",
    "write alignments to /home/de64/scratch/de64/2020-09-24_oDEPool3/output.gaf\n",
    "Align\n",
    "Alignment finished\n",
    "Input reads: 4000 (7071710bp)\n",
    "Seeds found: 422660\n",
    "Seeds extended: 12573\n",
    "Reads with a seed: 3984 (7025587bp)\n",
    "Reads with an alignment: 3984\n",
    "Alignments: 4126 (6980856bp) (8413 additional alignments discarded)\n",
    "End-to-end alignments: 3830 (6590459bp)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Get Reads and CIGAR Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqfile = headpath + \"/passed_reads.fastq\"\n",
    "gafpath = headpath + \"/output.gaf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dict = {}\n",
    "for idx, record in enumerate(SeqIO.parse(fastqfile, \"fastq\")):\n",
    "    read_dict[record.id] = str(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_ids = read_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar_dict = {}\n",
    "with open(gafpath, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        data = line.split(\"\\t\")\n",
    "        read_id = data[0].split(\" \")[0]\n",
    "        if \">\" in data[5]:\n",
    "            cigar_dict[read_id] = (\n",
    "                \"+\",\n",
    "                int(data[7]),\n",
    "                int(data[8]),\n",
    "                data[5],\n",
    "                data[15].split(\":\")[-1][:-1],\n",
    "            )\n",
    "        else:\n",
    "            cigar_dict[read_id] = (\n",
    "                \"-\",\n",
    "                int(data[7]),\n",
    "                int(data[8]),\n",
    "                data[5],\n",
    "                data[15].split(\":\")[-1][:-1],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar_ids = cigar_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(cigar_ids) - set(read_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Trim Reads to Constant Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_key = list(cigar_dict.keys())[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_read = read_dict[test_key]\n",
    "test_cigar = cigar_dict[test_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cigar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"[0-9]{0,10}[MDI]\")\n",
    "result = pattern.finditer(test_cigar[4])\n",
    "cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_comp(instr):\n",
    "    instr = Seq(instr.upper())\n",
    "    rcinstr = instr.reverse_complement()\n",
    "    rcinstr = str(rcinstr)\n",
    "    return rcinstr\n",
    "\n",
    "\n",
    "def align_read(read, cigar, pattern=re.compile(\"[0-9]{0,10}[MDI]\"), padding=1750):\n",
    "    result = pattern.finditer(cigar[4])\n",
    "    cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]\n",
    "    output_str = \"\".join([\"-\" for i in range(cigar[1])])\n",
    "    current_idx = 0\n",
    "    for item in cigar_seq:\n",
    "        if item[0] == \"M\":\n",
    "            added_str = read[current_idx : current_idx + item[1]]\n",
    "            output_str += added_str\n",
    "            current_idx += item[1]\n",
    "        elif item[0] == \"D\":\n",
    "            added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "            output_str += added_str\n",
    "        elif item[0] == \"I\":\n",
    "            current_idx += item[1]\n",
    "    output_str = output_str[:padding]\n",
    "    current_len = len(output_str)\n",
    "    pad_len = padding - current_len\n",
    "    if pad_len > 0:\n",
    "        output_str += \"\".join([\"-\" for i in range(pad_len)])\n",
    "    if cigar[0] == \"-\":\n",
    "        output_str = rev_comp(output_str)\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def make_seg_dict(gfafile):\n",
    "    segment_dict = {}\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                segment_dict[splitline[1]] = splitline[2][:-1]\n",
    "    return segment_dict\n",
    "\n",
    "\n",
    "def generate_reference(cigar, segment_dict):\n",
    "    if cigar[0] == \"+\":\n",
    "        traversal = cigar[3].split(\">\")[1:]\n",
    "        ref = \"\".join(list(map(lambda seg: segment_dict[seg], traversal)))\n",
    "    elif cigar[0] == \"-\":\n",
    "        traversal = cigar[3].split(\"<\")[1:][::-1]\n",
    "        ref = \"\".join(list(map(lambda seg: segment_dict[seg], traversal)))\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_read_dict = {}\n",
    "barcode_dict = {}\n",
    "for key in cigar_dict.keys():\n",
    "    cigar = cigar_dict[key]\n",
    "    #     read = read_dict[key]\n",
    "    if \"GFP\" in cigar[3] and \"SPACER4\" in cigar[3]:\n",
    "        #         aligned_read_dict[key] = align_read(read,cigar)\n",
    "        if cigar[0] == \"-\":\n",
    "            barcode = cigar[3].split(\"<\")\n",
    "            barcode = barcode[::-1]\n",
    "        elif cigar[0] == \"+\":\n",
    "            barcode = cigar[3].split(\">\")\n",
    "        barcode = barcode[:-1]\n",
    "        barcode = (\n",
    "            np.array([\"ON\" in item for item in barcode if \"BIT\" in item])\n",
    "            .astype(int)\n",
    "            .astype(str)\n",
    "            .tolist()\n",
    "        )\n",
    "        barcode = \"\".join(barcode)\n",
    "        barcode_dict[key] = barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(barcode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_arr = np.array(list(barcode_dict.values()))\n",
    "\n",
    "unique, counts = np.unique(barcode_arr, return_counts=True)\n",
    "plt.hist(counts, range=(3, 50), bins=48)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Ok, it looks like 50X depth with very time consuming settings on the alignment are suffecient to get the barcodes.\n",
    "For the record the command run was:\n",
    "```\n",
    "(nanopore) [de64@compute-e-16-192 ~]$ GraphAligner -g ~/scratch/de64/2020-09-24_oDEPool3/aDE4.gfa -f ~/scratch/de64/2020-09-24_oDEPool3/passed_reads.fastq -a ~/scratch/de64/2020-09-24_oDEPool3/output.gaf --high-memory --seeds-first-full-rows 64 -b 35 -C -1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(counts > 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_barcode_arr = unique[counts > 100]\n",
    "final_barcode_arr_counts = counts[counts > 100]\n",
    "final_barcode_idx = dict(zip(final_barcode_arr, range(len(final_barcode_arr))))\n",
    "inv_barcode_idx = dict(zip(range(len(final_barcode_arr)), final_barcode_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_barcode_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_barcode_codebook(barcode_dict, final_barcode_idx):\n",
    "    barcode_codebook = {}\n",
    "    inv_barcode_codebook = {i: [] for i in range(len(final_barcode_idx))}\n",
    "    for key, val in barcode_dict.items():\n",
    "        if val in final_barcode_idx.keys():\n",
    "            barcode_codebook[key] = final_barcode_idx[val]\n",
    "            inv_barcode_codebook[final_barcode_idx[val]].append(key)\n",
    "        else:\n",
    "            barcode_codebook[key] = None\n",
    "    return barcode_codebook, inv_barcode_codebook\n",
    "\n",
    "\n",
    "def get_perc_mapped(barcode_codebook):\n",
    "    mapped_arr = np.array([val != None for val in barcode_codebook.values()])\n",
    "    perc_mapped = np.sum(mapped_arr) / mapped_arr.shape[0]\n",
    "    return perc_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_codebook, inv_barcode_codebook = get_barcode_codebook(\n",
    "    barcode_dict, final_barcode_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_perc_mapped(barcode_codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Export Read Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "readgroup_path = headpath + \"/readgroups\"\n",
    "if os.path.exists(readgroup_path):\n",
    "    if os.path.exists(readgroup_path):\n",
    "        shutil.rmtree(readgroup_path)\n",
    "    os.makedirs(readgroup_path)\n",
    "\n",
    "seg_dict = make_seg_dict(headpath + \"/aDE4.gfa\")\n",
    "record_dict = SeqIO.to_dict(SeqIO.parse(fastqfile, \"fastq\"))\n",
    "for key, val in inv_barcode_codebook.items():\n",
    "    out_str = \"\"\n",
    "    ref_str = \"\"\n",
    "    for read_name in val:\n",
    "        seq_record = record_dict[read_name]\n",
    "        out_str += \"@\" + str(seq_record.id) + \"\\n\"\n",
    "        out_str += str(seq_record.seq) + \"\\n\"\n",
    "\n",
    "    with open(readgroup_path + \"/group_\" + str(key) + \".fastq\", \"w\") as outfile:\n",
    "        outfile.write(out_str)\n",
    "\n",
    "    ref_seq = generate_reference(cigar_dict[read_name], seg_dict)\n",
    "    ref_str += \">group_\" + str(key) + \"\\n\"\n",
    "    ref_str += ref_seq + \"\\n\"\n",
    "\n",
    "    with open(readgroup_path + \"/ref_\" + str(key) + \".fasta\", \"w\") as outfile:\n",
    "        outfile.write(ref_str)\n",
    "\n",
    "# for idx, record in enumerate(SeqIO.parse(fastqfile, \"fastq\")):\n",
    "#     if record.id in barcode_codebook.keys():\n",
    "#         read_group = barcode_codebook[record.id]\n",
    "#         with open(readgroup_path + \"/group_\" + str(read_group) + \".fastq\",\"a\") as outfile:\n",
    "#             outfile.write(\"@\" + str(record.id) + \"\\n\")\n",
    "#             outfile.write(str(record.seq) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Map to Reference Path with Minimap2\n",
    "\n",
    "```\n",
    "\n",
    "minimap2 -ax map-ont -a ./readgroups/ref_6.fasta ./readgroups/group_6.fastq > ./alignment_6.sam; samtools sort ./alignment_6.sam -o ./alignment_6.sorted.sam; cp ./readgroups/ref_6.fasta ./\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Nanopolish\n",
    "\n",
    "```\n",
    "sed -n '1~4s/^@/>/p;2~4p' group_6.fastq > group_6.fasta ##convert to fasta\n",
    "\n",
    "minimap2 -ax map-ont -t 8 ref_6.fasta group_6.fasta | samtools sort -o group_6.sorted.bam -T group_6.tmp\n",
    "\n",
    "samtools index group_6.sorted.bam\n",
    "\n",
    "nanopolish variants --consensus group_6.cons -o group_6_polished.vcf -w \"group_6\" -r group_6.fasta -b group_6.sorted.bam -g ref_6.fasta\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Madaka\n",
    "```\n",
    "medaka_consensus -i group_6.fastq -d ref_6.fasta -o consensus_6\n",
    "\n",
    "\n",
    "minimap2 -ax map-ont -t 8 ref_6.fasta group_6.fasta | samtools sort -o group_6.bam\n",
    "\n",
    "samtools index group_6.bam group_6.bam.bai\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimap2 -ax map-ont -t 8 ref_6.fasta consensus.fasta | samtools sort -o consensus.sorted.bam -T consensus.tmp\n",
    "\n",
    "samtools index consensus.sorted.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Make consensuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_dict[inv_barcode_codebook[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_reads(final_barcode_idx, reads_path, barcode_dict):\n",
    "    grouped_reads = {i: [] for i in range(len(final_Nmer_idx))}\n",
    "\n",
    "    for idx, record in enumerate(SeqIO.parse(reads_path, \"fastq\")):\n",
    "        if Nmer_codebook[idx] != None:\n",
    "            record_str = str(record.seq)\n",
    "            handle_start = record.seq.find(handle_seq)\n",
    "            if (\n",
    "                len(record.seq[handle_start : handle_start + min_read_len])\n",
    "                == min_read_len\n",
    "            ):\n",
    "                grouped_reads[Nmer_codebook[idx]].append(\n",
    "                    record.seq[handle_start : handle_start + min_read_len]\n",
    "                )\n",
    "    return grouped_reads\n",
    "\n",
    "\n",
    "def get_all_grouped_reads(\n",
    "    key_list, handle_dict, fwdread_paths, revread_paths, Nmer_codebooks, final_Nmer_idx\n",
    "):\n",
    "    grouped_reads_dict = {}\n",
    "    for key in key_list:\n",
    "        fwd_path = fwdread_paths[key]\n",
    "        rev_path = revread_paths[key]\n",
    "        fwd_handle, rev_handle = tuple(handle_dict[key])\n",
    "        Nmer_codebook = Nmer_codebooks[key]\n",
    "\n",
    "        fwd_grouped_reads = group_reads(\n",
    "            final_Nmer_idx, fwd_path, Nmer_codebook, fwd_handle\n",
    "        )\n",
    "        rev_grouped_reads = group_reads(\n",
    "            final_Nmer_idx, rev_path, Nmer_codebook, rev_handle\n",
    "        )\n",
    "        grouped_reads_dict[key] = [fwd_grouped_reads, rev_grouped_reads]\n",
    "    return grouped_reads_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = [\"GFP\", \"BC1\", \"BC2\"]\n",
    "handle_dict = {\n",
    "    \"GFP\": [\"AAGTAGTGACAAGTGTTGGC\", \"AGGCTAGCTAACGTTACTGT\"],\n",
    "    \"BC1\": [\"ACGAACGTTAGCAGCACTAT\", \"GTATCTGTTATGTAATTGCTAG\"],\n",
    "    \"BC2\": [\"ACGAACGTTAGCAGCACTAT\", \"ATTACTGATGGCAATGTGAT\"],\n",
    "}\n",
    "\n",
    "grouped_reads_dict = get_all_grouped_reads(\n",
    "    key_list, handle_dict, fwdread_paths, revread_paths, Nmer_codebooks, final_Nmer_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "#### Filter out barcodes with low representation in at least one group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_underrep_barcodes(grouped_reads_dict, min_count=5):\n",
    "    underrep_barcodes = []\n",
    "    for key in grouped_reads_dict.keys():\n",
    "        for idx, val in grouped_reads_dict[key][0].items():\n",
    "            if len(val) < min_count:\n",
    "                underrep_barcodes.append(idx)\n",
    "        for idx, val in grouped_reads_dict[key][1].items():\n",
    "            if len(val) < min_count:\n",
    "                underrep_barcodes.append(idx)\n",
    "    underrep_barcodes = sorted(list(set(underrep_barcodes)))\n",
    "    return underrep_barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "underrep_barcodes = get_underrep_barcodes(grouped_reads_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(underrep_barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_underrep(grouped_reads, underrep_barcodes):\n",
    "    new_idx = 0\n",
    "    output_dict = copy.copy(grouped_reads)\n",
    "\n",
    "    for key, val in grouped_reads.items():\n",
    "        if key in underrep_barcodes:\n",
    "            pass\n",
    "        else:\n",
    "            output_dict[new_idx] = val\n",
    "            new_idx += 1\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def remove_all_underrep(grouped_reads_dict, underrep_barcodes):\n",
    "    represented_reads_dict = copy.copy(grouped_reads_dict)\n",
    "\n",
    "    for key in grouped_reads_dict.keys():\n",
    "        represented_reads_dict[key][0] = remove_underrep(\n",
    "            grouped_reads_dict[key][0], underrep_barcodes\n",
    "        )\n",
    "        represented_reads_dict[key][1] = remove_underrep(\n",
    "            grouped_reads_dict[key][1], underrep_barcodes\n",
    "        )\n",
    "\n",
    "    return represented_reads_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "represented_reads_dict = remove_all_underrep(grouped_reads_dict, underrep_barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "represented_reads_dict[\"BC1\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_consensus(grouped_reads):\n",
    "    consensus_seqs = []\n",
    "\n",
    "    for key, val in grouped_reads.items():\n",
    "        working_motif = motifs.create(val)\n",
    "        consensus_seqs.append(str(working_motif.consensus))\n",
    "\n",
    "    consensus_seqs = np.array(consensus_seqs)\n",
    "    return consensus_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_seqs = get_group_consensus(represented_reads_dict[\"BC1\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_seqs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "#### Bit Extractiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bitmap(start_bit, start_bit_idx, rev_read, bit_len=20, read_length=145):\n",
    "    bit_starts = list(range(start_bit_idx, read_length, bit_len + 1))[:-1]\n",
    "    if rev_read:\n",
    "        bit_map = {\n",
    "            start_bit - i: slice(bit_start, bit_start + bit_len)\n",
    "            for i, bit_start in enumerate(bit_starts)\n",
    "        }\n",
    "    else:\n",
    "        bit_map = {\n",
    "            start_bit + i: slice(bit_start, bit_start + bit_len)\n",
    "            for i, bit_start in enumerate(bit_starts)\n",
    "        }\n",
    "    return bit_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc1_f_map = get_bitmap(0, 56, False)\n",
    "bc1_r_map = get_bitmap(9, 21, True)\n",
    "bc2_f_map = get_bitmap(0, 56, False)\n",
    "bc2_r_map = get_bitmap(29, 21, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc1_r_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "#### Define Bit Sequence Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_seqs = [\n",
    "    \"ACACTACCACCATTTCCTAT\",\n",
    "    \"AAACACACACTAAACCACCC\",\n",
    "    \"ATCCTCCTTCAATACATCCC\",\n",
    "    \"TATCTCATCAATCCCACACT\",\n",
    "    \"ACTCCACTACTACTCACTCT\",\n",
    "    \"AACTCATCTCAATCCTCCCA\",\n",
    "    \"ACCACAACCCATTCCTTTCA\",\n",
    "    \"TCTATCATCTCCAAACCACA\",\n",
    "    \"ACCCTCTAACTTCCATCACA\",\n",
    "    \"AATACTCTCCCACCTCAACT\",\n",
    "    \"TTTCTACCACTAATCAACCC\",\n",
    "    \"TCCAACTCATCTCTAATCTC\",\n",
    "    \"TCCTATTCTCAACCTAACCT\",\n",
    "    \"ATAAATCATTCCCACTACCC\",\n",
    "    \"ACCCTTTACAAACACACCCT\",\n",
    "    \"TTCCTAACAAATCACATCCC\",\n",
    "    \"TATCCTTCAATCCCTCCACA\",\n",
    "    \"ACCCAACACTCATAACATCC\",\n",
    "    \"TTTACTCCCTACACCTCCAA\",\n",
    "    \"ACTTTCCACATACTATCCCA\",\n",
    "    \"ACATTACACCTCATTCTCCC\",\n",
    "    \"TACTACAAACCCATAATCCC\",\n",
    "    \"TTCTCCCTCTATCAACTCTA\",\n",
    "    \"TTCTTCCCTCAATCTTCATC\",\n",
    "    \"TCCTAACAACCAACTACTCC\",\n",
    "    \"ACCTTTCTCCATACCCAACT\",\n",
    "    \"ACCCTTACTACTACATCATC\",\n",
    "    \"AATCTCACCTTCCACTTCAC\",\n",
    "    \"TCTATCATTACCCTCCTCCT\",\n",
    "    \"TCCTCATCTTACTCCCTCTA\",\n",
    "]\n",
    "\n",
    "neg_seqs = [\n",
    "    \"TCACCTTTCTCCTTTCCTCT\",\n",
    "    \"CCCTCTACTCTCCATCTTAT\",\n",
    "    \"AACCTCCTCTCTCCATCATA\",\n",
    "    \"TCACCATAATTCCTCCTCCT\",\n",
    "    \"ACCAACTTCCACACATCACT\",\n",
    "    \"CCCTCTTACTTATCTACCCA\",\n",
    "    \"ACATCTTCTCTCCAACCTTC\",\n",
    "    \"TATCATCCTCCTTCTCTCAC\",\n",
    "    \"CTTCTTCTCTTACACCCTCT\",\n",
    "    \"TCCCACCTTCACTTCACTAT\",\n",
    "    \"CACCCTAACATACAACTCTC\",\n",
    "    \"AAACTTCATCACTCTCCTCC\",\n",
    "    \"TCAATCCACCATTCCTCAAC\",\n",
    "    \"TAAAACCCATCCCACATCCT\",\n",
    "    \"TTAAACAACCCATCCCACCA\",\n",
    "    \"CATAACCCTACACACAACAC\",\n",
    "    \"CTCTCTACACCCACCAATAA\",\n",
    "    \"ATTCCATACCCACTCTCTTC\",\n",
    "    \"CCCTTACCAACAACAATCCT\",\n",
    "    \"TCAACTCATTACCCACAACC\",\n",
    "    \"CATATCCAACCACAACCTCA\",\n",
    "    \"CAACCACACTCAACTACCAT\",\n",
    "    \"ACCTTCTACTCCCAACATTC\",\n",
    "    \"CCTCTTCATCCTCTTTCAAC\",\n",
    "    \"AACTCACAAACACCTCACCT\",\n",
    "    \"CCCAAAACCACACACCAATT\",\n",
    "    \"ATCCATATCCTTCTCACCCT\",\n",
    "    \"CTCTTAACTACCCTCATTCC\",\n",
    "    \"TTTCCTTCTTCCCACCAACT\",\n",
    "    \"CAACCACCAACTTCAATCTC\",\n",
    "]\n",
    "\n",
    "bc_ref_map = np.array(list(zip(neg_seqs, pos_seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_ref_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "#### Decode Consensus Bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(string):\n",
    "    code = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "    conv_str = np.array(list(map(lambda x: code[x], string)))\n",
    "    return conv_str\n",
    "\n",
    "\n",
    "def compare_seqs(target_arr, reference_arr):\n",
    "    target_int_arr = np.array(list(map(str_to_int, target_arr)), dtype=\"uint8\")\n",
    "    reference_int_arr = np.array(list(map(str_to_int, reference_arr)), dtype=\"uint8\")\n",
    "\n",
    "    bool_arr = target_int_arr[:, np.newaxis, :] == reference_int_arr[np.newaxis, :, :]\n",
    "\n",
    "    agreement_arr = np.sum(bool_arr, axis=2, dtype=int)\n",
    "    hamming_arr = bool_arr.shape[2] - agreement_arr\n",
    "\n",
    "    return hamming_arr\n",
    "\n",
    "\n",
    "def get_bit_assignment(seq_arr, bc_ref, single_bit_map, rev_read):\n",
    "    if rev_read:\n",
    "        bit_arr = np.array(list(map(lambda x: x[single_bit_map], seq_arr)))\n",
    "    else:\n",
    "        bit_arr = np.array(list(map(lambda x: rev_comp(x[single_bit_map]), seq_arr)))\n",
    "\n",
    "    hamming_arr = compare_seqs(bit_arr, bc_ref)\n",
    "    assigned_bit_arr = np.argmin(hamming_arr, axis=1)\n",
    "\n",
    "    return assigned_bit_arr\n",
    "\n",
    "\n",
    "def get_read_bit_assignment(seq_arr, bit_map, bc_ref_map, rev_read):\n",
    "    bit_assignment = {}\n",
    "\n",
    "    for bit in bit_map.keys():\n",
    "        bc_ref = bc_ref_map[bit]\n",
    "        single_bit_map = bit_map[bit]\n",
    "        bit_assignment[bit] = get_bit_assignment(\n",
    "            seq_arr, bc_ref, single_bit_map, rev_read\n",
    "        )\n",
    "\n",
    "    return bit_assignment\n",
    "\n",
    "\n",
    "def get_perc_matched(grouped_reads, bit_assignment, bit_map, bc_ref_map, rev_read):\n",
    "    perc_match_dict = {key: [] for key in bit_map.keys()}\n",
    "\n",
    "    for read_idx in grouped_reads.keys():\n",
    "        query_arr = np.array([str(item) for item in grouped_reads[read_idx]])\n",
    "        query_assign = get_read_bit_assignment(query_arr, bit_map, bc_ref_map, rev_read)\n",
    "\n",
    "        for key in perc_match_dict.keys():\n",
    "            correct_assign_arr = query_assign[key] == bit_assignment[key][read_idx]\n",
    "            perc_match = np.sum(correct_assign_arr) / correct_assign_arr.shape[0]\n",
    "            perc_match_dict[key].append(perc_match)\n",
    "\n",
    "    return perc_match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_seqs = get_group_consensus(represented_reads_dict[\"BC1\"][0])\n",
    "bit_assignment = get_read_bit_assignment(consensus_seqs, bc1_f_map, bc_ref_map, False)\n",
    "bc1_f_perc_match_dict = get_perc_matched(\n",
    "    represented_reads_dict[\"BC1\"][0], bit_assignment, bc1_f_map, bc_ref_map, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    bc1_f_perc_match_dict[0],\n",
    "    range=(0.5, 1.0),\n",
    "    bins=20,\n",
    "    label=\"Bit 0\",\n",
    "    color=\"grey\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.hist(\n",
    "    bc1_r_perc_match_dict[9],\n",
    "    range=(0.5, 1.0),\n",
    "    bins=20,\n",
    "    label=\"Bit 9\",\n",
    "    color=\"salmon\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.ylim(0, 4000)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"BC1.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    bc2_f_perc_match_dict[0],\n",
    "    range=(0.5, 1.0),\n",
    "    bins=20,\n",
    "    label=\"Bit 0\",\n",
    "    color=\"grey\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.hist(\n",
    "    bc2_r_perc_match_dict[29],\n",
    "    range=(0.5, 1.0),\n",
    "    bins=20,\n",
    "    label=\"Bit 29\",\n",
    "    color=\"salmon\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.ylim(0, 4000)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"BC2.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bc1_f_perc_match_dict[0], range=(0.5, 1.0), bins=20)\n",
    "plt.ylim(0, 4000)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit 0 Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bc1_f_perc_match_dict[3], range=(0.5, 1.0), bins=20)\n",
    "plt.ylim(0, 4000)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit 3 Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_seqs = get_group_consensus(represented_reads_dict[\"BC1\"][1])\n",
    "bit_assignment = get_read_bit_assignment(consensus_seqs, bc1_r_map, bc_ref_map, True)\n",
    "bc1_r_perc_match_dict = get_perc_matched(\n",
    "    represented_reads_dict[\"BC1\"][1], bit_assignment, bc1_r_map, bc_ref_map, True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bc1_r_perc_match_dict[5], range=(0.5, 1.0), bins=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit 5 Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bc1_r_perc_match_dict[9], range=(0.5, 1.0), bins=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit 9 Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_seqs = get_group_consensus(represented_reads_dict[\"BC2\"][0])\n",
    "bit_assignment = get_read_bit_assignment(consensus_seqs, bc2_f_map, bc_ref_map, False)\n",
    "bc2_f_perc_match_dict = get_perc_matched(\n",
    "    represented_reads_dict[\"BC2\"][0], bit_assignment, bc2_f_map, bc_ref_map, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bc2_f_perc_match_dict[0], range=(0.5, 1.0), bins=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit 0 Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bc2_f_perc_match_dict[3], range=(0.5, 1.0), bins=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit 3 Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_seqs = get_group_consensus(represented_reads_dict[\"BC2\"][1])\n",
    "bit_assignment = get_read_bit_assignment(consensus_seqs, bc2_r_map, bc_ref_map, True)\n",
    "bc2_r_perc_match_dict = get_perc_matched(\n",
    "    represented_reads_dict[\"BC2\"][1], bit_assignment, bc2_r_map, bc_ref_map, True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bc2_r_perc_match_dict[25], range=(0.5, 1.0), bins=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit 25 Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bc2_r_perc_match_dict[29], range=(0.5, 1.0), bins=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"% Bit 29 Agreement\", fontsize=20)\n",
    "plt.ylabel(\"# of Barcodes\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_assign[1] == bit_assignment[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bit_assignment(seq_arr,bit_map,rev_read)\n",
    "bit_arr = np.array(list(map(lambda x: rev_comp(x[bc1_f_map[0]]), consensus_seqs)))\n",
    "\n",
    "hamming_arr = compare_seqs(bit_arr,bc_ref_map[0])\n",
    "assigned_bit = np.argmin(hamming_arr,axis=1)\n",
    "dist_from_assigned = np.min(hamming_arr,axis=1)\n",
    "good_assign = dist_from_assigned < 3\n",
    "perc_confident_assignment = np.sum(good_assign)/good_assign.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perc_confident_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dist_from_assigned, range=(1, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_0_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_reads_dict[\"BC1\"][1][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_second_max(grouped_reads):\n",
    "    try:\n",
    "        m = motifs.create(grouped_reads).counts.normalize(pseudocounts=0.001)\n",
    "        m = np.array([list(m[key]) for key in m.keys()]).T\n",
    "        where_max = np.equal(m, np.max(m, axis=1)[:, np.newaxis])\n",
    "        second_max = np.max(m[~where_max].reshape(m.shape[0], 3), axis=1)\n",
    "        plt.plot(second_max, c=\"grey\", alpha=0.3)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_reads_dict[\"BC1\"][0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_second_max(grouped_reads):\n",
    "    try:\n",
    "        m = motifs.create(grouped_reads).counts.normalize(pseudocounts=0.001)\n",
    "        m = np.array([list(m[key]) for key in m.keys()]).T\n",
    "        where_max = np.equal(m, np.max(m, axis=1)[:, np.newaxis])\n",
    "        second_max = np.max(m[~where_max].reshape(m.shape[0], 3), axis=1)\n",
    "        plt.plot(second_max, c=\"grey\", alpha=0.3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_over_thr_arr(grouped_reads):\n",
    "    over_thr_arr = []\n",
    "    for _, val in grouped_reads.items():\n",
    "        try:\n",
    "            m = motifs.create(val).counts.normalize(pseudocounts=0.001)\n",
    "            m = np.array([list(m[key]) for key in m.keys()]).T\n",
    "            where_max = np.equal(m, np.max(m, axis=1)[:, np.newaxis])\n",
    "            second_max = np.max(m[~where_max].reshape(m.shape[0], 3), axis=1)\n",
    "            over_thr = second_max > 0.1\n",
    "            over_thr_arr.append(over_thr)\n",
    "        except:\n",
    "            pass\n",
    "    over_thr_arr = np.array(over_thr_arr)\n",
    "    return over_thr_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    plot_second_max(grouped_reads[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_thr_arr = get_over_thr_arr(grouped_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_thr_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(over_thr_arr, axis=1) / over_thr_arr.shape[1], range=(0, 0.1), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_seq = rev_comp(\"ATCACATTGCCATCAGTAAT\")\n",
    "key = \"BC2\"\n",
    "\n",
    "grouped_reads = {i: [] for i in range(len(final_Nmer_idx))}\n",
    "\n",
    "fwd_path = fwdread_paths[key]\n",
    "rev_path = revread_paths[key]\n",
    "Nmer_codebook = Nmer_codebooks[key]\n",
    "for idx, record in enumerate(SeqIO.parse(rev_path, \"fastq\")):\n",
    "    if Nmer_codebook[idx] != None:\n",
    "        record_str = str(record.seq)\n",
    "        Nmer_start = record.seq.find(handle_seq)\n",
    "        if len(record.seq[Nmer_start : Nmer_start + 142]) == 142:\n",
    "            grouped_reads[Nmer_codebook[idx]].append(\n",
    "                record.seq[Nmer_start : Nmer_start + 142]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(grouped_reads[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    plot_second_max(grouped_reads[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_thr_arr = get_over_thr_arr(grouped_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(over_thr_arr, axis=1) / over_thr_arr.shape[1], range=(0, 0.1), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sum(over_thr_arr, axis=1) / over_thr_arr.shape[1], range=(0, 0.1), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwdread_paths[\"BC1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(counts, range=(5, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(final_Nmer_arr_counts, range=(0, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fastqlist = [\"reads/readset_0.fastq\", \"reads/readset_1.fastq\"]\n",
    "print(fastqlist)\n",
    "record_dict = [\n",
    "    SeqIO.to_dict(SeqIO.parse(fastqfile, \"fastq\")) for fastqfile in fastqlist\n",
    "]\n",
    "record_dict = {key: val for subdict in record_dict for key, val in subdict.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
