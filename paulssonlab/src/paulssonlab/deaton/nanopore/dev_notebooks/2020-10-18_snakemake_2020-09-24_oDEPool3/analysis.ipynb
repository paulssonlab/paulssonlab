{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_read(querystr, cigarstr, pattern=re.compile(\"[0-9]{0,10}[MDI]\")):\n",
    "    result = pattern.finditer(cigarstr)\n",
    "    cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]\n",
    "    #     output_str = \"\".join([\"-\" for i in range(cigar[1])])\n",
    "    output_str = \"\"\n",
    "    current_idx = 0\n",
    "    for item in cigar_seq:\n",
    "        if item[0] == \"M\":\n",
    "            added_str = querystr[current_idx : current_idx + item[1]]\n",
    "            output_str += added_str\n",
    "            current_idx += item[1]\n",
    "        elif item[0] == \"D\":\n",
    "            added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "            output_str += added_str\n",
    "        elif item[0] == \"I\":\n",
    "            current_idx += item[1]\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head \"./alignment/chunk_0/group_0.sam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cigarsfromsam(samfilepath):\n",
    "    cigars = {}\n",
    "    with open(samfilepath, \"r\") as samfile:\n",
    "        for line in samfile:\n",
    "            if line[0] == \"@\":\n",
    "                next(samfile)\n",
    "            else:\n",
    "                splitline = line.split(\"\\t\")\n",
    "                cigars[splitline[0]] = splitline[5]\n",
    "    return cigars\n",
    "\n",
    "\n",
    "def strsfromfasta(fastafilepath):\n",
    "    queries = SeqIO.to_dict(SeqIO.parse(fastafilepath, \"fasta\"))\n",
    "    queries = {key: str(val.seq) for key, val in queries.items()}\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cigars = cigarsfromsam(\"./alignment/chunk_0/group_0.sam\")\n",
    "queries = strsfromfasta(\"./consensus/chunk_0/group_0/consensus.fasta\")\n",
    "references = strsfromfasta(\"./grouprefs/chunk_0/group_0.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(list(cigars.keys())[0].split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar = list(cigars.values())[0]\n",
    "query = list(queries.values())[0]\n",
    "reference = list(references.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_read(query, cigar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seg_dict(gfafile):\n",
    "    segment_dict = {}\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                segment_dict[splitline[1]] = splitline[2][:-1]\n",
    "    return segment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_intervals(gfafile):\n",
    "    segment_dict = {}\n",
    "    current_idx = 0\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                if \"OFF\" not in splitline[1]:\n",
    "                    refstr = splitline[2][:-1]\n",
    "                    strlen = len(refstr)\n",
    "                    name = splitline[1]\n",
    "                    if \"ON\" in name:\n",
    "                        name = name[:-2]\n",
    "                    segment_dict[name] = tuple((current_idx, current_idx + strlen))\n",
    "                    current_idx += strlen\n",
    "    return segment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_intervals = get_ref_intervals(\"ref.gfa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/output.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_read(querystr, cigarstr, pattern=re.compile(\"[0-9]{0,10}[MDI]\")):\n",
    "    result = pattern.finditer(cigarstr)\n",
    "    cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]\n",
    "    #     output_str = \"\".join([\"-\" for i in range(cigar[1])])\n",
    "    output_str = \"\"\n",
    "    current_idx = 0\n",
    "    for item in cigar_seq:\n",
    "        if item[0] == \"M\":\n",
    "            added_str = querystr[current_idx : current_idx + item[1]]\n",
    "            output_str += added_str\n",
    "            current_idx += item[1]\n",
    "        elif item[0] == \"D\":\n",
    "            added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "            output_str += added_str\n",
    "        elif item[0] == \"I\":\n",
    "            current_idx += item[1]\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def splitstr(instr, ref_intervals):\n",
    "    strassign = {key: instr[val[0] : val[1]] for key, val in ref_intervals.items()}\n",
    "    return strassign\n",
    "\n",
    "\n",
    "def slow_hamming_distance(s1, s2):\n",
    "    if len(s1) != len(s2):\n",
    "        raise ValueError(\"Strand lengths are not equal!\")\n",
    "    term_list = []\n",
    "    for ch1, ch2 in zip(s1, s2):\n",
    "        if ch1 == \"N\" or ch2 == \"N\":\n",
    "            term_list.append(False)\n",
    "        else:\n",
    "            term_list.append(ch1 != ch2)\n",
    "    result = sum(term_list)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_dict_dist(dict1, dict2):\n",
    "    hamming_dict = {\n",
    "        key: slow_hamming_distance(dict1[key], dict2[key]) for key in dict1.keys()\n",
    "    }\n",
    "    return hamming_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_cons = data.apply(lambda x: align_read(x[\"consensus\"], x[\"cigar\"]), axis=1)\n",
    "data[\"aligned_cons\"] = aligned_cons\n",
    "\n",
    "split_ref = data.apply(lambda x: splitstr(x[\"reference\"], ref_intervals), axis=1)\n",
    "split_align = data.apply(lambda x: splitstr(x[\"aligned_cons\"], ref_intervals), axis=1)\n",
    "data[\"split_ref\"] = split_ref\n",
    "data[\"split_align\"] = split_align\n",
    "\n",
    "data[\"split_ref\"] = data[\"split_ref\"].apply(\n",
    "    lambda x: {key: val for key, val in x.items() if key != \"SPACER4\"}\n",
    ")  ## This is a hack until I can repull the alignment data...\n",
    "data[\"split_align\"] = data[\"split_align\"].apply(\n",
    "    lambda x: {key: val for key, val in x.items() if key != \"SPACER4\"}\n",
    ")  ## This is a hack until I can repull the alignment data...\n",
    "\n",
    "hamm_ref = data.apply(lambda x: get_dict_dist(x[\"split_align\"], x[\"split_ref\"]), axis=1)\n",
    "data[\"hamm_ref\"] = hamm_ref\n",
    "\n",
    "dark_gfp = (\n",
    "    data.apply(\n",
    "        lambda x: slow_hamming_distance(\n",
    "            x[\"split_align\"][\"GFP\"][623:625], x[\"split_ref\"][\"GFP\"][623:625]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    > 0\n",
    ")\n",
    "data[\"dark_gfp\"] = dark_gfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = data[data[\"subsample\"] == 200]\n",
    "gt_lookup = dict(zip(gt_data[\"barcodeid\"], gt_data[\"dark_gfp\"]))\n",
    "\n",
    "data[\"call\"] = data.apply(lambda x: x[\"dark_gfp\"] == gt_lookup[x[\"barcodeid\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_group = data.groupby(\"subsample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_curve = subsample_group.aggregate({\"call\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_scores = -10 * np.log10(1.0 - call_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(call_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1.0 - call_curve)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(q_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitlist = [\"BIT\" + str(i) for i in range(27)]\n",
    "bit_mismatch_dict = {}\n",
    "for bit in bitlist:\n",
    "    mismatch_list = data.apply(lambda x: x[\"hamm_ref\"][bit], axis=1).values\n",
    "    bit_mismatch_dict[bit] = mismatch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_mismatch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for key in bit_mismatch_dict.keys():\n",
    "    plt.hist(bit_mismatch_dict[key], bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscalls = data.apply(lambda x: x[\"hamm_ref\"][\"BIT26\"], axis=1).values > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([int(item[26]) for item in data[miscalls][\"barcode\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([int(item[26]) for item in data[~miscalls][\"barcode\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([int(item[26]) for item in data[\"barcode\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the last bit is always called as 0; fixed. was no newline at the end of the .gaf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.random.choice([0, 1, 2], size=3, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpathlist = [\n",
    "    \"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/graph_output/\"\n",
    "    + item\n",
    "    for item in os.listdir(\n",
    "        \"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/graph_output\"\n",
    "    )\n",
    "    if item[-3:] == \"tsv\" and item[:4] == \"read\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Barcode Histogram ###\n",
    "\n",
    "barcode_dict = {}\n",
    "for filepath in inpathlist:\n",
    "    with open(filepath, \"r\") as infile:\n",
    "        next(infile)\n",
    "        for line in infile:\n",
    "            data = line.split(\"\\t\")\n",
    "            barcode_dict[data[0]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_arr = np.array(list(barcode_dict.values()))\n",
    "unique, counts = np.unique(barcode_arr, return_counts=True)="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = (2, np.max(counts[counts]))\n",
    "nbins = vmax - vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = (0, int(np.percentile(counts, 99.9)))\n",
    "nbins = min(200, vmax - vmin)\n",
    "\n",
    "plt.hist(counts, range=(vmin, vmax), bins=nbins)\n",
    "plt.yscale(\"log\")\n",
    "plt.axvline(200, color=\"salmon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/graph_output/inv_codebook.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"barcodeid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[\"readlist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_barcode_codebook = {}\n",
    "for _, row in data.iterrows():\n",
    "    inv_barcode_codebook[int(row[\"barcodeid\"])] = ast.literal_eval(row[\"readlist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_barcode_codebook[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {1: 2}\n",
    "d.update({3: 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"making fastq dict\")\n",
    "record_dict_list = [{1: 2}, {3: 4}, {5: 6}]\n",
    "record_dict = {}\n",
    "for i in range(len(record_dict_list)):\n",
    "    subdict = record_dict_list[i]\n",
    "    record_dict.update(subdict)\n",
    "    del subdict\n",
    "    record_dict_list[i] = None\n",
    "del record_dict_list\n",
    "print(\"finished making fastq dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/output.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[data[\"subsample\"] == 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
