{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_read(querystr, cigarstr, pattern=re.compile(\"[0-9]{0,10}[MDI]\")):\n",
    "    result = pattern.finditer(cigarstr)\n",
    "    cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]\n",
    "    #     output_str = \"\".join([\"-\" for i in range(cigar[1])])\n",
    "    output_str = \"\"\n",
    "    current_idx = 0\n",
    "    for item in cigar_seq:\n",
    "        if item[0] == \"M\":\n",
    "            added_str = querystr[current_idx : current_idx + item[1]]\n",
    "            output_str += added_str\n",
    "            current_idx += item[1]\n",
    "        elif item[0] == \"D\":\n",
    "            added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "            output_str += added_str\n",
    "        elif item[0] == \"I\":\n",
    "            current_idx += item[1]\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def cigarsfromsam(samfilepath):\n",
    "    cigars = {}\n",
    "    with open(samfilepath, \"r\") as samfile:\n",
    "        for line in samfile:\n",
    "            if line[0] == \"@\":\n",
    "                next(samfile)\n",
    "            else:\n",
    "                splitline = line.split(\"\\t\")\n",
    "                cigars[splitline[0]] = splitline[5]\n",
    "    return cigars\n",
    "\n",
    "\n",
    "def strsfromfasta(fastafilepath):\n",
    "    queries = SeqIO.to_dict(SeqIO.parse(fastafilepath, \"fasta\"))\n",
    "    queries = {key: str(val.seq) for key, val in queries.items()}\n",
    "    return queries\n",
    "\n",
    "\n",
    "def make_seg_dict(gfafile):\n",
    "    segment_dict = {}\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                segment_dict[splitline[1]] = splitline[2][:-1]\n",
    "    return segment_dict\n",
    "\n",
    "\n",
    "def get_ref_intervals(gfafile):\n",
    "    segment_dict = {}\n",
    "    current_idx = 0\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                if \"OFF\" not in splitline[1]:\n",
    "                    refstr = splitline[2][:-1]\n",
    "                    strlen = len(refstr)\n",
    "                    name = splitline[1]\n",
    "                    if \"ON\" in name:\n",
    "                        name = name[:-2]\n",
    "                    segment_dict[name] = tuple((current_idx, current_idx + strlen))\n",
    "                    current_idx += strlen\n",
    "    return segment_dict\n",
    "\n",
    "\n",
    "def align_read(querystr, cigarstr, pattern=re.compile(\"[0-9]{0,10}[MDI]\")):\n",
    "    result = pattern.finditer(cigarstr)\n",
    "    cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]\n",
    "    #     output_str = \"\".join([\"-\" for i in range(cigar[1])])\n",
    "    output_str = \"\"\n",
    "    current_idx = 0\n",
    "    for item in cigar_seq:\n",
    "        if item[0] == \"M\":\n",
    "            added_str = querystr[current_idx : current_idx + item[1]]\n",
    "            output_str += added_str\n",
    "            current_idx += item[1]\n",
    "        elif item[0] == \"D\":\n",
    "            added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "            output_str += added_str\n",
    "        elif item[0] == \"I\":\n",
    "            current_idx += item[1]\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def splitstr(instr, ref_intervals):\n",
    "    strassign = {key: instr[val[0] : val[1]] for key, val in ref_intervals.items()}\n",
    "    return strassign\n",
    "\n",
    "\n",
    "def slow_hamming_distance(s1, s2):\n",
    "    if len(s1) != len(s2):\n",
    "        print(s1, s2)\n",
    "        raise ValueError(\"Strand lengths are not equal!\")\n",
    "    term_list = []\n",
    "    for ch1, ch2 in zip(s1, s2):\n",
    "        if ch1 == \"N\" or ch2 == \"N\":\n",
    "            term_list.append(False)\n",
    "        else:\n",
    "            term_list.append(ch1 != ch2)\n",
    "    result = sum(term_list)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_dict_dist(dict1, dict2):\n",
    "    hamming_dict = {\n",
    "        key: slow_hamming_distance(dict1[key], dict2[key]) for key in dict1.keys()\n",
    "    }\n",
    "    return hamming_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL PATHS\n",
    "# R9_data = pd.read_csv(\"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/output.tsv\",delimiter=\"\\t\")\n",
    "# R10_data = pd.read_csv(\"/home/de64/scratch/de64/2020-10-18_snakemake_2020-10-14_lDE11_R10-3_merged/output.tsv\",delimiter=\"\\t\")\n",
    "# ref_intervals = get_ref_intervals(\"/home/de64/scratch/de64/2020-10-18_snakemake_2020-10-14_lDE11_R10-3_merged/ref.gfa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R9_data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-12-05_DAC/R9_output.tsv\", delimiter=\"\\t\"\n",
    ")\n",
    "R10_data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-12-05_DAC/R10_output.tsv\", delimiter=\"\\t\"\n",
    ")\n",
    "ref_intervals = get_ref_intervals(\"./ref.gfa\")\n",
    "\n",
    "R9_barcodes = set(R9_data[\"barcode\"].tolist())\n",
    "R10_barcodes = set(R10_data[\"barcode\"].tolist())\n",
    "\n",
    "R9_only_barcodes = R9_barcodes - R10_barcodes\n",
    "R10_only_barcodes = R10_barcodes - R9_barcodes\n",
    "shared_barcodes = R10_barcodes & R9_barcodes\n",
    "barcode_count_arr = np.array(\n",
    "    [len(R9_only_barcodes), len(R10_only_barcodes), len(shared_barcodes)]\n",
    ")\n",
    "\n",
    "R9_data = R9_data[R9_data[\"barcode\"].isin(shared_barcodes)]\n",
    "R10_data = R10_data[R10_data[\"barcode\"].isin(shared_barcodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=[\"R9 Only\", \"R10 Only\", \"Both\"], y=barcode_count_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_arr = np.array([list(item) for item in shared_barcodes]).astype(int)\n",
    "bit_freq = np.mean(bit_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bit_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=list(range(27)), y=bit_freq, color=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_on = bit_arr @ bit_arr.T\n",
    "both_off = (-bit_arr + 1) @ (-bit_arr.T + 1)\n",
    "ttl_match = both_on + both_off\n",
    "np.fill_diagonal(ttl_match, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_match = np.min(ttl_match, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(closest_match, range=(0, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(closest_match == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    np.random.choice(ttl_match.flatten(), 50000, replace=False), range=(0, 27), bins=27\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_cons = R9_data.apply(lambda x: align_read(x[\"consensus\"], x[\"cigar\"]), axis=1)\n",
    "R9_data[\"aligned_cons\"] = aligned_cons\n",
    "\n",
    "aligned_cons = R10_data.apply(lambda x: align_read(x[\"consensus\"], x[\"cigar\"]), axis=1)\n",
    "R10_data[\"aligned_cons\"] = aligned_cons\n",
    "\n",
    "split_ref = R9_data.apply(lambda x: splitstr(x[\"reference\"], ref_intervals), axis=1)\n",
    "split_align = R9_data.apply(\n",
    "    lambda x: splitstr(x[\"aligned_cons\"], ref_intervals), axis=1\n",
    ")\n",
    "R9_data[\"split_ref\"] = split_ref\n",
    "R9_data[\"split_align\"] = split_align\n",
    "\n",
    "split_ref = R10_data.apply(lambda x: splitstr(x[\"reference\"], ref_intervals), axis=1)\n",
    "split_align = R10_data.apply(\n",
    "    lambda x: splitstr(x[\"aligned_cons\"], ref_intervals), axis=1\n",
    ")\n",
    "R10_data[\"split_ref\"] = split_ref\n",
    "R10_data[\"split_align\"] = split_align\n",
    "\n",
    "R9_data[\"split_ref\"] = R9_data[\"split_ref\"].apply(\n",
    "    lambda x: {key: val for key, val in x.items() if key == \"GFP\"}\n",
    ")  ## This is a hack until I can repull the alignment data...then I'll add padding for the unaligned parts\n",
    "R9_data[\"split_align\"] = R9_data[\"split_align\"].apply(\n",
    "    lambda x: {key: val for key, val in x.items() if key == \"GFP\"}\n",
    ")  ## This is a hack until I can repull the alignment data...\n",
    "\n",
    "R10_data[\"split_ref\"] = R10_data[\"split_ref\"].apply(\n",
    "    lambda x: {key: val for key, val in x.items() if key == \"GFP\"}\n",
    ")  ## This is a hack until I can repull the alignment data...then I'll add padding for the unaligned parts\n",
    "R10_data[\"split_align\"] = R10_data[\"split_align\"].apply(\n",
    "    lambda x: {key: val for key, val in x.items() if key == \"GFP\"}\n",
    ")  ## This is a hack until I can repull the alignment data...\n",
    "\n",
    "hamm_ref = R9_data.apply(\n",
    "    lambda x: get_dict_dist(x[\"split_align\"], x[\"split_ref\"]), axis=1\n",
    ")\n",
    "R9_data[\"hamm_ref\"] = hamm_ref\n",
    "\n",
    "hamm_ref = R10_data.apply(\n",
    "    lambda x: get_dict_dist(x[\"split_align\"], x[\"split_ref\"]), axis=1\n",
    ")\n",
    "R10_data[\"hamm_ref\"] = hamm_ref\n",
    "\n",
    "dark_gfp = (\n",
    "    R9_data.apply(\n",
    "        lambda x: slow_hamming_distance(\n",
    "            x[\"split_align\"][\"GFP\"][623:625], x[\"split_ref\"][\"GFP\"][623:625]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    > 0\n",
    ")\n",
    "R9_data[\"dark_gfp\"] = dark_gfp\n",
    "\n",
    "dark_gfp = (\n",
    "    R10_data.apply(\n",
    "        lambda x: slow_hamming_distance(\n",
    "            x[\"split_align\"][\"GFP\"][623:625], x[\"split_ref\"][\"GFP\"][623:625]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    > 0\n",
    ")\n",
    "R10_data[\"dark_gfp\"] = dark_gfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = R9_data[R9_data[\"subsample\"] == 200]\n",
    "gt_lookup = dict(zip(gt_data[\"barcodeid\"], gt_data[\"dark_gfp\"]))\n",
    "\n",
    "R9_data[\"call\"] = R9_data.apply(\n",
    "    lambda x: x[\"dark_gfp\"] == gt_lookup[x[\"barcodeid\"]], axis=1\n",
    ")\n",
    "\n",
    "gt_data = R10_data[R10_data[\"subsample\"] == 200]\n",
    "gt_lookup = dict(zip(gt_data[\"barcodeid\"], gt_data[\"dark_gfp\"]))\n",
    "\n",
    "R10_data[\"call\"] = R10_data.apply(\n",
    "    lambda x: x[\"dark_gfp\"] == gt_lookup[x[\"barcodeid\"]], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "R9_subsample_group = R9_data.groupby(\"subsample\")\n",
    "R10_subsample_group = R10_data.groupby(\"subsample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "R9_call_curve = R9_subsample_group.aggregate({\"call\": \"mean\"})\n",
    "R10_call_curve = R10_subsample_group.aggregate({\"call\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "R9_q_scores = -10 * np.log10(1.0 - R9_call_curve)\n",
    "R10_q_scores = -10 * np.log10(1.0 - R10_call_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "R9_q_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.0 - R10_call_curve) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((1.0 - R10_call_curve) * 100)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.xlim(0, 100)\n",
    "plt.xticks([2, 25, 50, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1.0 - R9_call_curve)\n",
    "plt.plot(1.0 - R10_call_curve)\n",
    "plt.xlim(0, 100)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(R9_q_scores)\n",
    "plt.plot(R10_q_scores)\n",
    "plt.xlim(0, 100)\n",
    "plt.xticks(R9_q_scores.index.values[:-3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Whole GFP Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "R9_gfp_error = R9_data[R9_data[\"call\"] == False].apply(\n",
    "    lambda x: slow_hamming_distance(x[\"split_align\"][\"GFP\"], x[\"split_ref\"][\"GFP\"])\n",
    "    / len(x[\"split_ref\"][\"GFP\"]),\n",
    "    axis=1,\n",
    ")\n",
    "R10_gfp_error = R10_data[R10_data[\"call\"] == False].apply(\n",
    "    lambda x: slow_hamming_distance(x[\"split_align\"][\"GFP\"], x[\"split_ref\"][\"GFP\"])\n",
    "    / len(x[\"split_ref\"][\"GFP\"]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "R9_data[\"GFP Error\"] = R9_gfp_error\n",
    "R10_data[\"GFP Error\"] = R10_gfp_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "R9_subsample_group = R9_data.groupby(\"subsample\")\n",
    "R10_subsample_group = R10_data.groupby(\"subsample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "R9_error_curve = R9_subsample_group.aggregate({\"GFP Error\": \"mean\"})\n",
    "R10_error_curve = R10_subsample_group.aggregate({\"GFP Error\": \"mean\"})\n",
    "R9_q_scores = -10 * np.log10(R9_error_curve)\n",
    "R10_q_scores = -10 * np.log10(R10_error_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(R9_q_scores)\n",
    "plt.plot(R10_q_scores)\n",
    "plt.xlim(0, 25)\n",
    "plt.xticks(R9_q_scores.index.values[:-4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "R9_error_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_error_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### UMI Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-12-05_DAC/R10_output.tsv\", delimiter=\"\\t\"\n",
    ")\n",
    "aligned_cons = R10_data.apply(lambda x: align_read(x[\"consensus\"], x[\"cigar\"]), axis=1)\n",
    "R10_data[\"aligned_cons\"] = aligned_cons\n",
    "\n",
    "split_ref = R10_data.apply(lambda x: splitstr(x[\"reference\"], ref_intervals), axis=1)\n",
    "split_align = R10_data.apply(\n",
    "    lambda x: splitstr(x[\"aligned_cons\"], ref_intervals), axis=1\n",
    ")\n",
    "R10_data[\"split_ref\"] = split_ref\n",
    "R10_data[\"split_align\"] = split_align\n",
    "R10_data[\"Nmer\"] = R10_data[\"split_align\"].apply(lambda x: x[\"GFP\"][925:940])\n",
    "gt_data = R10_data[R10_data[\"subsample\"] == 200]\n",
    "gt_lookup = dict(zip(gt_data[\"barcodeid\"], gt_data[\"Nmer\"]))\n",
    "R10_data[\"Nmer Errors\"] = R10_data.apply(\n",
    "    lambda x: slow_hamming_distance(x[\"Nmer\"], gt_lookup[x[\"barcodeid\"]]), axis=1\n",
    ")\n",
    "R10_data[\"Nmer Error Rate\"] = R10_data[\"Nmer Errors\"] / 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_subsample_group = R10_data.groupby(\"subsample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_call_curve = R10_subsample_group.aggregate({\"Nmer Error Rate\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_call_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(R10_call_curve * 100, linewidth=3.0)\n",
    "plt.axvline(24, color=\"C1\", ls=\"--\")\n",
    "plt.ylim(0.0, 2.0)\n",
    "plt.xlim(0, 100)\n",
    "plt.xticks([2, 25, 50, 100], fontsize=16)\n",
    "plt.yticks([0.0, 0.5, 1.0, 1.5, 2.0], fontsize=16)\n",
    "plt.xlabel(\"Depth\", fontsize=16)\n",
    "plt.ylabel(\"Error (%)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./Figure_1.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = R9_data[R9_data[\"subsample\"]==200]\n",
    "gt_lookup = dict(zip(gt_data[\"barcodeid\"],gt_data[\"dark_gfp\"]))\n",
    "\n",
    "R9_data[\"call\"] = R9_data.apply(lambda x: x[\"dark_gfp\"]==gt_lookup[x[\"barcodeid\"]],axis=1)\n",
    "\n",
    "gt_data = R10_data[R10_data[\"subsample\"]==200]\n",
    "gt_lookup = dict(zip(gt_data[\"barcodeid\"],gt_data[\"dark_gfp\"]))\n",
    "\n",
    "R10_data[\"call\"] = R10_data.apply(lambda x: slow_hamming_distance(x[\"dark_gfp\"],gt_lookup[x[\"barcodeid\"]]))\n",
    "                                  x[\"dark_gfp\"]==gt_lookup[x[\"barcodeid\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitlist = [\"BIT\" + str(i) for i in range(27)]\n",
    "bit_mismatch_dict = {}\n",
    "for bit in bitlist:\n",
    "    mismatch_list = data.apply(lambda x: x[\"hamm_ref\"][bit], axis=1).values\n",
    "    bit_mismatch_dict[bit] = mismatch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_mismatch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for key in bit_mismatch_dict.keys():\n",
    "    plt.hist(bit_mismatch_dict[key], bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "miscalls = data.apply(lambda x: x[\"hamm_ref\"][\"BIT26\"], axis=1).values > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([int(item[26]) for item in data[miscalls][\"barcode\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([int(item[26]) for item in data[~miscalls][\"barcode\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([int(item[26]) for item in data[\"barcode\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "So the last bit is always called as 0; fixed. was no newline at the end of the .gaf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.random.choice([0, 1, 2], size=3, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpathlist = [\n",
    "    \"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/graph_output/\"\n",
    "    + item\n",
    "    for item in os.listdir(\n",
    "        \"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/graph_output\"\n",
    "    )\n",
    "    if item[-3:] == \"tsv\" and item[:4] == \"read\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Barcode Histogram ###\n",
    "\n",
    "barcode_dict = {}\n",
    "for filepath in inpathlist:\n",
    "    with open(filepath, \"r\") as infile:\n",
    "        next(infile)\n",
    "        for line in infile:\n",
    "            data = line.split(\"\\t\")\n",
    "            barcode_dict[data[0]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_arr = np.array(list(barcode_dict.values()))\n",
    "unique, counts = np.unique(barcode_arr, return_counts=True)="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = (2, np.max(counts[counts]))\n",
    "nbins = vmax - vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = (0, int(np.percentile(counts, 99.9)))\n",
    "nbins = min(200, vmax - vmin)\n",
    "\n",
    "plt.hist(counts, range=(vmin, vmax), bins=nbins)\n",
    "plt.yscale(\"log\")\n",
    "plt.axvline(200, color=\"salmon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/graph_output/inv_codebook.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"barcodeid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[\"readlist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_barcode_codebook = {}\n",
    "for _, row in data.iterrows():\n",
    "    inv_barcode_codebook[int(row[\"barcodeid\"])] = ast.literal_eval(row[\"readlist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_barcode_codebook[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {1: 2}\n",
    "d.update({3: 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"making fastq dict\")\n",
    "record_dict_list = [{1: 2}, {3: 4}, {5: 6}]\n",
    "record_dict = {}\n",
    "for i in range(len(record_dict_list)):\n",
    "    subdict = record_dict_list[i]\n",
    "    record_dict.update(subdict)\n",
    "    del subdict\n",
    "    record_dict_list[i] = None\n",
    "del record_dict_list\n",
    "print(\"finished making fastq dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-10-18_snakemake_2020-09-24_oDEPool3/output.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[data[\"subsample\"] == 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
