{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE THERE MAY BE AN ERROR IN HAMMING DIST CALCULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cigarsfromsam(samfilepath):\n",
    "    cigars = {}\n",
    "    with open(samfilepath, \"r\") as samfile:\n",
    "        for line in samfile:\n",
    "            if line[0] == \"@\":\n",
    "                next(samfile)\n",
    "            else:\n",
    "                splitline = line.split(\"\\t\")\n",
    "                cigars[splitline[0]] = splitline[5]\n",
    "    return cigars\n",
    "\n",
    "\n",
    "def strsfromfasta(fastafilepath):\n",
    "    queries = SeqIO.to_dict(SeqIO.parse(fastafilepath, \"fasta\"))\n",
    "    queries = {key: str(val.seq) for key, val in queries.items()}\n",
    "    return queries\n",
    "\n",
    "\n",
    "def make_seg_dict(gfafile):\n",
    "    segment_dict = {}\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                segment_dict[splitline[1]] = splitline[2][:-1]\n",
    "    return segment_dict\n",
    "\n",
    "\n",
    "def get_ref_intervals(gfafile):\n",
    "    segment_dict = {}\n",
    "    current_idx = 0\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                if \"OFF\" not in splitline[1]:\n",
    "                    refstr = splitline[2][:-1]\n",
    "                    strlen = len(refstr)\n",
    "                    name = splitline[1]\n",
    "                    if \"ON\" in name:\n",
    "                        name = name[:-2]\n",
    "                    segment_dict[name] = tuple((current_idx, current_idx + strlen))\n",
    "                    current_idx += strlen\n",
    "    return segment_dict\n",
    "\n",
    "\n",
    "def align_read(\n",
    "    querystr, refstr, cigarstr, startpos=1, pattern=re.compile(\"[0-9]{0,10}[MDI]\")\n",
    "):\n",
    "    start_pos = startpos - 1  ##comes as 1 indexed from minimap\n",
    "    result = pattern.finditer(cigarstr)\n",
    "    cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]\n",
    "    output_str = \"\"\n",
    "    if start_pos > 0:\n",
    "        output_str += \"\".join([\"-\" for i in range(start_pos)])\n",
    "    current_idx = 0\n",
    "    for item in cigar_seq:\n",
    "        if item[0] == \"M\":\n",
    "            added_str = querystr[current_idx : current_idx + item[1]]\n",
    "            output_str += added_str\n",
    "            current_idx += item[1]\n",
    "        elif item[0] == \"D\":\n",
    "            added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "            output_str += added_str\n",
    "        elif item[0] == \"I\":\n",
    "            current_idx += item[1]\n",
    "    remaining_len = len(refstr) - len(output_str)\n",
    "    if remaining_len > 0:\n",
    "        output_str += \"\".join([\"-\" for i in range(remaining_len)])\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def splitstr(instr, ref_intervals):\n",
    "    strassign = {key: instr[val[0] : val[1]] for key, val in ref_intervals.items()}\n",
    "    return strassign\n",
    "\n",
    "\n",
    "def slow_hamming_distance(s1, s2):\n",
    "    if len(s1) != len(s2):\n",
    "        print(s1, s2)\n",
    "        raise ValueError(\"Strand lengths are not equal!\")\n",
    "    term_list = []\n",
    "    for ch1, ch2 in zip(s1, s2):\n",
    "        if ch1 == \"N\" or ch2 == \"N\":\n",
    "            term_list.append(False)\n",
    "        else:\n",
    "            term_list.append(ch1 != ch2)\n",
    "    result = sum(term_list)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_dict_dist(dict1, dict2):\n",
    "    hamming_dict = {\n",
    "        key: slow_hamming_distance(dict1[key], dict2[key]) for key in dict1.keys()\n",
    "    }\n",
    "    return hamming_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Library Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data from nanopore snakemake pipeline\n",
    "R10_data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-10-20_snakemake_2020-10-14_lDE11_R10-3_merged_final/output.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    ")\n",
    "\n",
    "## Get set of all observed barcodes\n",
    "R10_barcodes = set(R10_data[\"barcode\"].tolist())\n",
    "\n",
    "## Convert barcodes into array format\n",
    "bit_arr = np.array([list(item) for item in R10_barcodes]).astype(int)\n",
    "\n",
    "## Get frequency of the ON state for each bit\n",
    "bit_freq = np.mean(bit_arr, axis=0)\n",
    "\n",
    "## Determine the barcode hamming distance to the closest match for each observed barcode\n",
    "both_on = bit_arr @ bit_arr.T\n",
    "both_off = (-bit_arr + 1) @ (-bit_arr.T + 1)\n",
    "ttl_match = both_on + both_off\n",
    "np.fill_diagonal(ttl_match, 100)\n",
    "closest_match = np.min(ttl_match, axis=0)\n",
    "\n",
    "## Assign closest match to each barcode (for costructing output df later)\n",
    "closest_match_dict = {\n",
    "    barcode: closest_match[k] for k, barcode in enumerate(R10_barcodes)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x=list(range(27)), y=bit_freq, color=\"grey\")\n",
    "plt.xlabel(\"Bit Number\", fontsize=20)\n",
    "plt.ylabel(\"Percent Positive\", fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()\n",
    "# plt.savefig(\"./figure_1.png\",dpi=300,bbox_inches=\"tight\")\n",
    "\n",
    "plt.hist(closest_match, range=(0, 10))\n",
    "plt.xlabel(\"Closest Hamming Distance\", fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()\n",
    "# plt.savefig(\"./figure_2.png\",dpi=300,bbox_inches=\"tight\")\n",
    "\n",
    "plt.hist(closest_match, range=(0, 2), bins=3)\n",
    "plt.xlabel(\"Closest Hamming Distance\", fontsize=20)\n",
    "plt.xticks([0.25, 1.0, 1.75], [0, 1, 2], fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()\n",
    "# plt.savefig(\"./figure_3.png\",dpi=300,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call GFP and Make Output DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Align consensus sequence to reference using cigar string\n",
    "aligned_cons = R10_data.apply(\n",
    "    lambda x: align_read(\n",
    "        x[\"consensus\"], x[\"reference\"], x[\"cigar\"], startpos=x[\"alignmentstart\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "R10_data[\"aligned_cons\"] = aligned_cons\n",
    "\n",
    "## Use GFA reference to determine intervals for each annotation\n",
    "ref_intervals = get_ref_intervals(\n",
    "    \"/home/de64/scratch/de64/2020-10-20_snakemake_2020-10-14_lDE11_R10-3_merged_final/ref.gfa\"\n",
    ")\n",
    "\n",
    "## Split sequences based on annotated intervals\n",
    "split_ref = R10_data.apply(lambda x: splitstr(x[\"reference\"], ref_intervals), axis=1)\n",
    "split_align = R10_data.apply(\n",
    "    lambda x: splitstr(x[\"aligned_cons\"], ref_intervals), axis=1\n",
    ")\n",
    "R10_data[\"split_ref\"] = split_ref\n",
    "R10_data[\"split_align\"] = split_align\n",
    "\n",
    "## Compute hamming distance from reference, by annotated element\n",
    "hamm_ref = R10_data.apply(\n",
    "    lambda x: get_dict_dist(x[\"split_align\"], x[\"split_ref\"]), axis=1\n",
    ")\n",
    "R10_data[\"hamm_ref\"] = hamm_ref\n",
    "\n",
    "## Get hamming distance from reference of the nucleotides which vary in the library, to determine GFP vs DarkGFP\n",
    "dark_gfp = (\n",
    "    R10_data.apply(\n",
    "        lambda x: slow_hamming_distance(\n",
    "            x[\"split_align\"][\"GFP\"][623:625], x[\"split_ref\"][\"GFP\"][623:625]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    > 0\n",
    ")\n",
    "R10_data[\"dark_gfp\"] = dark_gfp\n",
    "\n",
    "## Assign closest match to each barcode (for costructing output df later)\n",
    "R10_data[\"Closest Hamming Distance\"] = R10_data[\"barcode\"].apply(\n",
    "    lambda x: closest_match_dict[x]\n",
    ")\n",
    "\n",
    "## Dropping leftover column\n",
    "del R10_data[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_data.to_csv(\"./lDE11_final_df.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanger Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to fastq and group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ab1_files/merged.fastq\", \"w\") as outfile:\n",
    "    for i in range(1, 97):\n",
    "        filepath1 = \"./ab1_files/lDE11_validation_sample_\" + str(i) + \"-oDE154.ab1\"\n",
    "        filepath2 = \"./ab1_files/lDE11_validation_sample_\" + str(i) + \"-oDE201.ab1\"\n",
    "\n",
    "        record1 = SeqIO.read(filepath1, \"abi\")\n",
    "        record2 = SeqIO.read(filepath2, \"abi\")\n",
    "\n",
    "        SeqIO.write(record1, outfile, \"fastq\")\n",
    "        SeqIO.write(record2, outfile, \"fastq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align to GAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!GraphAligner -g ./ref.gfa -f ./ab1_files/merged.fastq -a ./ab1_files/aligned.gaf -x dbg --high-memory -b 20 -B 35 -C -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get cigar strings, barcodes and read sequences for each isolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cigar_dict = {}\n",
    "with open(\"./ab1_files/aligned.gaf\", \"r\") as infile:\n",
    "    for line in infile:\n",
    "        data = line.split(\"\\t\")\n",
    "        read_id = data[0].split(\" \")[0]\n",
    "        if \">\" in data[5]:\n",
    "            cigar_dict[read_id] = (\n",
    "                \"+\",\n",
    "                int(data[7]),\n",
    "                int(data[8]),\n",
    "                data[5],\n",
    "                data[15].split(\":\")[-1][:-1],\n",
    "            )\n",
    "        else:\n",
    "            cigar_dict[read_id] = (\n",
    "                \"-\",\n",
    "                int(data[7]),\n",
    "                int(data[8]),\n",
    "                data[5],\n",
    "                data[15].split(\":\")[-1][:-1],\n",
    "            )\n",
    "\n",
    "barcode_dict = {}\n",
    "for key in cigar_dict.keys():\n",
    "    cigar = cigar_dict[key]\n",
    "    if \"oDE201\" in key:\n",
    "        barcode = cigar[3].split(\"<\")\n",
    "        barcode = barcode[::-1]\n",
    "        barcode = barcode[:-1]\n",
    "        barcode = (\n",
    "            np.array([\"ON\" in item for item in barcode if \"BIT\" in item])\n",
    "            .astype(int)\n",
    "            .astype(str)\n",
    "            .tolist()\n",
    "        )\n",
    "        barcode = \"\".join(barcode)\n",
    "        index = key.split(\"_\")[3].split(\"-\")[0]\n",
    "        barcode_dict[int(index)] = barcode\n",
    "\n",
    "with open(\"./ab1_files/merged.fastq\", \"r\") as infile:\n",
    "    read_dict = SeqIO.parse(infile, \"fastq\")\n",
    "    read_dict = SeqIO.to_dict(read_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get agreement between reads and nanopore calls at GFP/DarkGFP site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R10_data = pd.read_csv(\"./lDE11_final_df.tsv\", sep=\"\\t\")\n",
    "\n",
    "all_snp_hamming = []\n",
    "for i in range(1, 97):\n",
    "    if np.sum(R10_data[\"barcode\"] == barcode_dict[i]) == 1:\n",
    "        gfp_read_name = \"lDE11_validation_sample_\" + str(i) + \"-oDE154\"\n",
    "        aligned = align_read(\n",
    "            read_dict[gfp_read_name],\n",
    "            R10_data[R10_data[\"barcode\"] == barcode_dict[i]][\"reference\"].iloc[0],\n",
    "            cigar_dict[gfp_read_name][4],\n",
    "            startpos=cigar_dict[gfp_read_name][1] + 1,\n",
    "        )\n",
    "        ref_intervals = get_ref_intervals(\"./ref.gfa\")\n",
    "        split_ref = splitstr(\n",
    "            R10_data[R10_data[\"barcode\"] == barcode_dict[i]][\"reference\"].iloc[0],\n",
    "            ref_intervals,\n",
    "        )\n",
    "        split_consensus = splitstr(\n",
    "            R10_data[R10_data[\"barcode\"] == barcode_dict[i]][\"consensus\"].iloc[0],\n",
    "            ref_intervals,\n",
    "        )\n",
    "        split_align = splitstr(str(aligned.seq), ref_intervals)\n",
    "        snp_hamming = slow_hamming_distance(\n",
    "            split_align[\"GFP\"][623:625], split_consensus[\"GFP\"][623:625]\n",
    "        )\n",
    "        all_snp_hamming.append(snp_hamming)\n",
    "all_snp_hamming = np.array(all_snp_hamming)\n",
    "\n",
    "print(\"Percent Correct: \" + str(np.sum(all_snp_hamming == 0) / len(all_snp_hamming)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Determine sanger reads with barcodes not in library\n",
    "ttl_bc = []\n",
    "for i in range(1, 97):\n",
    "    ttl_bc.append(np.sum(R10_data[\"barcode\"] == barcode_dict[i]))\n",
    "ttl_bc = np.array(ttl_bc)\n",
    "no_found_barcode_mask = ttl_bc == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Measure average Phred quality of sanger reads\n",
    "qualities = []\n",
    "for i in range(1, 97):\n",
    "    record = SeqIO.read(\n",
    "        \"./ab1_files/lDE11_validation_sample_\" + str(i) + \"-oDE201.ab1\", \"abi\"\n",
    "    )\n",
    "    mean_quality = np.mean(record.letter_annotations[\"phred_quality\"])\n",
    "    qualities.append(mean_quality)\n",
    "qualities = np.array(qualities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Average Phred quality colored by whether a barcode was in or out of the library\n",
    "plt.hist(qualities[~no_found_barcode_mask], range=(10, 50), bins=10, label=\"In Library\")\n",
    "plt.hist(\n",
    "    qualities[no_found_barcode_mask], range=(10, 50), bins=10, label=\"Out of Library\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
