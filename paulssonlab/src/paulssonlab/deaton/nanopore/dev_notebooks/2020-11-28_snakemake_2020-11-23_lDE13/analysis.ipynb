{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_read(querystr, cigarstr, pattern=re.compile(\"[0-9]{0,10}[MDI]\")):\n",
    "    result = pattern.finditer(cigarstr)\n",
    "    cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]\n",
    "    #     output_str = \"\".join([\"-\" for i in range(cigar[1])])\n",
    "    output_str = \"\"\n",
    "    current_idx = 0\n",
    "    for item in cigar_seq:\n",
    "        if item[0] == \"M\":\n",
    "            added_str = querystr[current_idx : current_idx + item[1]]\n",
    "            output_str += added_str\n",
    "            current_idx += item[1]\n",
    "        elif item[0] == \"D\":\n",
    "            added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "            output_str += added_str\n",
    "        elif item[0] == \"I\":\n",
    "            current_idx += item[1]\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def cigarsfromsam(samfilepath):\n",
    "    cigars = {}\n",
    "    with open(samfilepath, \"r\") as samfile:\n",
    "        for line in samfile:\n",
    "            if line[0] == \"@\":\n",
    "                next(samfile)\n",
    "            else:\n",
    "                splitline = line.split(\"\\t\")\n",
    "                cigars[splitline[0]] = splitline[5]\n",
    "    return cigars\n",
    "\n",
    "\n",
    "def strsfromfasta(fastafilepath):\n",
    "    queries = SeqIO.to_dict(SeqIO.parse(fastafilepath, \"fasta\"))\n",
    "    queries = {key: str(val.seq) for key, val in queries.items()}\n",
    "    return queries\n",
    "\n",
    "\n",
    "def make_seg_dict(gfafile):\n",
    "    segment_dict = {}\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                segment_dict[splitline[1]] = splitline[2][:-1]\n",
    "    return segment_dict\n",
    "\n",
    "\n",
    "def get_ref_intervals(gfafile):\n",
    "    segment_dict = {}\n",
    "    current_idx = 0\n",
    "    with open(gfafile, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0] == \"S\":\n",
    "                splitline = line.split(\"\\t\")\n",
    "                if \"OFF\" not in splitline[1]:\n",
    "                    refstr = splitline[2][:-1]\n",
    "                    strlen = len(refstr)\n",
    "                    name = splitline[1]\n",
    "                    if \"ON\" in name:\n",
    "                        name = name[:-2]\n",
    "                    segment_dict[name] = tuple((current_idx, current_idx + strlen))\n",
    "                    current_idx += strlen\n",
    "    return segment_dict\n",
    "\n",
    "\n",
    "def align_read(\n",
    "    querystr, refstr, cigarstr, startpos=1, pattern=re.compile(\"[0-9]{0,10}[MDI]\")\n",
    "):\n",
    "    start_pos = startpos - 1  ##comes as 1 indexed from minimap\n",
    "    result = pattern.finditer(cigarstr)\n",
    "    cigar_seq = [(item.group(0)[-1], int(item.group(0)[:-1])) for item in result]\n",
    "    #     output_str = \"\".join([\"-\" for i in range(cigar[1])])\n",
    "    output_str = \"\"\n",
    "    if start_pos > 0:\n",
    "        output_str += \"\".join([\"-\" for i in range(start_pos)])\n",
    "    current_idx = 0\n",
    "    for item in cigar_seq:\n",
    "        if item[0] == \"M\":\n",
    "            added_str = querystr[current_idx : current_idx + item[1]]\n",
    "            output_str += added_str\n",
    "            current_idx += item[1]\n",
    "        elif item[0] == \"D\":\n",
    "            added_str = \"\".join([\"-\" for i in range(item[1])])\n",
    "            output_str += added_str\n",
    "        elif item[0] == \"I\":\n",
    "            current_idx += item[1]\n",
    "    remaining_len = len(refstr) - len(output_str)\n",
    "    if remaining_len > 0:\n",
    "        output_str += \"\".join([\"-\" for i in range(remaining_len)])\n",
    "    return output_str\n",
    "\n",
    "\n",
    "def splitstr(instr, ref_intervals):\n",
    "    strassign = {key: instr[val[0] : val[1]] for key, val in ref_intervals.items()}\n",
    "    return strassign\n",
    "\n",
    "\n",
    "def slow_hamming_distance(s1, s2):\n",
    "    if len(s1) != len(s2):\n",
    "        print(s1, s2)\n",
    "        raise ValueError(\"Strand lengths are not equal!\")\n",
    "    term_list = []\n",
    "    for ch1, ch2 in zip(s1, s2):\n",
    "        if ch1 == \"N\" or ch2 == \"N\":\n",
    "            term_list.append(False)\n",
    "        else:\n",
    "            term_list.append(ch1 != ch2)\n",
    "    result = sum(term_list)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_dict_dist(dict1, dict2):\n",
    "    hamming_dict = {\n",
    "        key: slow_hamming_distance(dict1[key], dict2[key]) for key in dict1.keys()\n",
    "    }\n",
    "    return hamming_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/de64/scratch/de64/2020-11-23_lDE13_sequencing/output.tsv\", delimiter=\"\\t\"\n",
    ")\n",
    "data[\"24bit_barcode\"] = data[\"barcode\"].apply(\n",
    "    lambda x: x[:24]\n",
    ")  # take off last 6 bits, since they were not recorded\n",
    "ref_intervals = get_ref_intervals(\n",
    "    \"/home/de64/scratch/de64/2020-11-23_lDE13_sequencing/ref.gfa\"\n",
    ")\n",
    "barcodes = set(data[\"barcode\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_arr = np.array([list(item) for item in barcodes]).astype(int)\n",
    "bit_freq = np.mean(bit_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bit_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "sns.barplot(x=list(range(30)), y=bit_freq, color=\"grey\")\n",
    "plt.xlabel(\"Bit Number\", fontsize=20)\n",
    "plt.ylabel(\"Percent Positive\", fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.savefig(\"./figure_1.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_on = bit_arr @ bit_arr.T\n",
    "both_off = (-bit_arr + 1) @ (-bit_arr.T + 1)\n",
    "ttl_match = both_on + both_off\n",
    "np.fill_diagonal(ttl_match, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_match = np.min(ttl_match, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(closest_match, range=(0, 12), bins=9)\n",
    "plt.xlabel(\"Closest Hamming Distance\", fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.savefig(\"./figure_2.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(closest_match, range=(0, 1), bins=2)\n",
    "plt.xlabel(\"Closest Hamming Distance\", fontsize=20)\n",
    "plt.xticks([0.25, 0.75], [0, 1], fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.savefig(\"./figure_3_24bits.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_cons = data.apply(\n",
    "    lambda x: align_read(\n",
    "        x[\"consensus\"], x[\"reference\"], x[\"cigar\"], startpos=x[\"alignmentstart\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "data[\"aligned_cons\"] = aligned_cons\n",
    "\n",
    "split_ref = data.apply(lambda x: splitstr(x[\"reference\"], ref_intervals), axis=1)\n",
    "split_align = data.apply(lambda x: splitstr(x[\"aligned_cons\"], ref_intervals), axis=1)\n",
    "data[\"split_ref\"] = split_ref\n",
    "data[\"split_align\"] = split_align\n",
    "\n",
    "hamm_ref = data.apply(lambda x: get_dict_dist(x[\"split_align\"], x[\"split_ref\"]), axis=1)\n",
    "data[\"hamm_ref\"] = hamm_ref\n",
    "\n",
    "data[\"sgRNA Target\"] = data[\"split_align\"].apply(lambda x: x[\"SGRNA\"][175:195])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgRNA_lib_df = pd.read_csv(\"./2020-11-01_mVenus_library_1.csv\")\n",
    "sgRNA_lib_df = sgRNA_lib_df.set_index(\"sequence\")\n",
    "sgRNA_lib_df = sgRNA_lib_df.rename(columns={\"Unnamed: 0\": \"sgrnaid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgRNA_lib_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_list = []\n",
    "for _, row in data.iterrows():\n",
    "    try:\n",
    "        entry = sgRNA_lib_df.loc[row[\"sgRNA Target\"]]\n",
    "        entry = pd.concat([row, entry])\n",
    "        entry_list.append(entry)\n",
    "    except:\n",
    "        pass\n",
    "output_df = pd.concat(entry_list, axis=1).T\n",
    "del output_df[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"./lDE13_final_df.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./lDE13_final_df.tsv\", delimiter=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
