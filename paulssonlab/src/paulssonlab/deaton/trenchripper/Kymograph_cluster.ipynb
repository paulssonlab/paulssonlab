{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Kymograph Code Draft\n",
    "\n",
    "Xref: Journal/12_26_18/Interactive_Kymograph_Draft_no_scaling.ipynb\n",
    "\n",
    "Goal: In this notebook, I will finalize the interactive kymograph code I wrote in `Interactive_Kymograph_v1.ipynb` This is a copy of `Interactive_Kymograph_Draft_no_scaling.ipynb`\n",
    "\n",
    "This code should have the following features:\n",
    "\n",
    "- seamless parameter tuning with visual outputs\n",
    "- chunking of the analysis process into steps\n",
    "- representative results from across the dataset\n",
    "- global qc stats?\n",
    "\n",
    "I should also use this code as an oppertunity to try out new things for the main (hdf5 using) codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "Modifying this code haphazardly is getting a bit unwieldy. Try to write down a game plan for the final drafting of the interactive kymograph, given what I have learned about the implementation. In addition, review the structure of this and the original kymograph code for restructuring/simplification. Finally, move on to the extraction code.\n",
    "\n",
    "**THIS KYMOGRAPH CODE MUST BE DEPLOYABLE BY 1/4**\n",
    "\n",
    "### PLAN TO GET THIS DONE\n",
    "\n",
    " - (1/2) Implement this structure and finish interactive code (including comments).\n",
    " - (1/3) Try to eleminate redundancy in codebase with global handlers for main code differences between interactive and\n",
    " server code...\n",
    " - (1/3) Revisit original code and implement structural simplification (i.e. distinct stopping points)\n",
    " - (1/3) Devise and implement library structure for the hdf5 conversion and kymograph code\n",
    " - (1/4) Finishing touches on library and start working on segmentation code.\n",
    " - (1/5) Write down structure of segmentation code (try to keep schematically similar to kymo code)\n",
    " - (?) Try to figure out if the read/write overhead is causing major problems...eliminate unnecessary I/O\n",
    " - (?) Play around with the dask way of chunking (in bookmarks) (don't do this until kymo interactive is done, but before seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import scipy.signal\n",
    "import shutil\n",
    "import skimage as sk\n",
    "from skimage import filters, transform\n",
    "\n",
    "from ipywidgets import (\n",
    "    interact,\n",
    "    interactive,\n",
    "    fixed,\n",
    "    interact_manual,\n",
    "    FloatSlider,\n",
    "    IntSlider,\n",
    ")\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.signal\n",
    "import shutil\n",
    "import skimage as sk\n",
    "import time\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "from skimage import filters\n",
    "\n",
    "\n",
    "class kymograph:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_file_prefix,\n",
    "        output_path,\n",
    "        fov_number,\n",
    "        all_channels,\n",
    "        trench_len_y=270,\n",
    "        padding_y=20,\n",
    "        trench_width_x=30,\n",
    "        t_chunk=1,\n",
    "        y_percentile=85,\n",
    "        y_min_edge_dist=50,\n",
    "        smoothing_kernel_y=(9, 1),\n",
    "        triangle_nbins=50,\n",
    "        triangle_scaling=1.0,\n",
    "        top_orientation=0,\n",
    "        x_percentile=85,\n",
    "        background_kernel_x=(301, 1),\n",
    "        smoothing_kernel_x=(9, 1),\n",
    "        otsu_nbins=50,\n",
    "        otsu_scaling=1.0,\n",
    "    ):\n",
    "        \"\"\"The kymograph class is used to generate kymographs using chunked computation on hdf5 arrays. The central function of this\n",
    "        class is the method 'generate_kymograph', which takes an hdf5 file of images from a single fov and\n",
    "        outputs an hdf5 file containing kymographs from all detected trenches. It is recommened that the user\n",
    "        supplies all hyperparameters given by keyword arguments, these can be checked using the interactive\n",
    "        class in the prepared jupyter notebook. At minimum, the user must specify a full input file path\n",
    "        prefix of the form [input_file_prefix][fov_number].hdf5, an output folder (which does not have to be\n",
    "        empty), the fov number to prepare kymographs for, and a list of channel names that corresponds to the\n",
    "        dataset keys of the input hdf5 files (the channel to use for segmentation should be placed first).\n",
    "\n",
    "        Args:\n",
    "            input_file_prefix (str): File prefix for all input hdf5 files of the form\n",
    "            [input_file_prefix][fov_number].hdf5\n",
    "            output_path (str): Directory to write output files to.\n",
    "            fov_number (int): The fov number to process.\n",
    "            all_channels (list): list of strings corresponding to the different image channels\n",
    "            available in the input hdf5 file, with the channel used for segmenting trenches in\n",
    "            the first position. NOTE: these names must match those of the input hdf5 file dataset keys.\n",
    "\n",
    "            trench_len_y (int, optional): Length from the end of the tenches to be used when cropping in the\n",
    "            y-dimension.\n",
    "            padding_y (int, optional): Padding to be used when cropping in the y-dimension.\n",
    "            trench_width_x (int, optional): Width to be used when cropping in the x-dimension.\n",
    "\n",
    "            t_chunk (str, optional): The chunk size to use when perfoming time-chunked computation.\n",
    "\n",
    "            y_percentile (int, optional): Used for reducing signal in xyt to only the yt dimension when cropping\n",
    "            in the y-dimension.\n",
    "            y_min_edge_dist (int, optional): Used when detecting present rows, filters for a minimum row size along the y dimension.\n",
    "            smoothing_kernel_y (tuple, optional): Two-entry tuple specifying a kernel size for smoothing out yt\n",
    "            signal when cropping in the y-dimension.\n",
    "            triangle_nbins (int, optional): Number of bins to use when applying the triangle method to y-dimension signal.\n",
    "            triangle_scaling (float, optional): Threshold scaling factor for triangle method thresholding.\n",
    "            top_orientation (int, optional): The orientation of the top-most row where 0 corresponds to a trench with\n",
    "            a downward-oriented trench opening and 1 corresponds to a trench with an upward-oriented trench opening.\n",
    "\n",
    "            x_percentile (int, optional): Used for reducing signal in xyt to only the xt dimension when cropping\n",
    "            in the x-dimension.\n",
    "            background_kernel_x (tuple, optional): Two-entry tuple specifying a kernel size for performing background subtraction\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "            smoothing_kernel_x (tuple, optional): Two-entry tuple specifying a kernel size for performing smoothing\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "            otsu_nbins (int, optional): Number of bins to use when applying Otsu's method to x-dimension signal.\n",
    "            otsu_scaling (float, optional): Threshold scaling factor for Otsu's method thresholding.\n",
    "        \"\"\"\n",
    "\n",
    "        self.input_file_prefix = input_file_prefix\n",
    "        self.output_path = output_path\n",
    "        self.temp_dir_prefix = output_path + \"/tempfiles_\"\n",
    "        self.fov_number = fov_number\n",
    "        self.input_path = self.input_file_prefix + str(self.fov_number) + \".hdf5\"\n",
    "        self.temp_path = self.temp_dir_prefix + str(self.fov_number) + \"/\"\n",
    "        self.output_file_path = (\n",
    "            self.output_path + \"/kymo_\" + str(self.fov_number) + \".hdf5\"\n",
    "        )\n",
    "\n",
    "        self.all_channels = all_channels\n",
    "        self.seg_channel = self.all_channels[0]\n",
    "\n",
    "        self.t_chunk = t_chunk\n",
    "\n",
    "        #### important paramaters to set\n",
    "        self.trench_len_y = trench_len_y\n",
    "        self.padding_y = padding_y\n",
    "        self.ttl_len_y = trench_len_y + padding_y\n",
    "        self.trench_width_x = trench_width_x\n",
    "\n",
    "        #### params for y\n",
    "        ## parameter for reducing signal to one dim\n",
    "        self.y_percentile = y_percentile\n",
    "        self.y_min_edge_dist = y_min_edge_dist\n",
    "        ## parameters for threshold finding\n",
    "        self.smoothing_kernel_y = smoothing_kernel_y\n",
    "        self.triangle_nbins = triangle_nbins\n",
    "        self.triangle_scaling = triangle_scaling\n",
    "        ###\n",
    "        self.top_orientation = top_orientation\n",
    "\n",
    "        #### params for x\n",
    "        ## parameter for reducing signal to one dim\n",
    "        self.x_percentile = x_percentile\n",
    "        ## parameters for midpoint finding\n",
    "        self.background_kernel_x = background_kernel_x\n",
    "        self.smoothing_kernel_x = smoothing_kernel_x\n",
    "        ## parameters for threshold finding\n",
    "        self.otsu_nbins = otsu_nbins\n",
    "        self.otsu_scaling = otsu_scaling\n",
    "\n",
    "    def writedir(self, directory, overwrite=False):\n",
    "        \"\"\"Creates an empty directory at the specified location. If a directory is\n",
    "        already at this location, it will be overwritten if 'overwrite' is true,\n",
    "        otherwise it will be left alone.\n",
    "\n",
    "        Args:\n",
    "            directory (str): Path to directory to be overwritten/created.\n",
    "            overwrite (bool, optional): Whether to overwrite a directory that\n",
    "            already exists in this location.\n",
    "        \"\"\"\n",
    "        print(directory)\n",
    "        if overwrite:\n",
    "            if os.path.exists(directory):\n",
    "                shutil.rmtree(directory)\n",
    "            os.makedirs(directory)\n",
    "        else:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "    def removefile(self, filepath):\n",
    "        \"\"\"Removes a file at the specified path, if it exists.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to file for deletion.\n",
    "        \"\"\"\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "\n",
    "    def median_filter_2d(self, array_tuple, smoothing_kernel):\n",
    "        \"\"\"Two-dimensional median filter, with average smoothing at the signal edges in\n",
    "        the first dimension (the non-time dimension).\n",
    "\n",
    "        Args:\n",
    "            array_list (list): List containing a single array of 2 dimensional signal to be smoothed.\n",
    "            smoothing_kernel (tuple): A tuple of ints specifying the kernel under which\n",
    "            the median will be taken.\n",
    "\n",
    "        Returns:\n",
    "            array: Median-filtered 2 dimensional signal.\n",
    "        \"\"\"\n",
    "        (array,) = array_tuple\n",
    "        kernel = np.array(smoothing_kernel)\n",
    "        kernel_pad = kernel // 2 + 1\n",
    "        med_filter = scipy.signal.medfilt(array, kernel_size=kernel)\n",
    "        start_edge = np.mean(med_filter[kernel_pad[0] : kernel[0]])\n",
    "        end_edge = np.mean(med_filter[-kernel[0] : -kernel_pad[0]])\n",
    "        med_filter[: kernel_pad[0]] = start_edge\n",
    "        med_filter[-kernel_pad[0] :] = end_edge\n",
    "        return med_filter\n",
    "\n",
    "    def reassign_idx(self, array, values, indices, axis):\n",
    "        \"\"\"Performs in-line value reassignment on numpy arrays, normally handled\n",
    "        with the \"array[:,indices] = values\" syntax, with the ability to supply\n",
    "        the axis as an argument.\n",
    "\n",
    "        Args:\n",
    "            array (array): Input array to have values reassigned.\n",
    "            values (array): New value positions in array.\n",
    "            indices (array): Positions in the input array to be reassigned.\n",
    "            axis (int): Axis along which to reassign values.\n",
    "        \"\"\"\n",
    "        str_constructor = \"\".join((len(array.shape) * [\":,\"]))[:-1]\n",
    "        str_constructor = \"[\" + str_constructor + \"]\"\n",
    "        str_constructor = (\n",
    "            \"array\"\n",
    "            + str_constructor[: axis * 2 + 1]\n",
    "            + \"indices\"\n",
    "            + str_constructor[axis * 2 + 2 :]\n",
    "            + \" = values\"\n",
    "        )\n",
    "        exec(str_constructor)\n",
    "\n",
    "    def write_hdf5(self, file_name, array, ti, t_len, t_dim_out, dataset_name):\n",
    "        \"\"\"Writes an array to a particular dataset in an hdf5 file. Positions\n",
    "        in time are left variable to enable chunking the dataset in time.\n",
    "\n",
    "        Args:\n",
    "            file_name (str): Name of the hdf5 file, assumed to be in the temp folder\n",
    "            initialized by this class.\n",
    "            array (array): Array to be written.\n",
    "            ti (int): Initial time position to write array values to.\n",
    "            t_len (int): Total size of the target time dimension.\n",
    "            t_dim_out (int): Axis of the target time dimension.\n",
    "            dataset_name (str): The name of the hdf5 dataset to write to.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.temp_path + file_name + \".hdf5\", \"r+\") as h5pyfile:\n",
    "            indices = list(range(ti, min(ti + self.t_chunk, t_len)))\n",
    "            self.reassign_idx(h5pyfile[dataset_name], array, indices, t_dim_out)\n",
    "\n",
    "    def delete_hdf5(self, file_handle):\n",
    "        \"\"\"Deletes an hdf5 file, given its file handle, and closes the handle\n",
    "        itself.\n",
    "\n",
    "        Args:\n",
    "            file_handle (hdf5file): Hdf5 file handle.\n",
    "        \"\"\"\n",
    "        filepath = file_handle.filename\n",
    "        file_handle.close()\n",
    "        self.removefile(filepath)\n",
    "\n",
    "    def init_hdf5(\n",
    "        self, file_name, dataset_name, array, t_len, t_dim_out, dtype=\"uint16\"\n",
    "    ):\n",
    "        \"\"\"Initializes an empty hdf5 file and dataset to write to, given an array\n",
    "        with the target shape in all axes but the time axis. The time axis\n",
    "        is then specified by t_len.\n",
    "\n",
    "        Args:\n",
    "            file_name (str): Name of the hdf5 file, assumed to be in the temp folder\n",
    "            initialized by this class.\n",
    "            dataset_name (str): The name of the hdf5 dataset to initialize.\n",
    "            array (array): Array which is of the same size as the dataset,\n",
    "            except in the time dimension.\n",
    "            t_len (int): Total size of the dataset time dimension.\n",
    "            t_dim_out (int): Axis of the dataset time dimension.\n",
    "\n",
    "            dtype(str, optional): Specifies the array datatype to initialize an\n",
    "            hdf5 file for. A 16 bit unsigned integer by default.\n",
    "        \"\"\"\n",
    "        chunk_shape = array.shape\n",
    "        out_shape = list(deepcopy(chunk_shape))\n",
    "        out_shape[t_dim_out] = t_len\n",
    "        out_shape = tuple(out_shape)\n",
    "        with h5py.File(self.temp_path + file_name + \".hdf5\", \"a\") as h5pyfile:\n",
    "            hdf5_dataset = h5pyfile.create_dataset(\n",
    "                dataset_name, out_shape, chunks=chunk_shape, dtype=dtype\n",
    "            )\n",
    "\n",
    "    def chunk_t(\n",
    "        self,\n",
    "        hdf5_array_tuple,\n",
    "        t_dim_in_tuple,\n",
    "        t_dim_out,\n",
    "        function,\n",
    "        file_name,\n",
    "        dataset_name,\n",
    "        *args,\n",
    "        dtype=\"uint16\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Applies a given function to any number of input hdf5 arrays, chunking this processing in the\n",
    "        time dimension, and outputs another hdf5 file.\n",
    "\n",
    "        Args:\n",
    "            hdf5_array_tuple (tuple): Tuple of input arrays to be operated on by the function.\n",
    "            t_dim_in_tuple (tuple): Tuple of ints that specify the time axis of each input array.\n",
    "            t_dim_out (int): Specifies the time axis of the output array.\n",
    "            function (func): Function to apply to the input arrays. The function must be of the form\n",
    "            func(array_tuple,*args,**kwargs).\n",
    "            file_name (str): Name of the output hdf5 file, assumed to be in the temp folder\n",
    "            initialized by this class.\n",
    "            dataset_name (str): The name of the hdf5 dataset to write to.\n",
    "            *args: Extra arguments to be passed to the function, that will be static across time chunks.\n",
    "            *kwargs: Extra keyword arguments to be passed to the function, that will be static across time chunks.\n",
    "\n",
    "        Returns:\n",
    "            hdf5file: Hdf5 file handle corresponding to the output array.\n",
    "        \"\"\"\n",
    "        t_len = hdf5_array_tuple[0].shape[t_dim_in_tuple[0]]\n",
    "        for ti in range(0, t_len, self.t_chunk):\n",
    "            indices = list(range(ti, min(ti + self.t_chunk, t_len)))\n",
    "            chunk_tuple = tuple(\n",
    "                np.take(hdf5_array_tuple[i], indices, axis=t_dim_in_tuple[i])\n",
    "                for i in range(len(hdf5_array_tuple))\n",
    "            )\n",
    "            f_chunk = function(chunk_tuple, *args, **kwargs)\n",
    "            del chunk_tuple\n",
    "            if ti == 0:\n",
    "                self.init_hdf5(\n",
    "                    file_name, dataset_name, f_chunk, t_len, t_dim_out, dtype=dtype\n",
    "                )\n",
    "            self.write_hdf5(file_name, f_chunk, ti, t_len, t_dim_out, dataset_name)\n",
    "            del f_chunk\n",
    "        out_hdf5_handle = h5py.File(self.temp_path + file_name + \".hdf5\", \"r\")\n",
    "        return out_hdf5_handle\n",
    "\n",
    "    def import_hdf5(self, file_name, dataset_name):\n",
    "        \"\"\"Stripped down version of 'self.chunk_t' that performs initial import of the hdf5 file to be\n",
    "        processed. Simply converts the input hdf5 file's \"channel\" datasets into the first dimension\n",
    "        of the array, ordered as specified by 'self.all_channels'\n",
    "\n",
    "        Args:\n",
    "            file_name (str): Name of the output hdf5 file, assumed to be in the temp folder\n",
    "            initialized by this class.\n",
    "            dataset_name (str): The name of the hdf5 dataset to write to.\n",
    "\n",
    "        Returns:\n",
    "            h5py.File: Hdf5 file handle corresponding to the output array.\n",
    "        \"\"\"\n",
    "        with h5py.File(self.input_path, \"r\") as h5pyfile:\n",
    "            t_len = h5pyfile[self.seg_channel].shape[2]\n",
    "            for ti in range(0, t_len, self.t_chunk):\n",
    "                indices = list(range(ti, min(ti + self.t_chunk, t_len)))\n",
    "                chunk_array = np.array(\n",
    "                    [\n",
    "                        np.take(h5pyfile[channel], indices, axis=2)\n",
    "                        for channel in self.all_channels\n",
    "                    ]\n",
    "                )\n",
    "                if ti == 0:\n",
    "                    self.init_hdf5(file_name, dataset_name, chunk_array, t_len, 3)\n",
    "                self.write_hdf5(file_name, chunk_array, ti, t_len, 3, dataset_name)\n",
    "                del chunk_array\n",
    "            out_hdf5_handle = h5py.File(self.temp_path + file_name + \".hdf5\", \"r\")\n",
    "            return out_hdf5_handle\n",
    "\n",
    "    def get_y_percentile(self, array_tuple, y_percentile):\n",
    "        \"\"\"Converts an input array of shape (y,x,t) to an array of shape (y,t) using a percentile cutoff applied\n",
    "        across the x-axis.\n",
    "\n",
    "        Args:\n",
    "            array_tuple (tuple): Singleton tuple containing the input array.\n",
    "\n",
    "        Returns:\n",
    "            array: Output array of shape (y,t).\n",
    "        \"\"\"\n",
    "        (array,) = array_tuple\n",
    "        out_array = np.percentile(array, y_percentile, axis=1)\n",
    "        return out_array\n",
    "\n",
    "    def get_smoothed_y_percentiles(\n",
    "        self, imported_hdf5_handle, y_percentile, smoothing_kernel_y\n",
    "    ):\n",
    "        \"\"\"For each imported array, computes the percentile along the x-axis of the segmentation\n",
    "        channel, generating a (y,t) array. Then performs median filtering of this array for smoothing.\n",
    "\n",
    "        Args:\n",
    "            imported_hdf5_handle (h5py.File): Hdf5 file handle corresponding to the input hdf5 dataset\n",
    "            \"data\" of shape (channel,y,x,t).\n",
    "            y_percentile (int): Percentile to apply along the x-axis.\n",
    "            smoothing_kernel_y (tuple): Kernel to use for median filtering.\n",
    "\n",
    "        Returns:\n",
    "            h5py.File: Hdf5 file handle corresponding to the output hdf5 dataset \"data\", a smoothed\n",
    "            percentile array of shape (channel,y,x,t).\n",
    "        \"\"\"\n",
    "        y_percentiles_handle = self.chunk_t(\n",
    "            (imported_hdf5_handle[\"data\"][0],),\n",
    "            (2,),\n",
    "            1,\n",
    "            self.get_y_percentile,\n",
    "            \"y_percentile\",\n",
    "            \"data\",\n",
    "            y_percentile,\n",
    "        )\n",
    "        y_percentiles_smoothed_handle = self.chunk_t(\n",
    "            (y_percentiles_handle[\"data\"],),\n",
    "            (1,),\n",
    "            1,\n",
    "            self.median_filter_2d,\n",
    "            \"y_percentile_smoothed\",\n",
    "            \"data\",\n",
    "            smoothing_kernel_y,\n",
    "        )\n",
    "        self.delete_hdf5(y_percentiles_handle)\n",
    "        return y_percentiles_smoothed_handle\n",
    "\n",
    "    def threshold(self, array_tuple, threshold):\n",
    "        \"\"\"Applys a triangle threshold, returning a boolean mask.\n",
    "\n",
    "        Args:\n",
    "            img_arr (array): ndarray to be thresholded.\n",
    "            triangle_nbins (int): Number of bins to be used to construct the thresholding\n",
    "            histogram.\n",
    "            triangle_scaling (float): Factor by which to scale the threshold.\n",
    "\n",
    "        Returns:\n",
    "            array: Boolean mask produced by the threshold.\n",
    "        \"\"\"\n",
    "        (img_arr,) = array_tuple\n",
    "        mask = img_arr > threshold\n",
    "        return mask\n",
    "\n",
    "    def remove_small_rows(self, edges, y_min_edge_dist):\n",
    "        \"\"\"Filters out small rows when performing automated row detection.\n",
    "\n",
    "        Args:\n",
    "            edges (array): Array of edges along y-axis.\n",
    "            y_min_edge_dist (int): Minimum row length necessary for detection.\n",
    "\n",
    "        Returns:\n",
    "            array: Array of edges, filtered for rows that are too small.\n",
    "        \"\"\"\n",
    "        grouped_edges = edges.reshape(-1, 2)\n",
    "        row_lens = np.diff(grouped_edges, axis=1)\n",
    "        row_mask = (row_lens > y_min_edge_dist).flatten()\n",
    "        filtered_edges = grouped_edges[row_mask]\n",
    "        return filtered_edges.flatten()\n",
    "\n",
    "    def get_edges_from_mask(self, mask, y_min_edge_dist):\n",
    "        \"\"\"Finds edges from a boolean mask of shape (y,t). Filters out rows of length\n",
    "        smaller than y_min_edge_dist.\n",
    "\n",
    "        Args:\n",
    "            mask (array): Boolean of shape (y,t) resulting from triangle thresholding.\n",
    "            y_min_edge_dist (int): Minimum row length necessary for detection.\n",
    "\n",
    "        Returns:\n",
    "            list: List containing arrays of edges for each timepoint, filtered for rows that are too small.\n",
    "        \"\"\"\n",
    "        edges_list = []\n",
    "        for t in range(mask.shape[1]):\n",
    "            edge_mask = mask[1:, t] != mask[:-1, t]\n",
    "            edges = np.where(edge_mask)[0]\n",
    "            edges = self.remove_small_rows(edges, y_min_edge_dist)\n",
    "            edges_list.append(edges)\n",
    "        return edges_list\n",
    "\n",
    "    def get_trench_edges_y(\n",
    "        self,\n",
    "        y_percentiles_smoothed_array,\n",
    "        triangle_nbins,\n",
    "        triangle_scaling,\n",
    "        y_min_edge_dist,\n",
    "    ):\n",
    "        \"\"\"Detects edges in the shape (y,t) smoothed percentile arrays for each input array.\n",
    "\n",
    "        Args:\n",
    "            y_percentiles_smoothed_list (list): List containing a smoothed percentile array for each input array.\n",
    "            triangle_nbins (int): Number of bins to be used to construct the thresholding histogram.\n",
    "            triangle_scaling (float): Factor by which to scale the threshold.\n",
    "            y_min_edge_dist (int): Minimum row length necessary for detection.\n",
    "\n",
    "        Returns:\n",
    "            list: List containing arrays of edges for each timepoint, filtered for rows that are too small.\n",
    "        \"\"\"\n",
    "        triangle_threshold = (\n",
    "            sk.filters.threshold_triangle(\n",
    "                y_percentiles_smoothed_array[:], nbins=triangle_nbins\n",
    "            )\n",
    "            * triangle_scaling\n",
    "        )\n",
    "        trench_mask_y_handle = self.chunk_t(\n",
    "            (y_percentiles_smoothed_array,),\n",
    "            (1,),\n",
    "            1,\n",
    "            self.threshold,\n",
    "            \"trench_mask_y\",\n",
    "            \"data\",\n",
    "            triangle_threshold,\n",
    "        )\n",
    "        trench_edges_y_list = self.get_edges_from_mask(\n",
    "            trench_mask_y_handle[\"data\"], y_min_edge_dist\n",
    "        )\n",
    "        self.delete_hdf5(trench_mask_y_handle)\n",
    "        return trench_edges_y_list\n",
    "\n",
    "    def get_row_number(self, trench_edges_y_list):\n",
    "        \"\"\"Computes the number of trench rows in the fov, from the detected edges.\n",
    "\n",
    "        Args:\n",
    "            trench_edges_y_list (list): List containing, for each fov entry, a list of time-sorted edge arrays.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of trench rows detected in the fov of index i.\n",
    "        \"\"\"\n",
    "        edge_num_list = [len(trench_edges_y) for trench_edges_y in trench_edges_y_list]\n",
    "        trench_row_num = (np.median(edge_num_list).astype(int)) // 2\n",
    "        return trench_row_num\n",
    "\n",
    "    def crop_y(self, array_tuple, padding_y, trench_len_y, top_orientation, row_num):\n",
    "        \"\"\"Performs cropping of the images in the y-dimension.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            trench_edges_y_list (list): List containing, for each fov entry, a list of time-sorted edge arrays.\n",
    "            row_num_list (list): List containing The number of trench rows detected in each fov.\n",
    "            imported_array_list (list): A list containing numpy arrays containing the hdf5 file image\n",
    "            data of shape (channel,y,x,t).\n",
    "            padding_y (int): Padding to be used when cropping in the y-dimension.\n",
    "            trench_len_y (int): Length from the end of the tenches to be used when cropping in the\n",
    "            y-dimension.\n",
    "            top_orientation (int): The orientation of the top-most row where 0 corresponds to a trench with\n",
    "            a downward-oriented trench opening and 1 corresponds to a trench with an upward-oriented trench opening.\n",
    "        Returns:\n",
    "            array: A y-cropped array of shape (rows,channels,x,y,t).\n",
    "        \"\"\"\n",
    "\n",
    "        (\n",
    "            imported_hdf5_array,\n",
    "            y_percentiles_smoothed_array,\n",
    "            trench_edges_y_list,\n",
    "        ) = array_tuple\n",
    "\n",
    "        time_list = []\n",
    "        for t in range(imported_hdf5_array.shape[3]):\n",
    "            trench_edges_y = trench_edges_y_list[t]\n",
    "            orientation = top_orientation\n",
    "\n",
    "            row_list = []\n",
    "            for r in range(0, row_num):\n",
    "                if orientation == 0:\n",
    "                    trench_edge_y = trench_edges_y[2 * r]\n",
    "                    upper = max(trench_edge_y - padding_y, 0)\n",
    "                    lower = min(\n",
    "                        trench_edge_y + trench_len_y, imported_hdf5_array.shape[1]\n",
    "                    )\n",
    "                else:\n",
    "                    trench_edge_y = trench_edges_y[(2 * r) + 1]\n",
    "                    upper = max(trench_edge_y - trench_len_y, 0)\n",
    "                    lower = min(trench_edge_y + padding_y, imported_hdf5_array.shape[1])\n",
    "\n",
    "                orientation = (orientation + 1) % 2\n",
    "\n",
    "                channel_list = []\n",
    "                for c in range(imported_hdf5_array.shape[0]):\n",
    "                    output_array = imported_hdf5_array[c, upper:lower, :, t]\n",
    "                    channel_list.append(output_array)\n",
    "                row_list.append(channel_list)\n",
    "            time_list.append(row_list)\n",
    "\n",
    "        cropped_in_y = np.array(time_list)\n",
    "        if len(cropped_in_y.shape) != 5:\n",
    "            return None\n",
    "        else:\n",
    "            cropped_in_y = np.moveaxis(cropped_in_y, (0, 1, 2, 3, 4), (4, 0, 1, 2, 3))\n",
    "            return cropped_in_y\n",
    "\n",
    "    def crop_trenches_in_y(self, imported_hdf5_handle):\n",
    "        \"\"\"Master function for cropping the input hdf5 file in the y-dimension.\n",
    "\n",
    "        Args:\n",
    "            imported_array_list (list): List containing, for each fov entry, a numpy array containing\n",
    "            the corresponding hdf5 file image data.\n",
    "\n",
    "        Returns:\n",
    "            list: List containing, for each fov entry, a y-cropped numpy array of shape (rows,channels,x,y,t).\n",
    "        \"\"\"\n",
    "        y_percentiles_smoothed_handle = self.get_smoothed_y_percentiles(\n",
    "            imported_hdf5_handle, self.y_percentile, self.smoothing_kernel_y\n",
    "        )\n",
    "        trench_edges_y_list = self.get_trench_edges_y(\n",
    "            y_percentiles_smoothed_handle[\"data\"],\n",
    "            self.triangle_nbins,\n",
    "            self.triangle_scaling,\n",
    "            self.y_min_edge_dist,\n",
    "        )\n",
    "        print(trench_edges_y_list)\n",
    "        row_num = self.get_row_number(trench_edges_y_list)\n",
    "        cropped_in_y_handle = self.chunk_t(\n",
    "            (\n",
    "                imported_hdf5_handle[\"data\"],\n",
    "                y_percentiles_smoothed_handle[\"data\"],\n",
    "                trench_edges_y_list,\n",
    "            ),\n",
    "            (3, 1, 0),\n",
    "            4,\n",
    "            self.crop_y,\n",
    "            \"cropped_in_y\",\n",
    "            \"data\",\n",
    "            self.padding_y,\n",
    "            self.trench_len_y,\n",
    "            self.top_orientation,\n",
    "            row_num,\n",
    "        )\n",
    "        self.delete_hdf5(y_percentiles_smoothed_handle)\n",
    "        self.delete_hdf5(imported_hdf5_handle)\n",
    "        return cropped_in_y_handle\n",
    "\n",
    "    def get_smoothed_x_percentiles(\n",
    "        self, array_tuple, x_percentile, background_kernel_x, smoothing_kernel_x\n",
    "    ):\n",
    "        \"\"\"Summary\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            cropped_in_y_list (list): List containing, for each fov entry, a y-cropped numpy array of shape (rows,channels,x,y,t).\n",
    "            x_percentile (int): Used for reducing signal in xyt to only the xt dimension when cropping\n",
    "            in the x-dimension.\n",
    "            background_kernel_x (tuple): Two-entry tuple specifying a kernel size for performing background subtraction\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "            smoothing_kernel_x (tuple): Two-entry tuple specifying a kernel size for performing smoothing\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "\n",
    "        Returns:\n",
    "            array: A smoothed and background subtracted percentile array of shape (rows,x,t)\n",
    "        \"\"\"\n",
    "        (cropped_in_y_array,) = array_tuple\n",
    "        x_percentiles_smoothed = []\n",
    "        for row_num in range(cropped_in_y_array.shape[0]):\n",
    "            cropped_in_y_seg = cropped_in_y_array[row_num, 0]\n",
    "            x_percentiles = np.percentile(cropped_in_y_seg, x_percentile, axis=0)\n",
    "            x_background_filtered = x_percentiles - self.median_filter_2d(\n",
    "                (x_percentiles,), background_kernel_x\n",
    "            )\n",
    "            x_smooth_filtered = self.median_filter_2d(\n",
    "                (x_background_filtered,), smoothing_kernel_x\n",
    "            )\n",
    "            x_percentiles_smoothed.append(x_smooth_filtered)\n",
    "        x_percentiles_smoothed = np.array(x_percentiles_smoothed)\n",
    "        return x_percentiles_smoothed\n",
    "\n",
    "    def get_midpoints_from_mask(self, mask):\n",
    "        \"\"\"Using a boolean x mask, computes the positions of trench midpoints.\n",
    "\n",
    "        Args:\n",
    "            mask (array): x boolean array, specifying where trenches are present.\n",
    "\n",
    "        Returns:\n",
    "            array: array of trench midpoint x positions.\n",
    "        \"\"\"\n",
    "        transitions = mask[:-1].astype(int) - mask[1:].astype(int)\n",
    "\n",
    "        trans_up = np.where((transitions == -1))[0]\n",
    "        trans_dn = np.where((transitions == 1))[0]\n",
    "\n",
    "        if len(np.where(trans_dn > trans_up[0])[0]) > 0:\n",
    "            first_dn = np.where(trans_dn > trans_up[0])[0][0]\n",
    "            trans_dn = trans_dn[first_dn:]\n",
    "            trans_up = trans_up[: len(trans_dn)]\n",
    "            midpoints = (trans_dn + trans_up) // 2\n",
    "        else:\n",
    "            midpoints = []\n",
    "        return midpoints\n",
    "\n",
    "    def get_midpoints(self, x_percentiles_t, otsu_nbins, otsu_scaling):\n",
    "        \"\"\"Given an array of signal in x, determines the position of trench midpoints.\n",
    "\n",
    "        Args:\n",
    "            x_percentiles_t (array): array of trench intensities in x, at time t.\n",
    "            otsu_nbins (int): Number of bins to use when applying Otsu's method to x-dimension signal.\n",
    "            otsu_scaling (float): Threshold scaling factor for Otsu's method thresholding.\n",
    "\n",
    "        Returns:\n",
    "            array: array of trench midpoint x positions.\n",
    "        \"\"\"\n",
    "        otsu_threshold = (\n",
    "            sk.filters.threshold_otsu(x_percentiles_t[:, np.newaxis], nbins=otsu_nbins)\n",
    "            * otsu_scaling\n",
    "        )\n",
    "        x_mask = x_percentiles_t > otsu_threshold\n",
    "        midpoints = self.get_midpoints_from_mask(x_mask)\n",
    "        return midpoints\n",
    "\n",
    "    def get_all_midpoints(self, x_percentiles_smoothed_array, otsu_nbins, otsu_scaling):\n",
    "        \"\"\"Given an x percentile array of shape (rows,x,t), determines the trench midpoints of each row array\n",
    "        at each time t.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            x_percentiles_smoothed (array): A smoothed and background subtracted percentile array of shape (rows,x,t)\n",
    "            otsu_nbins (TYPE): Description\n",
    "            otsu_scaling (TYPE): Description\n",
    "\n",
    "        Returns:\n",
    "            list: A nested list of the form [row_list,[time_list,[midpoint_array]]].\n",
    "        \"\"\"\n",
    "        all_midpoints_list = []\n",
    "        for j in range(x_percentiles_smoothed_array.shape[0]):\n",
    "            x_percentiles_smoothed = x_percentiles_smoothed_array[j]\n",
    "            all_midpoints = []\n",
    "            midpoints = self.get_midpoints(\n",
    "                x_percentiles_smoothed[:, 0], otsu_nbins, otsu_scaling\n",
    "            )\n",
    "            if len(midpoints) == 0:\n",
    "                return None\n",
    "            all_midpoints.append(midpoints)\n",
    "            for t in range(1, x_percentiles_smoothed.shape[1]):\n",
    "                midpoints = self.get_midpoints(\n",
    "                    x_percentiles_smoothed[:, t], otsu_nbins, otsu_scaling\n",
    "                )\n",
    "                if len(midpoints) / (len(all_midpoints[-1]) + 1) < 0.5:\n",
    "                    all_midpoints.append(all_midpoints[-1])\n",
    "                else:\n",
    "                    all_midpoints.append(midpoints)\n",
    "            all_midpoints_list.append(all_midpoints)\n",
    "        return all_midpoints_list\n",
    "\n",
    "    def get_x_drift(self, all_midpoints_list):\n",
    "        \"\"\"Given an t by x array of midpoints, computed the average drift in x for every timepoint.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            all_midpoints_list (list): A nested list of the form [fov_list,[row_list,[time_list,[midpoint_array]]]] containing\n",
    "            the trench midpoints.\n",
    "\n",
    "        Returns:\n",
    "            list: A nested list of the form [row_list,[time_list,[x_drift_int]]].\n",
    "        \"\"\"\n",
    "        x_drift_list = []\n",
    "        for all_midpoints in all_midpoints_list:\n",
    "            x_drift = []\n",
    "            for t in range(len(all_midpoints) - 1):\n",
    "                diff_mat = np.subtract.outer(all_midpoints[t + 1], all_midpoints[t])\n",
    "                min_dist_idx = np.argmin(abs(diff_mat), axis=0)\n",
    "                min_dists = diff_mat[min_dist_idx]\n",
    "                median_translation = int(np.median(min_dists))\n",
    "                x_drift.append(median_translation)\n",
    "            net_x_drift = np.append(np.array([0]), np.add.accumulate(x_drift))\n",
    "            x_drift_list.append(net_x_drift)\n",
    "        return x_drift_list\n",
    "\n",
    "    def init_counting_arr(self, x_dim):\n",
    "        \"\"\"Initializes a counting array of shape (x_dim,t_dim) which counts from 0 to\n",
    "        x_dim on axis 0 for all positions in axis 1.\n",
    "\n",
    "        Args:\n",
    "            x_dim (int): Size of x axis to use.\n",
    "            t_dim (int): Size of t axis to use.\n",
    "\n",
    "        Returns:\n",
    "            array: Counting array to be used for masking out trenches in x.\n",
    "        \"\"\"\n",
    "        ones_arr = np.ones(x_dim)\n",
    "        counting_arr = np.add.accumulate(np.ones(x_dim)).astype(int) - 1\n",
    "        return counting_arr\n",
    "\n",
    "    def get_k_mask(self, array_list, cropped_in_y, counting_arr):\n",
    "        (in_bounds,) = array_list\n",
    "        counting_arr_repeated = np.repeat(\n",
    "            counting_arr[:, np.newaxis], in_bounds.shape[1], axis=1\n",
    "        )\n",
    "        masks = []\n",
    "        for k in range(in_bounds.shape[2]):\n",
    "            mask = np.logical_and(\n",
    "                counting_arr_repeated > in_bounds[0, :, k],\n",
    "                counting_arr_repeated < in_bounds[1, :, k],\n",
    "            ).T\n",
    "            masks.append(mask)\n",
    "        all_mask = np.any(np.array(masks), axis=0)\n",
    "        k_mask = np.repeat(all_mask[np.newaxis, :, :], cropped_in_y.shape[2], axis=0)\n",
    "        return k_mask\n",
    "\n",
    "    def get_k_masks(\n",
    "        self, cropped_in_y, row_num, all_midpoints, x_drift, trench_width_x\n",
    "    ):\n",
    "        \"\"\"Generates a boolean trench mask of shape (x_dim,t_dim) for each trench k. This will be used to mask\n",
    "        out each trench at a later step.\n",
    "\n",
    "        Args:\n",
    "            cropped_in_y (array): A y-cropped numpy array of shape (rows,channels,x,y,t) containing y-cropped image data.\n",
    "            all_midpoints (list): A list containing, for each time t, an array of trench midpoints.\n",
    "            x_drift (list): A list containing, for each time t, an int corresponding to the drift of the midpoints in x.\n",
    "            trench_width_x (int): Width to be used when cropping in the x-dimension.\n",
    "\n",
    "        Returns:\n",
    "            list:  A list containing, for each trench k, a boolean trench mask of shape (x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        corrected_midpoints = x_drift[:, np.newaxis] + all_midpoints[0][np.newaxis, :]\n",
    "        midpoints_up, midpoints_dn = (\n",
    "            corrected_midpoints - trench_width_x // 2,\n",
    "            corrected_midpoints + trench_width_x // 2 + 1,\n",
    "        )\n",
    "        stays_in_frame = np.all(midpoints_up >= 0, axis=0) * np.all(\n",
    "            midpoints_dn <= cropped_in_y.shape[3], axis=0\n",
    "        )  # filters out midpoints that stay in the frame for the whole time...\n",
    "        no_overlap = np.append(\n",
    "            np.array([True]),\n",
    "            (corrected_midpoints[0, 1:] - corrected_midpoints[0, :-1])\n",
    "            >= (trench_width_x + 1),\n",
    "        )  # corrects for overlap\n",
    "        valid_mask = stays_in_frame * no_overlap\n",
    "        in_bounds = np.array([midpoints_up[:, valid_mask], midpoints_dn[:, valid_mask]])\n",
    "        k_tot = in_bounds.shape[2]\n",
    "        counting_arr = self.init_counting_arr(cropped_in_y.shape[3])\n",
    "        k_mask_handle = self.chunk_t(\n",
    "            (in_bounds,),\n",
    "            (1,),\n",
    "            1,\n",
    "            self.get_k_mask,\n",
    "            \"k_mask\",\n",
    "            \"data\",\n",
    "            cropped_in_y,\n",
    "            counting_arr,\n",
    "            dtype=bool,\n",
    "        )\n",
    "\n",
    "        return k_mask_handle, k_tot\n",
    "\n",
    "    def apply_kymo_mask(self, array_tuple, row_num, channel, k_tot):\n",
    "        \"\"\"Given a y-cropped image and a boolean trench mask of shape (x_dim,t_dim), masks that image in\n",
    "        xt to generate an output kymograph of shape (y_dim,x_dim,t_dim).\n",
    "\n",
    "        Args:\n",
    "            img_arr (array): A numpy array of a y-cropped image\n",
    "            mask_arr (array): A boolean trench mask of shape (x_dim,t_dim) for a given trench k\n",
    "            row_num (int): Int specifying the current row.\n",
    "            channel (int): Int specifying which channel we are getting midpoints from (order specified by\n",
    "            self.all_channels).\n",
    "\n",
    "        Returns:\n",
    "            array: Kymograph array of shape (y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        img_arr, k_mask = array_tuple\n",
    "        img_arr = img_arr[row_num, channel]\n",
    "        img_arr_swap = np.moveaxis(img_arr, (0, 1, 2), (0, 2, 1))\n",
    "        cropped_img_arr = img_arr_swap[k_mask]\n",
    "        cropped_img_arr = cropped_img_arr.reshape(\n",
    "            img_arr_swap.shape[0], img_arr_swap.shape[1], -1\n",
    "        )\n",
    "        cropped_img_arr = np.moveaxis(cropped_img_arr, (0, 1, 2), (0, 2, 1))\n",
    "        kymo_out = np.stack(np.split(cropped_img_arr, k_tot, axis=1), axis=0)\n",
    "        return kymo_out  # (56,290,31,25)\n",
    "\n",
    "    def crop_with_k_masks(self, cropped_in_y_handle, k_mask_handle, row_num, k_tot):\n",
    "        \"\"\"Performs cropping of the aleady y-cropped image data, using pregenerated kymograph masks\n",
    "        of shape (x_dim,t_dim).\n",
    "\n",
    "        Args:\n",
    "            cropped_in_y (array): A y-cropped array of shape (rows,channels,x,y,t).\n",
    "            row_num (int): The row number to crop kymographs from.\n",
    "            k_masks (list): A list containing, for each trench k, a boolean trench mask of shape (x_dim,t_dim).\n",
    "\n",
    "        Returns:\n",
    "            list: A kymograph array of shape (channels,trenches,y_dim,x_dim,t_dim)\n",
    "        \"\"\"\n",
    "        x_cropped = []\n",
    "        for c, channel in enumerate(self.all_channels):\n",
    "            dataset_name = str(row_num) + \"/\" + str(channel)\n",
    "            kymograph_handle = self.chunk_t(\n",
    "                (cropped_in_y_handle[\"data\"], k_mask_handle[\"data\"]),\n",
    "                (4, 1),\n",
    "                3,\n",
    "                self.apply_kymo_mask,\n",
    "                \"output\",\n",
    "                dataset_name,\n",
    "                row_num,\n",
    "                c,\n",
    "                k_tot,\n",
    "            )\n",
    "            kymograph_handle.close()\n",
    "        self.delete_hdf5(k_mask_handle)\n",
    "\n",
    "    def get_crop_in_x(\n",
    "        self, cropped_in_y_handle, all_midpoints_list, x_drift_list, trench_width_x\n",
    "    ):\n",
    "        \"\"\"Generates complete kymograph arrays for all trenches in the fov in every channel listed in 'self.all_channels'.\n",
    "        Outputs a list of these kymograph arrays, with entries corresponding to each row in the fov with index i.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            cropped_in_y_list (list): List containing, for each fov entry, a y-cropped numpy array of shape (rows,channels,x,y,t).\n",
    "            all_midpoints_list (list): A nested list of the form [fov_list,[row_list,[time_list,[midpoint_array]]]] containing\n",
    "            the trench midpoints.\n",
    "            x_drift_list (list): A nested list of the form [fov_list,[row_list,[time_list,[x_drift_int]]]] containing the computed\n",
    "            drift in the x dimension.\n",
    "            trench_width_x (int): Width to be used when cropping in the x-dimension.\n",
    "\n",
    "        Returns:\n",
    "            list: A list containing, for each row, a kymograph array of shape (channels,trenches,y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        for row_num, all_midpoints in enumerate(all_midpoints_list):\n",
    "            x_drift = x_drift_list[row_num]\n",
    "            k_mask_handle, k_tot = self.get_k_masks(\n",
    "                cropped_in_y_handle[\"data\"],\n",
    "                row_num,\n",
    "                all_midpoints,\n",
    "                x_drift,\n",
    "                trench_width_x,\n",
    "            )\n",
    "            self.crop_with_k_masks(cropped_in_y_handle, k_mask_handle, row_num, k_tot)\n",
    "\n",
    "    def crop_trenches_in_x(self, cropped_in_y_handle):\n",
    "        \"\"\"Performs cropping of the images in the x-dimension.\n",
    "\n",
    "        Args:\n",
    "            cropped_in_y_list (list): List containing, for each fov entry, a y-cropped numpy array of shape (rows,channels,x,y,t).\n",
    "\n",
    "        Returns:\n",
    "            list: A nested list of the form [fov_list,[row_list,[kymograph_array]]], containing kymograph arrays of\n",
    "            shape (channels,trenches,y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        smoothed_x_percentiles_handle = self.chunk_t(\n",
    "            (cropped_in_y_handle[\"data\"],),\n",
    "            (4,),\n",
    "            2,\n",
    "            self.get_smoothed_x_percentiles,\n",
    "            \"smoothed_x_percentiles\",\n",
    "            \"data\",\n",
    "            self.x_percentile,\n",
    "            self.background_kernel_x,\n",
    "            self.smoothing_kernel_x,\n",
    "        )\n",
    "        all_midpoints_list = self.get_all_midpoints(\n",
    "            smoothed_x_percentiles_handle[\"data\"], self.otsu_nbins, self.otsu_scaling\n",
    "        )\n",
    "\n",
    "        x_drift_list = self.get_x_drift(all_midpoints_list)\n",
    "\n",
    "        self.get_crop_in_x(\n",
    "            cropped_in_y_handle, all_midpoints_list, x_drift_list, self.trench_width_x\n",
    "        )\n",
    "\n",
    "    def generate_kymograph(self):\n",
    "        \"\"\"Master function for generating kymographs for the set of fovs specified on initialization.\n",
    "\n",
    "        Returns:\n",
    "            list: A nested list of the form [fov_list,[row_list,[kymograph_array]]], containing kymograph arrays of\n",
    "            shape (channels,trenches,y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        self.writedir(self.output_path, overwrite=False)\n",
    "        self.writedir(self.temp_path, overwrite=True)\n",
    "        imported_hdf5_handle = self.import_hdf5(\"imported_hdf5\", \"data\")\n",
    "        cropped_in_y_handle = self.crop_trenches_in_y(imported_hdf5_handle)\n",
    "        self.crop_trenches_in_x(cropped_in_y_handle)\n",
    "\n",
    "        temp_output_file_path = self.temp_path + \"output.hdf5\"\n",
    "        os.rename(temp_output_file_path, self.output_file_path)\n",
    "        self.delete_hdf5(cropped_in_y_handle)\n",
    "        shutil.rmtree(self.temp_path)\n",
    "\n",
    "    def plot_kymograph(self, kymograph):\n",
    "        \"\"\"Helper function for plotting kymographs. Takes a kymograph array of shape (y_dim,x_dim,t_dim).\n",
    "\n",
    "        Args:\n",
    "            kymograph (array): kymograph array of shape (y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        list_in_t = [kymograph[:, :, t] for t in range(kymograph.shape[2])]\n",
    "        img_arr = np.concatenate(list_in_t, axis=1)\n",
    "        plt.imshow(img_arr)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kymograph as ky\n",
    "from kymograph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path_prefix = (\n",
    "    \"/n/groups/paulsson/Daniel/Image_analysis_pipeline/tiff_extraction/test_out_4/fov_\"\n",
    ")\n",
    "output_path = \"/n/groups/paulsson/Daniel/Image_analysis_pipeline/kymographs_6\"\n",
    "fov_number = 12\n",
    "all_channels = [\"channel_BF\", \"channel_RFP\"]\n",
    "trench_len_y, padding_y, trench_width_x = (270, 20, 30)\n",
    "\n",
    "kymo = ky.chunked(\n",
    "    input_path_prefix,\n",
    "    output_path,\n",
    "    fov_number,\n",
    "    all_channels,\n",
    "    trench_len_y,\n",
    "    padding_y,\n",
    "    trench_width_x,\n",
    "    t_chunk=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kymo.generate_kymograph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(\n",
    "    \"/n/groups/paulsson/Daniel/Image_analysis_pipeline/kymographs_6/kymo_12.hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tplot.plot_kymograph(data[\"0/channel_BF\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_mem(t_chunk):\n",
    "    kymo = ky.chunked(\n",
    "        input_path_prefix,\n",
    "        output_path,\n",
    "        fov_number,\n",
    "        all_channels,\n",
    "        trench_len_y,\n",
    "        padding_y,\n",
    "        trench_width_x,\n",
    "        t_chunk=t_chunk,\n",
    "    )\n",
    "    kymo.generate_kymograph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit f_mem(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit f_mem(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r1 f_mem(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r1 f_mem(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
