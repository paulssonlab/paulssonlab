{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrenchRipper Master Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trenchripper as tr\n",
    "\n",
    "from ipywidgets import (\n",
    "    interact,\n",
    "    interactive,\n",
    "    fixed,\n",
    "    interact_manual,\n",
    "    FloatSlider,\n",
    "    IntSlider,\n",
    "    Dropdown,\n",
    "    IntText,\n",
    "    SelectMultiple,\n",
    "    IntRangeSlider,\n",
    "    FloatRangeSlider,\n",
    ")\n",
    "import ipywidgets as widgets\n",
    "import matplotlib\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify Paths\n",
    "\n",
    "Begin by defining the directory in which all processing will be done, as well as the initial nd2 file we will be processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = \"/n/scratch2/de64/2019-05-31_validation_data\"\n",
    "nd2file = \"/n/scratch2/de64/2019-05-31_validation_data/Main_Experiment.nd2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer files into the scratch folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedir = \"/n/files/SysBio/PAULSSON\\ LAB/Personal\\ Folders/Daniel/Image_Data/Bacillus_Project/2019-05-31_DE85_training_data/exp_folder\"\n",
    "targetdir = \"/n/scratch2/de64/2019-05-31_validation_data\"\n",
    "tr.trcluster.transferjob(sourcedir, targetdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Extract to hdf5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Dask Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=10,\n",
    "    memory=\"2GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_extractor = tr.ndextract.hdf5_fov_extractor(\n",
    "    nd2file,\n",
    "    headpath,\n",
    "    tpts_per_file=100,\n",
    "    ignore_fovmetadata=False,\n",
    "    nd2reader_override={\"z_levels\": [], \"z_coordinates\": []},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_extractor.inter_get_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_extractor.extract(dask_controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shutdown Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Kymographs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "#### Initialize the interactive kymograph class\n",
    "\n",
    "As a first step, initialize the `tr.interactive.kymograph_interactive` class that will be handling all steps of generating a kymograph. \n",
    "\n",
    "You will need to specify the following `args` and `kwargs` (in order):\n",
    "\n",
    "\n",
    "**Args**\n",
    "\n",
    "**input_file_prefix (string)** : File prefix for all input hdf5 files of the form \"\\[input_file_prefix\\]\\[number\\].hdf5\" This should be the default output format for the hdf5 export code, but you will need to rename files if taking input files from a different source.\n",
    "\n",
    "**all_channels (list)** : list of strings corresponding to the different image channels available in the input hdf5 file, with the channel used for segmenting trenches in the first position. NOTE: these names must match those of the input hdf5 file datasets.\n",
    "\n",
    "**fov_list (list)** : List of ints corresponding to the fovs that you wish to make kymographs of.\n",
    "\n",
    "**Kwargs**\n",
    "\n",
    "**t_subsample_step (int)** : Step size to be used for subsampling input files in time, recommend that subsampling results in between 5 and 20 timepoints for quick processing.\n",
    "\n",
    "**t_range (tuple of ints)** : Range size to be used for subsampling input files in time.\n",
    "\n",
    "The last line will perform import and subsampling of the input hdf5 image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "interactive_kymograph = tr.kymograph_interactive(headpath)\n",
    "channels, fov_list, timepoints_len = interactive_kymograph.get_image_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    interactive_kymograph.view_image,\n",
    "    fov_idx=IntText(value=0, description=\"FOV number:\", disabled=False),\n",
    "    t=IntSlider(\n",
    "        value=0, min=0, max=timepoints_len - 1, step=1, continuous_update=False\n",
    "    ),\n",
    "    channel=Dropdown(\n",
    "        options=channels, value=channels[0], description=\"Channel:\", disabled=False\n",
    "    ),\n",
    "    invert=Dropdown(options=[True, False], value=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_hdf5 = interactive(\n",
    "    interactive_kymograph.import_hdf5_files,\n",
    "    {\"manual\": True},\n",
    "    all_channels=fixed(channels),\n",
    "    seg_channel=Dropdown(options=channels, value=channels[0]),\n",
    "    invert=Dropdown(options=[True, False], value=False),\n",
    "    fov_list=SelectMultiple(options=fov_list),\n",
    "    t_range=IntRangeSlider(\n",
    "        value=[0, timepoints_len - 1],\n",
    "        min=0,\n",
    "        max=timepoints_len - 1,\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "    ),\n",
    "    t_subsample_step=IntSlider(value=10, min=0, max=200, step=1),\n",
    ")\n",
    "display(import_hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_array_list = copy.copy(import_hdf5.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune \"trench-row\" detection hyperparameters\n",
    "\n",
    "The kymograph code begins by detecting the positions of trench rows in the image as follows:\n",
    "\n",
    "1. Reducing each 2D image to a 1D signal along the y-axis by computing the qth percentile of the data along the x-axis\n",
    "2. Smooth this signal using a median kernel\n",
    "3. Use a [triangle threshold](https://imagej.net/Auto_Threshold#Triangle) to determine the trench row poisitons\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**y_percentile (int)** : Percentile to use for step 1.\n",
    "\n",
    "**smoothing_kernel_y_dim_0 (int)** : Median kernel size to use for step 2.\n",
    "\n",
    "**triangle_nbins (int)** : Number of bins to use in the triangle method histogram.\n",
    "\n",
    "**triangle_scaling (float)** : Scaling factor to apply to the threshold determined by the triangle method.\n",
    "\n",
    "\n",
    "Running the following widget will display the smoothed 1-D signal for each of your timepoints. In addition, the threshold value for each fov will be displayed as a red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "\n",
    "row_detection = interactive(\n",
    "    interactive_kymograph.preview_y_precentiles,\n",
    "    {\"manual\": True},\n",
    "    imported_array_list=fixed(imported_array_list),\n",
    "    y_percentile=IntSlider(value=99, min=0, max=100, step=1),\n",
    "    smoothing_kernel_y_dim_0=IntSlider(value=29, min=1, max=200, step=2),\n",
    "    triangle_nbins=IntSlider(value=50, min=10, max=300, step=10),\n",
    "    triangle_scaling=FloatSlider(value=3.5, min=0.0, max=4.0, step=0.05),\n",
    "    triangle_threshold_bounds=FloatRangeSlider(\n",
    "        value=[0.1, 0.25],\n",
    "        min=0,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "    ),\n",
    ")\n",
    "display(row_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate \"trench-row\" detection output\n",
    "\n",
    "After determining your desired hyperparameters, set them in the next cell and run it to produce output for later steps. **Note: The thresholding parameters do not need to be specified at this point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_percentiles_smoothed_list = copy.copy(row_detection.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune \"trench-row\" cropping hyperparameters\n",
    "\n",
    "Next, we will use the detected rows to perform cropping of the input image in the y-dimension:\n",
    "\n",
    "1. Determine edges of trench rows based on threshold mask.\n",
    "2. Filter out rows that are too small.\n",
    "3. Perform cropping using the \"end\" of the row as reference (the end referring to the part of the trench farthest from the feeding channel).\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**y_min_edge_dist (int)** : Minimum row length necessary for detection.\n",
    "\n",
    "**padding_y (int)** : Padding to be used when cropping in the y-dimension.\n",
    "\n",
    "**trench_len_y (int)** : Length from the end of the tenches to be used when cropping in the y-dimension.\n",
    "\n",
    "**top_orientation (int)** : The orientation of the top-most row where 0 corresponds to a trench with a downward-oriented trench opening and 1 corresponds to a trench with an upward-oriented trench opening.\n",
    "\n",
    "**vertical_spacing (float)** : Parameter for setting the distance of plots being viewed.\n",
    "\n",
    "Running the following widget will display y-cropped images for each fov and timepoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "y_cropping = interactive(\n",
    "    interactive_kymograph.preview_y_crop,\n",
    "    {\"manual\": True},\n",
    "    y_percentiles_smoothed_list=fixed(y_percentiles_smoothed_list),\n",
    "    imported_array_list=fixed(imported_array_list),\n",
    "    y_min_edge_dist=IntSlider(value=50, min=10, max=200, step=10),\n",
    "    padding_y=IntSlider(value=20, min=0, max=100, step=1),\n",
    "    trench_len_y=IntSlider(value=270, min=0, max=1000, step=10),\n",
    "    vertical_spacing=FloatSlider(value=0.9, min=0.0, max=2.0, step=0.01),\n",
    "    expected_num_rows=IntText(value=2, description=\"Number of Rows:\", disabled=False),\n",
    "    orientation_detection=Dropdown(\n",
    "        options=[0, 1, \"phase\"], value=0, description=\"Orientation:\", disabled=False\n",
    "    ),\n",
    "    orientation_on_fail=Dropdown(\n",
    "        options=[None, 0, 1],\n",
    "        value=0,\n",
    "        description=\"Orientation when < expected rows:\",\n",
    "        disabled=False,\n",
    "    ),\n",
    ")\n",
    "display(y_cropping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate \"trench-row\" cropping output\n",
    "\n",
    "After determining your desired hyperparameters, set them in the next cell and run it to produce output for later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_in_y_list = copy.copy(y_cropping.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune trench detection hyperparameters\n",
    "\n",
    "Next, we will detect the positions of trenchs in the y-cropped images as follows:\n",
    "\n",
    "1. Reducing each 2D image to a 1D signal along the x-axis by computing the qth percentile of the data along the y-axis.\n",
    "2. Determine the signal background by smooth this signal using a large median kernel.\n",
    "3. Subtract the background signal.\n",
    "4. Smooth the resultant signal using a median kernel.\n",
    "5. Use a [otsu threhsold](https://imagej.net/Auto_Threshold#Otsu) to determine the trench midpoint poisitons.\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**x_percentile (int)** : Percentile to use for step 1.\n",
    "\n",
    "**background_kernel_x (int)** : Median kernel size to use for step 2.\n",
    "\n",
    "**smoothing_kernel_x (int)** : Median kernel size to use for step 4.\n",
    "\n",
    "**otsu_nbins (int)** : Number of bins to use in the Otsu's method histogram.\n",
    "\n",
    "**otsu_scaling (float)** : Scaling factor to apply to the threshold determined by Otsu's method.\n",
    "\n",
    "**vertical_spacing (float)** : Parameter for setting the distance of plots being viewed.\n",
    "\n",
    "Running the following widget will display the smoothed 1-D signal for each of your timepoints. In addition, the threshold value for each fov will be displayed as a red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_detection = interactive(\n",
    "    interactive_kymograph.preview_x_percentiles,\n",
    "    {\"manual\": True},\n",
    "    cropped_in_y_list=fixed(cropped_in_y_list),\n",
    "    t=IntSlider(value=0, min=0, max=cropped_in_y_list[0].shape[4] - 1, step=1),\n",
    "    x_percentile=IntSlider(value=85, min=50, max=100, step=1),\n",
    "    background_kernel_x=IntSlider(value=21, min=1, max=601, step=20),\n",
    "    smoothing_kernel_x=IntSlider(value=9, min=1, max=31, step=2),\n",
    "    otsu_nbins=IntSlider(value=50, min=10, max=200, step=10),\n",
    "    otsu_scaling=FloatSlider(value=0.25, min=0.0, max=2.0, step=0.01),\n",
    "    vertical_spacing=FloatSlider(value=0.9, min=0.0, max=2.0, step=0.01),\n",
    ")\n",
    "display(trench_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate trench detection output\n",
    "\n",
    "After determining your desired hyperparameters, set them in the next cell and run it to produce output for later steps. **Note: The thresholding parameters do not need to be specified at this point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_x_percentiles_list = trench_detection.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check midpoint drift\n",
    "\n",
    "Next, we will perform x-dimension drift correction of our detected midpoints as follows:\n",
    "\n",
    "1. Begin at t=1\n",
    "2. For $m \\in \\{midpoints(t)\\}$ assign $n \\in \\{midpoints(t-1)\\}$ to m if n is the closest midpoint to m at time $t-1$,\n",
    "points that are not the closest midpoint to any midpoints in m will not be mapped.\n",
    "3. Compute the translation of each midpoint at time.\n",
    "4. Take the average of this value as the x-dimension drift from time t-1 to t.\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**vertical_spacing (float)** : Parameter for setting the distance of plots being viewed.\n",
    "\n",
    "Running the following widget will display the detected midpoints for each of your timepoints. If there is too much sparsity, or discontinuity, your drift correction will not be accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midpoint_drift = interactive(\n",
    "    interactive_kymograph.preview_midpoints,\n",
    "    {\"manual\": True},\n",
    "    smoothed_x_percentiles_list=fixed(smoothed_x_percentiles_list),\n",
    "    vertical_spacing=FloatSlider(value=0.8, min=0.0, max=2.0, step=0.01),\n",
    ")\n",
    "display(midpoint_drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate midpoint drift output\n",
    "\n",
    "After determining your desired hyperparameters, set them in the next cell and run it to produce output for later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_midpoints_list, x_drift_list = midpoint_drift.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune trench cropping hyperparameters\n",
    "\n",
    "Trench cropping simply uses the drift-corrected midpoints as a reference and crops out some fixed length around them to produce an output kymograph\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**trench_width_x (int)** : Trench width to use for cropping.\n",
    "\n",
    "**vertical_spacing (float)** : Parameter for setting the distance of plots being viewed.\n",
    "\n",
    "Running the following widget will display a random kymograph for each row in each fov.\n",
    "\n",
    "It will also produce midpoint plots showing retained midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "interact_manual(\n",
    "    interactive_kymograph.preview_kymographs,\n",
    "    cropped_in_y_list=fixed(cropped_in_y_list),\n",
    "    all_midpoints_list=fixed(all_midpoints_list),\n",
    "    x_drift_list=fixed(x_drift_list),\n",
    "    trench_width_x=IntSlider(value=30, min=10, max=50, step=2),\n",
    "    trench_present_thr=FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05),\n",
    "    vertical_spacing=FloatSlider(value=0.8, min=0.0, max=2.0, step=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export and save hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_kymograph.process_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_kymograph.write_param_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Kymograph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Dask Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=100,\n",
    "    memory=\"8GB\",\n",
    "    working_directory=\"/n/scratch2/de64/2019-11-09_CN_Growth_Curve/\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust = tr.kymograph.kymograph_cluster(\n",
    "    headpath=headpath, trenches_per_file=25, paramfile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust.generate_kymographs(dask_controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust.post_process(dask_controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check kymograph statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust.kymo_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shutdown Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Fluorescence Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the interactive segmentation class\n",
    "\n",
    "As a first step, initialize the `tr.interactive.fluo_segmentation_interactive` class that will be handling all steps of generating a segmentation. \n",
    "\n",
    "You will need to specify the following `args` (in order):\n",
    "\n",
    "\n",
    "**Args**\n",
    "\n",
    "**headpath (string)** : Top level path being used for processing (same as the rest of the mother machine pipeline.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "interactive_segmentation = tr.fluo_segmentation_interactive(headpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose channel to segment on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_channel = interactive(\n",
    "    interactive_segmentation.choose_seg_channel,\n",
    "    {\"manual\": True},\n",
    "    seg_channel=Dropdown(\n",
    "        options=interactive_segmentation.all_channels,\n",
    "        value=interactive_segmentation.all_channels[0],\n",
    "    ),\n",
    ")\n",
    "display(choose_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data\n",
    "\n",
    "Fill in \n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**fov_idx (int)** :\n",
    "\n",
    "**n_trenches (int)** :\n",
    "\n",
    "**t_range (tuple)** :\n",
    "\n",
    "**t_subsample_step (int)** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kymo_arr_int = interactive(\n",
    "    interactive_segmentation.import_array,\n",
    "    {\"manual\": True},\n",
    "    n_trenches=IntText(value=12, description=\"Number of trenches:\", disabled=False),\n",
    "    t_range=IntRangeSlider(\n",
    "        value=[\n",
    "            interactive_segmentation.t_range[0],\n",
    "            interactive_segmentation.t_range[1] - 1,\n",
    "        ],\n",
    "        description=\"Time Range:\",\n",
    "        min=interactive_segmentation.t_range[0],\n",
    "        max=interactive_segmentation.t_range[1] - 1,\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "    ),\n",
    "    t_subsample_step=IntSlider(\n",
    "        value=1, description=\"Time Subsampling Step:\", min=1, max=20, step=1\n",
    "    ),\n",
    "    fig_size_y=IntSlider(\n",
    "        value=20, description=\"Figure Size (Y Dimension):\", min=1, max=30, step=1\n",
    "    ),\n",
    "    fig_size_x=IntSlider(\n",
    "        value=12, description=\"Figure Size (X Dimension):\", min=1, max=30, step=1\n",
    "    ),\n",
    "    img_per_row=IntSlider(\n",
    "        value=6, description=\"Images per Row:\", min=1, max=30, step=1\n",
    "    ),\n",
    ")\n",
    "display(kymo_arr_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kymo_arr = copy.copy(kymo_arr_int.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data\n",
    "\n",
    "Fill in \n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**scale (bool)** : Whether to scale the kymograph in time.\n",
    "\n",
    "**scaling_percentile (int)** : Whole image intensity percentile to use to determine scaling constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Gaussian Filter\n",
    "\n",
    "Fill in \n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**smooth_sigma (float)** : Standard deviation of gaussian kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_list_int = interactive(\n",
    "    interactive_segmentation.plot_processed,\n",
    "    {\"manual\": True},\n",
    "    kymo_arr=fixed(kymo_arr),\n",
    "    smooth_sigma=FloatSlider(\n",
    "        value=0.75,\n",
    "        description=\"Gaussian Kernel Sigma:\",\n",
    "        min=0.0,\n",
    "        max=3.0,\n",
    "        step=0.25,\n",
    "        disabled=False,\n",
    "    ),\n",
    "    bit_max=IntSlider(\n",
    "        value=1000,\n",
    "        description=\"8-bit Maximum:\",\n",
    "        min=0,\n",
    "        max=65535,\n",
    "        step=250,\n",
    "        disabled=False,\n",
    "    ),\n",
    "    scale=Dropdown(\n",
    "        options=[True, False],\n",
    "        value=True,\n",
    "        description=\"Scale Fluorescence?\",\n",
    "        disabled=False,\n",
    "    ),\n",
    "    scaling_percentile=IntSlider(\n",
    "        value=90,\n",
    "        description=\"Scaling Percentile:\",\n",
    "        min=0,\n",
    "        max=100,\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(proc_list_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_list = copy.copy(proc_list_int.result)\n",
    "eigval_list = interactive_segmentation.plot_eigval(proc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Cell Mask Envelope\n",
    "\n",
    "Fill in.\n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**cell_mask_method (str)** : Thresholding method, can be a local or global Otsu threshold.\n",
    "\n",
    "**cell_otsu_scaling (float)** : Scaling factor applied to determined threshold.\n",
    "\n",
    "**local_otsu_r (int)** : Radius of thresholding kernel used in the local otsu thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_mask_list_int = interactive(\n",
    "    interactive_segmentation.plot_cell_mask,\n",
    "    {\"manual\": True},\n",
    "    proc_list=fixed(proc_list),\n",
    "    cell_mask_method=Dropdown(\n",
    "        options=[\"local\", \"global\"],\n",
    "        value=\"local\",\n",
    "        description=\"Cell Mask Thresholding Method:\",\n",
    "        disabled=False,\n",
    "    ),\n",
    "    global_threshold=IntSlider(\n",
    "        value=50,\n",
    "        description=\"Global Threshold:\",\n",
    "        min=0,\n",
    "        max=255,\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "    ),\n",
    "    cell_otsu_scaling=FloatSlider(\n",
    "        value=0.95,\n",
    "        description=\"Cell Threshold Scaling:\",\n",
    "        min=0.0,\n",
    "        max=2.0,\n",
    "        step=0.01,\n",
    "        disabled=False,\n",
    "    ),\n",
    "    local_otsu_r=IntSlider(\n",
    "        value=15,\n",
    "        description=\"Local Otsu Radius:\",\n",
    "        min=0,\n",
    "        max=30,\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "    ),\n",
    ")\n",
    "display(cell_mask_list_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_mask_list = copy.copy(cell_mask_list_int.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Edge Mask at Threshold Value\n",
    "\n",
    "Fill in.\n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**edge_threshold_scaling (float)** : Scaling factor applied to determined threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_mask_list_int = interactive(\n",
    "    interactive_segmentation.plot_threshold_result,\n",
    "    {\"manual\": True},\n",
    "    eigval_list=fixed(eigval_list),\n",
    "    cell_mask_list=fixed(cell_mask_list),\n",
    "    edge_threshold_scaling=FloatSlider(\n",
    "        value=1.0,\n",
    "        description=\"Edge Threshold Scaling\",\n",
    "        min=0.0,\n",
    "        max=2.0,\n",
    "        step=0.01,\n",
    "        disabled=False,\n",
    "    ),\n",
    "    min_obj_size=IntSlider(\n",
    "        value=30,\n",
    "        description=\"Minimum Object Size:\",\n",
    "        min=0,\n",
    "        max=100,\n",
    "        step=2,\n",
    "        disabled=False,\n",
    "    ),\n",
    ")\n",
    "display(composite_mask_list_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Sampling and Convexity Calculation\n",
    "\n",
    "Fill in.\n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**edge_threshold_scaling (float)** : Scaling factor applied to determined threshold.\n",
    "\n",
    "**threshold_step_perc (float)** : Threshold step size to be used for trying multiple thresholds.\n",
    "\n",
    "**threshold_perc_num_steps (int)** : Number of steps to use when generating multiple thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_scores_list_int = interactive(\n",
    "    interactive_segmentation.plot_scores,\n",
    "    {\"manual\": True},\n",
    "    eigval_list=fixed(eigval_list),\n",
    "    cell_mask_list=fixed(cell_mask_list),\n",
    "    edge_threshold_scaling=FloatSlider(\n",
    "        value=0.9,\n",
    "        description=\"Edge Threshold Scaling\",\n",
    "        min=0.0,\n",
    "        max=2.0,\n",
    "        step=0.01,\n",
    "        disabled=False,\n",
    "    ),\n",
    "    threshold_step_perc=FloatSlider(\n",
    "        value=0.05,\n",
    "        description=\"Threshold Step Percent\",\n",
    "        min=0.0,\n",
    "        max=0.5,\n",
    "        step=0.01,\n",
    "        disabled=False,\n",
    "    ),\n",
    "    threshold_perc_num_steps=IntSlider(\n",
    "        value=2,\n",
    "        description=\"Number of Threshold Steps\",\n",
    "        min=0,\n",
    "        max=5,\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "    ),\n",
    "    min_obj_size=IntSlider(\n",
    "        value=30,\n",
    "        description=\"Minimum Object Size:\",\n",
    "        min=0,\n",
    "        max=100,\n",
    "        step=2,\n",
    "        disabled=False,\n",
    "    ),\n",
    ")\n",
    "display(conv_scores_list_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_scores_list = copy.copy(conv_scores_list_int.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convexity Thresholding\n",
    "\n",
    "Fill in.\n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**convex_threshold (float)** : Threshold to be used for convexity thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mask_list_int = interactive(\n",
    "    interactive_segmentation.plot_final_mask,\n",
    "    {\"manual\": True},\n",
    "    conv_scores_list=fixed(conv_scores_list),\n",
    "    convex_threshold=FloatSlider(\n",
    "        value=0.75,\n",
    "        description=\"Convexity Threshold:\",\n",
    "        min=0.0,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        disabled=False,\n",
    "    ),\n",
    ")\n",
    "display(final_mask_list_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.process_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.write_param_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Dask Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"01:00:00\",\n",
    "    local=False,\n",
    "    n_workers=200,\n",
    "    memory=\"1GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = tr.segment.fluo_segmentation_cluster(headpath, paramfile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment.dask_segment(dask_controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Dask Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineage Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_function = tr.tracking.scorefn(\n",
    "    headpath,\n",
    "    \"fluorsegmentation\",\n",
    "    u_size=0.22,\n",
    "    sig_size=0.08,\n",
    "    u_pos=0.21,\n",
    "    sig_pos=0.1,\n",
    "    w_merge=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_function.interactive_scorefn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tracking_Solver = tr.tracking.tracking_solver(\n",
    "    headpath,\n",
    "    \"fluorsegmentation\",\n",
    "    ScoreFn=score_function,\n",
    "    merge_per_iter=0,\n",
    "    conv_tolerence=2,\n",
    "    edge_limit=2,\n",
    ")\n",
    "data, orientation, empty_trenches = score_function.output.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tracking_Solver.interactive_tracking(data, orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tracking_Solver.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Lineage Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"01:00:00\",\n",
    "    local=False,\n",
    "    n_workers=100,\n",
    "    memory=\"2GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tracking_Solver = tr.tracking.tracking_solver(\n",
    "    headpath, \"fluorsegmentation\", paramfile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tracking_Solver.compute_all_lineages(dask_controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Properties (No Lineage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = tr.analysis.regionprops_extractor(\n",
    "    headpath, \"fluorsegmentation\", intensity_channel_list=[\"mCherry\", \"YFP\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.export_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Kymographs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "kyview = tr.analysis.kymograph_viewer(headpath, \"mCherry\", \"fluorsegmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyviewer = interactive(\n",
    "    kyview.inspect_trench,\n",
    "    {\"manual\": True},\n",
    "    file_idx=IntText(value=0, description=\"File Index:\", disabled=False),\n",
    "    trench_idx=IntText(value=0, description=\"Trench Index:\", disabled=False),\n",
    "    x_size=IntSlider(\n",
    "        value=20, description=\"X Size:\", min=0, max=50, step=1, disabled=False\n",
    "    ),\n",
    "    y_size=IntSlider(\n",
    "        value=6, description=\"Y Size:\", min=0, max=30, step=1, disabled=False\n",
    "    ),\n",
    ")\n",
    "display(kyviewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    interactive_kymograph.view_image,\n",
    "    fov_idx=IntText(value=0, description=\"FOV number:\", disabled=False),\n",
    "    t=IntSlider(\n",
    "        value=0, min=0, max=timepoints_len - 1, step=1, continuous_update=False\n",
    "    ),\n",
    "    channel=Dropdown(\n",
    "        options=channels, value=channels[0], description=\"Channel:\", disabled=False\n",
    "    ),\n",
    "    invert=Dropdown(options=[True, False], value=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Phase Segmentation Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = tr.unet.UNet_Training_DataLoader(\n",
    "    nndatapath=\"/n/scratch2/de64/nntest7\",\n",
    "    experimentname=\"First NN\",\n",
    "    trainpath=\"/n/scratch2/de64/2019-06-18_DE85_training_data\",\n",
    "    testpath=\"/n/scratch2/de64/2019-05-31_validation_data\",\n",
    "    valpath=\"/n/scratch2/de64/2019-05-31_validation_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = tr.unet.UNet_Training_DataLoader(\n",
    "    nndatapath=\"/n/scratch2/de64/nntest8\",\n",
    "    experimentname=\"First NN\",\n",
    "    trainpath=\"/n/scratch2/de64/2019-05-31_validation_data\",\n",
    "    testpath=\"/n/scratch2/de64/2019-06-18_DE85_training_data\",\n",
    "    valpath=\"/n/scratch2/de64/2019-06-18_DE85_training_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = tr.unet.UNet_Training_DataLoader(\n",
    "    nndatapath=\"/n/scratch2/de64/nntest9\",\n",
    "    experimentname=\"First NN\",\n",
    "    trainpath=\"/n/scratch2/de64/2019-05-31_validation_data\",\n",
    "    testpath=\"/n/scratch2/de64/2019-06-18_DE85_training_data\",\n",
    "    valpath=\"/n/scratch2/de64/2019-06-18_DE85_training_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = tr.unet.UNet_Training_DataLoader(\n",
    "    nndatapath=\"/n/scratch2/de64/nntest10\",\n",
    "    experimentname=\"First NN\",\n",
    "    trainpath=\"/n/scratch2/de64/2019-06-18_DE85_training_data\",\n",
    "    testpath=\"/n/scratch2/de64/2019-05-31_validation_data\",\n",
    "    valpath=\"/n/scratch2/de64/2019-05-31_validation_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.inter_get_selection(dataloader.trainpath, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.inter_get_selection(dataloader.testpath, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.inter_get_selection(dataloader.valpath, \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weightmap Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.display_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.get_grid_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.export_all_data(memory=\"6GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Hyperparameter (Grid) Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-up Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = tr.unet.GridSearch(\"/n/scratch2/de64/nntest10\", numepochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.display_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.get_grid_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.run_grid_search(gres=\"gpu:teslaK80:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [12, 8]\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = tr.unet.TrainingVisualizer(\n",
    "    \"/n/scratch2/de64/nntest10\", \"/n/groups/paulsson/Daniel/NNModels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.inter_plot_loss(\"Val Loss\")\n",
    "vis.grid_widget.on(\"filter_changed\", vis.handle_filter_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.grid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.inter_df_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.model_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(vis.model_df[\"Val F1 Cell Scores\"][0], bins=50)\n",
    "plt.xlabel(\"F-Score\")\n",
    "plt.ylabel(\"Occurances\")\n",
    "plt.xticks(np.arange(0, 1.01, step=0.5))\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = \"/n/scratch2/de64/2019-07-08_bacillus_rodz_mut_expt_bmbm_ti4\"\n",
    "unetseg = tr.unet.UNet_Segmenter(\n",
    "    headpath, \"Phase\", \"/n/groups/paulsson/Daniel/NNModels\", min_obj_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_channel = interactive(\n",
    "    unetseg.choose_seg_channel,\n",
    "    {\"manual\": True},\n",
    "    seg_channel=Dropdown(options=unetseg.all_channels, value=unetseg.all_channels[0]),\n",
    ")\n",
    "display(choose_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unetseg.inter_df_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import trenchripper as tr\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/n/scratch2/de64/nntest7/test.hdf5\", \"r\") as infile:\n",
    "    img_arr = torch.Tensor(infile[\"img\"][535:550])\n",
    "    seg_arr = torch.Tensor(infile[\"seg\"][100:200:10])\n",
    "    weight_arr = infile[\"weight_(10.0, 4.0)\"][0:300:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testunet = tr.unet.UNet(1, 2, layers=3, hidden_size=32, dropout=0.0, withsoftmax=True)\n",
    "device = torch.device(\"cpu\")\n",
    "testunet.load_state_dict(\n",
    "    torch.load(\"/n/scratch2/de64/nntest7/models/0.pt\", map_location=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = testunet.forward(img_arr).detach().numpy()[:, 1]\n",
    "x = img_arr.detach().numpy().squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_kymo = tr.utils.kymo_handle()\n",
    "img_kymo.import_wrap(x)\n",
    "img = img_kymo.return_unwrap(padding=0)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_kymo = tr.utils.kymo_handle()\n",
    "seg_kymo.import_wrap(y)\n",
    "seg = seg_kymo.return_unwrap(padding=0)\n",
    "plt.imshow(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = seg > 0.6\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mask = sk.morphology.remove_small_objects(mask, min_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(filtered_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.retry_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.daskclient.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.retry_processing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
