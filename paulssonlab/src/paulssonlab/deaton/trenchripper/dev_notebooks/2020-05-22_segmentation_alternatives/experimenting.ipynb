{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import paulssonlab.deaton.trenchripper.trenchripper as tr\n",
    "\n",
    "warnings.filterwarnings(action=\"once\")\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = \"/n/scratch2/de64/2020-03-02_plasmid_loss/\"\n",
    "nd2file = \"/n/scratch2/de64/2020-03-02_plasmid_loss/Basilisk_SJC25x2_SJC28_Losses.nd2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Fluorescence Segmentation\n",
    "\n",
    "Now that you have copped your data into kymographs, we will now perform segmentation/cell detection <br>\n",
    "on your kymographs. Currently, this pipeline only supports segmentation of fluorescence images; however, <br>\n",
    "segmentation of transmitted light imaging techniques is in development.\n",
    "\n",
    "The output of this step will be a set of `segmentation_[File #].hdf5` files stored in `headpath/fluorsegmentation`.<br>\n",
    "The image data stored in these files takes the exact same form as the kymograph data, `(K,T,Y,X)` arrays <br>\n",
    "where K is the trench index, T is time, and Y,X are the crop dimensions. These arrays are accessible using <br>\n",
    "keys of the form `\"[Trench Row Number]\"`.\n",
    "\n",
    "Since no metadata is generated by this step, it is possible to use another segmentation algorithm on the kymograph <br>\n",
    "data. The output of segmentation must be split into `segmentation_[File #].hdf5` files, where `[File #]` agrees with the<br>\n",
    "corresponding `kymograph_[File #].hdf5` file. Additionally, the `(K,T,Y,X)` arrays must be of the same shape as the <br>\n",
    "kymograph arrays and accessible at the corresponding `\"[Trench Row Number]\"` key. These files must be placed into <br>\n",
    "their own folder at `headpath/foldername`. This folder may then be used in later steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Test Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "##### Initialize the interactive segmentation class\n",
    "\n",
    "As a first step, initialize the `tr.fluo_segmentation_interactive` class that will be handling all steps of generating a segmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation = tr.fluo_segmentation_interactive(headpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "##### Choose channel to segment on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.choose_seg_channel_inter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Import data\n",
    "\n",
    "Fill in \n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**fov_idx (int)** :\n",
    "\n",
    "**n_trenches (int)** :\n",
    "\n",
    "**t_range (tuple)** :\n",
    "\n",
    "**t_subsample_step (int)** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.import_array_inter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Scale data\n",
    "\n",
    "Fill in \n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**scale (bool)** : Whether to scale the kymograph in time.\n",
    "\n",
    "**scaling_percentile (int)** : Whole image intensity percentile to use to determine scaling constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Apply Gaussian Filter\n",
    "\n",
    "Fill in \n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**smooth_sigma (float)** : Standard deviation of gaussian kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.plot_processed_inter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Determine Cell Mask Envelope\n",
    "\n",
    "Fill in.\n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**cell_mask_method (str)** : Thresholding method, can be a local or global Otsu threshold.\n",
    "\n",
    "**cell_otsu_scaling (float)** : Scaling factor applied to determined threshold.\n",
    "\n",
    "**local_otsu_r (int)** : Radius of thresholding kernel used in the local otsu thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.plot_cell_mask_inter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Display Edge Mask at Threshold Value\n",
    "\n",
    "Fill in.\n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**edge_threshold_scaling (float)** : Scaling factor applied to determined threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.plot_threshold_result_inter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Threshold Sampling and Convexity Calculation\n",
    "\n",
    "Fill in.\n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**edge_threshold_scaling (float)** : Scaling factor applied to determined threshold.\n",
    "\n",
    "**threshold_step_perc (float)** : Threshold step size to be used for trying multiple thresholds.\n",
    "\n",
    "**threshold_perc_num_steps (int)** : Number of steps to use when generating multiple thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.plot_scores_inter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Convexity Thresholding\n",
    "\n",
    "Fill in.\n",
    "\n",
    "You will need to tune the following `args` and `kwargs` (in order):\n",
    "\n",
    "**convex_threshold (float)** : Threshold to be used for convexity thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.plot_final_mask_inter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.process_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_segmentation.write_param_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Generate Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Start Dask Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"02:00:00\",\n",
    "    local=False,\n",
    "    n_workers=200,\n",
    "    memory=\"2GB\",\n",
    "    cores=1,\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = tr.fluo_segmentation_cluster(headpath, paramfile=True)\n",
    "segment.edge_threshold_scaling = 1.1\n",
    "segment.threshold_perc_num_steps = 1\n",
    "segment.threshold_step_perc = 0.1\n",
    "segment.convex_threshold = 0.65\n",
    "segment.img_scaling = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment.img_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(headpath + \"/kymograph/kymograph_34.hdf5\") as infile:\n",
    "    data = infile[\"mCherry\"][20, :50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, eig = segment.segment(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "view.return_unwrap().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = tr.kymo_handle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "view.import_wrap(data)\n",
    "print(view.return_unwrap().shape)\n",
    "\n",
    "plt.imshow(view.return_unwrap()[:, :800])\n",
    "plt.show()\n",
    "\n",
    "view.import_wrap(output)\n",
    "plt.imshow(view.return_unwrap()[:, :800])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(eig[:, :800])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "view.import_wrap(data)\n",
    "temp = view.return_unwrap()[:, :800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage as sk\n",
    "\n",
    "edge_padding = 6\n",
    "img_arr = sk.util.invert(eig[:, :800])\n",
    "# img_arr = data[0]\n",
    "img_arr = np.pad(img_arr, edge_padding, \"reflect\")\n",
    "hessian = sk.feature.hessian_matrix(img_arr, order=\"rc\")\n",
    "eigvals = sk.feature.hessian_matrix_eigvals(hessian)\n",
    "min_eigvals = np.min(eigvals, axis=0)\n",
    "min_eigvals = min_eigvals[edge_padding:-edge_padding, edge_padding:-edge_padding]\n",
    "max_val, min_val = np.max(min_eigvals), np.min(min_eigvals)\n",
    "min_eigvals = (min_eigvals - min_val) / (max_val - min_val)\n",
    "min_eigvals = segment.to_8bit(min_eigvals)\n",
    "otsu_selem = sk.morphology.disk(20)\n",
    "thr = sk.filters.rank.otsu(min_eigvals, otsu_selem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(min_eigvals)\n",
    "plt.show()\n",
    "plt.imshow(min_eigvals > thr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = tr.kymo_handle()\n",
    "view.import_wrap(data[:20])\n",
    "meme_img = view.return_unwrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = tr.kymo_handle()\n",
    "view.import_wrap(data[:20])\n",
    "img = view.return_unwrap()\n",
    "img = sk.transform.rescale(img, 2.0, anti_aliasing=False, preserve_range=True)\n",
    "img = segment.to_8bit(img, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()\n",
    "otsu_selem = sk.morphology.disk(19)\n",
    "thr = sk.filters.rank.otsu(img, otsu_selem)\n",
    "mask = (img > thr) * (img > 25)\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "# Now we want to separate the two objects in image\n",
    "# Generate the markers as local maxima of the distance to the background\n",
    "# inmask = sk.morphology.binary_erosion(mask[:,:500])\n",
    "distance = ndi.distance_transform_edt(mask[:, :500])\n",
    "local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)))\n",
    "markers = ndi.label(local_maxi)[0]\n",
    "labels = watershed(-distance, markers, mask=mask[:, :500])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(20, 20), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(mask[:, :500], cmap=plt.cm.gray)\n",
    "ax[0].set_title(\"Overlapping objects\")\n",
    "ax[1].imshow(-distance, cmap=plt.cm.gray)\n",
    "ax[1].set_title(\"Distances\")\n",
    "ax[2].imshow(labels, cmap=plt.cm.nipy_spectral)\n",
    "ax[2].set_title(\"Separated objects\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = ndi.distance_transform_edt(mask)\n",
    "distance_mask = distance > 2\n",
    "plt.imshow(distance)\n",
    "plt.show()\n",
    "plt.imshow(distance_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage as sk\n",
    "\n",
    "edge_padding = 6\n",
    "img_arr = sk.util.invert(img)\n",
    "# img_arr = data[0]\n",
    "img_arr = np.pad(img_arr, edge_padding, \"reflect\")\n",
    "hessian = sk.feature.hessian_matrix(img_arr, order=\"rc\")\n",
    "eigvals = sk.feature.hessian_matrix_eigvals(hessian)\n",
    "min_eigvals = np.min(eigvals, axis=0)\n",
    "min_eigvals = min_eigvals[edge_padding:-edge_padding, edge_padding:-edge_padding]\n",
    "max_val, min_val = np.max(min_eigvals), np.min(min_eigvals)\n",
    "min_eigvals = (min_eigvals - min_val) / (max_val - min_val)\n",
    "min_eigvals = segment.to_8bit(min_eigvals)\n",
    "otsu_eig = sk.filters.threshold_niblack(min_eigvals) * 1.0\n",
    "eig_mask = min_eigvals > otsu_eig\n",
    "obj_mask = sk.measure.label(eig_mask * distance_mask)\n",
    "\n",
    "labels = watershed(\n",
    "    -distance,\n",
    "    obj_mask,\n",
    "    mask=mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(min_eigvals)\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(eig_mask,interpolation='nearest')\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(obj_mask,interpolation='nearest')\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(obj_mask>0,interpolation='nearest')\n",
    "# plt.show()\n",
    "\n",
    "plt_mask = labels == 0\n",
    "# plt.imshow(plt_mask,interpolation='nearest')\n",
    "# plt.show()\n",
    "\n",
    "plt.imshow(meme_img[0:75])\n",
    "plt.show()\n",
    "\n",
    "plt_img = np.ma.array(labels, mask=plt_mask)\n",
    "plt.imshow(plt_img[0:150], cmap=\"jet\", interpolation=\"nearest\")\n",
    "plt.show()\n",
    "\n",
    "scaled_labels = sk.transform.rescale(\n",
    "    labels, 1.0 / 2.0, order=0, anti_aliasing=False, preserve_range=True\n",
    ").astype(\"uint16\")\n",
    "plt_mask = scaled_labels == 0\n",
    "plt_img = np.ma.array(scaled_labels, mask=plt_mask)\n",
    "plt.imshow(plt_img[0:75], cmap=\"jet\", interpolation=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(img, 0.8)\n",
    "plt.imshow(contours[0] / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours[0] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(img, 0.8)\n",
    "ax.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(img, 0.8)\n",
    "\n",
    "# Display the image and plot all contours found\n",
    "fig, ax = plt.subplots()\n",
    "# ax.imshow(img, cmap=plt.cm.gray)\n",
    "\n",
    "for n, contour in enumerate(contours):\n",
    "    ax.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "\n",
    "ax.axis(\"image\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image and plot all contours found\n",
    "fig, ax = plt.subplots()\n",
    "# ax.imshow(img, cmap=plt.cm.gray)\n",
    "scaled_contours = [item / 2 for item in contours]\n",
    "\n",
    "for n, contour in enumerate(scaled_contours):\n",
    "    ax.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "\n",
    "ax.axis(\"image\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(contour[:, 0]).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(contour[:, 1]).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty image to store the masked array\n",
    "idx = 12\n",
    "img = labels == idx\n",
    "\n",
    "contours = measure.find_contours(img, 0.8)\n",
    "scaled_contours = [item / 2 for item in contours]\n",
    "\n",
    "contour = scaled_contours[0]\n",
    "r_mask = np.zeros(scaled_labels.shape, dtype=\"bool\")\n",
    "\n",
    "# Create a contour image by using the contour coordinates rounded to their nearest integer value\n",
    "r_mask[np.round(contour[:, 0]).astype(\"int\"), np.round(contour[:, 1]).astype(\"int\")] = 1\n",
    "\n",
    "# # Fill in the hole created by the contour boundary\n",
    "r_mask = sk.morphology.remove_small_holes(r_mask)\n",
    "\n",
    "# # Invert the mask since you want pixels outside of the region\n",
    "# r_mask = ~r_mask\n",
    "\n",
    "scaled_labels = sk.transform.rescale(\n",
    "    labels, 1.0 / 2.0, order=0, anti_aliasing=False, preserve_range=True\n",
    ").astype(\"uint16\")\n",
    "testmask = scaled_labels == idx\n",
    "plt.imshow(testmask[:150, :150])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(r_mask[:150, :150])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img[:300, :300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian\n",
    "from skimage.segmentation import active_contour\n",
    "\n",
    "rps = sk.measure.regionprops(labels)\n",
    "bboxes = [rp.bbox for rp in rps]\n",
    "bboxes[0]\n",
    "\n",
    "s = np.linspace(0, 2 * np.pi, 400)\n",
    "r = int((bboxes[0][0] + bboxes[0][2]) / 2) + 100 * np.sin(s)\n",
    "c = int((bboxes[0][1] + bboxes[0][3]) / 2) + 100 * np.cos(s)\n",
    "init = np.array([r, c]).T\n",
    "\n",
    "snake = active_contour(\n",
    "    img, contours[0], alpha=0.0001, beta=10, gamma=0.0001, coordinates=\"rc\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(img[:150, :150], cmap=plt.cm.gray)\n",
    "ax.plot(snake[:, 1], snake[:, 0], \"-b\", lw=3)\n",
    "ax.set_xticks([]), ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaled_labels, cmap=\"jet\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment.dask_segment(dask_controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "dask_controller.daskclient.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "#### Stop Dask Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_padding = 6\n",
    "img_arr = sk.util.invert(img)\n",
    "# img_arr = data[0]\n",
    "img_arr = np.pad(img_arr, edge_padding, \"reflect\")\n",
    "hessian = sk.feature.hessian_matrix(img_arr, order=\"rc\")\n",
    "eigvals = sk.feature.hessian_matrix_eigvals(hessian)\n",
    "min_eigvals = np.min(eigvals, axis=0)\n",
    "min_eigvals = min_eigvals[edge_padding:-edge_padding, edge_padding:-edge_padding]\n",
    "max_val, min_val = np.max(min_eigvals), np.min(min_eigvals)\n",
    "min_eigvals = (min_eigvals - min_val) / (max_val - min_val)\n",
    "\n",
    "min_eigvals = segment.to_8bit(min_eigvals)\n",
    "otsu_eig = sk.filters.threshold_niblack(min_eigvals) * 1.0\n",
    "eig_mask = min_eigvals > otsu_eig\n",
    "obj_mask = sk.measure.label(eig_mask * distance_mask)\n",
    "\n",
    "labels = watershed(\n",
    "    -distance,\n",
    "    obj_mask,\n",
    "    mask=mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = ndi.distance_transform_edt(mask)\n",
    "distance_mask = distance > 2\n",
    "plt.imshow(distance)\n",
    "plt.show()\n",
    "plt.imshow(distance_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.deaton.trenchripper.trenchripper import kymo_handle\n",
    "\n",
    "output_kymo = kymo_handle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_kymo.import_unwrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as sk\n",
    "import skimage.transform as transform\n",
    "\n",
    "from paulssonlab.deaton.trenchripper.trenchripper import (\n",
    "    kymo_handle,\n",
    "    pandas_hdf5_handler,\n",
    "    writedir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fluo_segmentation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        bit_max=0,\n",
    "        scale_timepoints=False,\n",
    "        scaling_percentage=0.9,\n",
    "        img_scaling=1.0,\n",
    "        smooth_sigma=0.75,\n",
    "        niblack_scaling=1.0,\n",
    "        hess_pad=6,\n",
    "        global_threshold=25,\n",
    "        cell_otsu_scaling=1.0,\n",
    "        local_otsu_r=15,\n",
    "        min_obj_size=30,\n",
    "        distance_threshold=2,\n",
    "    ):\n",
    "        self.bit_max = bit_max\n",
    "\n",
    "        self.scale_timepoints = scale_timepoints\n",
    "        self.scaling_percentage = scaling_percentage\n",
    "\n",
    "        self.img_scaling = img_scaling\n",
    "\n",
    "        self.smooth_sigma = smooth_sigma\n",
    "\n",
    "        self.niblack_scaling = niblack_scaling\n",
    "        self.hess_pad = hess_pad\n",
    "\n",
    "        self.global_threshold = global_threshold\n",
    "        self.cell_otsu_scaling = cell_otsu_scaling\n",
    "        self.local_otsu_r = local_otsu_r\n",
    "        self.min_obj_size = min_obj_size\n",
    "\n",
    "        self.distance_threshold = distance_threshold\n",
    "\n",
    "    def to_8bit(self, img_arr, bit_max=None):\n",
    "        img_max = np.max(img_arr) + 0.0001\n",
    "        if bit_max is None:\n",
    "            max_val = img_max\n",
    "        else:\n",
    "            max_val = max(img_max, bit_max)\n",
    "        min_val = np.min(img_arr)\n",
    "        #         min_val = np.min(img_arr)\n",
    "        norm_array = (img_arr - min_val) / (max_val - min_val)\n",
    "        norm_byte_array = sk.img_as_ubyte(norm_array)\n",
    "        return norm_byte_array\n",
    "\n",
    "    def scale_kymo(self, wrap_arr, percentile):\n",
    "        perc_t = np.percentile(\n",
    "            wrap_arr[:].reshape(wrap_arr.shape[0], -1), percentile, axis=1\n",
    "        )\n",
    "        norm_perc_t = perc_t / np.max(perc_t)\n",
    "        scaled_arr = wrap_arr.astype(float) / norm_perc_t[:, np.newaxis, np.newaxis]\n",
    "        scaled_arr[scaled_arr > 255.0] = 255.0\n",
    "        scaled_arr = scaled_arr.astype(\"uint8\")\n",
    "        return scaled_arr\n",
    "\n",
    "    def get_eig_img(self, img_arr, edge_padding=6):\n",
    "        inverted = sk.util.invert(img_arr)\n",
    "        del img_arr\n",
    "        inverted = np.pad(inverted, edge_padding, \"reflect\")\n",
    "        hessian = sk.feature.hessian_matrix(inverted, order=\"rc\")\n",
    "        del inverted\n",
    "        eig_img = sk.feature.hessian_matrix_eigvals(hessian)\n",
    "        del hessian\n",
    "        eig_img = np.min(eig_img, axis=0)\n",
    "        eig_img = eig_img[edge_padding:-edge_padding, edge_padding:-edge_padding]\n",
    "        max_val, min_val = np.max(eig_img), np.min(eig_img)\n",
    "        eig_img = self.to_8bit(eig_img)\n",
    "        return eig_img\n",
    "\n",
    "    def get_eig_mask(self, eig_img, niblack_scaling=1.0):\n",
    "        eig_thr = sk.filters.threshold_niblack(eig_img) * niblack_scaling\n",
    "        eig_mask = eig_img > eig_thr\n",
    "        return eig_mask\n",
    "\n",
    "    def get_cell_mask(\n",
    "        self,\n",
    "        img_arr,\n",
    "        global_threshold=50,\n",
    "        cell_otsu_scaling=1.0,\n",
    "        local_otsu_r=15,\n",
    "        min_obj_size=30,\n",
    "    ):\n",
    "        otsu_selem = sk.morphology.disk(local_otsu_r)\n",
    "        thr = sk.filters.rank.otsu(img_arr, otsu_selem)\n",
    "        del otsu_selem\n",
    "        cell_mask = (img_arr > thr) * (img_arr > global_threshold)\n",
    "        del img_arr\n",
    "        cell_mask = sk.morphology.remove_small_objects(cell_mask, min_size=min_obj_size)\n",
    "        cell_mask = sk.morphology.remove_small_holes(cell_mask)\n",
    "\n",
    "        return cell_mask\n",
    "\n",
    "    def segment(self, img_arr):  # img_arr is t,y,x\n",
    "        t_tot = img_arr.shape[0]\n",
    "        img_arr = self.to_8bit(img_arr, self.bit_max)\n",
    "        if self.scale_timepoints:\n",
    "            img_arr = self.scale_kymo(img_arr, self.scaling_percentage)\n",
    "\n",
    "        input_kymo = kymo_handle()\n",
    "        input_kymo.import_wrap(img_arr)\n",
    "        del img_arr\n",
    "\n",
    "        input_kymo = input_kymo.return_unwrap()\n",
    "        original_shape = input_kymo.shape\n",
    "        input_kymo = transform.rescale(\n",
    "            input_kymo, self.img_scaling, anti_aliasing=False, preserve_range=True\n",
    "        ).astype(\"uint8\")\n",
    "        input_kymo = sk.filters.gaussian(\n",
    "            input_kymo, sigma=self.smooth_sigma, preserve_range=True, mode=\"reflect\"\n",
    "        ).astype(\"uint8\")\n",
    "\n",
    "        eig_img = self.get_eig_img(input_kymo, edge_padding=self.hess_pad)\n",
    "        eig_mask = self.get_eig_mask(eig_img, niblack_scaling=self.niblack_scaling)\n",
    "        del eig_img\n",
    "\n",
    "        cell_mask = self.get_cell_mask(\n",
    "            input_kymo,\n",
    "            global_threshold=self.global_threshold,\n",
    "            cell_otsu_scaling=self.cell_otsu_scaling,\n",
    "            local_otsu_r=self.local_otsu_r,\n",
    "            min_obj_size=self.min_obj_size,\n",
    "        )\n",
    "        del input_kymo\n",
    "\n",
    "        dist_img = ndi.distance_transform_edt(cell_mask).astype(\"uint8\")\n",
    "        dist_mask = dist_img > self.distance_threshold\n",
    "        marker_mask = dist_mask * eig_mask\n",
    "        del dist_mask\n",
    "        marker_mask = sk.measure.label(marker_mask)\n",
    "\n",
    "        output_labels = watershed(-dist_img, markers=marker_mask, mask=cell_mask)\n",
    "\n",
    "        del dist_img\n",
    "        del marker_mask\n",
    "        del cell_mask\n",
    "        output_labels = sk.transform.resize(\n",
    "            output_labels,\n",
    "            original_shape,\n",
    "            order=0,\n",
    "            anti_aliasing=False,\n",
    "            preserve_range=True,\n",
    "        ).astype(\"uint32\")\n",
    "\n",
    "        output_kymo = kymo_handle()\n",
    "        output_kymo.import_unwrap(output_labels, t_tot)\n",
    "        del output_labels\n",
    "        output_kymo = output_kymo.return_wrap()\n",
    "        return output_kymo\n",
    "\n",
    "\n",
    "class fluo_segmentation_cluster(fluo_segmentation):\n",
    "    def __init__(\n",
    "        self,\n",
    "        headpath,\n",
    "        paramfile=True,\n",
    "        seg_channel=\"\",\n",
    "        bit_max=0,\n",
    "        scale_timepoints=False,\n",
    "        scaling_percentage=0.9,\n",
    "        img_scaling=1.0,\n",
    "        smooth_sigma=0.75,\n",
    "        niblack_scaling=1.0,\n",
    "        hess_pad=6,\n",
    "        global_threshold=25,\n",
    "        cell_otsu_scaling=1.0,\n",
    "        local_otsu_r=15,\n",
    "        min_obj_size=30,\n",
    "        distance_threshold=2,\n",
    "    ):\n",
    "        #         if paramfile:\n",
    "        #             parampath = headpath + \"/fluorescent_segmentation.par\"\n",
    "        #             with open(parampath, 'rb') as infile:\n",
    "        #                 param_dict = pickle.load(infile)\n",
    "\n",
    "        #             img_scaling = param_dict[\"Image Scaling Factor:\"]\n",
    "        #             scale_timepoints = param_dict[\"Scale Fluorescence?\"]\n",
    "        #             scaling_percentage = param_dict[\"Scaling Percentile:\"]\n",
    "        #             seg_channel = param_dict[\"Segmentation Channel:\"]\n",
    "        #             smooth_sigma = param_dict[\"Gaussian Kernel Sigma:\"]\n",
    "        #             bit_max = param_dict['8 Bit Maximum:']\n",
    "        #             min_obj_size = param_dict[\"Minimum Object Size:\"]\n",
    "        #             cell_mask_method = param_dict[\"Cell Mask Thresholding Method:\"]\n",
    "        #             global_threshold = param_dict[\"Global Threshold:\"]\n",
    "        #             cell_otsu_scaling = param_dict[\"Cell Threshold Scaling:\"]\n",
    "        #             local_otsu_r = param_dict[\"Local Otsu Radius:\"]\n",
    "        #             edge_threshold_scaling = param_dict[\"Edge Threshold Scaling:\"]\n",
    "        #             threshold_step_perc = param_dict[\"Threshold Step Percent:\"]\n",
    "        #             threshold_perc_num_steps = param_dict[\"Number of Threshold Steps:\"]\n",
    "        #             convex_threshold = param_dict[\"Convexity Threshold:\"]\n",
    "\n",
    "        super(fluo_segmentation_cluster, self).__init__(\n",
    "            bit_max=bit_max,\n",
    "            scale_timepoints=scale_timepoints,\n",
    "            scaling_percentage=scaling_percentage,\n",
    "            img_scaling=img_scaling,\n",
    "            smooth_sigma=smooth_sigma,\n",
    "            niblack_scaling=niblack_scaling,\n",
    "            hess_pad=hess_pad,\n",
    "            global_threshold=global_threshold,\n",
    "            cell_otsu_scaling=cell_otsu_scaling,\n",
    "            local_otsu_r=local_otsu_r,\n",
    "            min_obj_size=min_obj_size,\n",
    "            distance_threshold=distance_threshold,\n",
    "        )\n",
    "\n",
    "        self.headpath = headpath\n",
    "        self.seg_channel = seg_channel\n",
    "        self.kymographpath = headpath + \"/kymograph\"\n",
    "        self.fluorsegmentationpath = headpath + \"/fluorsegmentation\"\n",
    "        self.metapath = headpath + \"/metadata.hdf5\"\n",
    "        self.meta_handle = pandas_hdf5_handler(self.metapath)\n",
    "\n",
    "    def generate_segmentation(self, file_idx):\n",
    "        with h5py.File(\n",
    "            self.kymographpath + \"/kymograph_\" + str(file_idx) + \".hdf5\", \"r\"\n",
    "        ) as input_file:\n",
    "            input_data = input_file[self.seg_channel]\n",
    "            trench_output = []\n",
    "            for trench_idx in range(input_data.shape[0]):\n",
    "                trench_array = input_data[trench_idx]\n",
    "                trench_array = self.segment(trench_array)\n",
    "                trench_output.append(trench_array[np.newaxis])\n",
    "                del trench_array\n",
    "        trench_output = np.concatenate(trench_output, axis=0)\n",
    "        with h5py.File(\n",
    "            self.fluorsegmentationpath + \"/segmentation_\" + str(file_idx) + \".hdf5\", \"w\"\n",
    "        ) as h5pyfile:\n",
    "            hdf5_dataset = h5pyfile.create_dataset(\n",
    "                \"data\", data=trench_output, dtype=\"uint16\"\n",
    "            )\n",
    "        return file_idx\n",
    "\n",
    "    def segmentation_completed(self, seg_future):\n",
    "        return 0\n",
    "\n",
    "    def dask_segment(self, dask_controller):\n",
    "        writedir(self.fluorsegmentationpath, overwrite=True)\n",
    "        dask_controller.futures = {}\n",
    "\n",
    "        kymodf = self.meta_handle.read_df(\"kymograph\", read_metadata=True)\n",
    "        file_list = kymodf[\"File Index\"].unique().tolist()\n",
    "        num_file_jobs = len(file_list)\n",
    "\n",
    "        random_priorities = np.random.uniform(size=(num_file_jobs,))\n",
    "        for k, file_idx in enumerate(file_list):\n",
    "            priority = random_priorities[k]\n",
    "\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.generate_segmentation, file_idx, retries=0, priority=priority\n",
    "            )\n",
    "            dask_controller.futures[\"Segmentation: \" + str(file_idx)] = future\n",
    "        for k, file_idx in enumerate(file_list):\n",
    "            priority = random_priorities[k]\n",
    "\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.segmentation_completed,\n",
    "                dask_controller.futures[\"Segmentation: \" + str(file_idx)],\n",
    "                retries=0,\n",
    "                priority=priority,\n",
    "            )\n",
    "            dask_controller.futures[\"Segmentation Completed: \" + str(file_idx)] = future\n",
    "        gathered_tasks = dask_controller.daskclient.gather(\n",
    "            [\n",
    "                dask_controller.futures[\"Segmentation Completed: \" + str(file_idx)]\n",
    "                for file_idx in file_list\n",
    "            ],\n",
    "            errors=\"skip\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "from ipywidgets import (\n",
    "    Dropdown,\n",
    "    FloatRangeSlider,\n",
    "    FloatSlider,\n",
    "    IntRangeSlider,\n",
    "    IntSlider,\n",
    "    IntText,\n",
    "    Select,\n",
    "    SelectMultiple,\n",
    "    fixed,\n",
    "    interact,\n",
    "    interact_manual,\n",
    "    interactive,\n",
    ")\n",
    "from matplotlib.collections import PolyCollection\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage import filters, transform\n",
    "\n",
    "\n",
    "class fluo_segmentation_interactive(fluo_segmentation):\n",
    "    def __init__(\n",
    "        self,\n",
    "        headpath,\n",
    "        bit_max=0,\n",
    "        scale_timepoints=False,\n",
    "        scaling_percentage=0.9,\n",
    "        img_scaling=1.0,\n",
    "        smooth_sigma=0.75,\n",
    "        niblack_scaling=1.0,\n",
    "        hess_pad=6,\n",
    "        global_threshold=25,\n",
    "        cell_otsu_scaling=1.0,\n",
    "        local_otsu_r=15,\n",
    "        min_obj_size=30,\n",
    "        distance_threshold=2,\n",
    "    ):\n",
    "        fluo_segmentation.__init__(\n",
    "            self,\n",
    "            bit_max=bit_max,\n",
    "            scale_timepoints=scale_timepoints,\n",
    "            scaling_percentage=scaling_percentage,\n",
    "            img_scaling=img_scaling,\n",
    "            smooth_sigma=smooth_sigma,\n",
    "            niblack_scaling=niblack_scaling,\n",
    "            hess_pad=hess_pad,\n",
    "            global_threshold=global_threshold,\n",
    "            cell_otsu_scaling=cell_otsu_scaling,\n",
    "            local_otsu_r=local_otsu_r,\n",
    "            min_obj_size=min_obj_size,\n",
    "            distance_threshold=distance_threshold,\n",
    "        )\n",
    "\n",
    "        self.headpath = headpath\n",
    "        self.kymographpath = headpath + \"/kymograph\"\n",
    "        self.metapath = headpath + \"/metadata.hdf5\"\n",
    "        self.meta_handle = pandas_hdf5_handler(self.metapath)\n",
    "        self.kymodf = self.meta_handle.read_df(\"kymograph\", read_metadata=True)\n",
    "        globaldf = self.meta_handle.read_df(\"global\", read_metadata=True)\n",
    "        self.all_channels = globaldf.metadata[\"channels\"]\n",
    "\n",
    "        timepoint_num = len(\n",
    "            self.kymodf.index.get_level_values(\"timepoints\").unique().tolist()\n",
    "        )\n",
    "        self.t_range = (0, timepoint_num)\n",
    "        self.trenchid_arr = (\n",
    "            self.kymodf.index.get_level_values(\"trenchid\").unique().values\n",
    "        )\n",
    "\n",
    "        self.final_params = {}\n",
    "\n",
    "    def choose_seg_channel(self, seg_channel):\n",
    "        self.seg_channel = seg_channel\n",
    "\n",
    "    def choose_seg_channel_inter(self):\n",
    "        choose_channel = interactive(\n",
    "            self.choose_seg_channel,\n",
    "            {\"manual\": True},\n",
    "            seg_channel=Dropdown(options=self.all_channels, value=self.all_channels[0]),\n",
    "        )\n",
    "        display(choose_channel)\n",
    "\n",
    "    def plot_img_list(self, img_list):\n",
    "        nrow = ((len(img_list) - 1) // self.img_per_row) + 1\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=nrow, ncols=self.img_per_row, figsize=self.fig_size\n",
    "        )\n",
    "        for i in range(len(img_list)):\n",
    "            img = img_list[i]\n",
    "            if nrow < 2:\n",
    "                axes[i % self.img_per_row].imshow(img, cmap=\"Greys_r\")\n",
    "            else:\n",
    "                axes[i // self.img_per_row, i % self.img_per_row].imshow(\n",
    "                    img, cmap=\"Greys_r\"\n",
    "                )\n",
    "        extra_slots = self.img_per_row - (len(img_list) % self.img_per_row)\n",
    "        if extra_slots != 0:\n",
    "            for slot in range(1, extra_slots + 1):\n",
    "                if nrow < 2:\n",
    "                    axes[self.img_per_row - slot].axis(\"off\")\n",
    "                else:\n",
    "                    axes[-1, self.img_per_row - slot].axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def import_array(\n",
    "        self,\n",
    "        n_trenches,\n",
    "        t_range=(0, None),\n",
    "        t_subsample_step=1,\n",
    "        fig_size_y=9,\n",
    "        fig_size_x=6,\n",
    "        img_per_row=2,\n",
    "    ):\n",
    "        self.fig_size = (fig_size_y, fig_size_x)\n",
    "        self.img_per_row = img_per_row\n",
    "\n",
    "        rand_trench_arr = np.random.choice(\n",
    "            self.trenchid_arr, size=(n_trenches,), replace=False\n",
    "        )\n",
    "        self.selecteddf = self.kymodf.loc[\n",
    "            list(zip(rand_trench_arr, np.zeros(len(rand_trench_arr)).astype(int)))\n",
    "        ]\n",
    "        selectedlist = list(\n",
    "            zip(\n",
    "                self.selecteddf[\"File Index\"].tolist(),\n",
    "                self.selecteddf[\"File Trench Index\"].tolist(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        array_list = []\n",
    "        for item in selectedlist:\n",
    "            with h5py.File(\n",
    "                self.kymographpath + \"/kymograph_\" + str(item[0]) + \".hdf5\", \"r\"\n",
    "            ) as hdf5_handle:\n",
    "                if t_range[1] == None:\n",
    "                    array = hdf5_handle[self.seg_channel][\n",
    "                        item[1], t_range[0] :: t_subsample_step\n",
    "                    ]\n",
    "                else:\n",
    "                    array = hdf5_handle[self.seg_channel][\n",
    "                        item[1], t_range[0] : t_range[1] + 1 : t_subsample_step\n",
    "                    ]\n",
    "            array_list.append(array)\n",
    "        output_array = np.concatenate(np.expand_dims(array_list, axis=0), axis=0)\n",
    "        self.t_tot = output_array.shape[1]\n",
    "        self.plot_kymographs(output_array)\n",
    "        self.output_array = output_array\n",
    "\n",
    "        return output_array\n",
    "\n",
    "    def import_array_inter(self):\n",
    "        kymo_arr_int = interactive(\n",
    "            self.import_array,\n",
    "            {\"manual\": True},\n",
    "            n_trenches=IntText(\n",
    "                value=12, description=\"Number of trenches:\", disabled=False\n",
    "            ),\n",
    "            t_range=IntRangeSlider(\n",
    "                value=[self.t_range[0], self.t_range[1] - 1],\n",
    "                description=\"Time Range:\",\n",
    "                min=self.t_range[0],\n",
    "                max=self.t_range[1] - 1,\n",
    "                step=1,\n",
    "                disabled=False,\n",
    "            ),\n",
    "            t_subsample_step=IntSlider(\n",
    "                value=1, description=\"Time Subsampling Step:\", min=1, max=20, step=1\n",
    "            ),\n",
    "            fig_size_y=IntSlider(\n",
    "                value=20,\n",
    "                description=\"Figure Size (Y Dimension):\",\n",
    "                min=1,\n",
    "                max=30,\n",
    "                step=1,\n",
    "            ),\n",
    "            fig_size_x=IntSlider(\n",
    "                value=12,\n",
    "                description=\"Figure Size (X Dimension):\",\n",
    "                min=1,\n",
    "                max=30,\n",
    "                step=1,\n",
    "            ),\n",
    "            img_per_row=IntSlider(\n",
    "                value=6, description=\"Images per Row:\", min=1, max=30, step=1\n",
    "            ),\n",
    "        )\n",
    "        display(kymo_arr_int)\n",
    "\n",
    "    def plot_kymographs(self, kymo_arr):\n",
    "        input_kymo = kymo_handle()\n",
    "        img_list = []\n",
    "        for k in range(kymo_arr.shape[0]):\n",
    "            input_kymo.import_wrap(kymo_arr[k])\n",
    "            img_list.append(input_kymo.return_unwrap())\n",
    "        self.plot_img_list(img_list)\n",
    "        return img_list\n",
    "\n",
    "    def plot_processed(\n",
    "        self, bit_max, scale_timepoints, scaling_percentile, img_scaling, smooth_sigma\n",
    "    ):\n",
    "        self.final_params[\"8 Bit Maximum:\"] = bit_max\n",
    "        self.final_params[\"Scale Fluorescence?\"] = scale_timepoints\n",
    "        self.final_params[\"Scaling Percentile:\"] = scaling_percentile\n",
    "        self.final_params[\"Image Scaling Factor:\"] = img_scaling\n",
    "        self.final_params[\"Gaussian Kernel Sigma:\"] = smooth_sigma\n",
    "\n",
    "        output_array = copy.copy(self.output_array)  # k,t,y,x\n",
    "\n",
    "        percentile = int(np.percentile(output_array.flatten(), 99))\n",
    "        print(\"99th percentile:\" + str(percentile))\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.hist(output_array.flatten(), bins=50)\n",
    "        ax.axvline(bit_max, c=\"r\", linewidth=3, zorder=10)\n",
    "        ax.set_title(\"Pixel Value Histogram w/ 8-bit Maximum\", fontsize=20)\n",
    "        ax.set_xlabel(\"Pixel Value\", fontsize=15)\n",
    "        fig.set_size_inches(9, 6)\n",
    "        fig.show()\n",
    "\n",
    "        output_array_list = []\n",
    "        for k in range(output_array.shape[0]):\n",
    "            scaled_output_array = self.to_8bit(output_array[k], bit_max)\n",
    "            if scale_timepoints:\n",
    "                scaled_output_array = self.scale_kymo(\n",
    "                    scaled_output_array, scaling_percentile\n",
    "                )\n",
    "            output_array_list.append(scaled_output_array)\n",
    "        output_array = np.array(output_array_list)\n",
    "\n",
    "        #         proc_list = []\n",
    "        unwrap_proc_list = []\n",
    "        for k in range(output_array.shape[0]):\n",
    "            t_tot = output_array[k].shape[0]\n",
    "            output_array_unwrapped = kymo_handle()\n",
    "            output_array_unwrapped.import_wrap(output_array[k])\n",
    "            output_array_unwrapped = output_array_unwrapped.return_unwrap()\n",
    "            rescaled_unwrapped = transform.rescale(\n",
    "                output_array_unwrapped,\n",
    "                img_scaling,\n",
    "                anti_aliasing=False,\n",
    "                preserve_range=True,\n",
    "            ).astype(\"uint8\")\n",
    "            filtered_unwrapped = sk.filters.gaussian(\n",
    "                rescaled_unwrapped,\n",
    "                sigma=smooth_sigma,\n",
    "                preserve_range=True,\n",
    "                mode=\"reflect\",\n",
    "            ).astype(\"uint8\")\n",
    "            #             filtered_wrapped = kymo_handle()\n",
    "            #             filtered_wrapped.import_unwrap(filtered_unwrapped,t_tot)\n",
    "            #             filtered_wrapped = filtered_wrapped.return_wrap()\n",
    "            #             proc_list.append(filtered_wrapped)\n",
    "            unwrap_proc_list.append(filtered_unwrapped)\n",
    "        self.proc_list = unwrap_proc_list\n",
    "        del unwrap_proc_list\n",
    "        self.eig_list = [\n",
    "            self.get_eig_img(item, edge_padding=self.hess_pad)\n",
    "            for item in self.proc_list\n",
    "        ]\n",
    "\n",
    "        self.plot_img_list(self.proc_list)\n",
    "        self.plot_img_list(self.eig_list)\n",
    "\n",
    "    def plot_processed_inter(self):\n",
    "        proc_list_int = interactive(\n",
    "            self.plot_processed,\n",
    "            {\"manual\": True},\n",
    "            bit_max=IntSlider(\n",
    "                value=1000,\n",
    "                description=\"8-bit Maximum:\",\n",
    "                min=0,\n",
    "                max=65535,\n",
    "                step=250,\n",
    "                disabled=False,\n",
    "            ),\n",
    "            scale_timepoints=Dropdown(\n",
    "                options=[True, False],\n",
    "                value=False,\n",
    "                description=\"Scale Fluorescence?\",\n",
    "                disabled=False,\n",
    "            ),\n",
    "            scaling_percentile=IntSlider(\n",
    "                value=90,\n",
    "                description=\"Scaling Percentile:\",\n",
    "                min=0,\n",
    "                max=100,\n",
    "                step=1,\n",
    "                disabled=False,\n",
    "            ),\n",
    "            img_scaling=FloatSlider(\n",
    "                value=1.0,\n",
    "                description=\"Image Upsampling Factor:\",\n",
    "                min=1.0,\n",
    "                max=3.0,\n",
    "                step=0.25,\n",
    "                disabled=False,\n",
    "            ),\n",
    "            smooth_sigma=FloatSlider(\n",
    "                value=0.75,\n",
    "                description=\"Gaussian Kernel Sigma:\",\n",
    "                min=0.0,\n",
    "                max=3.0,\n",
    "                step=0.25,\n",
    "                disabled=False,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        display(proc_list_int)\n",
    "\n",
    "\n",
    "#     def plot_cell_mask(self,global_threshold,cell_mask_method,cell_otsu_scaling,local_otsu_r):\n",
    "#         self.final_params['Cell Mask Thresholding Method:'] = cell_mask_method\n",
    "#         self.final_params['Global Threshold:'] = global_threshold\n",
    "#         self.final_params['Cell Threshold Scaling:'] = cell_otsu_scaling\n",
    "#         self.final_params['Local Otsu Radius:'] = local_otsu_r\n",
    "\n",
    "#         cell_mask_list = []\n",
    "#         unwrap_cell_mask_list = []\n",
    "\n",
    "#         for proc in self.proc_list:\n",
    "#             cell_mask = self.cell_region_mask(proc,method=cell_mask_method,global_threshold=global_threshold,cell_otsu_scaling=cell_otsu_scaling,local_otsu_r=local_otsu_r)\n",
    "#             cell_mask_list.append(cell_mask)\n",
    "\n",
    "#             cell_mask_kymo = kymo_handle()\n",
    "#             cell_mask_kymo.import_wrap(cell_mask)\n",
    "#             unwrap_cell_mask = cell_mask_kymo.return_unwrap(padding=0)\n",
    "\n",
    "#             unwrap_cell_mask_list.append(unwrap_cell_mask)\n",
    "#         self.plot_img_list(unwrap_cell_mask_list)\n",
    "\n",
    "#         plt.hist(np.array(self.proc_list).flatten(),bins=50)\n",
    "#         plt.show()\n",
    "\n",
    "#         self.cell_mask_list = cell_mask_list\n",
    "\n",
    "#     def plot_cell_mask_inter(self):\n",
    "#         cell_mask_list_int = interactive(\n",
    "#             self.plot_cell_mask,\n",
    "#             {\"manual\": True},\n",
    "#             cell_mask_method=Dropdown(\n",
    "#                 options=[\"local\", \"global\"],\n",
    "#                 value=\"local\",\n",
    "#                 description=\"Cell Mask Thresholding Method:\",\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#             global_threshold=IntSlider(\n",
    "#                 value=50,\n",
    "#                 description=\"Global Threshold:\",\n",
    "#                 min=0,\n",
    "#                 max=255,\n",
    "#                 step=1,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#             cell_otsu_scaling=FloatSlider(\n",
    "#                 value=0.95,\n",
    "#                 description=\"Cell Threshold Scaling:\",\n",
    "#                 min=0.0,\n",
    "#                 max=2.0,\n",
    "#                 step=0.01,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#             local_otsu_r=IntSlider(\n",
    "#                 value=15,\n",
    "#                 description=\"Local Otsu Radius:\",\n",
    "#                 min=0,\n",
    "#                 max=30,\n",
    "#                 step=1,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#         )\n",
    "#         display(cell_mask_list_int)\n",
    "\n",
    "#     def plot_threshold_result(self,edge_threshold_scaling,min_obj_size):\n",
    "#         composite_mask_list = []\n",
    "#         edge_mask_list = []\n",
    "#         for i,min_eigvals in enumerate(self.eigval_list):\n",
    "#             cell_mask = self.cell_mask_list[i]\n",
    "\n",
    "#             edge_threshold = self.get_mid_threshold_arr(min_eigvals,edge_threshold_scaling=edge_threshold_scaling,padding=self.wrap_pad)\n",
    "\n",
    "#             cell_mask_kymo = kymo_handle()\n",
    "#             cell_mask_kymo.import_wrap(cell_mask)\n",
    "#             cell_mask = cell_mask_kymo.return_unwrap(padding=self.wrap_pad)\n",
    "\n",
    "#             min_eigvals_kymo = kymo_handle()\n",
    "#             min_eigvals_kymo.import_wrap(min_eigvals)\n",
    "#             min_eigvals = min_eigvals_kymo.return_unwrap(padding=self.wrap_pad)\n",
    "\n",
    "#             composite_mask = self.find_mask(cell_mask,min_eigvals,edge_threshold,min_obj_size=min_obj_size)\n",
    "#             composite_mask_list.append(composite_mask)\n",
    "\n",
    "#         self.plot_img_list(composite_mask_list)\n",
    "#         self.composite_mask_list = composite_mask_list\n",
    "\n",
    "#     def plot_threshold_result_inter(self):\n",
    "#         composite_mask_list_int = interactive(\n",
    "#             self.plot_threshold_result,\n",
    "#             {\"manual\": True},\n",
    "#             edge_threshold_scaling=FloatSlider(\n",
    "#                 value=1.0,\n",
    "#                 description=\"Edge Threshold Scaling\",\n",
    "#                 min=0.0,\n",
    "#                 max=2.0,\n",
    "#                 step=0.01,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#             min_obj_size=IntSlider(\n",
    "#                 value=30,\n",
    "#                 description=\"Minimum Object Size:\",\n",
    "#                 min=0,\n",
    "#                 max=100,\n",
    "#                 step=2,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#         )\n",
    "#         display(composite_mask_list_int)\n",
    "\n",
    "\n",
    "#     def plot_scores(self,edge_threshold_scaling,threshold_step_perc,threshold_perc_num_steps,min_obj_size):\n",
    "#         self.final_params['Edge Threshold Scaling:'] = edge_threshold_scaling\n",
    "#         self.final_params['Threshold Step Percent:'] = threshold_step_perc\n",
    "#         self.final_params['Number of Threshold Steps:'] = threshold_perc_num_steps\n",
    "#         self.final_params['Minimum Object Size:'] = min_obj_size\n",
    "\n",
    "#         conv_scores_list = []\n",
    "#         for i,min_eigvals in enumerate(self.eigval_list):\n",
    "#             cell_mask = self.cell_mask_list[i]\n",
    "\n",
    "#             mid_threshold_arr = self.get_mid_threshold_arr(min_eigvals,edge_threshold_scaling=edge_threshold_scaling,padding=self.wrap_pad)\n",
    "\n",
    "#             cell_mask_kymo = kymo_handle()\n",
    "#             cell_mask_kymo.import_wrap(cell_mask)\n",
    "#             cell_mask = cell_mask_kymo.return_unwrap(padding=self.wrap_pad)\n",
    "\n",
    "#             min_eigvals_kymo = kymo_handle()\n",
    "#             min_eigvals_kymo.import_wrap(min_eigvals)\n",
    "#             min_eigvals = min_eigvals_kymo.return_unwrap(padding=self.wrap_pad)\n",
    "\n",
    "#             conv_scores = self.get_scores(cell_mask,min_eigvals,mid_threshold_arr,\\\n",
    "#                                           threshold_step_perc=threshold_step_perc,threshold_perc_num_steps=threshold_perc_num_steps,min_obj_size=min_obj_size)\n",
    "#             conv_scores_list.append(conv_scores)\n",
    "#         self.plot_img_list(conv_scores_list)\n",
    "#         self.conv_scores_list = conv_scores_list\n",
    "\n",
    "#     def plot_scores_inter(self):\n",
    "#         conv_scores_list_int = interactive(\n",
    "#             self.plot_scores,\n",
    "#             {\"manual\": True},\n",
    "#             edge_threshold_scaling=FloatSlider(\n",
    "#                 value=0.9,\n",
    "#                 description=\"Edge Threshold Scaling\",\n",
    "#                 min=0.0,\n",
    "#                 max=2.0,\n",
    "#                 step=0.01,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#             threshold_step_perc=FloatSlider(\n",
    "#                 value=0.05,\n",
    "#                 description=\"Threshold Step Percent\",\n",
    "#                 min=0.0,\n",
    "#                 max=0.5,\n",
    "#                 step=0.01,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#             threshold_perc_num_steps=IntSlider(\n",
    "#                 value=2,\n",
    "#                 description=\"Number of Threshold Steps\",\n",
    "#                 min=0,\n",
    "#                 max=5,\n",
    "#                 step=1,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#             min_obj_size=IntSlider(\n",
    "#                 value=30,\n",
    "#                 description=\"Minimum Object Size:\",\n",
    "#                 min=0,\n",
    "#                 max=100,\n",
    "#                 step=2,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#         )\n",
    "#         display(conv_scores_list_int)\n",
    "\n",
    "#     def plot_final_mask(self,convex_threshold):\n",
    "#         self.final_params['Convexity Threshold:'] = convex_threshold\n",
    "#         img_scaling = self.final_params[\"Image Scaling Factor:\"]\n",
    "\n",
    "#         final_mask_list = []\n",
    "#         for conv_scores in self.conv_scores_list:\n",
    "#             final_mask = (conv_scores>convex_threshold)\n",
    "#             final_mask_new = []\n",
    "#             for t in range(final_mask.shape[0]):\n",
    "#                 image_rescaled = transform.rescale(final_mask[t], 1./img_scaling, anti_aliasing=False,order=0,preserve_range=True)\n",
    "#                 final_mask_new.append(image_rescaled)\n",
    "#             del final_mask\n",
    "#             final_mask = np.array(final_mask_new,dtype=bool)\n",
    "#             final_mask = sk.measure.label(final_mask)\n",
    "#             final_mask_list.append(final_mask)\n",
    "\n",
    "#         self.plot_img_list(final_mask_list)\n",
    "#         self.final_mask_list = final_mask_list\n",
    "\n",
    "#     def plot_final_mask_inter(self):\n",
    "#         final_mask_list_int = interactive(\n",
    "#             self.plot_final_mask,\n",
    "#             {\"manual\": True},\n",
    "#             convex_threshold=FloatSlider(\n",
    "#                 value=0.75,\n",
    "#                 description=\"Convexity Threshold:\",\n",
    "#                 min=0.0,\n",
    "#                 max=1.0,\n",
    "#                 step=0.01,\n",
    "#                 disabled=False,\n",
    "#             ),\n",
    "#         )\n",
    "#         display(final_mask_list_int)\n",
    "\n",
    "#     def process_results(self):\n",
    "#         self.final_params[\"Segmentation Channel:\"] = self.seg_channel\n",
    "#         for key,value in self.final_params.items():\n",
    "#             print(key + \" \" + str(value))\n",
    "\n",
    "#     def write_param_file(self):\n",
    "#         with open(self.headpath + \"/fluorescent_segmentation.par\", \"wb\") as outfile:\n",
    "#             pickle.dump(self.final_params, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_test = fluo_segmentation_interactive(headpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_test.choose_seg_channel_inter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_test.import_array_inter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_test.plot_processed_inter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo_seg = fluo_segmentation_cluster(\n",
    "    headpath, seg_channel=\"mCherry\", bit_max=20000, img_scaling=2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo_seg.generate_segmentation(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = tr.kymo_handle()\n",
    "view.import_wrap(img)\n",
    "img = view.return_unwrap()\n",
    "\n",
    "labels = test_seg.segment(data)\n",
    "plt_img = np.ma.array(labels, mask=(labels == 0))\n",
    "\n",
    "plt.imshow(img, cmap=\"Greys_r\", interpolation=\"nearest\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(plt_img, cmap=\"jet\", interpolation=\"ne
arest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg_img[:, :500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"02:00:00\",\n",
    "    local=False,\n",
    "    n_workers=100,\n",
    "    memory=\"2GB\",\n",
    "    cores=1,\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = fluo_segmentation_cluster(\n",
    "    headpath, seg_channel=\"mCherry\", bit_max=20000, img_scaling=2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment.dask_segment(dask_controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.daskclient.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 2\n",
    "idx = 11\n",
    "\n",
    "with h5py.File(\n",
    "    \"/n/scratch2/de64/2020-03-02_plasmid_loss/kymograph/kymograph_\"\n",
    "    + str(file)\n",
    "    + \".hdf5\",\n",
    "    \"r\",\n",
    ") as infile:\n",
    "    img = infile[\"mCherry\"][idx]\n",
    "with h5py.File(\n",
    "    \"/n/scratch2/de64/2020-03-02_plasmid_loss/fluorsegmentation/segmentation_\"\n",
    "    + str(file)\n",
    "    + \".hdf5\",\n",
    "    \"r\",\n",
    ") as infile:\n",
    "    seg = infile[\"data\"][idx]\n",
    "\n",
    "view = tr.kymo_handle()\n",
    "view.import_wrap(img)\n",
    "img = view.return_unwrap()\n",
    "\n",
    "view.import_wrap(seg)\n",
    "seg = view.return_unwrap()\n",
    "seg = np.ma.array(seg, mask=(seg == 0))\n",
    "\n",
    "plt.imshow(img[:, :100], cmap=\"Greys_r\", interpolation=\"nearest\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(seg[:, :100], cmap=\"jet\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
