{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import ipywidgets as ipyw\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import paulssonlab.deaton.trenchripper.trenchripper as tr\n",
    "from paulssonlab.deaton.trenchripper.trenchripper.utils import pandas_hdf5_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.transferjob(\"\", \"/n/scratch3/users/d/de64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedir = \"/n/files/SysBio/PAULSSON\\ LAB/Personal\\ Folders/Noah/190922/20x_segmentation_data/190925_20x_phase_yfp_segmentation\"\n",
    "targetdir = \"/n/scratch3/users/d/de64/20X_seg_yfp\"\n",
    "tr.trcluster.transferjob(sourcedir, targetdir, single_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue --user=de64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = tr.GridSearch(\"/n/scratch2/de64/nntest7\", numepochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.display_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.get_grid_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.run_grid_search(mem=\"16G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue --user=de64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingVisualizer:\n",
    "    def __init__(self, trainpath, modeldbpath):\n",
    "        self.trainpath = trainpath\n",
    "        self.modelpath = trainpath + \"/models\"\n",
    "        self.modeldfpath = trainpath + \"/model_metadata.hdf5\"\n",
    "        self.modeldbpath = modeldbpath\n",
    "        self.paramdbpath = modeldbpath + \"/Parameters\"\n",
    "        self.update_dfs()\n",
    "        if os.path.exists(self.modeldfpath):\n",
    "            self.models_widget = qgrid.show_grid(self.model_df.sort_index())\n",
    "\n",
    "    def update_dfs(self):\n",
    "        df_idx_list = []\n",
    "        for path in os.listdir(self.modelpath):\n",
    "            if \"training_metadata\" in path:\n",
    "                df_idx = int(path.split(\"_\")[-1][:-5])\n",
    "                df_idx_list.append(df_idx)\n",
    "        df_list = []\n",
    "        for df_idx in df_idx_list:\n",
    "            dfpath = self.modelpath + \"/training_metadata_\" + str(df_idx) + \".hdf5\"\n",
    "            df_handle = pandas_hdf5_handler(dfpath)\n",
    "            df = df_handle.read_df(\"data\")\n",
    "            df_list.append(copy.deepcopy(df))\n",
    "            del df\n",
    "        self.train_df = pd.concat(df_list)\n",
    "        if os.path.exists(self.modeldfpath):\n",
    "            modeldfhandle = pandas_hdf5_handler(self.modeldfpath)\n",
    "            self.model_df = modeldfhandle.read_df(\"data\").sort_index()\n",
    "\n",
    "    def select_df_columns(self, selected_columns):\n",
    "        df = copy.deepcopy(self.model_df)\n",
    "        for column in df.columns.tolist():\n",
    "            if column not in selected_columns:\n",
    "                df = df.drop(column, 1)\n",
    "        self.model_widget = qgrid.show_grid(df)\n",
    "\n",
    "    def inter_df_columns(self):\n",
    "        column_list = self.model_df.columns.tolist()\n",
    "        inter = ipyw.interactive(\n",
    "            self.select_df_columns,\n",
    "            {\"manual\": True},\n",
    "            selected_columns=ipyw.SelectMultiple(\n",
    "                options=column_list, description=\"Columns to Display:\", disabled=False\n",
    "            ),\n",
    "        )\n",
    "        display(inter)\n",
    "\n",
    "    def handle_filter_changed(self, event, widget):\n",
    "        df = widget.get_changed_df().sort_index()\n",
    "\n",
    "        all_model_indices = (\n",
    "            self.train_df.index.get_level_values(\"Model #\").unique().tolist()\n",
    "        )\n",
    "        current_model_indices = df.index.get_level_values(\"Model #\").unique().tolist()\n",
    "\n",
    "        all_epochs = []\n",
    "        all_loss = []\n",
    "        for model_idx in all_model_indices:\n",
    "            if model_idx in current_model_indices:\n",
    "                filter_df = df.loc[model_idx]\n",
    "                epochs, loss = (\n",
    "                    filter_df.index.get_level_values(\"Epoch\").tolist(),\n",
    "                    filter_df[self.losskey].tolist(),\n",
    "                )\n",
    "                all_epochs += epochs\n",
    "                all_loss += loss\n",
    "                self.line_dict[model_idx].set_data(epochs, loss)\n",
    "                self.line_dict[model_idx].set_label(str(model_idx))\n",
    "            else:\n",
    "                epochs_empty, loss_empty = ([], [])\n",
    "                self.line_dict[model_idx].set_data(epochs_empty, loss_empty)\n",
    "                self.line_dict[model_idx].set_label(\"_nolegend_\")\n",
    "\n",
    "        self.ax.set_xlim(min(all_epochs), max(all_epochs) + 1)\n",
    "        self.ax.set_ylim(0, max(all_loss) * 1.1)\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def inter_plot_loss(self, losskey):\n",
    "        self.losskey = losskey\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.grid_widget = qgrid.show_grid(self.train_df.sort_index())\n",
    "        current_df = self.grid_widget.get_changed_df()\n",
    "\n",
    "        self.line_dict = {}\n",
    "        for model_idx in current_df.index.get_level_values(\"Model #\").unique().tolist():\n",
    "            filter_df = current_df.loc[model_idx]\n",
    "            epochs, loss = (\n",
    "                filter_df.index.get_level_values(\"Epoch\").tolist(),\n",
    "                filter_df[losskey].tolist(),\n",
    "            )\n",
    "            (line,) = self.ax.plot(epochs, loss, label=str(model_idx))\n",
    "            self.line_dict[model_idx] = line\n",
    "\n",
    "        self.ax.set_xlabel(\"Epoch\")\n",
    "        self.ax.set_ylabel(losskey)\n",
    "        self.ax.legend()\n",
    "\n",
    "    def export_models(self):\n",
    "        writedir(self.modeldbpath, overwrite=False)\n",
    "        writedir(self.modeldbpath + \"/Parameters\", overwrite=False)\n",
    "        modeldbhandle = pandas_hdf5_handler(self.modeldbpath + \"/Models.hdf5\")\n",
    "        if \"Models.hdf5\" in os.listdir(self.modeldbpath):\n",
    "            old_df = modeldbhandle.read_df(\"data\")\n",
    "            current_df = self.models_widget.get_changed_df()\n",
    "            current_df = pd.concat([old_df, current_df])\n",
    "        else:\n",
    "            current_df = self.models_widget.get_changed_df()\n",
    "        modeldbhandle.write_df(\"data\", current_df)\n",
    "\n",
    "        indices = current_df.index.tolist()\n",
    "        exp_names = [str(item[0]) for item in indices]\n",
    "        model_numbers = [str(item[1]) for item in indices]\n",
    "        dates = [item.replace(\" \", \"_\") for item in current_df[\"Date/Time\"].tolist()]\n",
    "\n",
    "        for i in range(len(model_numbers)):\n",
    "            exp_name, model_number, date = (exp_names[i], model_numbers[i], dates[i])\n",
    "            shutil.copyfile(\n",
    "                self.modelpath + \"/\" + str(model_number) + \".pt\",\n",
    "                self.paramdbpath\n",
    "                + \"/\"\n",
    "                + exp_name\n",
    "                + \"_\"\n",
    "                + model_number\n",
    "                + \"_\"\n",
    "                + date\n",
    "                + \".pt\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = TrainingVisualizer(\"/n/scratch2/de64/nntest7\", \"/n/scratch2/de64/nndb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "vis.inter_plot_loss(\"Val Loss\")\n",
    "vis.grid_widget.on(\"filter_changed\", vis.handle_filter_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.grid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.inter_df_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.model_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(vis.model_df[\"Val F1 Cell Scores\"][2], bins=50)\n",
    "plt.xlabel(\"F-Score\")\n",
    "plt.ylabel(\"Occurances\")\n",
    "plt.xticks(np.arange(0, 1.01, step=0.5))\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(vis.model_df[\"Val F1 Cell Scores\"][1], bins=50)\n",
    "plt.xlabel(\"F-Score\")\n",
    "plt.ylabel(\"Occurances\")\n",
    "plt.xticks(np.arange(0, 1.01, step=0.5))\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(vis.model_df[\"Val F1 Cell Scores\"][2], bins=50)\n",
    "plt.xlabel(\"F-Score\")\n",
    "plt.ylabel(\"Occurances\")\n",
    "plt.xticks(np.arange(0, 1.01, step=0.5))\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = tr.TrainingVisualizer(\"/n/scratch2/de64/nntest7\", \"/n/scratch2/de64/nndb\")\n",
    "\n",
    "# :\n",
    "#     def __init__(self,trainpath,modeldbpath):\n",
    "#         self.trainpath = trainpath\n",
    "#         self.modelpath = trainpath + \"/models\"\n",
    "#         self.modeldfpath = trainpath + \"/model_metadata.hdf5\"\n",
    "#         self.modeldbpath = modeldbpath\n",
    "#         self.paramdbpath = modeldbpath+\"/Parameters\"\n",
    "#         self.update_dfs()\n",
    "#         if os.path.exists(self.modeldfpath):\n",
    "#             self.models_widget = qgrid.show_grid(self.model_df.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import pickle as pkl\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import ipywidgets as ipyw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "import skimage as sk\n",
    "import skimage.morphology\n",
    "import sklearn as skl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug.augmentables.heatmaps import HeatmapsOnImage\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import convolve1d\n",
    "from torch._six import container_abcs, int_classes, string_classes\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tr.UNet_Trainer(\"/n/scratch2/de64/nntest7\", 100, \"class\", lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "    test.model.parameters(),\n",
    "    lr=test.lr,\n",
    "    momentum=test.momentum,\n",
    "    weight_decay=test.weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_epochs = 10\n",
    "cool_epochs = 100\n",
    "warm_lambda = 1.0 / warm_epochs\n",
    "cool_lambda = 1.0 / cool_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annealfn(epoch):\n",
    "    numepochs = 500\n",
    "    warm_epochs = 10\n",
    "    cool_epochs = 100\n",
    "    warm_lambda = 1.0 / warm_epochs\n",
    "    cool_lambda = 1.0 / cool_epochs\n",
    "\n",
    "    if epoch < warm_epochs:\n",
    "        return warm_lambda * epoch\n",
    "    elif epoch > (numepochs - cool_epochs):\n",
    "        return max(0.0, cool_lambda * (numepochs - epoch))\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(test.optimizer, lr_lambda=annealfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "annealfn(460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.LambdaLR(test.optimizer, lr_lambda=annealfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    test.scheduler.step()\n",
    "    print(test.scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(0, self.numepochs):\n",
    "    train_iter = DataLoader(\n",
    "        train_data, batch_size=self.batch_size, shuffle=False, collate_fn=numpy_collate\n",
    "    )\n",
    "    test_iter = DataLoader(\n",
    "        test_data, batch_size=self.batch_size, shuffle=False, collate_fn=numpy_collate\n",
    "    )\n",
    "    val_iter = DataLoader(\n",
    "        val_data, batch_size=self.batch_size, shuffle=False, collate_fn=numpy_collate\n",
    "    )\n",
    "    df_out = self.perepoch(\n",
    "        e,\n",
    "        train_iter,\n",
    "        test_iter,\n",
    "        val_iter,\n",
    "        train_data_size,\n",
    "        test_data_size,\n",
    "        val_data_size,\n",
    "    )\n",
    "\n",
    "    self.write_metadata(\n",
    "        self.nndatapath\n",
    "        + \"/models/training_metadata_\"\n",
    "        + str(self.model_number)\n",
    "        + \".hdf5\",\n",
    "        \"w\",\n",
    "        df_out,\n",
    "    )\n",
    "end = time.time()\n",
    "time_elapsed = (end - start) / 60.0\n",
    "torch.save(\n",
    "    self.model.state_dict(),\n",
    "    self.nndatapath + \"/models/\" + str(self.model_number) + \".pt\",\n",
    ")\n",
    "\n",
    "try:\n",
    "    if self.mode == \"class\" or self.mode == \"multiclass\":\n",
    "        val_f = self.get_class_fscore(val_iter)\n",
    "        test_f = self.get_class_fscore(test_iter)\n",
    "    elif self.mode == \"cellpose\":\n",
    "        val_f = self.get_cellpose_fscore(val_iter)\n",
    "        test_f = self.get_cellpose_fscore(test_iter)\n",
    "except:\n",
    "    print(\"Failed to compute F-scores\")\n",
    "    val_f = [np.NaN]\n",
    "    test_f = [np.NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tr.UNet_Trainer(\n",
    "    \"/n/scratch2/de64/nntest7/\",\n",
    "    100,\n",
    "    \"cellpose\",\n",
    "    numepochs=1,\n",
    "    batch_size=50,\n",
    "    layers=4,\n",
    "    hidden_size=64,\n",
    "    lr=0.2,\n",
    "    gpuon=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "train.model.load_state_dict(torch.load(\"/n/scratch2/de64/nntest7/models/13.pt\"))\n",
    "train.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = tr.SegmentationDataset(\n",
    "    train.nndatapath + \"test.hdf5\", mode=train.mode, W0=train.W0, Wsigma=train.Wsigma\n",
    ")\n",
    "test_iter = DataLoader(\n",
    "    test_data, batch_size=train.batch_size, shuffle=False, collate_fn=tr.numpy_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f = train.get_cellpose_fscore(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(test_f, range=(0, 1), bins=50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
