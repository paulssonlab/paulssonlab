{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# TrenchRipper Master Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Experimental Notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "\t3. Experiment 3 (File name: 2020-01-10_strains_46_47)\n",
    "\t\ta. Strains: DE46 and DE47 mixed 1:1\n",
    "\t\tb. Chip: 1.5W/L25 (height: 1.36 um) snakes (Sylvia)\n",
    "\t\t\ti. Baked for ~3 mins\n",
    "\t\t\tii. However, was aged by ~2 weeks\n",
    "\t\t\tiii. Same chip as 2020-01-05_strains_46_47'\n",
    "\t\t\tiv. Passivated overnight in 2.5% F108\n",
    "\t\tc. Growth: Loaded cells in the morning, grew for ~8 hours\n",
    "\t\t\ti. Still some dead mother cells, but more robust growth than in previous days\n",
    "\t\t\tii. Cells loaded from extended (>10 hours) stationary\n",
    "\t\td. Results\n",
    "\t\t\ti. Less unloading than with the PFA fixation on the same chip (2020-01-05_strains_46_47)\n",
    "\t\t\tii. Loading balanced in strain representation\n",
    "            iii. Both cycles worked very well, but still problems from dead mothers/physiology. Suggest loading cells in early stationary if possible. Problem may be alleviated once in typical (MG1655) strain background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib\n",
    "import trenchripper as tr\n",
    "from ipywidgets import (\n",
    "    Dropdown,\n",
    "    FloatRangeSlider,\n",
    "    FloatSlider,\n",
    "    IntRangeSlider,\n",
    "    IntSlider,\n",
    "    IntText,\n",
    "    SelectMultiple,\n",
    "    fixed,\n",
    "    interact,\n",
    "    interact_manual,\n",
    "    interactive,\n",
    ")\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### Specify Paths\n",
    "\n",
    "Begin by defining the directory in which all processing will be done, as well as the initial nd2 file we will be processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = \"/n/scratch2/de64/2020-01-10_strains_46_47/cycle_1\"\n",
    "nd2file = \"/n/scratch2/de64/2020-01-10_strains_46_47/cycle_1/mothermachine_cycle_1.nd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = \"/n/scratch2/de64/2020-01-10_strains_46_47/cycle_2\"\n",
    "nd2file = \"/n/scratch2/de64/2020-01-10_strains_46_47/cycle_2/mothermachine_cycle_2.nd2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "#### Transfer files into the scratch folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedir = \"/n/files/SysBio/PAULSSON\\ LAB/Personal\\ Folders/Daniel/Image_Data/FISH_barcoding/2020-01-10_strains_46_47/cycle_2\"\n",
    "targetdir = \"/n/scratch2/de64/2020-01-10_strains_46_47/cycle_2\"\n",
    "tr.cluster.transferjob(sourcedir, targetdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Extract to hdf5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Start Dask Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.cluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=10,\n",
    "    memory=\"2GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()\n",
    "dask_controller.daskcluster.start_workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Perform Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_extractor = tr.ndextract.hdf5_fov_extractor(\n",
    "    nd2file, headpath, tpts_per_file=100, ignore_fovmetadata=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_extractor.inter_get_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_extractor.extract(dask_controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### Shutdown Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Kymographs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Test Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "#### Initialize the interactive kymograph class\n",
    "\n",
    "As a first step, initialize the `tr.interactive.kymograph_interactive` class that will be handling all steps of generating a kymograph. \n",
    "\n",
    "You will need to specify the following `args` and `kwargs` (in order):\n",
    "\n",
    "\n",
    "**Args**\n",
    "\n",
    "**input_file_prefix (string)** : File prefix for all input hdf5 files of the form \"\\[input_file_prefix\\]\\[number\\].hdf5\" This should be the default output format for the hdf5 export code, but you will need to rename files if taking input files from a different source.\n",
    "\n",
    "**all_channels (list)** : list of strings corresponding to the different image channels available in the input hdf5 file, with the channel used for segmenting trenches in the first position. NOTE: these names must match those of the input hdf5 file datasets.\n",
    "\n",
    "**fov_list (list)** : List of ints corresponding to the fovs that you wish to make kymographs of.\n",
    "\n",
    "**Kwargs**\n",
    "\n",
    "**t_subsample_step (int)** : Step size to be used for subsampling input files in time, recommend that subsampling results in between 5 and 20 timepoints for quick processing.\n",
    "\n",
    "**t_range (tuple of ints)** : Range size to be used for subsampling input files in time.\n",
    "\n",
    "The last line will perform import and subsampling of the input hdf5 image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "interactive_kymograph = tr.interactive.kymograph_interactive(headpath)\n",
    "channels, fov_list, timepoints_len = interactive_kymograph.get_image_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    interactive_kymograph.view_image,\n",
    "    fov_idx=IntText(value=0, description=\"FOV number:\", disabled=False),\n",
    "    t=IntSlider(\n",
    "        value=0, min=0, max=timepoints_len - 1, step=1, continuous_update=False\n",
    "    ),\n",
    "    channel=Dropdown(\n",
    "        options=channels, value=channels[0], description=\"Channel:\", disabled=False\n",
    "    ),\n",
    "    invert=Dropdown(options=[True, False], value=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_hdf5 = interactive(\n",
    "    interactive_kymograph.import_hdf5_files,\n",
    "    {\"manual\": True},\n",
    "    all_channels=fixed(channels),\n",
    "    seg_channel=Dropdown(options=channels, value=channels[0]),\n",
    "    invert=Dropdown(options=[True, False], value=False),\n",
    "    fov_list=SelectMultiple(options=fov_list),\n",
    "    t_range=IntRangeSlider(\n",
    "        value=[0, timepoints_len - 1],\n",
    "        min=0,\n",
    "        max=timepoints_len - 1,\n",
    "        step=1,\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "    ),\n",
    "    t_subsample_step=IntSlider(value=10, min=0, max=200, step=1),\n",
    ")\n",
    "display(import_hdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_array_list = copy.copy(import_hdf5.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Tune \"trench-row\" detection hyperparameters\n",
    "\n",
    "The kymograph code begins by detecting the positions of trench rows in the image as follows:\n",
    "\n",
    "1. Reducing each 2D image to a 1D signal along the y-axis by computing the qth percentile of the data along the x-axis\n",
    "2. Smooth this signal using a median kernel\n",
    "3. Use a [triangle threshold](https://imagej.net/Auto_Threshold#Triangle) to determine the trench row poisitons\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**y_percentile (int)** : Percentile to use for step 1.\n",
    "\n",
    "**smoothing_kernel_y_dim_0 (int)** : Median kernel size to use for step 2.\n",
    "\n",
    "**triangle_nbins (int)** : Number of bins to use in the triangle method histogram.\n",
    "\n",
    "**triangle_scaling (float)** : Scaling factor to apply to the threshold determined by the triangle method.\n",
    "\n",
    "\n",
    "Running the following widget will display the smoothed 1-D signal for each of your timepoints. In addition, the threshold value for each fov will be displayed as a red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "\n",
    "row_detection = interactive(\n",
    "    interactive_kymograph.preview_y_precentiles,\n",
    "    {\"manual\": True},\n",
    "    imported_array_list=fixed(imported_array_list),\n",
    "    y_percentile=IntSlider(value=100, min=0, max=100, step=1),\n",
    "    smoothing_kernel_y_dim_0=IntSlider(value=17, min=1, max=200, step=2),\n",
    "    triangle_nbins=IntSlider(value=50, min=10, max=300, step=10),\n",
    "    triangle_scaling=FloatSlider(value=3.5, min=0.0, max=4.0, step=0.05),\n",
    "    triangle_threshold_bounds=FloatRangeSlider(\n",
    "        value=[0, 1.0],\n",
    "        min=0,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "    ),\n",
    ")\n",
    "display(row_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "#### Generate \"trench-row\" detection output\n",
    "\n",
    "After determining your desired hyperparameters, set them in the next cell and run it to produce output for later steps. **Note: The thresholding parameters do not need to be specified at this point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_percentiles_smoothed_list = copy.copy(row_detection.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "#### Tune \"trench-row\" cropping hyperparameters\n",
    "\n",
    "Next, we will use the detected rows to perform cropping of the input image in the y-dimension:\n",
    "\n",
    "1. Determine edges of trench rows based on threshold mask.\n",
    "2. Filter out rows that are too small.\n",
    "3. Perform cropping using the \"end\" of the row as reference (the end referring to the part of the trench farthest from the feeding channel).\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**y_min_edge_dist (int)** : Minimum row length necessary for detection.\n",
    "\n",
    "**padding_y (int)** : Padding to be used when cropping in the y-dimension.\n",
    "\n",
    "**trench_len_y (int)** : Length from the end of the tenches to be used when cropping in the y-dimension.\n",
    "\n",
    "**top_orientation (int)** : The orientation of the top-most row where 0 corresponds to a trench with a downward-oriented trench opening and 1 corresponds to a trench with an upward-oriented trench opening.\n",
    "\n",
    "**vertical_spacing (float)** : Parameter for setting the distance of plots being viewed.\n",
    "\n",
    "Running the following widget will display y-cropped images for each fov and timepoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "y_cropping = interactive(\n",
    "    interactive_kymograph.preview_y_crop,\n",
    "    {\"manual\": True},\n",
    "    y_percentiles_smoothed_list=fixed(y_percentiles_smoothed_list),\n",
    "    imported_array_list=fixed(imported_array_list),\n",
    "    y_min_edge_dist=IntSlider(value=50, min=10, max=200, step=10),\n",
    "    padding_y=IntSlider(value=20, min=0, max=100, step=1),\n",
    "    trench_len_y=IntSlider(value=270, min=0, max=1000, step=10),\n",
    "    vertical_spacing=FloatSlider(value=0.9, min=0.0, max=2.0, step=0.01),\n",
    "    expected_num_rows=IntText(value=2, description=\"Number of Rows:\", disabled=False),\n",
    "    orientation_detection=Dropdown(\n",
    "        options=[0, 1, \"phase\"], value=0, description=\"Orientation:\", disabled=False\n",
    "    ),\n",
    "    orientation_on_fail=Dropdown(\n",
    "        options=[None, 0, 1],\n",
    "        value=0,\n",
    "        description=\"Orientation when < expected rows:\",\n",
    "        disabled=False,\n",
    "    ),\n",
    ")\n",
    "display(y_cropping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "#### Generate \"trench-row\" cropping output\n",
    "\n",
    "After determining your desired hyperparameters, set them in the next cell and run it to produce output for later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_in_y_list = copy.copy(y_cropping.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "#### Tune trench detection hyperparameters\n",
    "\n",
    "Next, we will detect the positions of trenchs in the y-cropped images as follows:\n",
    "\n",
    "1. Reducing each 2D image to a 1D signal along the x-axis by computing the qth percentile of the data along the y-axis.\n",
    "2. Determine the signal background by smooth this signal using a large median kernel.\n",
    "3. Subtract the background signal.\n",
    "4. Smooth the resultant signal using a median kernel.\n",
    "5. Use a [otsu threhsold](https://imagej.net/Auto_Threshold#Otsu) to determine the trench midpoint poisitons.\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**x_percentile (int)** : Percentile to use for step 1.\n",
    "\n",
    "**background_kernel_x (int)** : Median kernel size to use for step 2.\n",
    "\n",
    "**smoothing_kernel_x (int)** : Median kernel size to use for step 4.\n",
    "\n",
    "**otsu_nbins (int)** : Number of bins to use in the Otsu's method histogram.\n",
    "\n",
    "**otsu_scaling (float)** : Scaling factor to apply to the threshold determined by Otsu's method.\n",
    "\n",
    "**vertical_spacing (float)** : Parameter for setting the distance of plots being viewed.\n",
    "\n",
    "Running the following widget will display the smoothed 1-D signal for each of your timepoints. In addition, the threshold value for each fov will be displayed as a red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_detection = interactive(\n",
    "    interactive_kymograph.preview_x_percentiles,\n",
    "    {\"manual\": True},\n",
    "    cropped_in_y_list=fixed(cropped_in_y_list),\n",
    "    t=IntSlider(value=0, min=0, max=cropped_in_y_list[0].shape[4] - 1, step=1),\n",
    "    x_percentile=IntSlider(value=85, min=50, max=100, step=1),\n",
    "    background_kernel_x=IntSlider(value=21, min=1, max=601, step=20),\n",
    "    smoothing_kernel_x=IntSlider(value=9, min=1, max=31, step=2),\n",
    "    otsu_nbins=IntSlider(value=50, min=10, max=200, step=10),\n",
    "    otsu_scaling=FloatSlider(value=0.25, min=0.0, max=2.0, step=0.01),\n",
    "    vertical_spacing=FloatSlider(value=0.9, min=0.0, max=2.0, step=0.01),\n",
    ")\n",
    "display(trench_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### Generate trench detection output\n",
    "\n",
    "After determining your desired hyperparameters, set them in the next cell and run it to produce output for later steps. **Note: The thresholding parameters do not need to be specified at this point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_x_percentiles_list = trench_detection.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "#### Check midpoint drift\n",
    "\n",
    "Next, we will perform x-dimension drift correction of our detected midpoints as follows:\n",
    "\n",
    "1. Begin at t=1\n",
    "2. For $m \\in \\{midpoints(t)\\}$ assign $n \\in \\{midpoints(t-1)\\}$ to m if n is the closest midpoint to m at time $t-1$,\n",
    "points that are not the closest midpoint to any midpoints in m will not be mapped.\n",
    "3. Compute the translation of each midpoint at time.\n",
    "4. Take the average of this value as the x-dimension drift from time t-1 to t.\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**vertical_spacing (float)** : Parameter for setting the distance of plots being viewed.\n",
    "\n",
    "Running the following widget will display the detected midpoints for each of your timepoints. If there is too much sparsity, or discontinuity, your drift correction will not be accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "midpoint_drift = interactive(\n",
    "    interactive_kymograph.preview_midpoints,\n",
    "    {\"manual\": True},\n",
    "    smoothed_x_percentiles_list=fixed(smoothed_x_percentiles_list),\n",
    "    vertical_spacing=FloatSlider(value=0.8, min=0.0, max=2.0, step=0.01),\n",
    ")\n",
    "display(midpoint_drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "#### Generate midpoint drift output\n",
    "\n",
    "After determining your desired hyperparameters, set them in the next cell and run it to produce output for later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_midpoints_list, x_drift_list = midpoint_drift.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### Tune trench cropping hyperparameters\n",
    "\n",
    "Trench cropping simply uses the drift-corrected midpoints as a reference and crops out some fixed length around them to produce an output kymograph\n",
    "\n",
    "This method uses the following `kwargs`, which you can tune here:\n",
    "\n",
    "**trench_width_x (int)** : Trench width to use for cropping.\n",
    "\n",
    "**vertical_spacing (float)** : Parameter for setting the distance of plots being viewed.\n",
    "\n",
    "Running the following widget will display a random kymograph for each row in each fov.\n",
    "\n",
    "It will also produce midpoint plots showing retained midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "interact_manual(\n",
    "    interactive_kymograph.preview_kymographs,\n",
    "    cropped_in_y_list=fixed(cropped_in_y_list),\n",
    "    all_midpoints_list=fixed(all_midpoints_list),\n",
    "    x_drift_list=fixed(x_drift_list),\n",
    "    trench_width_x=IntSlider(value=30, min=10, max=50, step=2),\n",
    "    trench_present_thr=FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05),\n",
    "    vertical_spacing=FloatSlider(value=0.8, min=0.0, max=2.0, step=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### Export and save hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_kymograph.process_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_kymograph.write_param_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Generate Kymograph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "#### Start Dask Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.cluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=100,\n",
    "    memory=\"8GB\",\n",
    "    working_directory=\"/n/scratch2/de64/2019-11-09_CN_Growth_Curve/\",\n",
    ")\n",
    "dask_controller.startdask()\n",
    "dask_controller.daskcluster.start_workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust = tr.kymograph.kymograph_cluster(\n",
    "    headpath=headpath, trenches_per_file=100000, paramfile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust.generate_kymographs(dask_controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust.post_process(dask_controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "#### Check kymograph statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "kymoclust.kymo_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "#### Shutdown Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage as sk\n",
    "import trenchripper as tr\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_handle = tr.utils.pandas_hdf5_handler(\n",
    "    \"/n/scratch2/de64/2020-01-10_strains_46_47/cycle_1/metadata.hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_meta = meta_handle.read_df(\"kymograph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_meta[:1000:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_dict = {}\n",
    "with h5py.File(\n",
    "    \"/n/scratch2/de64/2020-01-10_strains_46_47/cycle_1/kymograph/kymograph_0.hdf5\"\n",
    ") as infile:\n",
    "    for key in infile.keys():\n",
    "        cycle_1_dict[key] = infile[key][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_rfp_imgs = cycle_1_dict[\"RFP\"][:, 0, 50:150]\n",
    "cycle_1_cy5_imgs = cycle_1_dict[\"Cy5\"][:, 0, 50:150]\n",
    "cycle_1_cy7_imgs = cycle_1_dict[\"Cy7\"][:, 0, 50:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_rfp = np.percentile(\n",
    "    cycle_1_rfp_imgs.reshape(cycle_1_rfp_imgs.shape[0], -1), 90, axis=1\n",
    ")\n",
    "cycle_1_cy5 = np.percentile(\n",
    "    cycle_1_cy5_imgs.reshape(cycle_1_cy5_imgs.shape[0], -1), 90, axis=1\n",
    ")\n",
    "cycle_1_cy7 = np.percentile(\n",
    "    cycle_1_cy7_imgs.reshape(cycle_1_cy7_imgs.shape[0], -1), 90, axis=1\n",
    ")\n",
    "\n",
    "# cycle_1_rfp = np.mean(cycle_1_rfp_imgs.reshape(cycle_1_rfp_imgs.shape[0],-1),axis=1)\n",
    "# cycle_1_cy5 = np.mean(cycle_1_cy5_imgs.reshape(cycle_1_cy5_imgs.shape[0],-1),axis=1)\n",
    "# cycle_1_cy7 = np.mean(cycle_1_cy7_imgs.reshape(cycle_1_cy7_imgs.shape[0],-1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_meta[\"RFP\"] = cycle_1_rfp\n",
    "cycle_1_meta[\"CY5\"] = cycle_1_cy5\n",
    "cycle_1_meta[\"CY7\"] = cycle_1_cy7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_meta[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_handle = tr.utils.pandas_hdf5_handler(\n",
    "    \"/n/scratch2/de64/2020-01-10_strains_46_47/cycle_2/metadata.hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_2_meta = meta_handle.read_df(\"kymograph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_2_meta[:1000:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_2_dict = {}\n",
    "with h5py.File(\n",
    "    \"/n/scratch2/de64/2020-01-10_strains_46_47/cycle_2/kymograph/kymograph_0.hdf5\"\n",
    ") as infile:\n",
    "    for key in infile.keys():\n",
    "        cycle_2_dict[key] = infile[key][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_2_rfp_imgs = cycle_2_dict[\"RFP\"][:, 0, 50:150]\n",
    "cycle_2_cy5_imgs = cycle_2_dict[\"Cy5\"][:, 0, 50:150]\n",
    "cycle_2_cy7_imgs = cycle_2_dict[\"Cy7\"][:, 0, 50:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_2_rfp = np.percentile(\n",
    "    cycle_2_rfp_imgs.reshape(cycle_2_rfp_imgs.shape[0], -1), 90, axis=1\n",
    ")\n",
    "cycle_2_cy5 = np.percentile(\n",
    "    cycle_2_cy5_imgs.reshape(cycle_2_cy5_imgs.shape[0], -1), 90, axis=1\n",
    ")\n",
    "cycle_2_cy7 = np.percentile(\n",
    "    cycle_2_cy7_imgs.reshape(cycle_2_cy7_imgs.shape[0], -1), 90, axis=1\n",
    ")\n",
    "\n",
    "# cycle_2_rfp = np.mean(cycle_2_rfp_imgs.reshape(cycle_2_rfp_imgs.shape[0],-1),axis=1)\n",
    "# cycle_2_cy5 = np.mean(cycle_2_cy5_imgs.reshape(cycle_2_cy5_imgs.shape[0],-1),axis=1)\n",
    "# cycle_2_cy7 = np.mean(cycle_2_cy7_imgs.reshape(cycle_2_cy7_imgs.shape[0],-1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_2_meta[\"RFP\"] = cycle_2_rfp\n",
    "cycle_2_meta[\"CY5\"] = cycle_2_cy5\n",
    "cycle_2_meta[\"CY7\"] = cycle_2_cy7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_2_meta[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_meta[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_meta = cycle_1_meta.set_index(\n",
    "    [\"fov\", \"row\", \"trench\"], drop=True, append=False, inplace=False\n",
    ")\n",
    "cycle_1_meta = cycle_1_meta.sort_index()\n",
    "cycle_2_meta = cycle_2_meta.set_index(\n",
    "    [\"fov\", \"row\", \"trench\"], drop=True, append=False, inplace=False\n",
    ")\n",
    "cycle_2_meta = cycle_2_meta.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = []\n",
    "for fov in cycle_1_meta.index.get_level_values(\"fov\").unique().tolist():\n",
    "    working_cycle_1_meta = copy.copy(cycle_1_meta.loc[fov])\n",
    "    working_cycle_2_meta = copy.copy(cycle_2_meta.loc[fov])\n",
    "    x_diff_mat = np.subtract.outer(\n",
    "        working_cycle_1_meta[\"x (global)\"], working_cycle_2_meta[\"x (global)\"]\n",
    "    )\n",
    "    y_diff_mat = np.subtract.outer(\n",
    "        working_cycle_1_meta[\"y (global)\"], working_cycle_2_meta[\"y (global)\"]\n",
    "    )\n",
    "    dist_mat = (x_diff_mat**2 + y_diff_mat**2) ** (1 / 2)\n",
    "    matched_idx = np.argmin(dist_mat, axis=1)\n",
    "    matched_cycle_2 = working_cycle_2_meta.iloc[matched_idx]\n",
    "    working_cycle_1_meta[\"RFP2\"] = working_cycle_2_meta[\"RFP\"]\n",
    "    working_cycle_1_meta[\"CY52\"] = working_cycle_2_meta[\"CY5\"]\n",
    "    working_cycle_1_meta[\"CY72\"] = working_cycle_2_meta[\"CY7\"]\n",
    "    working_cycle_1_meta[\"fov\"] = fov\n",
    "    out_df.append(working_cycle_1_meta)\n",
    "out_df = pd.concat(out_df)\n",
    "\n",
    "out_df = out_df[~out_df[\"RFP2\"].isna()]\n",
    "out_df = out_df[~out_df[\"CY52\"].isna()]\n",
    "out_df = out_df[~out_df[\"CY72\"].isna()]\n",
    "\n",
    "out_df = out_df.reset_index(inplace=False)\n",
    "out_df = out_df.set_index(\n",
    "    [\"fov\", \"row\", \"trench\"], drop=True, append=False, inplace=False\n",
    ")\n",
    "out_df = out_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rfp = np.array(out_df.loc[1:][\"RFP\"].tolist() + out_df.loc[1:][\"RFP2\"].tolist())\n",
    "all_cy5 = np.array(out_df.loc[1:][\"CY5\"].tolist() + out_df.loc[1:][\"CY52\"].tolist())\n",
    "all_cy7 = np.array(out_df.loc[1:][\"CY7\"].tolist() + out_df.loc[1:][\"CY72\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(out_df.loc[1:][\"RFP\"].tolist(), bins=200)\n",
    "plt.xlim(600, 1000)\n",
    "plt.show()\n",
    "plt.hist(out_df.loc[1:][\"RFP2\"].tolist(), bins=200)\n",
    "plt.xlim(600, 1000)\n",
    "plt.show()\n",
    "plt.hist(all_rfp, bins=200)\n",
    "plt.xlim(600, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(out_df.loc[1:][\"CY5\"].tolist(), bins=200)\n",
    "plt.xlim(300, 5000)\n",
    "plt.show()\n",
    "plt.hist(out_df.loc[1:][\"CY52\"].tolist(), bins=200)\n",
    "plt.xlim(300, 5000)\n",
    "plt.show()\n",
    "plt.hist(all_cy5, bins=200)\n",
    "plt.xlim(300, 5000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(out_df.loc[1:][\"CY7\"].tolist(), bins=200)\n",
    "plt.xlim(200, 500)\n",
    "plt.show()\n",
    "plt.hist(out_df.loc[1:][\"CY72\"].tolist(), bins=200)\n",
    "plt.xlim(200, 500)\n",
    "plt.show()\n",
    "plt.hist(all_cy7, bins=200)\n",
    "plt.xlim(200, 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_thr = np.median(all_rfp)\n",
    "cy5_thr = np.median(all_cy5)\n",
    "cy7_thr = np.median(all_cy7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfp_thr, cy5_thr, cy7_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_thr = sk.filters.threshold_triangle(all_rfp)\n",
    "cy5_thr = sk.filters.threshold_triangle(all_cy5)\n",
    "cy7_thr = sk.filters.threshold_triangle(all_cy7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfp_thr, cy5_thr, cy7_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## practical best\n",
    "rfp_thr = sk.filters.threshold_triangle(all_rfp)\n",
    "cy5_thr = np.median(all_cy5)\n",
    "cy7_thr = sk.filters.threshold_triangle(all_cy7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfp_thr, cy5_thr, cy7_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_ratio = out_df.loc[1:][\"RFP\"] / out_df.loc[1:][\"RFP2\"]\n",
    "cy5_ratio = out_df.loc[1:][\"CY5\"] / out_df.loc[1:][\"CY52\"]\n",
    "cy7_ratio = out_df.loc[1:][\"CY7\"] / out_df.loc[1:][\"CY72\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rfp_ratio, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cy5_ratio, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cy7_ratio, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_0 = rfp_ratio > 1.05\n",
    "rfp_1 = rfp_ratio < 0.95\n",
    "rfp_ambiguous = (~rfp_0) & (~rfp_1)\n",
    "cy5_0 = cy5_ratio > 1.05\n",
    "cy5_1 = cy5_ratio < 0.95\n",
    "cy5_ambiguous = (~cy5_0) & (~cy5_1)\n",
    "cy7_0 = cy7_ratio > 1.05\n",
    "cy7_1 = cy7_ratio < 0.95\n",
    "cy7_ambiguous = (~cy7_0) & (~cy7_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_ambiguous = np.any(\n",
    "    np.array([rfp_ambiguous, cy5_ambiguous, cy7_ambiguous]), axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_cyc_ambiguous = rfp_1_onecyc & cy5_1_onecyc & cy7_1_onecyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous = one_cyc_ambiguous & ratio_ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_1_onecyc = out_df.loc[1:][\"RFP\"] < (rfp_thr)\n",
    "TP = np.sum((rfp_1_onecyc & rfp_1) & ~rfp_ambiguous)\n",
    "FP = np.sum((rfp_1_onecyc & rfp_0) & ~rfp_ambiguous)\n",
    "FN = np.sum(((~rfp_1_onecyc) & rfp_1) & ~rfp_ambiguous)\n",
    "TN = np.sum(((~rfp_1_onecyc) & rfp_0) & ~rfp_ambiguous)\n",
    "marginal_rfp_err = (FP + FN) / (TP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TP, FP, FN, TN)\n",
    "print(marginal_rfp_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cy5_1_onecyc = out_df.loc[1:][\"CY5\"] < (cy5_thr)\n",
    "TP = np.sum((cy5_1_onecyc & cy5_1) & ~cy5_ambiguous)\n",
    "FP = np.sum((cy5_1_onecyc & cy5_0) & ~cy5_ambiguous)\n",
    "FN = np.sum(((~cy5_1_onecyc) & cy5_1) & ~cy5_ambiguous)\n",
    "TN = np.sum(((~cy5_1_onecyc) & cy5_0) & ~cy5_ambiguous)\n",
    "marginal_cy5_err = (FP + FN) / (TP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TP, FP, FN, TN)\n",
    "print(marginal_cy5_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "cy7_1_onecyc = out_df.loc[1:][\"CY7\"] < (cy7_thr)\n",
    "TP = np.sum((cy7_1_onecyc & cy7_1) & ~cy7_ambiguous)\n",
    "FP = np.sum((cy7_1_onecyc & cy7_0) & ~cy7_ambiguous)\n",
    "FN = np.sum(((~cy7_1_onecyc) & cy7_1) & ~cy7_ambiguous)\n",
    "TN = np.sum(((~cy7_1_onecyc) & cy7_0) & ~cy7_ambiguous)\n",
    "marginal_cy7_err = (FP + FN) / (TP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TP, FP, FN, TN)\n",
    "print(marginal_cy7_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_ratio_err = np.sum(rfp_0) / (np.sum(rfp_0) + np.sum(rfp_1))\n",
    "cy5_ratio_err = np.sum(cy5_1) / (np.sum(cy5_0) + np.sum(cy5_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfp_ratio_err, cy5_ratio_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_noratio_err = np.sum((~rfp_1_onecyc) & (~one_cyc_ambiguous)) / (\n",
    "    np.sum((rfp_1_onecyc) & (~one_cyc_ambiguous))\n",
    "    + np.sum((~rfp_1_onecyc) & (~one_cyc_ambiguous))\n",
    ")\n",
    "cy5_noratio_err = np.sum((cy5_1_onecyc) & (~one_cyc_ambiguous)) / (\n",
    "    np.sum((cy5_1_onecyc) & (~one_cyc_ambiguous))\n",
    "    + np.sum((~cy5_1_onecyc) & (~one_cyc_ambiguous))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfp_noratio_err, cy5_noratio_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(one_cyc_ambiguous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_cy5_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_signal = cycle_1_cy5_imgs[cycle_1_cy5 < tri_thr]\n",
    "signal = cycle_1_cy5_imgs[cycle_1_cy5 > tri_thr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(signal[11000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    " - it does not look like any of the dyes are significantly better/worse than the others\n",
    " - Once accounting for ambiguous trenches (probably empty), the error rates drop significantly (to under 2%) for RFP and CY5\n",
    "     - this is possible to compute because they both have the same bit throughout the population\n",
    " - As for marginal error (assuming the ratio measurment as ground truth), the rates hover at around 5% \n",
    "     - interpretation is difficult since two bits are uniform across the population\n",
    "     - at least in the case of cy7, the margin is ~5%\n",
    " - overall, I have the sense that the error rate is between 2-5% (this will possibly improve with better filtering of empty trenches and other methodological improvements to the signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom = sp.stats.binom(30, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(30))\n",
    "y = binom.pmf(x)\n",
    "\n",
    "N = 100000\n",
    "plt.bar(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_one_away = 1.0 - ((1.0 - y[1]) ** (N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_one_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_two_away = 1.0 - ((1.0 - y[2]) ** (N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_two_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(3))\n",
    "y = binom.pmf(x)\n",
    "\n",
    "N = 100000\n",
    "plt.bar(x, y * N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_len = 30\n",
    "error_rate = 0.02\n",
    "n_barcodes = 100000\n",
    "exp_barcodes = 10000\n",
    "\n",
    "barcodes = np.random.choice(np.array([True, False]), size=(n_barcodes, barcode_len))\n",
    "sampled_idx = np.random.choice(range(barcodes.shape[0]), size=(exp_barcodes,))\n",
    "sampled_barcodes = barcodes[sampled_idx]\n",
    "errors = np.random.choice(\n",
    "    [True, False],\n",
    "    size=(sampled_barcodes.shape),\n",
    "    replace=True,\n",
    "    p=[error_rate, 1.0 - error_rate],\n",
    ")\n",
    "read_barcodes = copy.copy(sampled_barcodes)\n",
    "read_barcodes[errors] = ~read_barcodes[errors]\n",
    "hamming_arr = barcode_len - np.sum(\n",
    "    sampled_barcodes[:, np.newaxis, :] == read_barcodes[np.newaxis, :, :], axis=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hamming_arr.flatten(), range=(0, 6), bins=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_barcodes[:, np.newaxis, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_barcodes[np.newaxis, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_barcodes == read_barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_idx = np.random.choice(range(barcodes.shape[0]), size=(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes[sampled_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_assignment_err(\n",
    "    barcode_len=18, error_rate=0.05, n_barcodes=100000, exp_barcodes=1000000\n",
    "):\n",
    "    barcodes = np.random.choice(np.array([True, False]), size=(n_barcodes, barcode_len))\n",
    "    sampled_idx = np.random.choice(range(barcodes.shape[0]), size=(exp_barcodes,))\n",
    "    sampled_barcodes = barcodes[sampled_idx]\n",
    "\n",
    "    read_barcodes = []\n",
    "\n",
    "    for i in range(sampled_barcodes.shape[0]):\n",
    "        errors = np.random.choice(\n",
    "            [True, False],\n",
    "            size=(barcode_len,),\n",
    "            replace=True,\n",
    "            p=[error_rate, 1.0 - error_rate],\n",
    "        )\n",
    "        barcode = sampled_barcodes[i]\n",
    "        error_barcode = copy.copy(barcode)\n",
    "        error_barcode[errors] = ~error_barcode[errors]\n",
    "        read_barcodes.append(error_barcode)\n",
    "\n",
    "    read_barcode_arr = np.array(read_barcodes)\n",
    "\n",
    "    read_barcode_arr = np.array(read_barcodes)\n",
    "\n",
    "    used_barcodes_indices = np.random.choice(\n",
    "        len(all_barcodes), size=(used_barcode_num,), replace=True\n",
    "    )\n",
    "    used_barcodes = []\n",
    "    for idx in used_barcodes_indices:\n",
    "        barcode = all_barcodes[idx]\n",
    "        used_barcodes.append(barcode)\n",
    "    read_barcode_indices = np.random.choice(\n",
    "        len(used_barcodes), size=(read_barcode_num,), replace=True\n",
    "    )\n",
    "    read_barcodes = []\n",
    "    true_barcodes = []\n",
    "    for idx in read_barcode_indices:\n",
    "        errors = np.random.choice(\n",
    "            [True, False],\n",
    "            size=(barcode_len,),\n",
    "            replace=True,\n",
    "            p=[error_rate, 1.0 - error_rate],\n",
    "        )\n",
    "        barcode = used_barcodes[idx]\n",
    "        true_barcodes.append(barcode)\n",
    "        error_barcode = copy.copy(barcode)\n",
    "        error_barcode[errors] = ~error_barcode[errors]\n",
    "        read_barcodes.append(error_barcode)\n",
    "    used_barcode_arr = np.array(used_barcodes)\n",
    "    read_barcode_arr = np.array(read_barcodes)\n",
    "    hdist_arr = []\n",
    "    for i in range(read_barcode_arr.shape[0]):\n",
    "        read_barcode = read_barcode_arr[i]\n",
    "        xor_out = np.logical_xor(read_barcode, used_barcode_arr)\n",
    "        h_dists = np.sum(xor_out, axis=1)\n",
    "        hdist_arr.append(h_dists)\n",
    "    hdist_arr = np.array(hdist_arr)\n",
    "    matched_indices = np.argmin(hdist_arr, axis=1)\n",
    "    matched_idx_hdist = np.min(hdist_arr, axis=1)\n",
    "    within_tolerence = matched_idx_hdist < 3\n",
    "\n",
    "    true_match = (matched_indices == read_barcode_indices)[within_tolerence]\n",
    "    perc_discarded = np.sum(~within_tolerence) / read_barcode_num\n",
    "    err_rate = np.sum(~true_match) / np.sum(within_tolerence)\n",
    "\n",
    "    return err_rate, perc_discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_assignment_err(30, 0.03, 10000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_assignment_err(12, 0.02, 10000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_lens = [10, 15, 20]\n",
    "error_rates = [0.0, 0.02, 0.05, 0.1]\n",
    "err_rates = []\n",
    "perc_discardeds = []\n",
    "for barcode_len in barcode_lens:\n",
    "    err_rates_list = []\n",
    "    perc_discardeds_list = []\n",
    "    for error_rate in error_rates:\n",
    "        err_rate, perc_discarded = compute_assignment_err(\n",
    "            barcode_len, error_rate, 10000, 1000\n",
    "        )\n",
    "        err_rates_list.append(err_rate)\n",
    "        perc_discardeds_list.append(perc_discarded)\n",
    "    err_rates.append(err_rates_list)\n",
    "    perc_discardeds.append(perc_discardeds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rates = np.array(err_rates)\n",
    "perc_discardeds = np.array(perc_discardeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_ratio = [np.round((1000 / (2**item)), decimals=4) for item in barcode_lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(err_rates, xticklabels=error_rates, yticklabels=subsample_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(perc_discardeds, xticklabels=error_rates, yticklabels=subsample_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(err_rates[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(err_rates[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(err_rates[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(err_rates[2, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
