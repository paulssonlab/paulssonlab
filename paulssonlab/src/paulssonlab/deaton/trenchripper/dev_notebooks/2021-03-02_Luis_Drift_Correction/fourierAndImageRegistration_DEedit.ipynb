{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from scipy.fftpack import fft2, fftshift, ifft2, ifftshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py_cache\n",
    "import paulssonlab.deaton.trenchripper.trenchripper as tr\n",
    "from paulssonlab.deaton.trenchripper.trenchripper import pandas_hdf5_handler\n",
    "from paulssonlab.deaton.trenchripper.trenchripper import writedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = \"/home/de64/scratch/de64/sync_folder/2021-01-28_lDE14/gfp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fft_drift_correction:\n",
    "    def __init__(self, vert_cross_w=-1, horiz_cross_w=-1):\n",
    "\n",
    "        self.vert_cross_w = vert_cross_w\n",
    "        self.horiz_cross_w = horiz_cross_w\n",
    "\n",
    "    def make_mask_cross(self, imgs_h, imgs_w, wy=-1, wx=-1, preview=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            imgs_h (int) Height of images\n",
    "            imgs_w (int) Width of images\n",
    "            wy (int) Height of cross\n",
    "            wx (int) Width of cross\n",
    "            preview (bool) If want to plot image\n",
    "        Returns\n",
    "            (imgs_h x imgs_w array)\n",
    "        \"\"\"\n",
    "\n",
    "        x0 = imgs_w // 2\n",
    "        y0 = imgs_h // 2\n",
    "\n",
    "        if wy == -1:\n",
    "            wy = imgs_h // 6\n",
    "\n",
    "        if wx == -1:\n",
    "            wx = imgs_w // 6\n",
    "\n",
    "        img_mask = np.zeros((imgs_h, imgs_w), dtype=bool)\n",
    "        img_mask[y0 - wy // 2 : y0 + wy // 2, :] = True\n",
    "        img_mask[:, x0 - wx // 2 : x0 + wx // 2] = True\n",
    "\n",
    "        if preview:\n",
    "            plt.imshow(img_mask)\n",
    "\n",
    "        return img_mask\n",
    "\n",
    "    def filter_fourier(self, imgs, img_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            imgs: (T, Y, X)\n",
    "            imgs_mask\n",
    "        Returns\n",
    "            Filtered image stack\n",
    "        \"\"\"\n",
    "        imgs_filt = np.zeros(imgs.shape, dtype=\"uint16\")\n",
    "\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img_fft = fftshift(fft2(imgs[i]))\n",
    "            img_fft[img_mask] = 0.0\n",
    "            img_fft = ifftshift(img_fft)\n",
    "            imgs_filt[i] = np.abs(ifft2(img_fft))\n",
    "        #         if i%20 == 0:\n",
    "        #             print(i)\n",
    "        return imgs_filt\n",
    "\n",
    "    def drift_correction_find_shifts(self, imgs, img_ref):\n",
    "        \"\"\"\n",
    "        Finds shifts for drift corarection\n",
    "\n",
    "        Returns:\n",
    "            shifts (array): shifts for each image in the stack ordered as row_shift (y-shift), column_shift (x-shift)\n",
    "        \"\"\"\n",
    "\n",
    "        shifts = np.zeros(\n",
    "            (imgs.shape[0], 2), dtype=int\n",
    "        )  # Stores the shifts, the first one is the shift of the second image (index 1) with respect to the first one (index 0),\n",
    "        # the second one is the shift of the third (index 2) with respect to the second (index 1)\n",
    "\n",
    "        for i in range(imgs.shape[0]):\n",
    "\n",
    "            # Compute shifts for a single image with respect to reference\n",
    "            shifts[i, :], _, _ = phase_cross_correlation(img_ref, imgs[i])\n",
    "\n",
    "        return shifts\n",
    "\n",
    "    def drift_correct_images(self, imgs, shifts):\n",
    "        \"\"\"\n",
    "        Applies shifts to return and save drift-corrected images. Returns and saves the corrected images\n",
    "        Parameters:\n",
    "            imgs: Image stack to correct (T, Y, X)\n",
    "            shifts (array): shifts for each image in the stack ordered as row_shift (y-shift), column_shift (x-shift)\n",
    "        Returns:\n",
    "            imgs_reg (array): Drift-corrected image stack\n",
    "        \"\"\"\n",
    "        # Calculate max abs value of shifts to define padding\n",
    "        max_shifts = np.max(np.abs(shifts), axis=0).astype(int)\n",
    "\n",
    "        imgs_median = np.median(imgs)  # TODO Does it have to be for each frame?\n",
    "        imgs_padded = np.pad(\n",
    "            imgs,\n",
    "            ((0, 0), (max_shifts[0], max_shifts[0]), (max_shifts[1], max_shifts[1])),\n",
    "            constant_values=(\n",
    "                (imgs_median, imgs_median),\n",
    "                (imgs_median, imgs_median),\n",
    "                (imgs_median, imgs_median),\n",
    "            ),\n",
    "        )\n",
    "        imgs_reg = np.zeros(imgs_padded.shape, dtype=\"uint16\")\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img_reg = np.roll(imgs_padded[i], shift=shifts[i, :], axis=(0, 1))\n",
    "            imgs_reg[i] = img_reg\n",
    "\n",
    "        # Crops the edges\n",
    "        imgs_reg = imgs_reg[\n",
    "            :,\n",
    "            max_shifts[0] : imgs_reg.shape[1] - max_shifts[0],\n",
    "            max_shifts[1] : imgs_reg.shape[2] - max_shifts[1],\n",
    "        ]\n",
    "\n",
    "        return imgs_reg\n",
    "\n",
    "\n",
    "class fft_drift_correction_cluster(fft_drift_correction):\n",
    "    def __init__(\n",
    "        self, headpath, outputfolder, driftchannel, vert_cross_w=-1, horiz_cross_w=-1\n",
    "    ):\n",
    "        super(fft_drift_correction_cluster, self).__init__(\n",
    "            vert_cross_w=vert_cross_w, horiz_cross_w=horiz_cross_w\n",
    "        )\n",
    "\n",
    "        self.headpath = headpath\n",
    "        self.metapath = headpath + \"/metadata.hdf5\"\n",
    "        self.hdf5path = headpath + \"/hdf5\"\n",
    "        self.outputpath = headpath + \"/\" + outputfolder\n",
    "        self.driftchannel = driftchannel\n",
    "\n",
    "        self.meta_handle = pandas_hdf5_handler(self.metapath)\n",
    "        self.metadata = self.meta_handle.read_df(\"global\", read_metadata=True).metadata\n",
    "\n",
    "        self.chunk_shape = (1, self.metadata[\"height\"], self.metadata[\"width\"])\n",
    "        chunk_bytes = 2 * np.multiply.accumulate(np.array(self.chunk_shape))[-1]\n",
    "        self.chunk_cache_mem_size = 2 * chunk_bytes\n",
    "\n",
    "    def drift_correct_file(self, file_idx, ref_file_idx, ref_img_idx):\n",
    "        with h5py.File(\n",
    "            self.hdf5path + \"/hdf5_\" + str(ref_file_idx) + \".hdf5\", \"r\"\n",
    "        ) as input_file:\n",
    "            ref_img = input_file[self.driftchannel][\n",
    "                ref_img_idx : ref_img_idx + 1\n",
    "            ]  # 1,y,x\n",
    "\n",
    "        with h5py.File(\n",
    "            self.hdf5path + \"/hdf5_\" + str(file_idx) + \".hdf5\", \"r\"\n",
    "        ) as input_file:\n",
    "            imgs = input_file[self.driftchannel][:]  # t,y,x\n",
    "\n",
    "        img_mask = self.make_mask_cross(\n",
    "            imgs_h=imgs.shape[1],\n",
    "            imgs_w=imgs.shape[2],\n",
    "            wy=self.vert_cross_w,\n",
    "            wx=self.horiz_cross_w,\n",
    "        )\n",
    "\n",
    "        ref_imgs_filt = self.filter_fourier(ref_img, img_mask)\n",
    "        imgs_filt = self.filter_fourier(imgs, img_mask)\n",
    "\n",
    "        shifts = self.drift_correction_find_shifts(imgs_filt, ref_imgs_filt[0])\n",
    "\n",
    "        with h5py_cache.File(\n",
    "            self.outputpath + \"/hdf5_\" + str(file_idx) + \".hdf5\",\n",
    "            \"w\",\n",
    "            chunk_cache_mem_size=self.chunk_cache_mem_size,\n",
    "        ) as output_file:\n",
    "            with h5py.File(\n",
    "                self.hdf5path + \"/hdf5_\" + str(file_idx) + \".hdf5\", \"r\"\n",
    "            ) as input_file:\n",
    "                for channel in input_file.keys():\n",
    "                    imgs_reg = self.drift_correct_images(input_file[channel], shifts)\n",
    "                    hdf5_dataset = output_file.create_dataset(\n",
    "                        channel, data=imgs_reg, dtype=\"uint16\"\n",
    "                    )\n",
    "\n",
    "        return file_idx\n",
    "\n",
    "    def dask_segment(self, dask_controller):\n",
    "        writedir(self.outputpath, overwrite=True)\n",
    "        dask_controller.futures = {}\n",
    "\n",
    "        global_df = self.meta_handle.read_df(\"global\")\n",
    "        file_list = global_df[\"File Index\"].unique().tolist()\n",
    "\n",
    "        file_to_fov_dict = (\n",
    "            global_df.groupby(\"File Index\")\n",
    "            .apply(lambda x: x.index.get_level_values(\"fov\").unique()[0])\n",
    "            .to_dict()\n",
    "        )\n",
    "        template_file_index_dict = (\n",
    "            global_df.groupby(\"fov\").apply(lambda x: np.min(x[\"File Index\"])).to_dict()\n",
    "        )\n",
    "        template_image_index_dict = (\n",
    "            global_df.groupby(\"fov\").apply(lambda x: np.min(x[\"Image Index\"])).to_dict()\n",
    "        )\n",
    "\n",
    "        num_file_jobs = len(file_list)\n",
    "\n",
    "        random_priorities = np.random.uniform(size=(num_file_jobs,))\n",
    "        for k, file_idx in enumerate(file_list):\n",
    "            priority = random_priorities[k]\n",
    "\n",
    "            fov_idx = file_to_fov_dict[file_idx]\n",
    "            ref_file_idx = template_file_index_dict[fov_idx]\n",
    "            ref_img_idx = template_image_index_dict[fov_idx]\n",
    "\n",
    "            future = dask_controller.daskclient.submit(\n",
    "                self.drift_correct_file,\n",
    "                file_idx,\n",
    "                ref_file_idx,\n",
    "                ref_img_idx,\n",
    "                retries=0,\n",
    "                priority=priority,\n",
    "            )\n",
    "            dask_controller.futures[\"Drift Correction: \" + str(file_idx)] = future\n",
    "        #         for k,file_idx in enumerate(file_list):\n",
    "        #             priority = random_priorities[k]\n",
    "\n",
    "        #             future = dask_controller.daskclient.submit(self.segmentation_completed,dask_controller.futures[\"Segmentation: \" + str(file_idx)],retries=0,priority=priority)\n",
    "        #             dask_controller.futures[\"Segmentation Completed: \" + str(file_idx)] = future\n",
    "        gathered_tasks = dask_controller.daskclient.gather(\n",
    "            [\n",
    "                dask_controller.futures[\"Drift Correction: \" + str(file_idx)]\n",
    "                for file_idx in file_list\n",
    "            ],\n",
    "            errors=\"skip\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_drift_clust = fft_drift_correction_cluster(headpath, \"luistest\", \"RFP-Penta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=100,\n",
    "    memory=\"2GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.daskclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
