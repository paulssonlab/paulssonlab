{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Steady-state Analysis of lDE20 (with lineage Dataframe ready)\n",
    "\n",
    "- Note that there are fluctuations in the illumination intensity which may be resulting in pathological behavior from the reporter\n",
    "\n",
    "- Consider either normalizing this out or fixing the underlying problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import paulssonlab.deaton.trenchripper.trenchripper as tr\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_bins(df, t_label, y_labels, min_tpt, max_tpt, bins):\n",
    "    del_tpt = max_tpt - min_tpt\n",
    "    intervals = np.linspace(min_tpt, max_tpt, num=bins, dtype=float)\n",
    "\n",
    "    timeseries_bin_dfs = []\n",
    "\n",
    "    for i in range(len(intervals) - 1):\n",
    "        bin_df = {}\n",
    "        bin_df[\"Bin Mean Timepoint\"] = np.mean(intervals[i : i + 2])\n",
    "        bin_df[\"Timepoint Bin\"] = i\n",
    "        for y_label in y_labels:\n",
    "            bin_df[y_label + \": Bin Values\"] = df.apply(\n",
    "                lambda x: x[y_label][\n",
    "                    (x[t_label] >= intervals[i]) & (x[t_label] < intervals[i + 1])\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "            bin_df[y_label + \": Mean\"] = bin_df[y_label + \": Bin Values\"].apply(\n",
    "                lambda x: np.mean(x)\n",
    "            )\n",
    "            bin_df[y_label + \": Standard Deviation\"] = bin_df[\n",
    "                y_label + \": Bin Values\"\n",
    "            ].apply(lambda x: np.std(x))\n",
    "            bin_df[y_label + \": CV\"] = (\n",
    "                bin_df[y_label + \": Standard Deviation\"] / bin_df[y_label + \": Mean\"]\n",
    "            )\n",
    "\n",
    "        timeseries_bin_df = pd.DataFrame(bin_df)\n",
    "        timeseries_bin_df.index = df.index\n",
    "        timeseries_bin_dfs.append(timeseries_bin_df)\n",
    "    timeseries_bin_df_output = (\n",
    "        pd.concat(timeseries_bin_dfs).join(df).set_index(\"sgRNA\").sort_index()\n",
    "    )\n",
    "\n",
    "    return timeseries_bin_df_output\n",
    "\n",
    "\n",
    "def filter_strong_KOs(df, sampling_thr=4, n_strongest=2):\n",
    "    for i in range(sampling_thr, 0, -1):\n",
    "        sampling_mask = df[\"N Observations\"] >= sampling_thr\n",
    "        mismatch_series = df[sampling_mask][\"N Mismatch\"]\n",
    "\n",
    "        for n in range(n_strongest, 0, -1):\n",
    "            if len(mismatch_series) >= n:\n",
    "                keep_indices = np.argsort(mismatch_series)[:n]\n",
    "                out_df = df[sampling_mask].iloc[keep_indices]\n",
    "\n",
    "                return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Initial Data Processing\n",
    "\n",
    "Here, I am going to try and replicate (to some extant) the corrections from \"Genomewide phenotypic analysis of growth, cell morphogenesis, and cell cycle events in Escherichia coli\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### Start Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpath = (\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Barcodes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller = tr.trcluster.dask_controller(\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=10,\n",
    "    memory=\"16GB\",\n",
    "    working_directory=headpath + \"/dask\",\n",
    ")\n",
    "dask_controller.startdask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_controller.displaydashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_output_df_pd = pd.read_pickle(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/2021-07-26_lDE20_Lineage_Analysis.pkl\"\n",
    ")\n",
    "final_output_df_pd = final_output_df_pd[\n",
    "    ~final_output_df_pd[\"final cell timepoints list\"].isna()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Filter for \"Normal\" Sizes at Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_timepoint_cutoff = 30\n",
    "gaussian_subsample = 0.2\n",
    "\n",
    "filter_params = [\n",
    "    \"delS list\",\n",
    "    \"Sb list\",\n",
    "    \"Sd list\",\n",
    "    \"delL list\",\n",
    "    \"Lb list\",\n",
    "    \"Ld list\",\n",
    "    \"Mean Area Increment list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    \"Mean Width list\",\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Delta t list\",\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "]\n",
    "\n",
    "final_output_df_pd_dask = dd.from_pandas(final_output_df_pd, npartitions=100).persist()\n",
    "final_output_df_pd_dask[\"Early Timepoint Mask\"] = final_output_df_pd_dask[\n",
    "    \"cell timepoints list\"\n",
    "].apply(\n",
    "    lambda x: np.array([item if (type(item) is int) else 10000000 for item in x])\n",
    "    < early_timepoint_cutoff,\n",
    "    meta=(None, \"object\"),\n",
    ")\n",
    "\n",
    "for filter_param in filter_params:\n",
    "    early_param_series = final_output_df_pd_dask.apply(\n",
    "        lambda x: np.array(x[filter_param])[x[\"Early Timepoint Mask\"]]\n",
    "        if type(x[filter_param]) is list\n",
    "        else np.array([]),\n",
    "        axis=1,\n",
    "        meta=(None, \"object\"),\n",
    "    )\n",
    "    all_param_values = [\n",
    "        val\n",
    "        for item in early_param_series.sample(frac=gaussian_subsample)\n",
    "        .compute()\n",
    "        .tolist()\n",
    "        for val in item\n",
    "    ]\n",
    "    gaussian_fit = sp.stats.norm.fit(all_param_values)\n",
    "    gaussian_fit = sp.stats.norm(loc=gaussian_fit[0], scale=gaussian_fit[1])\n",
    "\n",
    "    final_output_df_pd[filter_param + \": Probability\"] = early_param_series.apply(\n",
    "        lambda x: np.exp(np.sum(gaussian_fit.logpdf(x)) / len(x)), meta=float\n",
    "    ).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentile_threshold = 10\n",
    "\n",
    "plt.figure(figsize=(22, 16))\n",
    "query_list = []\n",
    "for i, filter_param in enumerate(filter_params):\n",
    "    prob_threshold = np.nanpercentile(\n",
    "        final_output_df_pd[filter_param + \": Probability\"].tolist(),\n",
    "        percentile_threshold,\n",
    "    )\n",
    "    query = \"`\" + filter_param + \": Probability` > \" + str(prob_threshold)\n",
    "    query_list.append(query)\n",
    "\n",
    "    min_v, max_v = np.min(final_output_df_pd[filter_param + \": Probability\"]), np.max(\n",
    "        final_output_df_pd[filter_param + \": Probability\"]\n",
    "    )\n",
    "\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.title(filter_param)\n",
    "    plt.hist(\n",
    "        final_output_df_pd[\n",
    "            final_output_df_pd[filter_param + \": Probability\"] < prob_threshold\n",
    "        ][filter_param + \": Probability\"].tolist(),\n",
    "        bins=50,\n",
    "        range=(min_v, max_v),\n",
    "    )\n",
    "    plt.hist(\n",
    "        final_output_df_pd[\n",
    "            final_output_df_pd[filter_param + \": Probability\"] >= prob_threshold\n",
    "        ][filter_param + \": Probability\"].tolist(),\n",
    "        bins=50,\n",
    "        range=(min_v, max_v),\n",
    "    )\n",
    "plt.show()\n",
    "\n",
    "compiled_query = \" and \".join(query_list)\n",
    "final_output_df_pd_filtered = final_output_df_pd.query(compiled_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_output_df_pd_filtered) / len(final_output_df_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Pool Results by sgRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_output_df_pd_groupby = final_output_df_pd.groupby(\"sgRNA\")\n",
    "final_output_df_pd_groupby = final_output_df_pd_filtered.groupby(\"sgRNA\")\n",
    "\n",
    "merged_timeseries_df = (\n",
    "    final_output_df_pd_groupby.apply(\n",
    "        lambda x: np.array(\n",
    "            [val for item in x[\"final cell timepoints list\"].tolist() for val in item]\n",
    "        )\n",
    "    )\n",
    "    .to_frame()\n",
    "    .rename(columns={0: \"final cell timepoints\"})\n",
    ")\n",
    "merged_timeseries_df[\"init cell timepoints\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"cell timepoints list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Delta t list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Delta t list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Mean mCherry Intensity list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"Mean mCherry Intensity list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Mean Width list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Mean Width list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\"\n",
    "] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            val\n",
    "            for item in x[\"Mean mCherry Promoter Activity list (area normed)\"].tolist()\n",
    "            for val in item\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\"\n",
    "] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            val\n",
    "            for item in x[\n",
    "                \"Mean mCherry Promoter Activity list (length normed)\"\n",
    "            ].tolist()\n",
    "            for val in item\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Mean Area Increment list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"Mean Area Increment list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "merged_timeseries_df[\"Mean Length Increment list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array(\n",
    "        [val for item in x[\"Mean Length Increment list\"].tolist() for val in item]\n",
    "    )\n",
    ")\n",
    "\n",
    "merged_timeseries_df[\"Sb list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Sb list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Sd list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Sd list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"delS list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"delS list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Lb list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Lb list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"Ld list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"Ld list\"].tolist() for val in item])\n",
    ")\n",
    "merged_timeseries_df[\"delL list\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: np.array([val for item in x[\"delL list\"].tolist() for val in item])\n",
    ")\n",
    "\n",
    "merged_timeseries_df[\"phenotype trenchids\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"phenotype trenchid\"].tolist()\n",
    ")\n",
    "merged_timeseries_df[\"Gene\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"Gene\"].iloc[0]\n",
    ")\n",
    "merged_timeseries_df[\"TargetID\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"TargetID\"].iloc[0]\n",
    ")\n",
    "merged_timeseries_df[\"N Mismatch\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"N Mismatch\"].iloc[0]\n",
    ")\n",
    "merged_timeseries_df[\"N Observations\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: len(x[\"phenotype trenchid\"].tolist())\n",
    ")\n",
    "merged_timeseries_df[\"Category\"] = final_output_df_pd_groupby.apply(\n",
    "    lambda x: x[\"Category\"].iloc[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Filter sgRNAs for Strongest + All Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_timeseries_index_df = merged_timeseries_df.reset_index(drop=False)\n",
    "merged_timeseries_index_df_best_KO = (\n",
    "    merged_timeseries_index_df.groupby([\"TargetID\"])\n",
    "    .apply(lambda x: filter_strong_KOs(x))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "no_nan_mask = merged_timeseries_index_df_best_KO[\"sgRNA\"].apply(\n",
    "    lambda x: type(x) == str\n",
    ")\n",
    "merged_timeseries_index_df_best_KO = merged_timeseries_index_df_best_KO[no_nan_mask]\n",
    "merged_timeseries_index_df_best_KO = pd.concat(\n",
    "    [\n",
    "        merged_timeseries_index_df_best_KO,\n",
    "        merged_timeseries_df[merged_timeseries_df[\"Category\"] != \"Target\"].reset_index(\n",
    "            drop=False\n",
    "        ),\n",
    "    ]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_timeseries_index_df_nofilter = merged_timeseries_index_df.reset_index(drop=True)\n",
    "no_nan_mask_nofilter = merged_timeseries_index_df_nofilter[\"sgRNA\"].apply(\n",
    "    lambda x: type(x) == str\n",
    ")\n",
    "merged_timeseries_index_df_nofilter = merged_timeseries_index_df_nofilter[\n",
    "    no_nan_mask_nofilter\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Bin Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tpt, max_tpt, bins = 0, 143, 10\n",
    "\n",
    "timeseries_bin_df_output = timeseries_bins(\n",
    "    merged_timeseries_index_df_best_KO,\n",
    "    \"final cell timepoints\",\n",
    "    [\n",
    "        \"Ld list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "        \"Sd list\",\n",
    "        \"delS list\",\n",
    "        \"Sb list\",\n",
    "        \"Delta t list\",\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"Mean Area Increment list\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    ],\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_bin_df_output_nofilter = timeseries_bins(\n",
    "    merged_timeseries_index_df_nofilter,\n",
    "    \"final cell timepoints\",\n",
    "    [\n",
    "        \"Ld list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "        \"Sd list\",\n",
    "        \"delS list\",\n",
    "        \"Sb list\",\n",
    "        \"Delta t list\",\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"Mean Area Increment list\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    ],\n",
    "    min_tpt,\n",
    "    max_tpt,\n",
    "    bins,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "controldf = timeseries_bin_df_output[timeseries_bin_df_output[\"Category\"] == \"NoTarget\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Correlations in Null Distribution (early timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_binned_vars(\n",
    "    ax,\n",
    "    df,\n",
    "    label_x,\n",
    "    label_y,\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    unwrap_list_items=False,\n",
    "    **scatterkwargs,\n",
    "):\n",
    "    timepoints = range(min_timepoint, max_timepoint)\n",
    "    df_sub = df[df[\"Timepoint Bin\"].isin(timepoints)]\n",
    "\n",
    "    x_list = df_sub[label_x].tolist()\n",
    "    y_list = df_sub[label_y].tolist()\n",
    "\n",
    "    if unwrap_list_items:\n",
    "        x_list = [val for item in x_list for val in item]\n",
    "        y_list = [val for item in y_list for val in item]\n",
    "\n",
    "    ax.scatter(x_list, y_list, **scatterkwargs)\n",
    "\n",
    "\n",
    "def scatter_means_and_binned_vals(\n",
    "    df,\n",
    "    control_df,\n",
    "    x_label,\n",
    "    y_label,\n",
    "    min_time=0,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 10),\n",
    "    ylim=(0, 10),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    "):\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "\n",
    "    scatter_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Bin Values\",\n",
    "        y_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=True,\n",
    "        alpha=alpha_list[0],\n",
    "        s=s_list[0],\n",
    "    )\n",
    "    ax.set_title(\"All Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "\n",
    "    scatter_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Mean\",\n",
    "        y_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        alpha=alpha_list[1],\n",
    "        s=s_list[1],\n",
    "    )\n",
    "    ax.set_title(\"sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Mean\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "\n",
    "    scatter_binned_vars(\n",
    "        ax,\n",
    "        control_df,\n",
    "        x_label + \": Bin Values\",\n",
    "        y_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=True,\n",
    "        alpha=alpha_list[2],\n",
    "        s=s_list[2],\n",
    "    )\n",
    "    ax.set_title(\"All Control Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 4)\n",
    "\n",
    "    scatter_binned_vars(\n",
    "        ax,\n",
    "        control_df,\n",
    "        x_label + \": Mean\",\n",
    "        y_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        alpha=alpha_list[3],\n",
    "        s=s_list[3],\n",
    "    )\n",
    "    ax.set_title(\"Control sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Mean\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def barchart_binned_vars(\n",
    "    ax,\n",
    "    df,\n",
    "    label_x,\n",
    "    label_y,\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    min_xval,\n",
    "    max_xval,\n",
    "    bins=10,\n",
    "    unwrap_list_items=False,\n",
    "    bar_width=0.1,\n",
    "    **scatterkwargs,\n",
    "):\n",
    "    timepoints = range(min_timepoint, max_timepoint)\n",
    "    df_sub = df[df[\"Timepoint Bin\"].isin(timepoints)]\n",
    "\n",
    "    x_list = df_sub[label_x].tolist()\n",
    "    y_list = df_sub[label_y].tolist()\n",
    "\n",
    "    if unwrap_list_items:\n",
    "        x_list = [val for item in x_list for val in item]\n",
    "        y_list = [val for item in y_list for val in item]\n",
    "\n",
    "    x_arr = np.array(x_list)\n",
    "    y_arr = np.array(y_list)\n",
    "\n",
    "    intervals = np.linspace(min_xval, max_xval, num=bins, dtype=float)\n",
    "\n",
    "    spacing = (max_xval - min_xval) / (bins - 1)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    err = []\n",
    "    for i in intervals:\n",
    "        selection = y_arr[(x_arr >= i) & (x_arr < (i + spacing))]\n",
    "        avg = np.mean(selection)\n",
    "        sem = sp.stats.sem(selection)\n",
    "        middle_point = i + (spacing / 2)\n",
    "\n",
    "        x.append(middle_point)\n",
    "        y.append(avg)\n",
    "        err.append(sem)\n",
    "\n",
    "    ax.bar(x, y, yerr=err, width=bar_width)\n",
    "\n",
    "\n",
    "def barchart_means_and_binned_vals(\n",
    "    df,\n",
    "    control_df,\n",
    "    x_label,\n",
    "    y_label,\n",
    "    min_xval,\n",
    "    max_xval,\n",
    "    bins=10,\n",
    "    min_time=0,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 10),\n",
    "    ylim=(0, 10),\n",
    "):\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "\n",
    "    barchart_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Bin Values\",\n",
    "        y_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        min_xval,\n",
    "        max_xval,\n",
    "        unwrap_list_items=True,\n",
    "    )\n",
    "    ax.set_title(\"All Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "\n",
    "    barchart_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Mean\",\n",
    "        y_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        min_xval,\n",
    "        max_xval,\n",
    "        unwrap_list_items=False,\n",
    "    )\n",
    "    ax.set_title(\"sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Mean\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "\n",
    "    barchart_binned_vars(\n",
    "        ax,\n",
    "        control_df,\n",
    "        x_label + \": Bin Values\",\n",
    "        y_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        min_xval,\n",
    "        max_xval,\n",
    "        unwrap_list_items=True,\n",
    "    )\n",
    "    ax.set_title(\"All Control Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 4)\n",
    "\n",
    "    barchart_binned_vars(\n",
    "        ax,\n",
    "        control_df,\n",
    "        x_label + \": Mean\",\n",
    "        y_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        min_xval,\n",
    "        max_xval,\n",
    "        unwrap_list_items=False,\n",
    "    )\n",
    "    ax.set_title(\"Control sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "    ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_ylabel(y_label + \": Mean\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def filter_binned_timeseries_df(\n",
    "    df, label, min_timepoint, max_timepoint, value_min, value_max, n_timepoints_min\n",
    "):\n",
    "    timepoint_mask = (df[\"Timepoint Bin\"] >= min_timepoint) & (\n",
    "        df[\"Timepoint Bin\"] <= max_timepoint\n",
    "    )\n",
    "    masked_df = df[timepoint_mask]\n",
    "    value_series = masked_df.groupby(\"sgRNA\").apply(\n",
    "        lambda x: np.sum((x[label] >= value_min) & (x[label] <= value_max))\n",
    "    )\n",
    "    value_mask = value_series >= n_timepoints_min\n",
    "    sgRNA_hits = value_series[value_mask].index.tolist()\n",
    "    hits_df = df[df[\"Timepoint Bin\"] == 0].loc[sgRNA_hits]\n",
    "    return hits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### mCherry (Ribosome synthesis) and Growth\n",
    "\n",
    "Here, I note a correlation between the incremental growth rate and the mCherry promoter activity. This is a little fraught to interpret because part of the promoter activity measurement included a growth correction. \n",
    "\n",
    "The extra cluster of high mCherry activity may be a segmentation artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "##### mCherry Promoter Activity vs Added Length over cell cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"log\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1, 10000),\n",
    "    ylim=(0, 12),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "##### mCherry Intensity vs Added Length over cell cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"log\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(100, 100000),\n",
    "    ylim=(0, 12),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "##### mCherry Promoter Activity vs Average Length Increment (over cell cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"log\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1, 10000),\n",
    "    ylim=(0, 4),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1000, 5000),\n",
    "    ylim=(0.0, 0.6),\n",
    "    alpha_list=[0.01, 0.1, 0.3, 0.3],\n",
    "    s_list=[1, 2, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 250),\n",
    "    ylim=(0.0, 0.6),\n",
    "    alpha_list=[0.01, 0.1, 0.3, 0.3],\n",
    "    s_list=[1, 2, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "##### mCherry Intensity vs Average Length Increment (over cell cycle)\n",
    "\n",
    "Here we see that the cluster in the promoter synthesis rate is being inherited from the incremental length measurements. This does not entirely seem to be a misassignment issue (one would expect some negative incremental values). Must be some kind of error given how large the values are through..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1000, 2250),\n",
    "    ylim=(0, 0.6),\n",
    "    alpha_list=[0.01, 0.1, 0.3, 0.3],\n",
    "    s_list=[1, 2, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### mCherry (Ribosome synthesis) and Division\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    \"Delta t list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 300),\n",
    "    ylim=(0, 15),\n",
    "    alpha_list=[0.1, 0.1, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "#### Growth and Division\n",
    "\n",
    "Here, we see that the abnormal length increment cluster is coming from cells annotated as singletons (dividing in a single timepoint)\n",
    "\n",
    "Probably a reasonable idea to filter cells as having to exist for at least 3 timepoints (12 mins) to be considered legitimate\n",
    "\n",
    "This is fixed in the current version, so the weird cluster will not appear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Length Increment list\",\n",
    "    \"Delta t list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 0.7),\n",
    "    ylim=(0, 12),\n",
    "    alpha_list=[0.1, 0.2, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "#### Width vs Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Length Increment list\",\n",
    "    \"Mean Width list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 0.7),\n",
    "    ylim=(0, 2),\n",
    "    alpha_list=[0.1, 0.2, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### Width vs Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    \"Mean Width list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 12),\n",
    "    ylim=(0, 2),\n",
    "    alpha_list=[0.1, 0.2, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "#### Added Size vs Birth Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(0, 6),\n",
    "    ylim=(0, 6),\n",
    "    alpha_list=[0.1, 0.2, 0.3, 0.3],\n",
    "    s_list=[4, 4, 4, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    \"delL list\",\n",
    "    2,\n",
    "    4,\n",
    "    bins=10,\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1.9, 4.4),\n",
    "    ylim=(0, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### Implementing CJW Paper Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df_pd_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timepoint_values(\n",
    "    df,\n",
    "    label,\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    time_label=\"final cell timepoints list\",\n",
    "    flatten_vals=True,\n",
    "):\n",
    "    masked_label_series = df.apply(\n",
    "        lambda x: np.array(x[label])[\n",
    "            (np.array(x[time_label]) >= min_timepoint)\n",
    "            * (np.array(x[time_label]) <= max_timepoint)\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    if flatten_vals:\n",
    "        flattened_vals = [val for item in masked_label_series.tolist() for val in item]\n",
    "        return flattened_vals\n",
    "    else:\n",
    "        return masked_label_series\n",
    "\n",
    "\n",
    "def get_feature_stats(df, feature_label, min_timepoint, max_timepoint):\n",
    "    feature_vals = get_timepoint_values(df, feature_label, min_timepoint, max_timepoint)\n",
    "    feature_median = np.median(feature_vals)\n",
    "    feature_iqr = sp.stats.iqr(feature_vals)\n",
    "    return feature_median, feature_iqr\n",
    "\n",
    "\n",
    "def get_feature_median_bytrench(df, feature_label, min_timepoint, max_timepoint):\n",
    "    masked_label_series = get_timepoint_values(\n",
    "        final_output_df_pd_filtered,\n",
    "        feature_label,\n",
    "        min_timepoint,\n",
    "        max_timepoint,\n",
    "        flatten_vals=False,\n",
    "    )\n",
    "    trench_median_series = masked_label_series.apply(lambda x: np.median(x))\n",
    "    return trench_median_series\n",
    "\n",
    "\n",
    "def get_feature_scores(\n",
    "    df,\n",
    "    feature_label,\n",
    "    trench_median_series,\n",
    "    feature_median,\n",
    "    feature_iqr,\n",
    "    time_label=\"final cell timepoints list\",\n",
    "    timepoint_range=None,\n",
    "):\n",
    "    scaling_factor = 1.35 * (feature_median / feature_iqr)\n",
    "\n",
    "    if timepoint_range == None:\n",
    "        feature_scores = (\n",
    "            (df[feature_label].apply(lambda x: np.array(x))) / trench_median_series\n",
    "        ) - 1.0\n",
    "    else:\n",
    "        feature_scores = (\n",
    "            (\n",
    "                df[feature_label].apply(\n",
    "                    lambda x: np.array(x)[\n",
    "                        (np.array(x[time_label]) >= timepoint_range[0])\n",
    "                        * (np.array(x[time_label]) <= timepoint_range[1])\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            / trench_median_series\n",
    "        ) - 1.0\n",
    "    feature_scores = scaling_factor * feature_scores\n",
    "    return feature_scores\n",
    "\n",
    "\n",
    "def get_avg_feature_score(\n",
    "    df,\n",
    "    feature_label,\n",
    "    init_timepoint_range=(0, 20),\n",
    "    time_label=\"final cell timepoints list\",\n",
    "    timepoint_range=None,\n",
    "):\n",
    "    feature_median, feature_iqr = get_feature_stats(\n",
    "        df, feature_label, init_timepoint_range[0], init_timepoint_range[1]\n",
    "    )\n",
    "    trench_median_series = get_feature_median_bytrench(\n",
    "        df, feature_label, init_timepoint_range[0], init_timepoint_range[1]\n",
    "    )\n",
    "    feature_scores = get_feature_scores(\n",
    "        df,\n",
    "        feature_label,\n",
    "        trench_median_series,\n",
    "        feature_median,\n",
    "        feature_iqr,\n",
    "        time_label=time_label,\n",
    "        timepoint_range=timepoint_range,\n",
    "    )\n",
    "    avg_feature_scores = feature_scores.apply(lambda x: np.mean(x))\n",
    "    return avg_feature_scores\n",
    "\n",
    "\n",
    "def get_all_avg_feature_scores(\n",
    "    df,\n",
    "    feature_labels,\n",
    "    init_timepoint_range=(0, 20),\n",
    "    time_label=\"final cell timepoints list\",\n",
    "    timepoint_range=None,\n",
    "):\n",
    "    for feature_label in feature_labels:\n",
    "        print(feature_label)\n",
    "        avg_feature_scores = get_avg_feature_score(\n",
    "            df,\n",
    "            feature_label,\n",
    "            init_timepoint_range=init_timepoint_range,\n",
    "            time_label=time_label,\n",
    "            timepoint_range=timepoint_range,\n",
    "        )\n",
    "        df[feature_label + \": score\"] = avg_feature_scores\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_sgrnadf_from_scoredf(\n",
    "    scoredf, feature_labels, score_agg=np.median, score_agg_name=\"median\"\n",
    "):\n",
    "    scoredf_groupby = scoredf.groupby(\"sgRNA\")\n",
    "    sgrnadf = (\n",
    "        scoredf_groupby.apply(lambda x: x[\"phenotype trenchid\"].tolist())\n",
    "        .to_frame()\n",
    "        .rename(columns={0: \"phenotype trenchid\"})\n",
    "    )\n",
    "\n",
    "    for feature_label in feature_labels:\n",
    "        sgrnadf[feature_label + \": score \" + score_agg_name] = scoredf_groupby.apply(\n",
    "            lambda x: score_agg(np.array(x[feature_label + \": score\"].tolist()))\n",
    "        )\n",
    "\n",
    "    sgrnadf[\"Gene\"] = scoredf_groupby.apply(lambda x: x[\"Gene\"].iloc[0])\n",
    "    sgrnadf[\"TargetID\"] = scoredf_groupby.apply(lambda x: x[\"TargetID\"].iloc[0])\n",
    "    sgrnadf[\"N Mismatch\"] = scoredf_groupby.apply(lambda x: x[\"N Mismatch\"].iloc[0])\n",
    "    sgrnadf[\"N Observations\"] = scoredf_groupby.apply(\n",
    "        lambda x: len(x[\"phenotype trenchid\"].tolist())\n",
    "    )\n",
    "    sgrnadf[\"Category\"] = scoredf_groupby.apply(lambda x: x[\"Category\"].iloc[0])\n",
    "\n",
    "    return sgrnadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(final_output_df_pd_filtered[\"delS list\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredf = get_all_avg_feature_scores(\n",
    "    final_output_df_pd_filtered,\n",
    "    [\n",
    "        \"delS list\",\n",
    "        \"Sb list\",\n",
    "        \"Sd list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "        \"Ld list\",\n",
    "        \"Mean Area Increment list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Delta t list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrnadf = get_sgrnadf_from_scoredf(\n",
    "    scoredf,\n",
    "    [\n",
    "        \"delS list\",\n",
    "        \"Sb list\",\n",
    "        \"Sd list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "        \"Ld list\",\n",
    "        \"Mean Area Increment list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Delta t list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrnadf_index_df = sgrnadf.reset_index(drop=False)\n",
    "sgrnadf_index_df_best_KO = (\n",
    "    sgrnadf_index_df.groupby([\"TargetID\"])\n",
    "    .apply(lambda x: filter_strong_KOs(x))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "no_nan_mask = sgrnadf_index_df_best_KO[\"sgRNA\"].apply(lambda x: type(x) == str)\n",
    "sgrnadf_index_df_best_KO = sgrnadf_index_df_best_KO[no_nan_mask]\n",
    "sgrnadf_index_df_best_KO = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            sgrnadf_index_df_best_KO,\n",
    "            sgrnadf_index_df[sgrnadf_index_df[\"Category\"] != \"Target\"].reset_index(\n",
    "                drop=False\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    .set_index(\"sgRNA\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    sgrnadf_index_df_best_KO[\"Mean Width list: score median\"],\n",
    "    range=(-3, 3),\n",
    "    bins=50,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = sgrnadf_index_df_best_KO[\n",
    "    sgrnadf_index_df_best_KO[\"Mean Width list: score median\"] > 1.5\n",
    "]\n",
    "unique, counts = np.unique(\n",
    "    filtered_df[filtered_df[\"Gene\"].apply(lambda x: type(x) == str)][\"Gene\"],\n",
    "    return_counts=True,\n",
    ")\n",
    "wide_cells = set(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = sgrnadf_index_df_best_KO[\n",
    "    sgrnadf_index_df_best_KO[\"Lb list: score median\"] > 1\n",
    "]\n",
    "unique, counts = np.unique(\n",
    "    filtered_df[filtered_df[\"Gene\"].apply(lambda x: type(x) == str)][\"Gene\"],\n",
    "    return_counts=True,\n",
    ")\n",
    "long_cells = set(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(wide_cells - long_cells))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "#### Quick tsne test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size_filter = 1.0\n",
    "zero_vector_thr = 0.65\n",
    "\n",
    "\n",
    "def zero_vector_under_thr(arr_list, threshold=zero_vector_thr):\n",
    "    array = np.array(arr_list)\n",
    "    array[np.abs(array) < threshold] = 0.0\n",
    "    return array.tolist()\n",
    "\n",
    "\n",
    "tsne_df = sgrnadf_index_df_best_KO\n",
    "tsne_df[\"TSNE Vector\"] = tsne_df[tsne_df.columns[1:14]].apply(\n",
    "    lambda x: x.tolist(), axis=1\n",
    ")\n",
    "tsne_df = tsne_df[tsne_df[\"TSNE Vector\"].apply(lambda x: ~np.any(np.isnan(x)))]\n",
    "max_effect = tsne_df[\"TSNE Vector\"].apply(lambda x: np.max(np.abs(x)))\n",
    "tsne_df = tsne_df[max_effect > effect_size_filter]\n",
    "tsne_df[\"TSNE Vector\"] = tsne_df[\"TSNE Vector\"].apply(zero_vector_under_thr)\n",
    "mean_vector = np.mean(np.array(tsne_df[\"TSNE Vector\"].tolist()), axis=0)\n",
    "tsne_df[\"TSNE Vector\"] = tsne_df[\"TSNE Vector\"].apply(\n",
    "    lambda x: x - mean_vector\n",
    ")  # subtract mean normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(tsne_df[\"TSNE Vector\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(\n",
    "    n_components=2,\n",
    "    init=\"pca\",\n",
    "    perplexity=20.0,\n",
    "    early_exaggeration=50.0,\n",
    "    metric=\"cosine\",\n",
    ").fit_transform(X)\n",
    "tsne_df[\"TSNE Coords\"] = [X_embedded[i] for i in range(X_embedded.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "query_arr = np.array(\n",
    "    tsne_df[tsne_df[\"Gene\"].apply(lambda x: \"fts\" in str(x))][\"TSNE Coords\"].tolist()\n",
    ")\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], s=3, alpha=1)\n",
    "plt.scatter(query_arr[:, 0], query_arr[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=3.5, min_samples=8, metric=\"euclidean\").fit_predict(X_embedded)\n",
    "tsne_df[\"DBSCAN Cluster\"] = [clustering[i] for i in range(X_embedded.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_arr = np.array(\n",
    "    tsne_df[tsne_df[\"Gene\"].apply(lambda x: \"rps\" in str(x))][\"TSNE Coords\"].tolist()\n",
    ")\n",
    "\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], s=3, alpha=1, c=clustering)\n",
    "plt.scatter(query_arr[:, 0], query_arr[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_clusters, cluster_counts = np.unique(\n",
    "    tsne_df[\"DBSCAN Cluster\"].tolist(), return_counts=True\n",
    ")\n",
    "large_clusters = unique_clusters[1:][cluster_counts[1:] > 10]\n",
    "large_clust_df = tsne_df[tsne_df[\"DBSCAN Cluster\"].isin(large_clusters)]\n",
    "large_clust_arr = np.array(large_clust_df[\"TSNE Coords\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    large_clust_arr[:, 0],\n",
    "    large_clust_arr[:, 1],\n",
    "    s=3,\n",
    "    alpha=1,\n",
    "    c=large_clust_df[\"DBSCAN Cluster\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "#### Trying an alternative to tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_threshold = 1.75\n",
    "\n",
    "\n",
    "def to_ternary(arr_list, threshold=sigma_threshold):\n",
    "    array = np.array(arr_list)\n",
    "    array[np.abs(array) < threshold] = 0\n",
    "    array[array < -threshold] = -1\n",
    "    array[array > threshold] = 1\n",
    "\n",
    "\n",
    "#     return array.astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_df.columns[1:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_of_interest = [\n",
    "    \"Lb list: score median\",\n",
    "    \"Ld list: score median\",\n",
    "    \"Mean Length Increment list: score median\",\n",
    "    \"Mean Width list: score median\",\n",
    "    \"Mean mCherry Intensity list: score median\",\n",
    "    \"Delta t list: score median\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hierarchical_df = sgrnadf_index_df_best_KO\n",
    "hierarchical_df[\"Ternary Vector\"] = hierarchical_df[features_of_interest].apply(\n",
    "    lambda x: x.tolist(), axis=1\n",
    ")\n",
    "hierarchical_df = hierarchical_df[\n",
    "    hierarchical_df[\"Ternary Vector\"].apply(lambda x: ~np.any(np.isnan(x)))\n",
    "]\n",
    "hierarchical_df[\"Ternary Vector\"] = hierarchical_df[\"Ternary Vector\"].apply(to_ternary)\n",
    "zero_vector = np.zeros(len(hierarchical_df[\"Ternary Vector\"].iloc[0]))\n",
    "hierarchical_df = hierarchical_df[\n",
    "    hierarchical_df[\"Ternary Vector\"].apply(lambda x: np.any(x != zero_vector))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ternary_arr = np.array(hierarchical_df[\"Ternary Vector\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kmodes import KModes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# km_cao = KModes(n_clusters=15, init = \"Cao\", n_init = 10, verbose=1)\n",
    "km_huang = KModes(n_clusters=10, init=\"Huang\", n_init=20, verbose=0)\n",
    "\n",
    "fitClusters_huang = km_huang.fit_predict(ternary_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_df[\"KModes Cluster\"] = fitClusters_huang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles = np.array(\n",
    "    [\n",
    "        np.mean(ternary_arr[fitClusters_huang == i], axis=0)\n",
    "        for i in range(len(np.unique(fitClusters_huang)))\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt.imshow(cluster_profiles)\n",
    "plt.xticks(\n",
    "    ticks=range(0, len(features_of_interest)),\n",
    "    labels=list(features_of_interest),\n",
    "    rotation=90,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(hierarchical_df[\"KModes Cluster\"], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(hierarchical_df[hierarchical_df[\"KModes Cluster\"] == 0][\"Gene\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(hierarchical_df[hierarchical_df[\"KModes Cluster\"] == 10][\"Gene\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = hierarchical_df[hierarchical_df[\"Gene\"].apply(lambda x: \"mak\" in str(x))]\n",
    "ternary_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ternary_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_df = sgrnadf_index_df_best_KO\n",
    "affinity_df[\"Affinity Vector\"] = affinity_df[features_of_interest].apply(\n",
    "    lambda x: x.tolist(), axis=1\n",
    ")\n",
    "affinity_df = affinity_df[\n",
    "    affinity_df[\"Affinity Vector\"].apply(lambda x: ~np.any(np.isnan(x)))\n",
    "]\n",
    "zero_vector = np.zeros(len(affinity_df[\"Affinity Vector\"].iloc[0]))\n",
    "affinity_df = affinity_df[\n",
    "    affinity_df[\"Affinity Vector\"].apply(lambda x: np.any(x != zero_vector))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_arr = np.array(affinity_df[\"Affinity Vector\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "af = skl.cluster.AffinityPropagation().fit(affinity_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(af.preference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.unique(ternary_arr, axis=0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "#### distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_mat = np.equal.outer(ternary_arr, ternary_arr.T)\n",
    "hamming_dist = np.sum(np.diagonal(agreement_mat, axis1=1, axis2=2), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity_arr = hamming_dist < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_connectivity = skl.neighbors.radius_neighbors_graph(\n",
    "    ternary_arr, 3, mode=\"connectivity\", metric=\"hamming\", include_self=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_df.columns[1:14][[0, 3, 12, 11, 8, 1, 4, 6, 7, 2, 5, 10, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ternary_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo = skl.cluster.AgglomerativeClustering(\n",
    "    n_clusters=2,\n",
    "    affinity=\"precomputed\",\n",
    "    linkage=\"average\",\n",
    "    connectivity=radius_connectivity,\n",
    "    compute_distances=True,\n",
    ")\n",
    "agglo = agglo.fit(hamming_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_dendrogram(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo.n_leaves_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "Idea:\n",
    "\n",
    "- kmean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "### Histograms of Single Variables and Outlier Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_binned_vars(\n",
    "    ax, df, label_x, min_timepoint, max_timepoint, unwrap_list_items=False, **histkwargs\n",
    "):\n",
    "    timepoints = range(min_timepoint, max_timepoint)\n",
    "    df_sub = df[df[\"Timepoint Bin\"].isin(timepoints)]\n",
    "\n",
    "    x_list = df_sub[label_x].tolist()\n",
    "\n",
    "    if unwrap_list_items:\n",
    "        x_list = [val for item in x_list for val in item]\n",
    "\n",
    "    ax.hist(x_list, **histkwargs)\n",
    "\n",
    "\n",
    "def hist_means_and_binned_vals(\n",
    "    df,\n",
    "    control_df,\n",
    "    x_label,\n",
    "    min_time=0,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 10),\n",
    "    bins=25,\n",
    "    legend=False,\n",
    "    **histkwargs,\n",
    "):\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "\n",
    "    if xscale == \"log\":\n",
    "        bins = np.logspace(np.log10(xlim[0]), np.log10(xlim[1]), num=bins)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=True,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"All Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "    if legend:\n",
    "        ax.legend()\n",
    "\n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": Bin Values\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=True,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"All Control Cells\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Bin Values\")\n",
    "\n",
    "    ax = plt.subplot(2, 2, 4)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": Mean\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"Contro
l sgRNA Means\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Mean\")\n",
    "\n",
    "\n",
    "def hist_CV(\n",
    "    df,\n",
    "    control_df,\n",
    "    x_label,\n",
    "    min_time=0,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 10),\n",
    "    bins=25,\n",
    "    **histkwargs,\n",
    "):\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "\n",
    "    if xscale == \"log\":\n",
    "        bins = np.logspace(np.log10(xlim[0]), np.log10(xlim[1]), num=bins)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": CV\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"sgRNA CV\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": CV\")\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": CV\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"Control sgRNA CV\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": CV\")\n",
    "\n",
    "\n",
    "def hist_std(\n",
    "    df,\n",
    "    control_df,\n",
    "    x_label,\n",
    "    min_time=0,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 10),\n",
    "    bins=25,\n",
    "    **histkwargs,\n",
    "):\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "\n",
    "    if xscale == \"log\":\n",
    "        bins = np.logspace(np.log10(xlim[0]), np.log10(xlim[1]), num=bins)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        df,\n",
    "        x_label + \": Standard Deviation\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"sgRNA Standard Deviation\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Standard Deviation\")\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "    hist_binned_vars(\n",
    "        ax,\n",
    "        controldf,\n",
    "        x_label + \": Standard Deviation\",\n",
    "        min_time,\n",
    "        max_time,\n",
    "        unwrap_list_items=False,\n",
    "        bins=bins,\n",
    "        range=xlim,\n",
    "        **histkwargs,\n",
    "    )\n",
    "    ax.set_title(\"Control sgRNA Standard Deviation\")\n",
    "    ax.set_xscale(xscale)\n",
    "    ax.set_xlim(xlim[0], xlim[1])\n",
    "    ax.set_xlabel(x_label + \": Standard Deviation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "#### mCherry Intensity and Synthesis\n",
    "\n",
    "Note that repression of rne (Ribonuclease E) significantly decreases the amount of ribosome synthesis. Seems to do so in somewhat tunable manner (since many hits mapped to it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 5000),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 5000),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 200),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (length normed)\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 200),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 200),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 200),\n",
    "    bins=25,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 10\n",
    "value_min = 2200\n",
    "value_max = 30000\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Intensity list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "high_mean_intensity_genes = set(unique)\n",
    "high_mean_intensity_sgRNA = set(hits.index.unique().tolist())\n",
    "\n",
    "print(\"High Mean Intensity Genes\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 10\n",
    "value_min = 0\n",
    "value_max = 1300\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Intensity list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "low_mean_intensity_genes = set(unique)\n",
    "low_mean_intensity_sgRNA = set(hits.index.unique().tolist())\n",
    "\n",
    "print(\"Low Mean Intensity Genes\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique[counts > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "##### Some notes\n",
    "\n",
    "##### dnaB\n",
    "\n",
    "- This is one of the more interesting hits...could dnaB be linking replication to ribosome synthesis...Seems the effect is mostly captured by an increase in the growth rate...\n",
    "\n",
    "DnaB, the replicative DNA helicase, processively unwinds DNA at replication forks in advance of DNA polymerase. Along with primase, it is responsible for the initation of chromosomal DNA replication and for the continued priming of lagging-strand synthesis [Fujimura79]. It is also required for DNA replication in a number of plasmids [Conrad79, Hasunuma79, Pritchard80].\n",
    "DnaB is a component of the primosome, the protein complex that initiates replicative DNA synthesis at the origin of replication, oriC. Such initiation requires DnaA, DNA gyrase, DnaB and DnaC [Kaguni85]. Four or five DnaA monomers bind to a single DnaB helicase as well as binding to oriC, loading the DnaB onto one of the DNA strands exposed at the prepared origin of replication [Sutton98, Carr01, Carr02]. The resulting complex of DnaA, DnaB and DnaC binds asymmetrically along the DNA, extending fifty base pairs farther \"upstream\" from oriC [Funnell87]. Formation of this initiation complex on an oriC plasmid requires supercoiled DNA [Funnell86]. DnaB subsequently unwinds DNA bidirectionally from oriC. DNA gyrase is required for this bidirectional activity. In the absence of DNA synthesis, single-strand binding protein (SSB) binds the unwound DNA [Baker87]. DnaB remains continuously associated with the advancing replication forks during subsequent DNA synthesis [Wu92].\n",
    "\n",
    "DnaC acts as a loader for DnaB, binding to it and localizing it to duplex DNA for its role in initiating replication and to single-stranded DNA for its role in assisting primer formation by primase [Wickner75, Marszalek94, Wahle89, Wahle89a]. Though it is required for loading DnaB onto DNA, bound DnaC directly limits DnaB's ATPase activity [Biswas87, Biswas86]. As a consequence, replication speed is depends on the DnaB:DnaC ratio in vivo [Allen91, Skarstad95]. Six DnaC bind to one helicase hexamer, binding as a trio of dimers. While DnaC is bound, the opposite entrance to the helicase channel is nearly completely blocked, preventing efficient passage of DNA [Barcena01, San98]. ATP hydrolysis is not required for release of DnaC [Galletto03].\n",
    "\n",
    "The role of DnaB in initiation of phage  DNA replication has also been extensively characterized. The formation of the lambda primosome analog, the \"O-some,\" begins with binding of several O proteins at ori lambda. DnaB and lambda P, a DnaC analog, subsequently bind the O proteins [Dodson85, Mallory90]. The members of the DnaK chaperone system (DnaJ, DnaK, GrpE) then bind, with GrpE being required for bidirectional unwinding by DnaB [Dodson86, Wyman93, Liberek90, Alfano89].\n",
    "\n",
    "DnaB can also be reloaded onto arrested replication forks. PriA opens a collapsed replication fork to allow subsequent DnaB binding [Jones99]. Though PriA restarting requires PriB and DnaT as well as a gapless leading strand, PriC can reload DnaB by itself [Heller05].\n",
    "\n",
    "DnaB interacts with DNA primase (DnaG) [Lu96]. As DnaB processively unwinds DNA, primase follows, putting down primers on the lagging strand [McMacken77]. DnaB relaxes the specificity of primase from GTC to PuPyPy [Yoda91]. DnaB also stimulates RNA primer synthesis by primase over 5,000 fold [Johnson00]. Indeed, the DnaB-DnaG interaction is the sole determinant in the rate of Okazaki fragment priming [Tougu96]. Three DnaG monomers interact with each DnaB helicase [Mitkova03]. Accurate initiation of bidirectional DNA replication from oriC requires proper primer placement for leading strand synthesis and thus depends on the helicase-primase interaction [Hiasa99]. The DnaB-DnaG interaction may also explain the need for DnaB in postreplication gap repair [Johnson75].\n",
    "\n",
    "DnaB moves processively in the 5' to 3' direction on ssDNA. Its helicase activity is stimulated by SSB, but can be inhibited by prior binding of SSB to single-stranded regions of substrate DNA [LeBowitz86, Arai81]. This inhibition by SSB helps limit futile ATPase activity when DnaB is unable to progress, thus coupling its helicase and ATPase activities [Biswas02]. Helicase binding to ssDNA requires ATP binding but not ATP hydrolysis and involves a binding-induced conformational change in DnaB [Arai81a, Jezewska97, Galletto04]. The rate of DnaB helicase activity depends on the length of available 3' ssDNA in the replication fork. At least five nucleotides must be accessible for the maximal rate, though processivity has been demonstrated to depend on fourteen or more available nucleotides [Biswas02, Galletto04a]. DnaB's rate is inversely proportional to the stability of the duplex it is unwinding [Galletto04a]. In addition, mutations that disrupt helical phasing or DNA curvature slow DnaB helicase activity dramatically [Doran98]. The ssDNA strand on which DnaB travels passes through the inside of the hexameric helicase ring structure [Jezewska98]. The kinetics of DNA binding and nucleotide binding and hydrolysis have been examined in detail [Rajendran00, Bujalowski00, Bujalowski00a].\n",
    "\n",
    "##### ftsH\n",
    "ftsH encodes an ATP dependent metalloprotease which, as part of the FtsH/HflKC complex, degrades both soluble and inner membrane proteins. The FtsH/HflKC complex (also known as the FtsH holoenzyme) is regarded as the physiological complex although enzyme activity is often studied with isolated FtsH hexamers ([Ito05]).\n",
    "[Please refer to the complex page for further details regarding FtsH activity]\n",
    "FtsH has two transmembrane segments near the N-terminus and a large cytoplasmic domain which comprises two subdomains: an ATPase domain and a zinc metalloprotease motif-containing protease domain [Ogura91, Tomoyasu93, Tomoyasu95].\n",
    "\n",
    "FtsH has been implicated in the import of specific toxins of contact-dependent growth inhibition (CDI) systems in gram-negative bacteria; ftsH in-frame deletion mutants are resistant to the toxins CdiA-CTEC536, CdiA-CTECL and CdiA-CTPestA ; inner membrane proteins such as FtsH are thought to act as receptors which bring the nuclease domain of CDI toxins into close proximity with the inner membrane of target cells [Willett15].\n",
    "\n",
    "##### hemD\n",
    "\n",
    "Uroporphyrinogen III synthase catalyzes the cyclization of hydroxymethylbilane with inversion of ring D to form uroporphyrinogen III, the last common intermediate in the heme and corrin (B-12) pathways [Sasarman87, Neidhardt96]. Uroporphyrinogen III synthase forms a complex with hydroxymethylbilane synthase [Jordan91, Neidhardt96].\n",
    "The hemD gene which encodes uroporphyrinogen III synthase has been cloned, and the product has been overexpressed, purified and characterized [Alwan89, Jordan88]. The hemD gene is adjacent to hemC and both genes appear to be transcribed by the same promoter [Alefounder88, Sasarman87].\n",
    "\n",
    "A group of hemin requiring mutants had defects in uroporphyrinogen III synthase [McConville79].\n",
    "\n",
    "##### infA\n",
    "\n",
    "IF-1 is one of three translation initiation factors in E. coli and is essential for viability [Cummings94, Baba06]. Its functional role has not been fully elucidated; a collection of mutants was generated to attempt to determine the function of IF-1 [Croitoru04]. It was suggested that the essential function of IF-1 and IF-3 may be to minimize the fraction of ribosomes lacking an initiator tRNA [Antoun06].\n",
    "IF-1 binds to the ribosomal A site [Moazed95], which may suggest a function in translational fidelity; such a function could not be shown [Croitoru05]. Certain mutations in 16S rRNA disrupt binding of IF-1 to the 30S subunit [Dahlquist00], and a model where IF-1 modulates specific conformational change during initiation has been suggested [Dahlquist00]. IF-1 enhances the dissociation rate of 70S ribosomes apparently by stimulating the activity of IF-3 [DottavioMartin79, GrunbergManago75, Pon84]. IF-1 stimulates the association of IF-2 with the 30S subunit [Stringer77, Moreno99] and the ability of IF-2 to stimulate template-dependent binding of aminoacyl-tRNAs to the ribosome [Canonaco86]. IF-1 is released from the ribosome during association of the 30S and 50S subunits [Celano88].\n",
    "\n",
    "The solution structure of IF-1 has been determined, and residues that are involved in interactions with the 30S ribosomal subunit have been identified. The structure appears similar to the oligomer-binding (OB) fold family of proteins [Sette97].\n",
    "\n",
    "Expression of infA is growth rate-controlled at the level of transcription [Cummings91]. Transcription of infA is increased by cold shock via activation of the distal promoter [Ko06].\n",
    "\n",
    "Reviews: [Boelens02, Laursen05]\n",
    "\n",
    "##### rne\n",
    "\n",
    "Ribonuclease E (RNase E) is a single-strand-specific endonuclease that is essential for viability. It processes rRNA, tRNA and other RNAs, is involved in plasmid and phage stability and is part of the degradosome, a multienzyme complex involved in mRNA degradation.\n",
    "RNase E is involved in processing and cleavage of several rRNAs. It processes the 9S rRNA precursor to yield the mature 5S rRNA by cleaving quite near the 5' end and downstream from the 3' end of the final product [Ghora78, Roy83, Apirion78]. RNase E also participates in the 5' maturation of 16S rRNA from its 17S precursor, as well as being able to cleave single-stranded regions within mature 16S and 23S rRNAs [Li99, Bessarab98].\n",
    "\n",
    "RNase E initiates the processing of both poly- and monicistronic tRNA transcripts, including those within rRNA transcripts, by cleaving within a few nucleotides of the mature 3' CCA terminus, thus allowing RNase P and other 3' to 5' exonucleases to complete tRNA maturation [Ow02, Li02]. RNase E similarly cleaves at the 3' CCA terminus of the ssrA RNA precursor to yield its final form [LinChao99]. RNase E may also be involved in processing of the 5' leader of precursor tRNAs [Soderbom05]. Maturation of the three proline tRNA-3' ends utilizes an endonucleolytic pathway independent of exonucleases in which RNase E is primarily responsible for removal of the Rho-independent transcription terminator associated with the proK proL and proM primary transcripts [Mohanty16].\n",
    "\n",
    "RNase E carries out the 3' processing of M1 mRNA, which codes for the catalytic subunit of RNase P [Lundberg95, Sim01]. Other mRNA processing substrates include the cell division inhibitor DicF, the RNA polymerase sigma70 activity modulator 6S RNA, the polycistronic histidine operon mRNA and the papAB primary transcript, which is cleaved to yield stable papA and unstable papB mRNA [Faubladier90, Balasubramanian16, Kim04, Fadouloglou15, Alifano94, Nilsson91]. Domains of RNase E have been identified that are important for the degradation of the Rep mRNA of the ColE2 plasmid, versus the antisense RNA that controls its expression [Nishio09].\n",
    "\n",
    "The stability of plasmids R1 and Colicin E1 is influenced by RNase E. It initiates degradation of CopA, the R1 copy regulator RNA [Soderbom98]. RNase E also cleaves near the 5' end of the sok component of the hok/sok sense/antisense RNA plasmid stabilization mechanism from R1, allowing subsequent degradation by another degradosome component, PNPase [Dam97]. The Colicin E1 DNA synthesis inhibitor RNA, RNAI, is also cleaved at its 5' end by RNase E [Tomcsanyi85, LinChao91]. Finally, RNase E cleaves FinP, which binds to the 5'-untranslated region of the positive F-plasmid transfer regulator traJ [Jerome99].\n",
    "\n",
    "- Is this messing with the plasmid replication system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 10\n",
    "value_min = 200\n",
    "value_max = 15000\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Promoter Activity list (length normed): Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "high_promoter_syn_genes_length_normed = set(unique)\n",
    "high_promoter_syn_sgRNA_length_normed = set(hits.index.unique().tolist())\n",
    "\n",
    "print(\"High Promoter Synthesis Genes (length normed)\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = -1000\n",
    "value_max = 50\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Promoter Activity list (length normed): Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "low_promoter_syn_genes_length_normed = set(unique)\n",
    "low_promoter_syn_sgRNA_length_normed = set(hits.index.unique().tolist())\n",
    "\n",
    "print(\"Low Promoter Synthesis Genes (length normed)\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 10\n",
    "value_min = 200\n",
    "value_max = 15000\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Promoter Activity list (length normed): Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "high_promoter_syn_genes_area_normed = set(unique)\n",
    "high_promoter_syn_sgRNA_area_normed = set(hits.index.unique().tolist())\n",
    "\n",
    "print(\"High Promoter Synthesis Genes (area normed)\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = -1000\n",
    "value_max = 50\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean mCherry Promoter Activity list (area normed): Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "low_promoter_syn_genes_area_normed = set(unique)\n",
    "low_promoter_syn_sgRNA_area_normed = set(hits.index.unique().tolist())\n",
    "\n",
    "print(\"Low Promoter Synthesis Genes (area normed)\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_timeseries_df.loc[list(low_promoter_syn_sgRNA - low_mean_intensity_sgRNA)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "#### Growth Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 0.6),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Length Increment list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 0.6),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Area Increment list\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 0.6),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Area Increment list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 0.6),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0.4\n",
    "value_max = 2.0\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean Length Increment list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "high_growth_genes_length = set(unique)\n",
    "high_growth_sgRNA_length = set(hits.index.unique().tolist())\n",
    "print(\"High Growth Rate (Length)\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0.4\n",
    "value_max = 2.0\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean Area Increment list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "high_growth_genes_area = set(unique)\n",
    "high_growth_sgRNA_area = set(hits.index.unique().tolist())\n",
    "print(\"High Growth Rate (Area)\")\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0.0\n",
    "value_max = 0.22\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean Length Increment list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Low Growth Rate (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "\n",
    "low_growth_genes_length = set(unique)\n",
    "low_growth_sgRNA_length = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0.0\n",
    "value_max = 0.22\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean Area Increment list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Low Growth Rate (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "\n",
    "low_growth_genes_area = set(unique)\n",
    "low_growth_sgRNA_area = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "#### Division Rate\n",
    "\n",
    "Something is strange here...ftsZ is not coming through even through it comes through with the size analysis...\n",
    "\n",
    "Oh, wait of course its not here. It effects cell size not division rate (which is basically coupled to growth rate if we have homeostatic cell size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Delta t list\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 12),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Delta t list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0, 12),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 12\n",
    "value_max = 200\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Delta t list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "low_div_rate_genes = set(unique)\n",
    "low_div_rate_sgRNA = set(hits.index.unique().tolist())\n",
    "print(\"Low Division Rate\")\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 4\n",
    "max_timepoint = 8\n",
    "value_min = 0\n",
    "value_max = 5\n",
    "n_timepoints_min = 1\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Delta t list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "high_div_rate_genes = set(unique)\n",
    "high_div_rate_sgRNA = set(hits.index.unique().tolist())\n",
    "print(\"High Division Rate\")\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "#### Added Size (Length units)\n",
    "\n",
    "This is where most of the division related genes come up in a consistent way\n",
    "\n",
    "At some point a manual check of the ribosome and RNA pol may be worth it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(timeseries_bin_df_output[\"Bin Mean Timepoint\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "(140 * 4) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=2,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(2, 4),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    "    label=\"0-3 hours\",\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"delL list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(2, 4),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    "    legend=True,\n",
    "    label=\"4.5 - 9.5 hours\",\n",
    ")\n",
    "\n",
    "plt.savefig(\"figure_1.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 10\n",
    "value_min = 3.6\n",
    "value_max = 50\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"delL list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Large Added Size (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "large_delL_genes = set(unique)\n",
    "large_delL_sgRNA = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 0\n",
    "value_max = 2.4\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"delL list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Small Added Size (Length)\")\n",
    "print(unique)\n",
    "small_delL_genes = set(unique)\n",
    "small_delL_sgRNA = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(list(large_delL_genes.intersection(small_delL_genes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135",
   "metadata": {},
   "source": [
    "#### Birth Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(2, 4),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    min_time=8,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(2, 4),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 9\n",
    "value_min = 3.65\n",
    "value_max = 50\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Lb list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Large Birth Size (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "large_Lb_genes = set(unique)\n",
    "large_Lb_sgRNA = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 9\n",
    "value_min = -10\n",
    "value_max = 2.5\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Lb list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Large Birth Size (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "small_Lb_genes = set(unique)\n",
    "small_Lb_sgRNA = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "#### Division Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Ld list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(2, 10),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Ld list\",\n",
    "    min_time=8,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(2, 10),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 9\n",
    "value_min = 7\n",
    "value_max = 50\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Ld list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Large Birth Size (Length)\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "large_Ld_genes = set(unique)\n",
    "large_Ld_sgRNA = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142",
   "metadata": {},
   "source": [
    "#### Wide Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Width list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(1.0, 1.7),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")\n",
    "\n",
    "hist_means_and_binned_vals(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"Mean Width list\",\n",
    "    min_time=8,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(1.0, 1.7),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 1.4\n",
    "value_max = 2\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean Width list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Wide Cells\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "wide_cell_genes = set(unique)\n",
    "wide_cell_sgRNA = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = -10\n",
    "value_max = 1.05\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"Mean Width list: Mean\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"Narrow Cells\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "narrow_cell_genes = set(unique)\n",
    "narrow_cell_sgRNA = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Variability in Added Size (Length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "hist_std(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"delL list\",\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0.0, 3.0),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "\n",
    "hist_std(\n",
    "    timeseries_bin_df_output,\n",
    "    controldf,\n",
    "    \"delL list\",\n",
    "    min_time=4,\n",
    "    max_time=11,\n",
    "    xscale=\"linear\",\n",
    "    xlim=(0.0, 3.0),\n",
    "    bins=50,\n",
    "    alpha=0.7,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timepoint = 3\n",
    "max_timepoint = 8\n",
    "value_min = 2.5\n",
    "value_max = 100.0\n",
    "n_timepoints_min = 2\n",
    "\n",
    "hits = filter_binned_timeseries_df(\n",
    "    timeseries_bin_df_output,\n",
    "    \"delL list: Standard Deviation\",\n",
    "    min_timepoint,\n",
    "    max_timepoint,\n",
    "    value_min,\n",
    "    value_max,\n",
    "    n_timepoints_min,\n",
    ")\n",
    "\n",
    "# hits = time_window[(time_window[\"Mean\"]>4)&(violin_bins[\"Timepoint Bin\"]<7)]\n",
    "gene_list = hits[\"Gene\"].tolist()\n",
    "unique, counts = np.unique(gene_list, return_counts=True)\n",
    "# filamenting_genes = unique\n",
    "print(\"High Standard Deviation delL Cells\")\n",
    "print(unique)\n",
    "variable_delL_genes = set(unique)\n",
    "variable_delL_sgRNA = set(hits.index.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149",
   "metadata": {},
   "source": [
    "##### Note: Redo variability section with proper timeseries analysis\n",
    "\n",
    "Fast and slow changes are conflated in this standard deviation measure. Too difficult to disentangle with this ipynb's representations. Recommend extracting proper autocorrelations in the timeseries focused ipynb and performing measures of variability there. Also worth considering carefully the expectations of a KO that nullifies cell size homeostasis.\n",
    "\n",
    "This may also help distinguishing transient departures from homeostasis with seriously dysregulated ones.\n",
    "\n",
    "Outline this approach before implementing\n",
    "\n",
    "\n",
    "##### Additional Note: Suspicious of promoter activity calculation\n",
    "\n",
    "Not seeming to catch obvious hits. Recheck the math and implementation of this..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150",
   "metadata": {},
   "source": [
    "### Major Phenotypic Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151",
   "metadata": {},
   "source": [
    "#### Genes with decreased reporter (and possibly ribosome) levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrna_of_interest_df = merged_timeseries_df.loc[list(low_mean_intensity_sgRNA)]\n",
    "sgrna_of_interest_df[\"Gene\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153",
   "metadata": {},
   "source": [
    "##### Without fast growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrna_of_interest_df = merged_timeseries_df.loc[\n",
    "    list(low_mean_intensity_sgRNA - high_growth_sgRNA_area)\n",
    "]\n",
    "sgrna_of_interest_df[\"Gene\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155",
   "metadata": {},
   "source": [
    "##### With fast growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrna_of_interest_df = merged_timeseries_df.loc[\n",
    "    list(low_mean_intensity_sgRNA.intersection(high_growth_sgRNA_area))\n",
    "]\n",
    "sgrna_of_interest_df[\"Gene\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157",
   "metadata": {},
   "source": [
    "##### Interesting genes to discuss\n",
    "\n",
    "- dnaABE\n",
    "- rne - very strong hit\n",
    "- ftsHK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "rne_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"rne\"]\n",
    "rne_selection = rne_df.iloc[6]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = rne_selection[\"init cell timepoints\"]\n",
    "    y = rne_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"rne.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnaB_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"dnaB\"]\n",
    "dnaB_selection = dnaB_df.iloc[0]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = dnaB_selection[\"init cell timepoints\"]\n",
    "    y = dnaB_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"dnab.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160",
   "metadata": {},
   "source": [
    "#### Genes with Increased Reporter Levels\n",
    "\n",
    "This is mostly composed of genes which give a ribosome-like KO. Cells increase in intensity and size, then stop growing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrna_of_interest_df = merged_timeseries_df.loc[list(high_mean_intensity_sgRNA)]\n",
    "np.sort(\n",
    "    sgrna_of_interest_df[\"Gene\"].unique()[\n",
    "        sgrna_of_interest_df[\"Gene\"].unique() != \"nan\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162",
   "metadata": {},
   "source": [
    "##### Interesting genes to discuss\n",
    "\n",
    "- folA - resembles ribosomal protein KOs (increased size/intensity)\n",
    "- ribosomal proteins\n",
    "- ftsY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "folA_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"folA\"]\n",
    "folA_selection = folA_df.iloc[23]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = folA_selection[\"init cell timepoints\"]\n",
    "    y = folA_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"folA.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "rplA_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"rplA\"]\n",
    "rplA_selection = rplA_df.iloc[16]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = rplA_selection[\"init cell timepoints\"]\n",
    "    y = rplA_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"rplA.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftsY_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"ftsY\"]\n",
    "ftsY_selection = ftsY_df.iloc[26]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = ftsY_selection[\"init cell timepoints\"]\n",
    "    y = ftsY_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"ftsY.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166",
   "metadata": {},
   "source": [
    "##### Subset that does not increase in size or affect growth rate (do not resemble ribosomal KO)\n",
    "\n",
    "- Note, filtering by gene here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(sorted(high_mean_intensity_genes - large_Lb_genes - low_growth_genes_area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrna_of_interest_df = merged_timeseries_df.loc[\n",
    "    list(\n",
    "        high_mean_intensity_sgRNA\n",
    "        - large_Lb_sgRNA\n",
    "        - large_Ld_sgRNA\n",
    "        - low_growth_sgRNA_area\n",
    "    )\n",
    "]\n",
    "np.sort(\n",
    "    sgrna_of_interest_df[\"Gene\"].unique()[\n",
    "        sgrna_of_interest_df[\"Gene\"].unique() != \"nan\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Interesting genes to discuss\n",
    "\n",
    "- rrl - 23S ribosomal RNA\n",
    "- rsfS - ribosomal silencing factor (also effects mrdAB)\n",
    "- rnb - confusing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrl_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"rrlA rrlC rrlE rrlH\"]\n",
    "rrl_selection = rrl_df.iloc[9]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = rrl_selection[\"init cell timepoints\"]\n",
    "    y = rrl_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"rrl.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsfS_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"rsfS\"]\n",
    "rsfS_selection = rsfS_df.iloc[2]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = rsfS_selection[\"init cell timepoints\"]\n",
    "    y = rsfS_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"rsfS.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172",
   "metadata": {},
   "source": [
    "#### Genes with Increased Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrna_of_interest_df = merged_timeseries_df.loc[list(large_Lb_sgRNA)]\n",
    "np.sort(\n",
    "    sgrna_of_interest_df[\"Gene\"].unique()[\n",
    "        sgrna_of_interest_df[\"Gene\"].unique() != \"nan\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174",
   "metadata": {},
   "source": [
    "##### Subset that does not increase reporter intensity or decrease growth rate (unlike ribosomal proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sorted(large_Lb_genes - high_mean_intensity_genes - low_growth_genes_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176",
   "metadata": {},
   "source": [
    "##### Interesting genes to discuss\n",
    "\n",
    "- fts/dna/muk\n",
    "- mur\n",
    "- esrE\n",
    "- ribosome exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftsZ_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"ftsZ\"]\n",
    "ftsZ_selection = ftsZ_df.iloc[1]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = ftsZ_selection[\"init cell timepoints\"]\n",
    "    y = ftsZ_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"ftsZ.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftsN_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"ftsN\"]\n",
    "ftsN_selection = ftsN_df.iloc[3]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = ftsN_selection[\"init cell timepoints\"]\n",
    "    y = ftsN_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"ftsN.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dnaA_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"dnaA\"]\n",
    "dnaA_selection = dnaA_df.iloc[9]\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = dnaA_selection[\"init cell timepoints\"]\n",
    "    y = dnaA_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"dnaA.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180",
   "metadata": {},
   "source": [
    " - sgRNA which increases Lb near the start of the CDS\n",
    " - sgRNA which decreases reporter intensity might be an off target?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnaB_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"dnaB\"]\n",
    "dnaB_selection = dnaB_df.iloc[3]\n",
    "for label in [\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "    \"Mean Width list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    \"delL list\",\n",
    "    \"Lb list\",\n",
    "]:\n",
    "    t = dnaB_selection[\"init cell timepoints\"]\n",
    "    y = dnaB_selection[label]\n",
    "    plt.title(label)\n",
    "    plt.ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    plt.scatter(t, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182",
   "metadata": {},
   "outputs": [],
   "source": [
    "murC_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"murC\"]\n",
    "murC_selection = murC_df.iloc[3]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = murC_selection[\"init cell timepoints\"]\n",
    "    y = murC_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"murC.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183",
   "metadata": {},
   "outputs": [],
   "source": [
    "esrE_selection = merged_timeseries_df.loc[\"CTAGATATCACCGGTATAAG\"]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",

    "for i, label in enumerate(\n",
    "    [\n",
    "        \"Mean mCherry Intensity list\",\n",
    "        \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "        \"Mean Width list\",\n",
    "        \"Mean Length Increment list\",\n",
    "        \"delL list\",\n",
    "        \"Lb list\",\n",
    "    ]\n",
    "):\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    t = esrE_selection[\"init cell timepoints\"]\n",
    "    y = esrE_selection[label]\n",
    "    ax.set_ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    ax.set_title(label)\n",
    "    ax.scatter(t, y)\n",
    "plt.savefig(\"esrE.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184",
   "metadata": {},
   "source": [
    "#### Genes with Decreased Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrna_of_interest_df = merged_timeseries_df.loc[list(small_Lb_sgRNA)]\n",
    "sgrna_of_interest_df = sgrna_of_interest_df[\n",
    "    sgrna_of_interest_df[\"Gene\"].apply(lambda x: (type(x) == str) and x != \"nan\")\n",
    "]\n",
    "np.sort(sgrna_of_interest_df[\"Gene\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186",
   "metadata": {},
   "source": [
    "##### Interesting genes to discuss\n",
    "\n",
    "- tufAB - EF-Tu\n",
    "- rplJKL - weird exceptions to typical ribosomal protein behavior\n",
    "- rpoW\n",
    "- relB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "tufA_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"tufA\"]\n",
    "tufA_selection = tufA_df.iloc[0]\n",
    "for label in [\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "    \"Mean Width list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    \"delL list\",\n",
    "    \"Lb list\",\n",
    "]:\n",
    "    t = tufA_selection[\"init cell timepoints\"]\n",
    "    y = tufA_selection[label]\n",
    "    plt.title(label)\n",
    "    plt.ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    plt.scatter(t, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188",
   "metadata": {},
   "outputs": [],
   "source": [
    "rplJ_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"rplJ\"]\n",
    "rplJ_selection = rplJ_df.iloc[6]\n",
    "for label in [\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "    \"Mean Width list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    \"delL list\",\n",
    "    \"Lb list\",\n",
    "]:\n",
    "    t = rplJ_selection[\"init cell timepoints\"]\n",
    "    y = rplJ_selection[label]\n",
    "    plt.title(label)\n",
    "    plt.ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    plt.scatter(t, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {},
   "outputs": [],
   "source": [
    "spoT_df = merged_timeseries_df[merged_timeseries_df[\"Gene\"] == \"spoT\"]\n",
    "spoT_selection = spoT_df.iloc[22]\n",
    "for label in [\n",
    "    \"Mean mCherry Intensity list\",\n",
    "    \"Mean mCherry Promoter Activity list (area normed)\",\n",
    "    \"Mean Width list\",\n",
    "    \"Mean Length Increment list\",\n",
    "    \"delL list\",\n",
    "    \"Lb list\",\n",
    "]:\n",
    "    t = spoT_selection[\"init cell timepoints\"]\n",
    "    y = spoT_selection[label]\n",
    "    plt.title(label)\n",
    "    plt.ylim(np.percentile(y, 1), np.percentile(y, 99))\n",
    "    plt.scatter(t, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190",
   "metadata": {},
   "source": [
    "##### Reproducing late log \"adder-timers\"\n",
    "\n",
    "- No clue what's happening here. Make this work later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_gene_timeseries = timeseries_bin_df_output.loc[sgrna_of_interest_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart_means_and_binned_vals(\n",
    "    small_gene_timeseries,\n",
    "    timeseries_bin_df_output,\n",
    "    \"Lb list\",\n",
    "    \"delL list\",\n",
    "    1.5,\n",
    "    5.5,\n",
    "    bins=20,\n",
    "    min_time=5,\n",
    "    max_time=10,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1.0, 6.0),\n",
    "    ylim=(0, 6.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193",
   "metadata": {},
   "source": [
    "#### Genes with Increased Width\n",
    "\n",
    "\n",
    "do this and then make slides??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgrna_of_interest_df = merged_timeseries_df.loc[list(wide_cell_sgRNA)]\n",
    "sgrna_of_interest_df = sgrna_of_interest_df[\n",
    "    sgrna_of_interest_df[\"Gene\"].apply(lambda x: (type(x) == str) and x != \"nan\")\n",
    "]\n",
    "np.sort(sgrna_of_interest_df[\"Gene\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195",
   "metadata": {},
   "source": [
    "#### Filtering for putative division/replication proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(large_cell_genes - high_mean_intensity_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(large_cell_genes - high_mean_intensity_genes - wide_cell_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    sorted(\n",
    "        list(\n",
    "            large_cell_genes\n",
    "            - high_mean_intensity_genes\n",
    "            - wide_cell_genes\n",
    "            - low_div_rate_genes\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(\n",
    "    list(\n",
    "        large_cell_genes\n",
    "        - high_mean_intensity_genes\n",
    "        - wide_cell_genes\n",
    "        - low_div_rate_genes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200",
   "metadata": {},
   "source": [
    "#### Filtering for Genes Perturbing Ribosome Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = sorted(list(large_cell_genes.intersection(high_mean_intensity_genes)))\n",
    "[\"yagH\", \"ycgB\", \"yghJ\", \"yhcN\", \"ypaB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filter_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203",
   "metadata": {},
   "source": [
    "### Adder Measurement for Genes of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df = timeseries_bin_df_output[timeseries_bin_df_output[\"Gene\"].isin([\"ftsI\"])]\n",
    "# filtered_df = timeseries_bin_df_output[timeseries_bin_df_output[\"Gene\"].isin([gene for gene in filter_list if \"thyA\" in gene])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart_means_and_binned_vals(\n",
    "    filtered_df,\n",
    "    controldf,\n",
    "    \"Lb list\",\n",
    "    \"delL list\",\n",
    "    2,\n",
    "    4,\n",
    "    bins=10,\n",
    "    min_time=0,\n",
    "    max_time=3,\n",
    "    xscale=\"linear\",\n",
    "    yscale=\"linear\",\n",
    "    xlim=(1.9, 4.4),\n",
    "    ylim=(0, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206",
   "metadata": {},
   "source": [
    "### PCA on Major Metrics\n",
    "\n",
    "Doesn't seem to be a good direction with the current data; maybe with additional sampling this will improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207",
   "metadata": {},
   "source": [
    "### Genes of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208",
   "metadata": {},
   "source": [
    "### Gene Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"yejM\" \"yghJ\" \"ypaB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_output_df_pd.groupby(\"sgRNA\").apply(lambda x: x.iloc[0])\n",
    "df[\"phenotype trenchids\"] = final_output_df_pd.groupby(\"sgRNA\").apply(\n",
    "    lambda x: x[\"phenotype trenchid\"].tolist()\n",
    ")\n",
    "df = df[\n",
    "    [\n",
    "        \"Gene\",\n",
    "        \"Target Sequence\",\n",
    "        \"phenotype trenchids\",\n",
    "        \"N Mismatch\",\n",
    "        \"N Target Sites\",\n",
    "        \"Category\",\n",
    "        \"Strand\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kymo_xarr = tr.kymo_xarr(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Growth_Division\"\n",
    ")\n",
    "wrapped_kymo_xarr = tr.kymo_xarr(\n",
    "    \"/home/de64/scratch/de64/sync_folder/2021-06-14_lDE20_biofloat_fullrun_1/Growth_Division\",\n",
    "    unwrap=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gene_table_layout,\n",
    "    select_gene,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid,\n",
    ") = tr.linked_gene_table(\n",
    "    df, trenchids_as_list=True, trenchid_column=\"phenotype trenchids\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gene_table_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_display, save_button = tr.linked_kymograph_for_gene_table(\n",
    "    kymo_xarr,\n",
    "    wrapped_kymo_xarr,\n",
    "    df,\n",
    "    select_gene,\n",
    "    select_trenchid,\n",
    "    select_unpacked_trenchid=select_unpacked_trenchid,\n",
    "    trenchid_column=\"phenotype trenchids\",\n",
    "    y_scale=3,\n",
    "    x_window_size=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_button  ## NEED OPTION WHETHER OR NOT TO NORM SIGNAL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
