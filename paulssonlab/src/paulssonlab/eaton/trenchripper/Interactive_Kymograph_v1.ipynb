{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Kymograph Code Draft\n",
    "\n",
    "Xref: Journal/12_26_18/Interactive_Kymograph_Draft_no_scaling.ipynb\n",
    "\n",
    "Goal: In this notebook, I will finalize the interactive kymograph code I wrote in `Interactive_Kymograph_v1.ipynb` This is a copy of `Interactive_Kymograph_Draft_no_scaling.ipynb`\n",
    "\n",
    "This code should have the following features:\n",
    "\n",
    "- seamless parameter tuning with visual outputs\n",
    "- chunking of the analysis process into steps\n",
    "- representative results from across the dataset\n",
    "- global qc stats?\n",
    "\n",
    "I should also use this code as an oppertunity to try out new things for the main (hdf5 using) codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "Modifying this code haphazardly is getting a bit unwieldy. Try to write down a game plan for the final drafting of the interactive kymograph, given what I have learned about the implementation. In addition, review the structure of this and the original kymograph code for restructuring/simplification. Finally, move on to the extraction code.\n",
    "\n",
    "**THIS KYMOGRAPH CODE MUST BE DEPLOYABLE BY 1/4**\n",
    "\n",
    "### PLAN TO GET THIS DONE\n",
    "\n",
    " - (1/2) Implement this structure and finish interactive code (including comments).\n",
    " - (1/3) Try to eleminate redundancy in codebase with global handlers for main code differences between interactive and\n",
    " server code...\n",
    " - (1/3) Revisit original code and implement structural simplification (i.e. distinct stopping points)\n",
    " - (1/3) Devise and implement library structure for the hdf5 conversion and kymograph code\n",
    " - (1/4) Finishing touches on library and start working on segmentation code.\n",
    " - (1/5) Write down structure of segmentation code (try to keep schematically similar to kymo code)\n",
    " - (?) Try to figure out if the read/write overhead is causing major problems...eliminate unnecessary I/O\n",
    " - (?) Play around with the dask way of chunking (in bookmarks) (don't do this until kymo interactive is done, but before seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import scipy.signal\n",
    "import shutil\n",
    "import skimage as sk\n",
    "from skimage import filters, transform\n",
    "\n",
    "from ipywidgets import (\n",
    "    interact,\n",
    "    interactive,\n",
    "    fixed,\n",
    "    interact_manual,\n",
    "    FloatSlider,\n",
    "    IntSlider,\n",
    ")\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kymograph_interactive:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_file_prefix,\n",
    "        all_channels,\n",
    "        trench_len_y,\n",
    "        padding_y,\n",
    "        trench_width_x,\n",
    "        fov_list,\n",
    "        t_subsample_step=1,\n",
    "        y_percentile=85,\n",
    "        y_min_edge_dist=50,\n",
    "        smoothing_kernel_y=(9, 3),\n",
    "        triangle_nbins=50,\n",
    "        triangle_scaling=1.0,\n",
    "        x_percentile=85,\n",
    "        background_kernel_x=(301, 1),\n",
    "        smoothing_kernel_x=(9, 1),\n",
    "        otsu_nbins=50,\n",
    "        otsu_scaling=1.0,\n",
    "    ):\n",
    "        \"\"\"The kymograph class is used to generate and visualize kymographs. The central function of this\n",
    "        class is the method 'generate_kymograph', which takes an hdf5 file of images from a single fov and\n",
    "        outputs an hdf5 file containing kymographs from all detected trenches.\n",
    "\n",
    "        NOTE: I need to revisit the row detection, must ensure there can be no overlap...\n",
    "\n",
    "        Args:\n",
    "            input_file_prefix (string): File prefix for all input hdf5 files of the form\n",
    "            [input_file_prefix][number].hdf5\n",
    "            all_channels (list): list of strings corresponding to the different image channels\n",
    "            available in the input hdf5 file, with the channel used for segmenting trenches in\n",
    "            the first position. NOTE: these names must match those of the input hdf5 file datasets.\n",
    "            trench_len_y (int): Length from the end of the tenches to be used when cropping in the\n",
    "            y-dimension.\n",
    "            padding_y (int): Padding to be used when cropping in the y-dimension.\n",
    "            trench_width_x (int): Width to be used when cropping in the x-dimension.\n",
    "            fov_list (list): List of ints corresponding to fovs of interest.\n",
    "\n",
    "            t_subsample_step(int): Step size to be used for subsampling input files in time.\n",
    "\n",
    "            y_percentile (int): Used for reducing signal in xyt to only the yt dimension when cropping\n",
    "            in the y-dimension.\n",
    "            y_min_edge_dist (int): Used when detecting present rows, filters for a minimum row size along the y dimension.\n",
    "            smoothing_kernel_y (tuple): Two-entry tuple specifying a kernel size for smoothing out yt\n",
    "            signal when cropping in the y-dimension.\n",
    "            triangle_nbins (int): Number of bins to use when applying the triangle method to y-dimension signal.\n",
    "            triangle_scaling (float): Threshold scaling factor for triangle method thresholding.\n",
    "\n",
    "            x_percentile (int): Used for reducing signal in xyt to only the xt dimension when cropping\n",
    "            in the x-dimension.\n",
    "            background_kernel_x (tuple): Two-entry tuple specifying a kernel size for performing background subtraction\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "            smoothing_kernel_x (tuple): Two-entry tuple specifying a kernel size for performing smoothing\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "            otsu_nbins (int): Number of bins to use when applying Otsu's method to x-dimension signal.\n",
    "            otsu_scaling (float): Threshold scaling factor for Otsu's method thresholding.\n",
    "        \"\"\"\n",
    "\n",
    "        self.input_file_prefix = input_file_prefix\n",
    "\n",
    "        self.all_channels = all_channels\n",
    "        self.seg_channel = self.all_channels[0]\n",
    "\n",
    "        #### For prieviewing\n",
    "        self.fov_list = fov_list\n",
    "        self.num_fovs = len(fov_list)\n",
    "        self.t_subsample_step = t_subsample_step\n",
    "\n",
    "        #### important paramaters to set\n",
    "        self.trench_len_y = trench_len_y\n",
    "        self.padding_y = padding_y\n",
    "        self.ttl_len_y = trench_len_y + padding_y\n",
    "        self.trench_width_x = trench_width_x\n",
    "\n",
    "        #### params for y\n",
    "        ## parameter for reducing signal to one dim\n",
    "        self.y_percentile = y_percentile\n",
    "        self.y_min_edge_dist = y_min_edge_dist\n",
    "        ## parameters for threshold finding\n",
    "        self.smoothing_kernel_y = smoothing_kernel_y\n",
    "        self.triangle_nbins = triangle_nbins\n",
    "        self.triangle_scaling = triangle_scaling\n",
    "\n",
    "        #### params for x\n",
    "        ## parameter for reducing signal to one dim\n",
    "        self.x_percentile = x_percentile\n",
    "        ## parameters for midpoint finding\n",
    "        self.background_kernel_x = background_kernel_x\n",
    "        self.smoothing_kernel_x = smoothing_kernel_x\n",
    "        ## parameters for threshold finding\n",
    "        self.otsu_nbins = otsu_nbins\n",
    "        self.otsu_scaling = otsu_scaling\n",
    "\n",
    "    def writedir(self, directory, overwrite=False):\n",
    "        \"\"\"Creates an empty directory at the specified location. If a directory is\n",
    "        already at this location, it will be overwritten if 'overwrite' is true,\n",
    "        otherwise it will be left alone.\n",
    "\n",
    "        Args:\n",
    "            directory (str): Path to directory to be overwritten/created.\n",
    "            overwrite (bool, optional): Whether to overwrite a directory that\n",
    "            already exists in this location.\n",
    "        \"\"\"\n",
    "        print(directory)\n",
    "        if overwrite:\n",
    "            if os.path.exists(directory):\n",
    "                shutil.rmtree(directory)\n",
    "            os.makedirs(directory)\n",
    "        else:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "    def removefile(self, filepath):\n",
    "        \"\"\"Removes a file at the specified path, if it exists.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to file for deletion.\n",
    "        \"\"\"\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "\n",
    "    def median_filter_2d(self, array, smoothing_kernel):\n",
    "        \"\"\"Two-dimensional median filter, with average smoothing at the signal edges in\n",
    "        the first dimension.\n",
    "\n",
    "        Args:\n",
    "            array_list (list): List containing a single array of yt signal to be smoothed.\n",
    "\n",
    "        Returns:\n",
    "            array: Median-filtered yt signal.\n",
    "        \"\"\"\n",
    "        kernel = np.array(smoothing_kernel)\n",
    "        kernel_pad = kernel // 2 + 1\n",
    "        med_filter = scipy.signal.medfilt(array, kernel_size=kernel)\n",
    "        start_edge = np.mean(med_filter[kernel_pad[0] : kernel[0]])\n",
    "        end_edge = np.mean(med_filter[-kernel[0] : -kernel_pad[0]])\n",
    "        med_filter[: kernel_pad[0]] = start_edge\n",
    "        med_filter[-kernel_pad[0] :] = end_edge\n",
    "        return med_filter\n",
    "\n",
    "    def map_to_fovs(self, func, *args, **kargs):\n",
    "        \"\"\"Handler for performing steps of analysis across multiple fovs. Appends output\n",
    "        of a function to a list of outputs for each fov.\n",
    "\n",
    "        Args:\n",
    "            func (function): Function to apply to each fov. NOTE: Must be written\n",
    "            to accept the fov index i as the first argument.\n",
    "            *args: Arguments to pass to the function.\n",
    "            **kargs: Keyword arguments to pass to the function.\n",
    "\n",
    "        Returns:\n",
    "            list: List of function outputs, one for each fov.\n",
    "        \"\"\"\n",
    "        output_list = []\n",
    "        for i in range(self.num_fovs):\n",
    "            output = func(i, *args, **kargs)\n",
    "            output_list.append(output)\n",
    "        return output_list\n",
    "\n",
    "    def import_hdf5(self, i):\n",
    "        \"\"\"Performs initial import of the hdf5 file to be processed. Converts the input hdf5 file's \"channel\"\n",
    "        datasets into the first dimension of the array, ordered as specified by 'self.all_channels'. Outputs\n",
    "        a numpy array.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "\n",
    "        Returns:\n",
    "            array: A numpy array containing the hdf5 file image data.\n",
    "        \"\"\"\n",
    "        fov = self.fov_list[i]\n",
    "        hdf5_handle = h5py.File(self.input_file_prefix + str(fov) + \".hdf5\", \"a\")\n",
    "        t_len = hdf5_handle[self.seg_channel].shape[2]\n",
    "        indices = list(range(0, t_len, self.t_subsample_step))\n",
    "        array = np.array(\n",
    "            [\n",
    "                np.take(hdf5_handle[channel], indices, axis=2)\n",
    "                for channel in self.all_channels\n",
    "            ]\n",
    "        )\n",
    "        hdf5_handle.close()\n",
    "        return array\n",
    "\n",
    "    def get_smoothed_y_percentiles(\n",
    "        self, i, imported_array_list, y_percentile, smoothing_kernel_y\n",
    "    ):\n",
    "        \"\"\"For each imported array, computes the percentile along the x-axis of the segmentation\n",
    "        channel, generating a (y,t) array. Then performs median filtering of this array for smoothing.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            imported_array_list (list): A list containing numpy arrays containing the hdf5 file image\n",
    "            data of shape (channel,y,x,t).\n",
    "            y_percentile (int): Percentile to apply along the x-axis.\n",
    "            smoothing_kernel_y (tuple): Kernel to use for median filtering.\n",
    "\n",
    "        Returns:\n",
    "            array: A smoothed percentile array of shape (y,t)\n",
    "        \"\"\"\n",
    "        imported_array = imported_array_list[i]\n",
    "        y_percentiles = np.percentile(imported_array[0], y_percentile, axis=1)\n",
    "        y_percentiles_smoothed = self.median_filter_2d(\n",
    "            y_percentiles, smoothing_kernel_y\n",
    "        )\n",
    "        return y_percentiles_smoothed\n",
    "\n",
    "    def triangle_threshold(self, img_arr, triangle_nbins, triangle_scaling):\n",
    "        \"\"\"Applys a triangle threshold, returning a boolean mask.\n",
    "\n",
    "        Args:\n",
    "            img_arr (array): Image array to be thresholded.\n",
    "            triangle_nbins (int): Number of bins to be used to construct the thresholding\n",
    "            histogram.\n",
    "            triangle_scaling (float): Factor by which to scale the threshold.\n",
    "\n",
    "        Returns:\n",
    "            array: Boolean mask produced by the threshold.\n",
    "        \"\"\"\n",
    "        triangle_threshold = (\n",
    "            sk.filters.threshold_triangle(img_arr, nbins=triangle_nbins)\n",
    "            * triangle_scaling\n",
    "        )\n",
    "        triangle_mask = img_arr > triangle_threshold\n",
    "        return triangle_mask\n",
    "\n",
    "    def remove_small_rows(self, edges, min_edge_dist):\n",
    "        \"\"\"Filters out small rows when performing automated row detection.\n",
    "\n",
    "        Args:\n",
    "            edges (array): Array of edges along y-axis.\n",
    "            min_edge_dist (int): Minimum row length necessary for detection.\n",
    "\n",
    "        Returns:\n",
    "            array: Array of edges, filtered for rows that are too small.\n",
    "        \"\"\"\n",
    "        grouped_edges = edges.reshape(-1, 2)\n",
    "        row_lens = np.diff(grouped_edges, axis=1)\n",
    "        row_mask = (row_lens > min_edge_dist).flatten()\n",
    "        filtered_edges = grouped_edges[row_mask]\n",
    "        return filtered_edges.flatten()\n",
    "\n",
    "    def get_edges_from_mask(self, mask, min_edge_dist):\n",
    "        \"\"\"Finds edges from a boolean mask of shape (y,t). Filters out rows of length\n",
    "        smaller than min_edge_dist.\n",
    "\n",
    "        Args:\n",
    "            mask (array): Boolean of shape (y,t) resulting from triangle thresholding.\n",
    "            min_edge_dist (int): Minimum row length necessary for detection.\n",
    "\n",
    "        Returns:\n",
    "            list: List containing arrays of edges for each timepoint, filtered for rows that are too small.\n",
    "        \"\"\"\n",
    "        edges_list = []\n",
    "        for t in range(mask.shape[1]):\n",
    "            edge_mask = mask[1:, t] != mask[:-1, t]\n",
    "            edges = np.where(edge_mask)[0]\n",
    "            edges = self.remove_small_rows(edges, min_edge_dist)\n",
    "            edges_list.append(edges)\n",
    "        return edges_list\n",
    "\n",
    "    def get_trench_edges_y(\n",
    "        self,\n",
    "        i,\n",
    "        y_percentiles_smoothed_list,\n",
    "        triangle_nbins,\n",
    "        triangle_scaling,\n",
    "        min_edge_dist,\n",
    "    ):\n",
    "        \"\"\"Detects edges in the shape (y,t) smoothed percentile arrays for each input array.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            y_percentiles_smoothed_list (list): List containing a smoothed percentile array for each input array.\n",
    "            triangle_nbins (int): Number of bins to be used to construct the thresholding histogram.\n",
    "            triangle_scaling (float): Factor by which to scale the threshold.\n",
    "            min_edge_dist (int): Minimum row length necessary for detection.\n",
    "\n",
    "        Returns:\n",
    "            list: List containing arrays of edges for each timepoint, filtered for rows that are too small.\n",
    "        \"\"\"\n",
    "        y_percentiles_smoothed = y_percentiles_smoothed_list[i]\n",
    "        trench_mask_y = self.triangle_threshold(\n",
    "            y_percentiles_smoothed, triangle_nbins, triangle_scaling\n",
    "        )\n",
    "        trench_edges_y_list = self.get_edges_from_mask(trench_mask_y, min_edge_dist)\n",
    "        return trench_edges_y_list\n",
    "\n",
    "    def get_row_numbers(self, i, trench_edges_y_list):\n",
    "        \"\"\"Computes the number of trench rows in the fov, from the detected edges.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            trench_edges_y_list (list): List containing, for each fov entry, a list of time-sorted edge arrays.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of trench rows detected in the fov of index i.\n",
    "        \"\"\"\n",
    "        trench_edges_y = trench_edges_y_list[i]\n",
    "        edge_num_list = [len(item) for item in trench_edges_y]\n",
    "        trench_row_num = (np.median(edge_num_list).astype(int)) // 2\n",
    "        return trench_row_num\n",
    "\n",
    "    def crop_y(\n",
    "        self,\n",
    "        i,\n",
    "        trench_edges_y_lists,\n",
    "        row_num_list,\n",
    "        imported_array_list,\n",
    "        padding_y,\n",
    "        trench_len_y,\n",
    "        top_orientation=0,\n",
    "    ):\n",
    "        \"\"\"Performs cropping of the images in the y-dimension.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            trench_edges_y_list (list): List containing, for each fov entry, a list of time-sorted edge arrays.\n",
    "            row_num_list (list): List containing The number of trench rows detected in each fov.\n",
    "            imported_array_list (list): A list containing numpy arrays containing the hdf5 file image\n",
    "            data of shape (channel,y,x,t).\n",
    "            padding_y (int): Padding to be used when cropping in the y-dimension.\n",
    "            trench_len_y (int): Length from the end of the tenches to be used when cropping in the\n",
    "            y-dimension.\n",
    "            top_orientation (int, optional): The orientation of the top-most row where 0 corresponds to a trench with\n",
    "            a downward-oriented trench opening and 1 corresponds to a trench with an upward-oriented trench opening.\n",
    "        Returns:\n",
    "            array: A y-cropped array of shape (rows,channels,x,y,t).\n",
    "        \"\"\"\n",
    "        trench_edges_y_list = trench_edges_y_lists[i]\n",
    "        imported_array = imported_array_list[i]\n",
    "        trench_row_num = row_num_list[i]\n",
    "\n",
    "        time_list = []\n",
    "        for t in range(imported_array.shape[3]):\n",
    "            trench_edges_y = trench_edges_y_list[t]\n",
    "            orientation = top_orientation\n",
    "\n",
    "            top_bottom_list = []\n",
    "            for r in range(0, trench_row_num):\n",
    "                if orientation == 0:\n",
    "                    trench_edge_y = trench_edges_y[2 * r]\n",
    "                    upper = max(trench_edge_y - padding_y, 0)\n",
    "                    lower = min(trench_edge_y + trench_len_y, imported_array.shape[1])\n",
    "                else:\n",
    "                    trench_edge_y = trench_edges_y[(2 * r) + 1]\n",
    "                    upper = max(trench_edge_y - trench_len_y, 0)\n",
    "                    lower = min(trench_edge_y + padding_y, imported_array.shape[1])\n",
    "\n",
    "                orientation = (orientation + 1) % 2\n",
    "\n",
    "                channel_list = []\n",
    "                for c in range(imported_array.shape[0]):\n",
    "                    output_array = imported_array[c, upper:lower, :, t]\n",
    "                    channel_list.append(output_array)\n",
    "                top_bottom_list.append(channel_list)\n",
    "            time_list.append(top_bottom_list)\n",
    "\n",
    "        cropped_in_y = np.array(time_list)\n",
    "        if len(cropped_in_y.shape) != 5:\n",
    "            return None\n",
    "        else:\n",
    "            cropped_in_y = np.moveaxis(cropped_in_y, (0, 1, 2, 3, 4), (4, 0, 1, 2, 3))\n",
    "            return cropped_in_y\n",
    "\n",
    "    def crop_trenches_in_y(self, imported_array_list):\n",
    "        \"\"\"Master function for cropping the input hdf5 file in the y-dimension.\n",
    "\n",
    "        Args:\n",
    "            imported_array_list (list): List containing, for each fov entry, a numpy array containing\n",
    "            the corresponding hdf5 file image data.\n",
    "\n",
    "        Returns:\n",
    "            list: List containing, for each fov entry, a y-cropped numpy array of shape (rows,channels,x,y,t).\n",
    "        \"\"\"\n",
    "        y_percentiles_smoothed_list = self.map_to_fovs(\n",
    "            self.get_smoothed_y_percentiles,\n",
    "            imported_array_list,\n",
    "            self.y_percentile,\n",
    "            self.smoothing_kernel_y,\n",
    "        )\n",
    "\n",
    "        trench_edges_y_lists = self.map_to_fovs(\n",
    "            self.get_trench_edges_y,\n",
    "            y_percentiles_smoothed_list,\n",
    "            self.triangle_nbins,\n",
    "            self.triangle_scaling,\n",
    "            self.min_edge_dist,\n",
    "        )\n",
    "        row_num_list = self.map_to_fovs(self.get_row_numbers, trench_edges_y_lists)\n",
    "        cropped_in_y_list = self.map_to_fovs(\n",
    "            self.crop_y,\n",
    "            trench_edges_y_lists,\n",
    "            row_num_list,\n",
    "            imported_array_list,\n",
    "            self.padding_y,\n",
    "            self.trench_len_y,\n",
    "        )\n",
    "        return cropped_in_y_list\n",
    "\n",
    "    def get_smoothed_x_percentiles(\n",
    "        self,\n",
    "        i,\n",
    "        cropped_in_y_list,\n",
    "        x_percentile,\n",
    "        background_kernel_x,\n",
    "        smoothing_kernel_x,\n",
    "    ):\n",
    "        \"\"\"Summary\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            cropped_in_y_list (list): List containing, for each fov entry, a y-cropped numpy array of shape (rows,channels,x,y,t).\n",
    "            x_percentile (int): Used for reducing signal in xyt to only the xt dimension when cropping\n",
    "            in the x-dimension.\n",
    "            background_kernel_x (tuple): Two-entry tuple specifying a kernel size for performing background subtraction\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "            smoothing_kernel_x (tuple): Two-entry tuple specifying a kernel size for performing smoothing\n",
    "            on xt signal when cropping in the x-dimension. Dim_1 (time) should be set to 1.\n",
    "\n",
    "        Returns:\n",
    "            array: A smoothed and background subtracted percentile array of shape (rows,x,t)\n",
    "        \"\"\"\n",
    "        cropped_in_y = cropped_in_y_list[i]\n",
    "        x_percentiles_smoothed_rows = []\n",
    "        for row_num in range(cropped_in_y.shape[0]):\n",
    "            cropped_in_y_arr = cropped_in_y[row_num, 0]\n",
    "            x_percentiles = np.percentile(cropped_in_y_arr, x_percentile, axis=0)\n",
    "            x_background_filtered = x_percentiles - self.median_filter_2d(\n",
    "                x_percentiles, background_kernel_x\n",
    "            )\n",
    "            x_smooth_filtered = self.median_filter_2d(\n",
    "                x_background_filtered, smoothing_kernel_x\n",
    "            )\n",
    "            x_percentiles_smoothed_rows.append(x_smooth_filtered)\n",
    "        x_percentiles_smoothed_rows = np.array(x_percentiles_smoothed_rows)\n",
    "        return x_percentiles_smoothed_rows\n",
    "\n",
    "    def get_midpoints_from_mask(self, mask):\n",
    "        \"\"\"Using a boolean x mask, computes the positions of trench midpoints.\n",
    "\n",
    "        Args:\n",
    "            mask (array): x boolean array, specifying where trenches are present.\n",
    "\n",
    "        Returns:\n",
    "            array: array of trench midpoint x positions.\n",
    "        \"\"\"\n",
    "        transitions = mask[:-1].astype(int) - mask[1:].astype(int)\n",
    "\n",
    "        trans_up = np.where((transitions == -1))[0]\n",
    "        trans_dn = np.where((transitions == 1))[0]\n",
    "\n",
    "        if len(np.where(trans_dn > trans_up[0])[0]) > 0:\n",
    "            first_dn = np.where(trans_dn > trans_up[0])[0][0]\n",
    "            trans_dn = trans_dn[first_dn:]\n",
    "            trans_up = trans_up[: len(trans_dn)]\n",
    "            midpoints = (trans_dn + trans_up) // 2\n",
    "        else:\n",
    "            midpoints = []\n",
    "        return midpoints\n",
    "\n",
    "    def get_midpoints(self, x_percentiles_t, otsu_nbins, otsu_scaling):\n",
    "        \"\"\"Given an array of signal in x, determines the position of trench midpoints.\n",
    "\n",
    "        Args:\n",
    "            x_percentiles_t (array): array of trench intensities in x, at time t.\n",
    "            otsu_nbins (int): Number of bins to use when applying Otsu's method to x-dimension signal.\n",
    "            otsu_scaling (float): Threshold scaling factor for Otsu's method thresholding.\n",
    "\n",
    "        Returns:\n",
    "            array: array of trench midpoint x positions.\n",
    "        \"\"\"\n",
    "        otsu_threshold = (\n",
    "            sk.filters.threshold_otsu(x_percentiles_t[:, np.newaxis], nbins=otsu_nbins)\n",
    "            * otsu_scaling\n",
    "        )\n",
    "        x_mask = x_percentiles_t > otsu_threshold\n",
    "        midpoints = self.get_midpoints_from_mask(x_mask)\n",
    "        return midpoints\n",
    "\n",
    "    def get_all_midpoints(\n",
    "        self, i, x_percentiles_smoothed_list, otsu_nbins, otsu_scaling\n",
    "    ):\n",
    "        \"\"\"Given an x percentile array of shape (rows,x,t), determines the trench midpoints of each row array\n",
    "        at each time t.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            x_percentiles_smoothed (array): A smoothed and background subtracted percentile array of shape (rows,x,t)\n",
    "            otsu_nbins (TYPE): Description\n",
    "            otsu_scaling (TYPE): Description\n",
    "\n",
    "        Returns:\n",
    "            list: A nested list of the form [row_list,[time_list,[midpoint_array]]].\n",
    "        \"\"\"\n",
    "        x_percentiles_smoothed_row = x_percentiles_smoothed_list[i]\n",
    "        midpoints_row_list = []\n",
    "        for j in range(x_percentiles_smoothed_row.shape[0]):\n",
    "            x_percentiles_smoothed = x_percentiles_smoothed_row[j]\n",
    "            all_midpoints = []\n",
    "            midpoints = self.get_midpoints(\n",
    "                x_percentiles_smoothed[:, 0], otsu_nbins, otsu_scaling\n",
    "            )\n",
    "            if len(midpoints) == 0:\n",
    "                return None\n",
    "            all_midpoints.append(midpoints)\n",
    "            for t in range(1, x_percentiles_smoothed.shape[1]):\n",
    "                midpoints = self.get_midpoints(\n",
    "                    x_percentiles_smoothed[:, t], otsu_nbins, otsu_scaling\n",
    "                )\n",
    "                if len(midpoints) / (len(all_midpoints[-1]) + 1) < 0.5:\n",
    "                    all_midpoints.append(all_midpoints[-1])\n",
    "                else:\n",
    "                    all_midpoints.append(midpoints)\n",
    "            midpoints_row_list.append(all_midpoints)\n",
    "        return midpoints_row_list\n",
    "\n",
    "    def get_x_drift(self, i, all_midpoints_list):\n",
    "        \"\"\"Given an t by x array of midpoints, computed the average drift in x for every timepoint.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            all_midpoints_list (list): A nested list of the form [fov_list,[row_list,[time_list,[midpoint_array]]]] containing\n",
    "            the trench midpoints.\n",
    "\n",
    "        Returns:\n",
    "            list: A nested list of the form [row_list,[time_list,[x_drift_int]]].\n",
    "        \"\"\"\n",
    "        midpoints_row_list = all_midpoints_list[i]\n",
    "        x_drift_row_list = []\n",
    "        for all_midpoints in midpoints_row_list:\n",
    "            x_drift = []\n",
    "            for t in range(len(all_midpoints) - 1):\n",
    "                diff_mat = np.subtract.outer(all_midpoints[t + 1], all_midpoints[t])\n",
    "                min_dist_idx = np.argmin(abs(diff_mat), axis=0)\n",
    "                min_dists = diff_mat[min_dist_idx]\n",
    "                median_translation = int(np.median(min_dists))\n",
    "                x_drift.append(median_translation)\n",
    "            net_x_drift = np.append(np.array([0]), np.add.accumulate(x_drift))\n",
    "            x_drift_row_list.append(net_x_drift)\n",
    "        return x_drift_row_list\n",
    "\n",
    "    def init_counting_arr(self, x_dim, t_dim):\n",
    "        \"\"\"Initializes a counting array of shape (x_dim,t_dim) which counts from 0 to\n",
    "        x_dim on axis 0 for all positions in axis 1.\n",
    "\n",
    "        Args:\n",
    "            x_dim (int): Size of x axis to use.\n",
    "            t_dim (int): Size of t axis to use.\n",
    "\n",
    "        Returns:\n",
    "            array: Counting array to be used for masking out trenches in x.\n",
    "        \"\"\"\n",
    "        ones_arr = np.ones(x_dim)\n",
    "        counting_arr = np.add.accumulate(np.ones(x_dim)).astype(int) - 1\n",
    "        counting_arr_repeated = np.repeat(counting_arr[:, np.newaxis], t_dim, axis=1)\n",
    "        return counting_arr_repeated\n",
    "\n",
    "    def get_k_mask(self, in_bounds, counting_arr, k):\n",
    "        \"\"\"Generates a boolean trench mask of shape (x_dim,t_dim) for a given trench k, using\n",
    "        the trench boundary values in in_bounds_list.\n",
    "\n",
    "        Args:\n",
    "            in_bounds (array): A shape (2,t_dim,k_dim) array specifying the start and end bounds in x of a\n",
    "            given trench k over time.\n",
    "            counting_arr (array): Counting array to be used for masking out trenches in x.\n",
    "            k (int): Int specifying the trench to generate a mask for.\n",
    "\n",
    "        Returns:\n",
    "            array: Boolean trench mask of shape (x_dim,t_dim) for a given trench k.\n",
    "        \"\"\"\n",
    "        working_t_dim = in_bounds.shape[1]\n",
    "        cropped_counting_arr = counting_arr[:, :working_t_dim]\n",
    "        k_mask = np.logical_and(\n",
    "            cropped_counting_arr > in_bounds[0, :, k],\n",
    "            cropped_counting_arr < in_bounds[1, :, k],\n",
    "        ).T\n",
    "        return k_mask\n",
    "\n",
    "    def apply_kymo_mask(self, img_arr, mask_arr, row_num, channel):\n",
    "        \"\"\"Given a y-cropped image and a boolean trench mask of shape (x_dim,t_dim), masks that image in\n",
    "        xt to generate an output kymograph of shape (y_dim,x_dim,t_dim).\n",
    "\n",
    "        Args:\n",
    "            img_arr (array): A numpy array of a y-cropped image\n",
    "            mask_arr (array): A boolean trench mask of shape (x_dim,t_dim) for a given trench k\n",
    "            row_num (int): Int specifying the current row.\n",
    "            channel (int): Int specifying which channel we are getting midpoints from (order specified by\n",
    "            self.all_channels).\n",
    "\n",
    "        Returns:\n",
    "            array: Kymograph array of shape (y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        working_img_arr = img_arr[row_num, channel]\n",
    "        reshaped_arr = np.swapaxes(working_img_arr, 1, 2)\n",
    "        masked_arr = reshaped_arr[:, mask_arr.astype(bool)]\n",
    "        reshaped_masked_arr = masked_arr.reshape(\n",
    "            reshaped_arr.shape[0], reshaped_arr.shape[1], -1\n",
    "        )\n",
    "        swapped_masked_arr = np.swapaxes(reshaped_masked_arr, 1, 2)\n",
    "        return swapped_masked_arr\n",
    "\n",
    "    def get_k_masks(self, cropped_in_y, all_midpoints, x_drift, trench_width_x):\n",
    "        \"\"\"Generates a boolean trench mask of shape (x_dim,t_dim) for each trench k. This will be used to mask\n",
    "        out each trench at a later step.\n",
    "\n",
    "        Args:\n",
    "            cropped_in_y (array): A y-cropped numpy array of shape (rows,channels,x,y,t) containing y-cropped image data.\n",
    "            all_midpoints (list): A list containing, for each time t, an array of trench midpoints.\n",
    "            x_drift (list): A list containing, for each time t, an int corresponding to the drift of the midpoints in x.\n",
    "            trench_width_x (int): Width to be used when cropping in the x-dimension.\n",
    "\n",
    "        Returns:\n",
    "            list:  A list containing, for each trench k, a boolean trench mask of shape (x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        corrected_midpoints = x_drift[:, np.newaxis] + all_midpoints[0][np.newaxis, :]\n",
    "        midpoints_up, midpoints_dn = (\n",
    "            corrected_midpoints - trench_width_x // 2,\n",
    "            corrected_midpoints + trench_width_x // 2 + 1,\n",
    "        )\n",
    "        valid_mask = np.all(midpoints_up >= 0, axis=0) * np.all(\n",
    "            midpoints_dn <= cropped_in_y.shape[3], axis=0\n",
    "        )\n",
    "        in_bounds = np.array([midpoints_up[:, valid_mask], midpoints_dn[:, valid_mask]])\n",
    "        counting_arr = self.init_counting_arr(\n",
    "            cropped_in_y.shape[3], cropped_in_y.shape[4]\n",
    "        )\n",
    "\n",
    "        k_masks = []\n",
    "        for k in range(in_bounds.shape[2]):\n",
    "            k_mask = self.get_k_mask(in_bounds, counting_arr, k)\n",
    "            k_masks.append(k_mask)\n",
    "        return k_masks\n",
    "\n",
    "    def crop_with_k_masks(self, cropped_in_y, row_num, k_masks):\n",
    "        \"\"\"Performs cropping of the aleady y-cropped image data, using pregenerated kymograph masks\n",
    "        of shape (x_dim,t_dim).\n",
    "\n",
    "        Args:\n",
    "            cropped_in_y (array): A y-cropped array of shape (rows,channels,x,y,t).\n",
    "            row_num (int): The row number to crop kymographs from.\n",
    "            k_masks (list): A list containing, for each trench k, a boolean trench mask of shape (x_dim,t_dim).\n",
    "\n",
    "        Returns:\n",
    "            list: A kymograph array of shape (channels,trenches,y_dim,x_dim,t_dim)\n",
    "        \"\"\"\n",
    "        x_cropped = []\n",
    "        for channel in range(len(self.all_channels)):\n",
    "            kymographs = []\n",
    "            for k in range(len(k_masks)):\n",
    "                k_mask = k_masks[k]\n",
    "                kymograph = self.apply_kymo_mask(cropped_in_y, k_mask, row_num, channel)\n",
    "                kymographs.append(kymograph)\n",
    "            x_cropped.append(np.array(kymographs))\n",
    "        x_cropped = np.array(x_cropped)\n",
    "        return x_cropped\n",
    "\n",
    "    def get_crop_in_x(\n",
    "        self, i, cropped_in_y_list, all_midpoints_list, x_drift_list, trench_width_x\n",
    "    ):\n",
    "        \"\"\"Generates complete kymograph arrays for all trenches in the fov in every channel listed in 'self.all_channels'.\n",
    "        Outputs a list of these kymograph arrays, with entries corresponding to each row in the fov with index i.\n",
    "\n",
    "        Args:\n",
    "            i (int): Specifies the current fov index.\n",
    "            cropped_in_y_list (list): List containing, for each fov entry, a y-cropped numpy array of shape (rows,channels,x,y,t).\n",
    "            all_midpoints_list (list): A nested list of the form [fov_list,[row_list,[time_list,[midpoint_array]]]] containing\n",
    "            the trench midpoints.\n",
    "            x_drift_list (list): A nested list of the form [fov_list,[row_list,[time_list,[x_drift_int]]]] containing the computed\n",
    "            drift in the x dimension.\n",
    "            trench_width_x (int): Width to be used when cropping in the x-dimension.\n",
    "\n",
    "        Returns:\n",
    "            list: A list containing, for each row, a kymograph array of shape (channels,trenches,y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        cropped_in_y = cropped_in_y_list[i]\n",
    "        midpoints_row_list = all_midpoints_list[i]\n",
    "        x_drift_row_list = x_drift_list[i]\n",
    "        crop_in_x_row_list = []\n",
    "        for row_num, all_midpoints in enumerate(midpoints_row_list):\n",
    "            x_drift = x_drift_row_list[row_num]\n",
    "            k_masks = self.get_k_masks(\n",
    "                cropped_in_y, all_midpoints, x_drift, trench_width_x\n",
    "            )\n",
    "            x_cropped = self.crop_with_k_masks(cropped_in_y, row_num, k_masks)\n",
    "            crop_in_x_row_list.append(x_cropped)\n",
    "        return crop_in_x_row_list\n",
    "\n",
    "    def crop_trenches_in_x(self, cropped_in_y_list):\n",
    "        \"\"\"Performs cropping of the images in the x-dimension.\n",
    "\n",
    "        Args:\n",
    "            cropped_in_y_list (list): List containing, for each fov entry, a y-cropped numpy array of shape (rows,channels,x,y,t).\n",
    "\n",
    "        Returns:\n",
    "            list: A nested list of the form [fov_list,[row_list,[kymograph_array]]], containing kymograph arrays of\n",
    "            shape (channels,trenches,y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        smoothed_x_percentiles_list = self.map_to_fovs(\n",
    "            self.get_smoothed_x_percentiles,\n",
    "            cropped_in_y_list,\n",
    "            self.x_percentile,\n",
    "            self.background_kernel_x,\n",
    "            self.smoothing_kernel_x,\n",
    "        )\n",
    "        all_midpoints_list = self.map_to_fovs(\n",
    "            self.get_all_midpoints,\n",
    "            smoothed_x_percentiles_list,\n",
    "            self.otsu_nbins,\n",
    "            self.otsu_scaling,\n",
    "        )\n",
    "        x_drift_list = self.map_to_fovs(self.get_x_drift, all_midpoints_list)\n",
    "        cropped_in_x_list = self.map_to_fovs(\n",
    "            self.get_crop_in_x,\n",
    "            cropped_in_y_list,\n",
    "            all_midpoints_list,\n",
    "            x_drift_list,\n",
    "            self.trench_width_x,\n",
    "        )\n",
    "        return cropped_in_x_list\n",
    "\n",
    "    def generate_kymograph(self):\n",
    "        \"\"\"Master function for generating kymographs for the set of fovs specified on initialization.\n",
    "\n",
    "        Returns:\n",
    "            list: A nested list of the form [fov_list,[row_list,[kymograph_array]]], containing kymograph arrays of\n",
    "            shape (channels,trenches,y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        array_list = self.map_to_fovs(self.import_hdf5)\n",
    "        cropped_in_y_list = self.crop_trenches_in_y(array_list)\n",
    "        cropped_in_x_list = self.crop_trenches_in_x(cropped_in_y_list)\n",
    "\n",
    "        return cropped_in_x_list\n",
    "\n",
    "    def preview_y_precentiles(\n",
    "        self,\n",
    "        imported_array_list,\n",
    "        y_percentile,\n",
    "        smoothing_kernel_y_dim_0,\n",
    "        smoothing_kernel_y_dim_1,\n",
    "        triangle_nbins,\n",
    "        triangle_scaling,\n",
    "    ):\n",
    "        y_percentiles_smoothed_list = self.map_to_fovs(\n",
    "            self.get_smoothed_y_percentiles,\n",
    "            imported_array_list,\n",
    "            y_percentile,\n",
    "            (smoothing_kernel_y_dim_0, smoothing_kernel_y_dim_1),\n",
    "        )\n",
    "\n",
    "        thresholds = [\n",
    "            sk.filters.threshold_triangle(y_percentiles_smoothed, nbins=triangle_nbins)\n",
    "            * triangle_scaling\n",
    "            for y_percentiles_smoothed in y_percentiles_smoothed_list\n",
    "        ]\n",
    "        self.plot_y_precentiles(y_percentiles_smoothed_list, self.fov_list, thresholds)\n",
    "\n",
    "    def plot_y_precentiles(self, y_percentiles_smoothed_list, fov_list, thresholds):\n",
    "        matplotlib.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ### Subplot dimensions of plot\n",
    "        root_list_len = np.ceil(np.sqrt(len(y_percentiles_smoothed_list)))\n",
    "\n",
    "        ### Looping through each fov\n",
    "        idx = 0\n",
    "        for j, y_percentiles_smoothed in enumerate(y_percentiles_smoothed_list):\n",
    "            ### Managing Subplots\n",
    "            idx += 1\n",
    "            ax = fig.add_subplot(root_list_len, root_list_len, idx, projection=\"3d\")\n",
    "\n",
    "            ### Making list of vertices (tuples) for use with PolyCollection\n",
    "            vert_arr = np.array(\n",
    "                [\n",
    "                    np.add.accumulate(\n",
    "                        np.ones(y_percentiles_smoothed.shape, dtype=int), axis=0\n",
    "                    ),\n",
    "                    y_percentiles_smoothed,\n",
    "                ]\n",
    "            )\n",
    "            verts = []\n",
    "            for t in range(vert_arr.shape[2]):\n",
    "                w_vert = vert_arr[:, :, t]\n",
    "                verts.append(\n",
    "                    [\n",
    "                        (w_vert[0, i], w_vert[1, i])\n",
    "                        for i in range(0, w_vert.shape[1], 10)\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            ### Making counting array for y position\n",
    "            zs = np.add.accumulate(np.ones(len(verts)))\n",
    "\n",
    "            ### Creating PolyCollection and add to plot\n",
    "            poly = PolyCollection(verts, facecolors=[\"b\"])\n",
    "            poly.set_alpha(0.5)\n",
    "            ax.add_collection3d(poly, zs=zs, zdir=\"y\")\n",
    "\n",
    "            ### Depecting thresholds as straight lines\n",
    "            x_len = y_percentiles_smoothed.shape[0]\n",
    "            y_len = y_percentiles_smoothed.shape[1]\n",
    "            thr_x = np.repeat(\n",
    "                np.add.accumulate(np.ones(x_len, dtype=int))[:, np.newaxis],\n",
    "                y_len,\n",
    "                axis=1,\n",
    "            ).T.flatten()\n",
    "            thr_y = np.repeat(np.add.accumulate(np.ones(y_len, dtype=int)), x_len)\n",
    "            thr_z = np.repeat(thresholds[j], x_len * y_len)\n",
    "            for i in range(0, x_len * y_len, x_len):\n",
    "                ax.plot(\n",
    "                    thr_x[i : i + x_len],\n",
    "                    thr_y[i : i + x_len],\n",
    "                    thr_z[i : i + x_len],\n",
    "                    c=\"r\",\n",
    "                )\n",
    "\n",
    "            ### Plot lebels\n",
    "            ax.set_title(\"FOV: \" + str(fov_list[j]))\n",
    "            ax.set_xlabel(\"y position\")\n",
    "            ax.set_xlim3d(0, vert_arr[0, -1, 0])\n",
    "            ax.set_ylabel(\"time (s)\")\n",
    "            ax.set_ylim3d(0, len(verts))\n",
    "            ax.set_zlabel(\"intensity\")\n",
    "            ax.set_zlim3d(0, np.max(vert_arr[1]))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def preview_y_crop(\n",
    "        self,\n",
    "        y_percentiles_smoothed_list,\n",
    "        imported_array_list,\n",
    "        triangle_nbins,\n",
    "        triangle_scaling,\n",
    "        y_min_edge_dist,\n",
    "        padding_y,\n",
    "        trench_len_y,\n",
    "        vertical_spacing,\n",
    "    ):\n",
    "\n",
    "        trench_edges_y_lists = self.map_to_fovs(\n",
    "            self.get_trench_edges_y,\n",
    "            y_percentiles_smoothed_list,\n",
    "            triangle_nbins,\n",
    "            triangle_scaling,\n",
    "            y_min_edge_dist,\n",
    "        )\n",
    "        row_num_list = self.map_to_fovs(self.get_row_numbers, trench_edges_y_lists)\n",
    "\n",
    "        cropped_in_y_list = self.map_to_fovs(\n",
    "            self.crop_y,\n",
    "            trench_edges_y_lists,\n",
    "            row_num_list,\n",
    "            imported_array_list,\n",
    "            padding_y,\n",
    "            trench_len_y,\n",
    "        )\n",
    "        self.plot_y_crop(\n",
    "            cropped_in_y_list, imported_array_list, self.fov_list, vertical_spacing\n",
    "        )\n",
    "\n",
    "    def plot_y_crop(\n",
    "        self,\n",
    "        cropped_in_y_list,\n",
    "        imported_array_list,\n",
    "        fov_list,\n",
    "        vertical_spacing,\n",
    "        num_rows=2,\n",
    "    ):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection=\"3d\")\n",
    "\n",
    "        time_list = range(1, imported_array_list[0].shape[3] + 1)\n",
    "\n",
    "        nrows = num_rows * len(fov_list)\n",
    "        ncols = len(time_list)\n",
    "\n",
    "        idx = 0\n",
    "        for i, cropped_in_y in enumerate(cropped_in_y_list):\n",
    "            for j in range(num_rows):\n",
    "                for k, t in enumerate(time_list):\n",
    "                    idx += 1\n",
    "                    ax = plt.subplot(nrows, ncols, idx)\n",
    "                    ax.set_title(\n",
    "                        \"row=\" + str(j) + \",fov=\" + str(fov_list[i]) + \",t=\" + str(t)\n",
    "                    )\n",
    "                    ax.imshow(cropped_in_y[j, 0, :, :, k])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=vertical_spacing)\n",
    "        plt.show()\n",
    "\n",
    "    def preview_x_percentiles(\n",
    "        self,\n",
    "        cropped_in_y_list,\n",
    "        t,\n",
    "        x_percentile,\n",
    "        background_kernel_x,\n",
    "        smoothing_kernel_x,\n",
    "        otsu_nbins,\n",
    "        otsu_scaling,\n",
    "        vertical_spacing,\n",
    "    ):\n",
    "\n",
    "        smoothed_x_percentiles_list = self.map_to_fovs(\n",
    "            self.get_smoothed_x_percentiles,\n",
    "            cropped_in_y_list,\n",
    "            x_percentile,\n",
    "            (background_kernel_x, 1),\n",
    "            (smoothing_kernel_x, 1),\n",
    "        )\n",
    "        thresholds = []\n",
    "        for smoothed_x_percentiles_row in smoothed_x_percentiles_list:\n",
    "            for smoothed_x_percentiles in smoothed_x_percentiles_row:\n",
    "                thresholds.append(\n",
    "                    sk.filters.threshold_otsu(smoothed_x_percentiles, nbins=otsu_nbins)\n",
    "                    * otsu_scaling\n",
    "                )\n",
    "        self.plot_x_percentiles(\n",
    "            smoothed_x_percentiles_list,\n",
    "            self.fov_list,\n",
    "            t,\n",
    "            thresholds,\n",
    "            vertical_spacing,\n",
    "            num_rows=2,\n",
    "        )\n",
    "\n",
    "    def plot_x_percentiles(\n",
    "        self,\n",
    "        smoothed_x_percentiles_list,\n",
    "        fov_list,\n",
    "        t,\n",
    "        thresholds,\n",
    "        vertical_spacing,\n",
    "        num_rows=2,\n",
    "    ):\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ncol = num_rows\n",
    "        nrow = len(smoothed_x_percentiles_list)\n",
    "\n",
    "        idx = 0\n",
    "        for i, smoothed_x_percentiles_top_bottom in enumerate(\n",
    "            smoothed_x_percentiles_list\n",
    "        ):\n",
    "            for j, smoothed_x_percentiles in enumerate(\n",
    "                smoothed_x_percentiles_top_bottom\n",
    "            ):\n",
    "                idx += 1\n",
    "                data = smoothed_x_percentiles[:, t]\n",
    "                ax = fig.add_subplot(ncol, nrow, idx)\n",
    "                ax.plot(data)\n",
    "\n",
    "                current_threshold = thresholds[idx - 1]\n",
    "                threshold_data = np.repeat(current_threshold, len(data))\n",
    "                ax.plot(threshold_data, c=\"r\")\n",
    "                ax.set_title(\"FOV: \" + str(fov_list[j]))\n",
    "                ax.set_xlabel(\"x position\")\n",
    "                ax.set_ylabel(\"intensity\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def preview_midpoints(\n",
    "        self, smoothed_x_percentiles_list, otsu_nbins, otsu_scaling, vertical_spacing\n",
    "    ):\n",
    "        all_midpoints_list = self.map_to_fovs(\n",
    "            self.get_all_midpoints,\n",
    "            smoothed_x_percentiles_list,\n",
    "            otsu_nbins,\n",
    "            otsu_scaling,\n",
    "        )\n",
    "        self.plot_midpoints(all_midpoints_list, self.fov_list, vertical_spacing)\n",
    "\n",
    "    def plot_midpoints(self, all_midpoints_list, fov_list, vertical_spacing):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca()\n",
    "\n",
    "        nrows = 2 * len(fov_list)\n",
    "        ncols = 2\n",
    "\n",
    "        idx = 0\n",
    "        for i, top_bottom_list in enumerate(all_midpoints_list):\n",
    "            for j, all_midpoints in enumerate(top_bottom_list):\n",
    "                idx += 1\n",
    "                ax = plt.subplot(nrows, ncols, idx)\n",
    "                ax.set_title(\"row=\" + str(j) + \",fov=\" + str(fov_list[i]))\n",
    "                data = np.concatenate(\n",
    "                    [\n",
    "                        np.array([item, np.ones(item.shape, dtype=int) * k]).T\n",
    "                        for k, item in enumerate(all_midpoints)\n",
    "                    ]\n",
    "                )\n",
    "                ax.scatter(data[:, 0], data[:, 1], alpha=0.7)\n",
    "                ax.set_xlabel(\"x position\")\n",
    "                ax.set_ylabel(\"time\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=vertical_spacing)\n",
    "        plt.show()\n",
    "\n",
    "    def preview_kymographs(\n",
    "        self, cropped_in_y_list, all_midpoints_list, trench_width_x, vertical_spacing\n",
    "    ):\n",
    "        cropped_in_x_list = self.map_to_fovs(\n",
    "            self.get_crop_in_x,\n",
    "            cropped_in_y_list,\n",
    "            all_midpoints_list,\n",
    "            x_drift_list,\n",
    "            trench_width_x,\n",
    "        )\n",
    "        self.plot_kymographs(cropped_in_x_list, self.fov_list, vertical_spacing)\n",
    "\n",
    "    def plot_kymographs(\n",
    "        self, cropped_in_x_list, fov_list, vertical_spacing, num_rows=2\n",
    "    ):\n",
    "        plt.figure()\n",
    "        idx = 0\n",
    "        ncol = num_rows\n",
    "        nrow = len(fov_list) * num_rows\n",
    "\n",
    "        for i, row_list in enumerate(cropped_in_x_list):\n",
    "            for j, channel in enumerate(row_list):\n",
    "                seg_channel = channel[0]\n",
    "                idx += 1\n",
    "                rand_k = np.random.randint(0, seg_channel.shape[0])\n",
    "                ax = plt.subplot(ncol, nrow, idx)\n",
    "                ex_kymo = seg_channel[rand_k]\n",
    "                self.plot_kymograph(ax, ex_kymo)\n",
    "                ax.set_title(\n",
    "                    \"row=\"\n",
    "                    + str(j)\n",
    "                    + \",fov=\"\n",
    "                    + str(fov_list[i])\n",
    "                    + \",trench=\"\n",
    "                    + str(rand_k)\n",
    "                )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=vertical_spacing)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_kymograph(self, ax, kymograph):\n",
    "        \"\"\"Helper function for plotting kymographs. Takes a kymograph array of shape (y_dim,x_dim,t_dim).\n",
    "\n",
    "        Args:\n",
    "            kymograph (array): kymograph array of shape (y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        list_in_t = [kymograph[:, :, t] for t in range(kymograph.shape[2])]\n",
    "        img_arr = np.concatenate(list_in_t, axis=1)\n",
    "        ax.imshow(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path_prefix = (\n",
    "    \"/n/groups/paulsson/Daniel/Image_analysis_pipeline/tiff_extraction/test_out_4/fov_\"\n",
    ")\n",
    "kymo = kymograph_interactive(\n",
    "    input_path_prefix,\n",
    "    [\"channel_BF\", \"channel_RFP\"],\n",
    "    270,\n",
    "    20,\n",
    "    30,\n",
    "    [64, 12, 32, 45],\n",
    "    t_subsample_step=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_array_list = kymo.map_to_fovs(kymo.import_hdf5)\n",
    "# imported_array_list = kymo.import_hdf5_list(fov_list,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(\n",
    "    kymo.preview_y_precentiles,\n",
    "    imported_array_list=fixed(imported_array_list),\n",
    "    y_percentile=IntSlider(value=85, min=0, max=100, step=1),\n",
    "    smoothing_kernel_y_dim_0=IntSlider(value=9, min=0, max=20, step=1),\n",
    "    smoothing_kernel_y_dim_1=IntSlider(value=3, min=0, max=10, step=1),\n",
    "    triangle_nbins=IntSlider(value=50, min=10, max=200, step=10),\n",
    "    triangle_scaling=FloatSlider(value=1.0, min=0.0, max=2.0, step=0.05),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_percentiles_smoothed_list = kymo.map_to_fovs(\n",
    "    kymo.get_smoothed_y_percentiles, imported_array_list, 85, (9, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(\n",
    "    kymo.preview_y_crop,\n",
    "    y_percentiles_smoothed_list=fixed(y_percentiles_smoothed_list),\n",
    "    imported_array_list=fixed(imported_array_list),\n",
    "    y_time_percentile=IntSlider(value=85, min=0, max=100, step=1),\n",
    "    triangle_nbins=IntSlider(value=50, min=10, max=200, step=10),\n",
    "    triangle_scaling=FloatSlider(value=1.0, min=0.0, max=2.0, step=0.01),\n",
    "    y_min_edge_dist=IntSlider(value=50, min=10, max=200, step=10),\n",
    "    padding_y=IntSlider(value=20, min=0, max=100, step=1),\n",
    "    trench_len_y=IntSlider(value=270, min=0, max=1000, step=10),\n",
    "    vertical_spacing=FloatSlider(value=0.9, min=0.0, max=2.0, step=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_edges_y_lists = kymo.map_to_fovs(\n",
    "    kymo.get_trench_edges_y, y_percentiles_smoothed_list, 50, 1.1, min_edge_dist=50\n",
    ")\n",
    "row_num_list = kymo.map_to_fovs(kymo.get_row_numbers, trench_edges_y_lists)\n",
    "cropped_in_y_list = kymo.map_to_fovs(\n",
    "    kymo.crop_y,\n",
    "    trench_edges_y_lists,\n",
    "    row_num_list,\n",
    "    imported_array_list,\n",
    "    20,\n",
    "    270,\n",
    "    top_orientation=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(\n",
    "    kymo.preview_x_percentiles,\n",
    "    cropped_in_y_list=fixed(cropped_in_y_list),\n",
    "    t=IntSlider(value=0, min=0, max=cropped_in_y_list[0].shape[4] - 1, step=1),\n",
    "    x_percentile=IntSlider(value=85, min=0, max=100, step=1),\n",
    "    background_kernel_x=IntSlider(value=301, min=1, max=601, step=50),\n",
    "    smoothing_kernel_x=IntSlider(value=9, min=1, max=31, step=2),\n",
    "    otsu_nbins=IntSlider(value=50, min=10, max=200, step=10),\n",
    "    otsu_scaling=FloatSlider(value=1.0, min=0.0, max=2.0, step=0.01),\n",
    "    vertical_spacing=FloatSlider(value=0.9, min=0.0, max=2.0, step=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_x_percentiles_list = kymo.map_to_fovs(\n",
    "    kymo.get_smoothed_x_percentiles, cropped_in_y_list, 85, (301, 1), (9, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(\n",
    "    kymo.preview_midpoints,\n",
    "    smoothed_x_percentiles_list=fixed(smoothed_x_percentiles_list),\n",
    "    otsu_nbins=IntSlider(value=50, min=10, max=200, step=10),\n",
    "    otsu_scaling=FloatSlider(value=1.0, min=0.0, max=2.0, step=0.01),\n",
    "    vertical_spacing=FloatSlider(value=0.8, min=0.0, max=2.0, step=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_midpoints_list = kymo.map_to_fovs(\n",
    "    kymo.get_all_midpoints, smoothed_x_percentiles_list, 50, 1.0\n",
    ")\n",
    "x_drift_list = kymo.map_to_fovs(kymo.get_x_drift, all_midpoints_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(\n",
    "    kymo.preview_kymographs,\n",
    "    cropped_in_y_list=fixed(cropped_in_y_list),\n",
    "    all_midpoints_list=fixed(all_midpoints_list),\n",
    "    trench_width_x=IntSlider(value=30, min=10, max=50, step=1),\n",
    "    vertical_spacing=FloatSlider(value=0.8, min=0.0, max=2.0, step=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_in_x_list = kymo.map_to_fovs(\n",
    "    kymo.get_crop_in_x_list, cropped_in_y_list, all_midpoints_list, x_drift_list, 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    " - Would it be worth converting the image to an 8 byte encoding for thresholding purposes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f kymo.import_hdf5 kymo.preview_y_crop([64,14,34,46])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the limiting factor is by far the initial read in, so it doesn't seem that necessary to use the 8 bit encoding / resizing unless it is done in the primary kymograph code. The pros and cons of including it there are:\n",
    "\n",
    "#### Pros\n",
    " - speedup on all computational operations\n",
    " - major speedup on intermediate read/write operations during processing\n",
    " \n",
    "#### Cons\n",
    " - computational speedup pretty small\n",
    " - would need to compile information about places to crop prior to a final step in which\n",
    " cropping actually occurs on the original image data. This is a major restructuring....\n",
    " \n",
    "#### outcome\n",
    "\n",
    "Just keep this in mind for future features, but for now don't implement. Take interactive mode as is without resizing...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAJOR NOTE FOR SEGMENTATION CODE\n",
    "\n",
    "The conversion to bits can be currupted by outlier signal, possibly from fringing at the end of trenches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection=\"3d\")\n",
    "\n",
    "cc = lambda arg: colorConverter.to_rgba(arg, alpha=0.6)\n",
    "\n",
    "xs = np.arange(0, 10, 0.4)\n",
    "verts = []\n",
    "zs = [0.0, 1.0, 2.0, 3.0]\n",
    "for z in zs:\n",
    "    ys = np.random.rand(len(xs))\n",
    "    ys[0], ys[-1] = 0, 0\n",
    "    verts.append(list(zip(xs, ys)))\n",
    "\n",
    "poly = PolyCollection(verts, facecolors=[cc(\"r\"), cc(\"g\"), cc(\"b\"), cc(\"y\")])\n",
    "poly.set_alpha(0.7)\n",
    "ax.add_collection3d(poly, zs=zs, zdir=\"y\")\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_xlim3d(0, 10)\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_ylim3d(-1, 4)\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_zlim3d(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
