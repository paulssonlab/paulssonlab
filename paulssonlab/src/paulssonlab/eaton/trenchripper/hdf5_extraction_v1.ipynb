{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nd2reader import ND2Reader\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tifffile import imsave\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = [14, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: ND2 to hdf5\n",
    "\n",
    "I'd like the first step in the pipeline to convert the entire file to hdf5 so we can throw the nd2 away (maybe keep metadata)\n",
    "\n",
    "I need both a slow local version with parallelization (low priority) and one that can be distributed to slurm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hdf5_fov_extractor:\n",
    "    def __init__(self, nd2filename, hdf5path):\n",
    "        self.nd2filename = nd2filename\n",
    "        self.hdf5path = hdf5path\n",
    "        self.writedir(hdf5path)\n",
    "\n",
    "    def writedir(self, directory, overwrite=False):\n",
    "        if overwrite:\n",
    "            if os.path.exists(directory):\n",
    "                shutil.rmtree(directory)\n",
    "            os.makedirs(directory)\n",
    "        else:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "    def extract_fov(self, fovnum):\n",
    "        nd2file = ND2Reader(self.nd2filename)\n",
    "        metadata = nd2file.metadata\n",
    "        with h5py.File(\n",
    "            self.hdf5path + \"/fov_\" + str(fovnum) + \".hdf5\", \"w\"\n",
    "        ) as h5pyfile:\n",
    "            for i, channel in enumerate(nd2file.metadata[\"channels\"]):\n",
    "                y_dim = metadata[\"height\"]\n",
    "                x_dim = metadata[\"width\"]\n",
    "                t_dim = len(nd2file.metadata[\"frames\"])\n",
    "                hdf5_dataset = h5pyfile.create_dataset(\n",
    "                    \"channel_\" + str(channel),\n",
    "                    (x_dim, y_dim, t_dim),\n",
    "                    chunks=(x_dim, y_dim, 1),\n",
    "                    dtype=\"uint16\",\n",
    "                )\n",
    "                for frame in nd2file.metadata[\"frames\"]:\n",
    "                    print(frame)\n",
    "                    nd2_image = nd2file.get_frame_2D(c=i, t=frame, v=fovnum)\n",
    "                    hdf5_dataset[:, :, int(frame)] = nd2_image\n",
    "        nd2file.close()\n",
    "\n",
    "\n",
    "class tiff_fov_extractor:\n",
    "    def __init__(self, nd2filename, tiffpath):\n",
    "        self.nd2filename = nd2filename\n",
    "        self.tiffpath = tiffpath\n",
    "\n",
    "    def writedir(self, directory, overwrite=False):\n",
    "        if overwrite:\n",
    "            if os.path.exists(directory):\n",
    "                shutil.rmtree(directory)\n",
    "            os.makedirs(directory)\n",
    "        else:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "    def extract_fov(self, fovnum):\n",
    "        nd2file = ND2Reader(self.nd2filename)\n",
    "        metadata = nd2file.metadata\n",
    "        for i, channel in enumerate(nd2file.metadata[\"channels\"]):\n",
    "            t_dim = len(nd2file.metadata[\"frames\"])\n",
    "            dirpath = self.tiffpath + \"/fov_\" + str(fovnum) + \"/\" + channel + \"/\"\n",
    "            self.writedir(dirpath, overwrite=True)\n",
    "            for frame in nd2file.metadata[\"frames\"]:\n",
    "                filepath = dirpath + \"t_\" + str(frame) + \".tif\"\n",
    "                nd2_image = nd2file.get_frame_2D(c=i, t=frame, v=fovnum)\n",
    "                imsave(filepath, nd2_image)\n",
    "        nd2file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_extractor = hdf5_fov_extractor(\n",
    "    \"/n/scratch2/de64/for_sylvia/Bacillus_revival_12_7_2020.nd2\",\n",
    "    \"/n/scratch2/de64/full_pipeline_test/hdf5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_extractor.extract_fov(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f hdf5_extractor.extract_fov hdf5_extractor.extract_fov(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hdf5writer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nd2filename,\n",
    "        outputpath,\n",
    "        n_workers=6,\n",
    "        local=True,\n",
    "        queue=\"short\",\n",
    "        walltime=\"01:30:00\",\n",
    "        cores=1,\n",
    "        processes=1,\n",
    "        memory=\"6GB\",\n",
    "    ):\n",
    "        self.nd2filename = nd2filename\n",
    "        self.outputpath = outputpath\n",
    "        self.local = local\n",
    "        self.n_workers = n_workers\n",
    "        self.walltime = walltime\n",
    "        self.queue = queue\n",
    "        self.processes = processes\n",
    "        self.memory = memory\n",
    "        self.cores = cores\n",
    "\n",
    "    def writedir(self, directory):\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "    def startdask(self):\n",
    "        if self.local:\n",
    "            self.daskclient = Client()\n",
    "            self.daskclient.cluster.scale(self.n_workers)\n",
    "        else:\n",
    "            # note the specifed walltime, don't use too much or too little, 01:30:00 is a good baseline,\n",
    "            # you just need enough time to finish 'gathering' to props_all before the jobs die\n",
    "            # you can always spin up more jobs later\n",
    "            # you will launch many jobs, so you don't need multiple processes, a lot of ram or multiple threads\n",
    "            self.daskcluster = SLURMCluster(\n",
    "                queue=self.queue,\n",
    "                walltime=self.walltime,\n",
    "                processes=self.processes,\n",
    "                memory=self.memory,\n",
    "                cores=self.cores,\n",
    "            )\n",
    "            self.workers = self.daskcluster.start_workers(self.n_workers)\n",
    "            self.daskclient = Client(self.daskcluster)\n",
    "\n",
    "    def printprogress(self):\n",
    "        complete = len([item for item in self.futures if item.status == \"finished\"])\n",
    "        print(str(complete) + \"/\" + str(len(self.futures)))\n",
    "\n",
    "    def startwritehdf5(self):\n",
    "        self.writedir(self.outputpath)\n",
    "        extractor = hdf5_fov_extractor(self.nd2filename, self.outputpath)\n",
    "        nd2file = ND2Reader(self.nd2filename)\n",
    "        self.futures = self.daskclient.map(\n",
    "            extractor.extract_fov, nd2file.metadata[\"fields_of_view\"]\n",
    "        )\n",
    "        nd2file.close()\n",
    "\n",
    "    def startwritetiff(self):\n",
    "        self.writedir(self.outputpath)\n",
    "        extractor = tiff_fov_extractor(self.nd2filename, self.outputpath)\n",
    "        nd2file = ND2Reader(self.nd2filename)\n",
    "        self.futures = self.daskclient.map(\n",
    "            extractor.extract_fov, nd2file.metadata[\"fields_of_view\"]\n",
    "        )\n",
    "        nd2file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer1 = hdf5writer(\n",
    "    \"/n/scratch2/de64/for_sylvia/Bacillus_revival_12_7_2020.nd2\",\n",
    "    \"/n/scratch2/de64/for_sylvia/tiff_out\",\n",
    "    walltime=\"04:00:00\",\n",
    "    local=False,\n",
    "    n_workers=20,\n",
    "    memory=\"500MB\",\n",
    ")\n",
    "writer1.startdask()\n",
    "writer1.daskcluster.start_workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer1.daskclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer1.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer1.startwritetiff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer1.printprogress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = writer1.daskclient.gather(\n",
    "    writer1.futures\n",
    ")  # this will hang until all futures are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer1.daskcluster.stop_workers(writer1.workers)  # this is still not working\n",
    "writer1.daskcluster.stop_all_jobs()  # this seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"mytestfile.hdf5\", \"r\") as df:\n",
    "    for fov in df:\n",
    "        for frame in df[fov]:\n",
    "            for color in df[fov + \"/\" + frame]:\n",
    "                print(df[fov + \"/\" + frame + \"/\" + color][:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
