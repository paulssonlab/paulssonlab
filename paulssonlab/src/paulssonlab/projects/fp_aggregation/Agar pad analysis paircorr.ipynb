{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "from cytoolz import compose\n",
    "import skimage\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from paulssonlab.projects.molecule_counting.segmentation import segment, invert\n",
    "from paulssonlab.projects.molecule_counting.matriarch_stub import permute_labels\n",
    "import itertools\n",
    "import os.path\n",
    "from os import path\n",
    "import itertools\n",
    "\n",
    "# import cv2\n",
    "from matplotlib.offsetbox import TextArea, DrawingArea, OffsetImage, AnnotationBbox\n",
    "import signal\n",
    "import time\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_phase = compose(segment, invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up timers so that functions timeout and move on if something is weird and they don't run properly.\n",
    "# Should diagnose this issue properly eventually, but for testing this should be ok.\n",
    "class TimeoutException(Exception):  # Custom exception class\n",
    "    pass\n",
    "\n",
    "\n",
    "def timeout_handler(signum, frame):  # Custom signal handler\n",
    "    raise TimeoutException\n",
    "\n",
    "\n",
    "# Change the behavior of SIGALRM\n",
    "signal.signal(signal.SIGALRM, timeout_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = glob.glob(\"/n/scratch2/jqs1/200228/*.nd2\") + glob.glob(\n",
    "#     \"/n/scratch2/jqs1/200305/*.nd2\")\n",
    "\n",
    "filenames = glob.glob(\"/n/scratch3/users/j/jqs1/200228/*.nd2\") + glob.glob(\n",
    "    \"/n/scratch3/users/j/jqs1/200305/*.nd2\"\n",
    ")\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    print(i, filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filenames[2]\n",
    "print(\"file\", file)\n",
    "nd2 = nd2reader.ND2Reader(file)\n",
    "fov_index = 2\n",
    "phase_img = nd2.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "fluor_img = nd2.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "# phase_img = nd2.get_frame_2D(v=0, c=0, z=0)[1100:3000,500:2250]\n",
    "# fluor_img = nd2.get_frame_2D(v=0, c=1, z=0)[1100:3000,500:2250]\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(phase_img)\n",
    "ax[1].imshow(fluor_img, cmap=\"RdGy\")\n",
    "# seg = segment_phase(phase_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = segment_phase(phase_img)\n",
    "fig, ax = plt.subplots()\n",
    "# ax.imshow(seg)\n",
    "ax.imshow(permute_labels(seg))\n",
    "print(np.amax(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check segmented cell sizes\n",
    "# unique, counts = np.unique(seg, return_counts=True)\n",
    "# dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_in_r(ref_indices, r):\n",
    "    # ref_indices is a list of the indices that define the location of the reference point.\n",
    "    # r is the radius within which we want to collect indices.\n",
    "    ranges = np.arange(np.floor(-r), np.ceil(r) + 1)\n",
    "    rel_points = np.where(\n",
    "        (ranges[np.newaxis, :]) ** 2 + (ranges[:, np.newaxis]) ** 2 < r**2\n",
    "    )\n",
    "    points = [\n",
    "        rel_points[0] + ref_indices[0] - np.ceil(r),\n",
    "        rel_points[1] + ref_indices[1] - np.ceil(r),\n",
    "    ]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf_single_ref_point_single_cell(cell, ref_point, time_allowed=80, start_r=1, dr=1):\n",
    "    #     returns rdf for a single reference point in a single cell.\n",
    "    #     cell is a masked array, where the mask is False where the cell is, and True everywhere else.\n",
    "    #     cell.data is the fluorescence intensity array.\n",
    "    #     ref_point is a tuple of 2 arrays, corresponding to the indices of the location of the 'nucleus'\n",
    "    # rho is the average 'particle' density, where a particle corresponds to an intensity unit.\n",
    "    rho = np.ma.mean(cell)\n",
    "    #     print('cell sum in function',np.ma.sum(cell))\n",
    "    r = start_r\n",
    "    r_values = []\n",
    "    #         masked_norm_fluor_img.mask is False where the cell is, and True outside.\n",
    "    #         mask = np.copy(cell.mask)\n",
    "    gr_values = []\n",
    "    previous_r_vol = 0\n",
    "    while np.count_nonzero(cell.mask == 0) > 0:\n",
    "        #         print('points remaining',np.count_nonzero(cell.mask==0))\n",
    "        #             While the cell mask still has 'False' values i.e. not all values have been used in the\n",
    "        #             pair correlation function calculation somewhere.\n",
    "        #             Get indices of the points within the current radius (r) of the ref point.\n",
    "        indices_in_r = get_indices_in_r(ref_point, r)\n",
    "        flat_indices_in_r = [item for sublist in indices_in_r for item in sublist]\n",
    "        img_shape = np.shape(cell)\n",
    "        #         Remove indices pairs which fall outside the image.\n",
    "        if any(flat_indices_in_r >= np.min(img_shape)):\n",
    "            indices_to_delete_0 = np.where(indices_in_r[0] >= img_shape[0])[0]\n",
    "            indices_to_delete_1 = np.where(indices_in_r[1] >= img_shape[1])[0]\n",
    "            indices_to_delete = np.concatenate(\n",
    "                (indices_to_delete_0, indices_to_delete_1)\n",
    "            )\n",
    "            indices_to_delete = np.unique(indices_to_delete)\n",
    "            indices_in_r[0] = np.delete(indices_in_r[0], indices_to_delete)\n",
    "            indices_in_r[1] = np.delete(indices_in_r[1], indices_to_delete)\n",
    "        # Calculate numerator (gr_num) and volume element (gr_vol)\n",
    "        # gr_num should be the sum total of intensities of points in the current shell.\n",
    "        #             Since the cell is masked, we don't need to worry about the non-cell regions.\n",
    "        gr_num = np.sum(\n",
    "            cell[list(map(int, indices_in_r[0])), list(map(int, indices_in_r[1]))]\n",
    "        )\n",
    "        #         print('grnum',gr_num)\n",
    "        # gr_vol should be the number of points in the current shell.\n",
    "        #             Note that the mask masks both the background and the previous regions that we have considered,\n",
    "        #             so we simply subtract these from our list of indices in the current radius.\n",
    "        gr_vol = len(indices_in_r[0]) - np.count_nonzero(\n",
    "            cell.mask[list(map(int, indices_in_r[0])), list(map(int, indices_in_r[1]))]\n",
    "        )\n",
    "        #         print('gr vol',gr_vol)\n",
    "        #             update the 'previous_r_vol' for the next radius shell.\n",
    "        previous_r_vol = gr_vol\n",
    "        #             Update the cell mask so that the values we have now included are not included\n",
    "        #             in the next dr calculation.\n",
    "        cell.mask[\n",
    "            list(map(int, indices_in_r[0])), list(map(int, indices_in_r[1]))\n",
    "        ] = True\n",
    "        #             print('number of non masked values',np.count_nonzero(cell.mask==0))\n",
    "        gr_values.append(gr_num / gr_vol)\n",
    "        r_values.append(r)\n",
    "        r += dr\n",
    "    # Since rho is constant for all r, divide all at the same time to save on number of computations.\n",
    "    gr_values = np.array(gr_values)\n",
    "    gr_values = np.divide(gr_values, rho)\n",
    "    return r_values, gr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf_multi_ref_point_single_cell(\n",
    "    cell, ref_points, time_allowed=80, start_r=1, dr=1, intensity_weighted=True\n",
    "):\n",
    "    #     cell is a masked array, where the mask is False where the cell is, and True everywhere else.\n",
    "    #     returns r_values, gr_values for one cell, where gr_values is the average gr over the\n",
    "    #     ref_points.\n",
    "    #     ref_points should be a tuple of 2 arrays, where the first array is the axis 0\n",
    "    #     indices, and second array is the axis 1 indices, as we would get from np.where\n",
    "    max_r_values = []\n",
    "    all_gr_values = []\n",
    "    if intensity_weighted:\n",
    "        total_ref_point_intensity = np.sum(\n",
    "            cell[list(map(int, ref_points[0])), list(map(int, ref_points[1]))]\n",
    "        )\n",
    "        num_ref_points = len(ref_points[0])\n",
    "    #         total_cell_intensity = np.sum(cell)\n",
    "    #         pixels_in_cell = np.count_nonzero(cell.mask == 0)\n",
    "    for i in range(len(ref_points[0])):\n",
    "        cell_for_analysis = np.ma.copy(cell)\n",
    "        ref_point_0, ref_point_1 = ref_points[0][i], ref_points[1][i]\n",
    "        r_values, gr_values = rdf_single_ref_point_single_cell(\n",
    "            cell_for_analysis,\n",
    "            (np.array(ref_point_0), np.array(ref_point_1)),\n",
    "            time_allowed=80,\n",
    "            start_r=start_r,\n",
    "            dr=dr,\n",
    "        )\n",
    "        if intensity_weighted:\n",
    "            gr_values *= cell.data[ref_point_0][ref_point_1]\n",
    "        if len(r_values) > len(max_r_values):\n",
    "            max_r_values = r_values\n",
    "        all_gr_values.append(gr_values)\n",
    "    gr_values_length_corrected = list(\n",
    "        itertools.zip_longest(*all_gr_values, fillvalue=np.nan)\n",
    "    )\n",
    "    mean_gr_values = [np.nanmean(i) for i in gr_values_length_corrected]\n",
    "    if intensity_weighted:\n",
    "        #         mean_gr_values = np.multiply(pixels_in_cell,mean_gr_values/total_cell_intensity)\n",
    "        mean_gr_values = np.multiply(\n",
    "            num_ref_points, mean_gr_values / total_ref_point_intensity\n",
    "        )\n",
    "    return max_r_values, mean_gr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf(\n",
    "    seg,\n",
    "    fluor_img,\n",
    "    ref_point_val=\"max\",\n",
    "    cell_indices=[0],\n",
    "    time_allowed=80,\n",
    "    savetxt=\"rdf\",\n",
    "    start_r=1,\n",
    "    dr=1,\n",
    "    intensity_weighted=True,\n",
    "    stdevs=True,\n",
    "    stdevs_savetxt=\"stdevs\",\n",
    "    fov_indices=[0],\n",
    "    cell_norm=\"none\",\n",
    "):\n",
    "    # Seg is the segmentation array.\n",
    "    #     Get the background fluorescence of the image, to subtract from all cell fluorescence.\n",
    "    min_fluor = np.amin(fluor_img)\n",
    "    # Get number of cells in the image.\n",
    "    cells = np.amax(seg)\n",
    "    if cell_indices == \"all\":\n",
    "        cell_indices = np.arange(cells)\n",
    "    # all_r_values will be a list of lists of r values, while all_gr_values will be a list of lists, with\n",
    "    # the corresponding g(r) (pair correlation function) values. The overall function will return\n",
    "    # all_r_values, all_gr_values.\n",
    "    all_r_values = []\n",
    "    all_gr_values = []\n",
    "    stdevs_list = []\n",
    "    pixels = []\n",
    "    for cell_index in cell_indices:\n",
    "        if cell_index % 25 == 0:\n",
    "            print(\"cell index\", cell_index)\n",
    "        if cell_index > cells:\n",
    "            print(\"Error in rdf: cell_index larger than number of cells in fov.\")\n",
    "            pass\n",
    "        #         Mask the fluorescence image everywhere except for the cell.\n",
    "        cell = np.ma.masked_where(seg != cell_index + 1, fluor_img)\n",
    "        # Normalise the intensities of the cell. The mean_int_cell isn't needed since everything gets normalised\n",
    "        #         wrt total cell intensity anyway.\n",
    "        #         mean_int_cell = np.mean(cell)\n",
    "        cell -= min_fluor\n",
    "        #         ref_point is the 'nucleus' i.e. the point relative to which the pair\n",
    "        #         correlation function is to be calculated. For now, we set it to the\n",
    "        #         maximum fluorescence intensity point of the cell.\n",
    "        # CELL_NORM HERE\n",
    "        if stdevs:\n",
    "            stdevs_list.append(np.ma.std(cell))\n",
    "        if ref_point_val == \"max\":\n",
    "            ref_point = np.ma.where(cell == np.amax(cell))\n",
    "            #         If there is more than one maximum fluorescence point, take the first one of these.\n",
    "            if len(ref_point[0]) > 1:\n",
    "                ref_point = (np.array([ref_point[0][0]]), np.array([ref_point[1][0]]))\n",
    "        elif ref_point_val == \"all\":\n",
    "            ref_point = np.where(cell.mask == 0)\n",
    "        elif ref_point_val[0] == \"sample\":\n",
    "            points_in_cell = np.where(cell.mask == 0)\n",
    "            ref_point = (\n",
    "                points_in_cell[0][:: ref_point_val[1]],\n",
    "                points_in_cell[1][:: ref_point_val[1]],\n",
    "            )\n",
    "        elif (\n",
    "            ref_point_val[0] == \"max\"\n",
    "        ):  # ref_point_val=['max',10] to take mean of 10 most intense pixels\n",
    "            cell_for_maxs = np.ma.copy(cell)\n",
    "            ref_point = [[], []]\n",
    "            for i in range(ref_point_val[1]):\n",
    "                current_max = np.ma.where(cell_for_maxs == np.amax(cell_for_maxs))\n",
    "                cell_for_maxs.mask[current_max] = 1\n",
    "                ref_point[0].append(current_max[0][0])\n",
    "                ref_point[1].append(current_max[1][0])\n",
    "            ref_point = np.array(ref_point)\n",
    "        else:\n",
    "            ref_point = ref_point_val\n",
    "        #         print('sum',np.ma.sum(cell))\n",
    "        r_values, gr_values = rdf_multi_ref_point_single_cell(\n",
    "            cell,\n",
    "            ref_point,\n",
    "            time_allowed=80,\n",
    "            start_r=start_r,\n",
    "            dr=dr,\n",
    "            intensity_weighted=intensity_weighted,\n",
    "        )\n",
    "        #         print('int rdf',np.trapz(gr_values,x=r_values))\n",
    "        #         print('sum gr',np.sum(gr_values))\n",
    "        #         print('int rdf with 4pir^2',np.trapz(gr_values*np.pi*(2*np.array(r_values)+1),x=r_values))\n",
    "\n",
    "        pixels.append(np.count_nonzero(cell.mask == 0))\n",
    "        all_gr_values.append(gr_values)\n",
    "        all_r_values.append(r_values)\n",
    "    if savetxt:\n",
    "        all_r_to_save = np.concatenate(all_r_values).ravel()\n",
    "        all_gr_to_save = np.concatenate(all_gr_values).ravel()\n",
    "        np.savetxt(savetxt, np.transpose(np.array([all_r_to_save, all_gr_to_save])))\n",
    "    if stdevs_savetxt:\n",
    "        np.savetxt(stdevs_savetxt, np.array(stdevs_list))\n",
    "    return all_r_values, all_gr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using seg as the fluor image, since this should return g(r) = 1 for all r.\n",
    "# Everything is 1 in this case\n",
    "# r_values_list, gr_values_list = rdf(seg,seg,cell_indices=np.arange(6),\n",
    "#                                     ref_point_val=['sample',10],dr=10,\n",
    "#                                    intensity_weighted=True)\n",
    "# Everything is also 1 in this case\n",
    "# r_values_list, gr_values_list = rdf(seg,seg,cell_indices=np.arange(6),\n",
    "#                                     ref_point_val=['sample',10],dr=10,\n",
    "#                                    intensity_weighted=False)\n",
    "\n",
    "# print('20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue')\n",
    "# r,gr=rdf(seg,fluor_img,cell_indices='all',ref_point_val='max',dr=1,\n",
    "#                                    intensity_weighted=True,\n",
    "#                                    savetxt='20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_funcvals_from_txt(filename, start_r):\n",
    "    # start_r is the start value of r in that dataset, so we can identify where each cell dataset starts.\n",
    "    values = np.genfromtxt(filename)\n",
    "    all_r_values = values[:, 0]\n",
    "    all_func_values = values[:, 1]\n",
    "    start_indices = np.where(all_r_values == start_r)[0]\n",
    "    r_values_list = []\n",
    "    func_values_list = []\n",
    "    for i, val in enumerate(start_indices):\n",
    "        if i != len(start_indices) - 1:\n",
    "            r_values_list.append(all_r_values[val : start_indices[i + 1]])\n",
    "            func_values_list.append(all_func_values[val : start_indices[i + 1]])\n",
    "        else:\n",
    "            r_values_list.append(all_r_values[val:])\n",
    "            func_values_list.append(all_func_values[val:])\n",
    "    return r_values_list, func_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot gr from file\n",
    "def plot_gr_from_file(\n",
    "    filename,\n",
    "    start_r,\n",
    "    ax=None,\n",
    "    savefig=None,\n",
    "    indices_to_plot=None,\n",
    "    legend=False,\n",
    "    title=None,\n",
    "    line=[1],\n",
    "):\n",
    "    r_values_list, gr_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots()\n",
    "    if not indices_to_plot:\n",
    "        indices_to_plot = np.arange(len(r_values_list))\n",
    "    for i in indices_to_plot:\n",
    "        ax.plot(r_values_list[i], gr_values_list[i])\n",
    "    if legend:\n",
    "        ax.legend([i for i in indices_to_plot])\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    if line:\n",
    "        for line_val in line:\n",
    "            ax.axhline(y=line_val, ls=\":\", color=\"k\")\n",
    "    if savefig:\n",
    "        fig.savefig(savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation function\n",
    "# Can do multiple cells in same image\n",
    "def autocorr(\n",
    "    seg,\n",
    "    fluor_img,\n",
    "    cell_indices=[0],\n",
    "    time_allowed=80,\n",
    "    savetxt=\"autocorr\",\n",
    "    ref_point_val=\"max\",\n",
    "    r_values=None,\n",
    "    gr_values=None,\n",
    "    intensity_weighted=True,\n",
    "    start_r=1,\n",
    "    dr=1,\n",
    "    rdfsavetxt=\"rdf\",\n",
    "    stdevs=True,\n",
    "    stdevs_savetxt=\"stdevs\",\n",
    "):\n",
    "    if not r_values or not gr_values:\n",
    "        r_values, gr_values = rdf(\n",
    "            seg,\n",
    "            fluor_img,\n",
    "            ref_point_val=ref_point_val,\n",
    "            cell_indices=cell_indices,\n",
    "            time_allowed=80,\n",
    "            savetxt=rdfsavetxt,\n",
    "            start_r=start_r,\n",
    "            dr=dr,\n",
    "            intensity_weighted=intensity_weighted,\n",
    "            stdevs=stdevs,\n",
    "            stdevs_savetxt=stdevs_savetxt,\n",
    "        )\n",
    "    if cell_indices == \"all\":\n",
    "        cell_indices = np.arange(np.amax(seg))\n",
    "    for cell_index in cell_indices:\n",
    "        min_fluor = np.amin(fluor_img)\n",
    "        cell = np.ma.masked_where(seg != cell_index + 1, fluor_img)\n",
    "        cell -= min_fluor\n",
    "    all_auto_corr = []\n",
    "    all_k_values = []\n",
    "    for i, cell_index in enumerate(cell_indices):\n",
    "        r_vals = r_values[i]\n",
    "        gr_vals = gr_values[i]\n",
    "        gr_mean = np.mean(gr_values[i])\n",
    "        k_vals = np.arange(dr, r_vals[-1], dr)\n",
    "        all_k_values.append(k_vals)\n",
    "        auto_corr = []\n",
    "        denom = 0\n",
    "        for i in range(len(r_vals)):\n",
    "            denom += np.power(gr_vals[i] - gr_mean, 2)\n",
    "        for ki, k in enumerate(k_vals):\n",
    "            num = 0\n",
    "            contrib_to_num = 0\n",
    "            for i in k_vals[: len(k_vals) - ki]:\n",
    "                contrib_to_num += 1\n",
    "                num += (gr_vals[i - 1] - gr_mean) * (gr_vals[i + ki] - gr_mean)\n",
    "            num = num / contrib_to_num\n",
    "            auto_corr.append(num / denom)\n",
    "        all_auto_corr.append(auto_corr)\n",
    "    if savetxt:\n",
    "        all_r_to_save = np.concatenate(\n",
    "            np.array([r_vals[:-1] for r_vals in r_values])\n",
    "        ).ravel()\n",
    "        all_autocorr_to_save = np.concatenate(all_auto_corr).ravel()\n",
    "        np.savetxt(\n",
    "            savetxt, np.transpose(np.array([all_r_to_save, all_autocorr_to_save]))\n",
    "        )\n",
    "    return all_k_values, all_auto_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial gradient of rdf or autocorr might not be that good - if we have a random high intensity point,\n",
    "# it will very quickly drop since it's not a real blob, so this would increase the gradient artificially.\n",
    "# Instead, calculate area under curve before autocorr = 0 or rdf = 1.\n",
    "\n",
    "# def gradients(r_vals, func_vals, savetxt = 'gradients'):\n",
    "# # r_vals is a list of lists of r_values, and func_vals is a list of lists of function values\n",
    "#     all_gradient_vals = []\n",
    "#     for i,r_val_list in enumerate(r_vals):\n",
    "#         gradient_vals = np.gradient(func_vals[i], r_val_list)\n",
    "#         all_gradient_vals.append(gradient_vals)\n",
    "#     if savetxt:\n",
    "\n",
    "#     return all_gradient_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_under(\n",
    "    r_vals,\n",
    "    func_vals,\n",
    "    threshold,\n",
    "    as_frac_total=False,\n",
    "    shift=None,\n",
    "    below_thresh_zero=False,\n",
    "    as_frac_total_original=False,\n",
    "    total_area_above_thresh=False,\n",
    "):\n",
    "    #     threshold = area above the first crossing of which we want to integrate.\n",
    "    # as_frac_total = True means our output will be the above area divided by the total integral of the shifted function.\n",
    "    # shift = if we want to integrate RDF-1, then shift = 1\n",
    "    # below_thresh_zero = True means all values below the threshold (of the shifted function)\n",
    "    # will be set to 0 and so be ignore in the integration.\n",
    "    # as_frac_total_original = True means our output will be the above area divided\n",
    "    # by the total integral of the UNshifted function.\n",
    "    # total_area_above_thresh = True means instead of just integrating above the first cross,\n",
    "    # we integrate everything above the threshold.\n",
    "    func_vals_original = np.copy(func_vals)\n",
    "    if shift:\n",
    "        func_vals -= shift\n",
    "    if not total_area_above_thresh:\n",
    "        i = 0\n",
    "        while i < len(func_vals) and func_vals[i] > threshold:\n",
    "            i += 1\n",
    "        r_vals_thresh, func_vals_thresh = r_vals[:i], func_vals[:i]\n",
    "        area = np.trapz(func_vals_thresh, x=r_vals_thresh)\n",
    "    else:\n",
    "        f_vals = np.copy(func_vals)\n",
    "        for i, val in enumerate(f_vals):\n",
    "            if val < threshold:\n",
    "                f_vals[i] = 0\n",
    "        area = np.trapz(f_vals, x=r_vals)\n",
    "    if below_thresh_zero:\n",
    "        for i, val in enumerate(func_vals):\n",
    "            if val < threshold:\n",
    "                func_vals[i] = 0\n",
    "    if as_frac_total:\n",
    "        if as_frac_total_original:\n",
    "            total_int = np.trapz(func_vals_original, x=r_vals)\n",
    "        else:\n",
    "            total_int = np.trapz(func_vals, x=r_vals)\n",
    "        area /= total_int\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_under_from_file(\n",
    "    filename,\n",
    "    start_r,\n",
    "    threshold,\n",
    "    as_frac_total=False,\n",
    "    shift=None,\n",
    "    below_thresh_zero=False,\n",
    "    as_frac_total_original=False,\n",
    "    total_area_above_thresh=False,\n",
    "):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    area_under_list = []\n",
    "    for i in range(len(r_values_list)):\n",
    "        area_under_list.append(\n",
    "            area_under(\n",
    "                r_values_list[i],\n",
    "                func_values_list[i],\n",
    "                threshold,\n",
    "                as_frac_total=as_frac_total,\n",
    "                shift=shift,\n",
    "                below_thresh_zero=below_thresh_zero,\n",
    "                as_frac_total_original=as_frac_total_original,\n",
    "                total_area_above_thresh=total_area_above_thresh,\n",
    "            )\n",
    "        )\n",
    "    return area_under_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_threshold_cross(r_vals, func_vals, threshold, shift=None):\n",
    "    if shift:\n",
    "        func_vals -= shift\n",
    "    i = 0\n",
    "    while i < len(func_vals) and func_vals[i] > threshold:\n",
    "        i += 1\n",
    "    return r_vals[i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_threshold_cross_from_file(filename, start_r, threshold, shift=None):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    results_list = []\n",
    "    for i in range(len(r_values_list)):\n",
    "        results_list.append(\n",
    "            first_threshold_cross(\n",
    "                r_values_list[i], func_values_list[i], threshold, shift=shift\n",
    "            )\n",
    "        )\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_threshold_crosses(\n",
    "    r_vals, func_vals, threshold, shift=None, rel_to_length=False\n",
    "):\n",
    "    if shift:\n",
    "        func_vals -= shift\n",
    "    crosses_count = 0\n",
    "    for i in range(len(r_vals) - 1):\n",
    "        if func_vals[i] <= threshold and func_vals[i + 1] > threshold:\n",
    "            crosses_count += 1\n",
    "        elif func_vals[i] > threshold and func_vals[i + 1] <= threshold:\n",
    "            crosses_count += 1\n",
    "    if rel_to_length:\n",
    "        crosses_count /= len(r_vals)\n",
    "    return crosses_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_threshold_crosses_from_file(\n",
    "    filename, start_r, threshold, shift=None, rel_to_length=False\n",
    "):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    results_list = []\n",
    "    for i in range(len(r_values_list)):\n",
    "        results_list.append(\n",
    "            number_threshold_crosses(\n",
    "                r_values_list[i],\n",
    "                func_values_list[i],\n",
    "                threshold,\n",
    "                shift=shift,\n",
    "                rel_to_length=rel_to_length,\n",
    "            )\n",
    "        )\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_func_val(r_vals, func_vals):\n",
    "    inside = np.multiply(r_vals, func_vals)\n",
    "    expected_val = np.trapz(inside, x=r_vals)\n",
    "    norm_factor = np.trapz(func_vals, x=r_vals)\n",
    "    expected_val /= norm_factor\n",
    "    return expected_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_func_val_from_file(filename, start_r):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    expected_val_list = []\n",
    "    for i in range(len(r_values_list)):\n",
    "        expected_val_list.append(\n",
    "            expected_func_val(r_values_list[i], func_values_list[i])\n",
    "        )\n",
    "    return expected_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_func_from_file(filename, start_r, savetxt=None):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    norm_func_values_list = []\n",
    "    for i, r_vals in enumerate(r_values_list):\n",
    "        norm_factor = np.trapz(func_values_list[i], x=r_vals)\n",
    "        norm_func_values_list.append(func_values_list[i] / norm_factor)\n",
    "    if savetxt:\n",
    "        all_r_to_save = np.concatenate(r_values_list).ravel()\n",
    "        all_norm_func_to_save = np.concatenate(norm_func_values_list).ravel()\n",
    "        np.savetxt(\n",
    "            savetxt, np.transpose(np.array([all_r_to_save, all_norm_func_to_save]))\n",
    "        )\n",
    "    return r_values_list, norm_func_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def smooth_func_data_from_file(filename, start_r, smooth_window):\n",
    "#     r_values_list, func_values_list = get_funcvals_from_txt(filename,start_r)\n",
    "#     for i,r_vals in enumerate(r_values_list):\n",
    "\n",
    "\n",
    "#     def moving_average(a, n=3) :\n",
    "#     ret = np.cumsum(a, dtype=float)\n",
    "#     ret[n:] = ret[n:] - ret[:-n]\n",
    "#     return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_analyse = [\n",
    "    [14, \"chr_P_sfGFP_100x_ref5max\", 20, \"all\", 5],\n",
    "    [3, \"chr_P_GFPmut3_100x_ref5max\", 50, \"all\", 5],\n",
    "    [16, \"chr_P_sfGFP_40x_ref5max\", 10, np.arange(400), 5],\n",
    "    [6, \"chr_P_GFPmut3_40x_ref5max\", 0, np.arange(400), 5],\n",
    "    [15, \"chr_P_sfGFP_20x_ref5max\", 0, np.arange(400), 5],\n",
    "    [4, \"chr_P_GFPmut3_20x_ref5max\", 0, np.arange(400), 5],\n",
    "    [14, \"chr_P_sfGFP_100x_ref10max\", 20, \"all\", 10],\n",
    "    [3, \"chr_P_GFPmut3_100x_ref10max\", 50, \"all\", 10],\n",
    "    [16, \"chr_P_sfGFP_40x_ref10max\", 10, np.arange(200), 10],\n",
    "    [6, \"chr_P_GFPmut3_40x_ref10max\", 0, np.arange(200), 10],\n",
    "    [15, \"chr_P_sfGFP_20x_ref10max\", 0, np.arange(200), 10],\n",
    "    [4, \"chr_P_GFPmut3_20x_ref10max\", 0, np.arange(200), 10],\n",
    "]\n",
    "# files_to_analyse = [[16,\"chr_P_sfGFP_40x_ref5max\",10,np.arange()],[6,\"chr_P_GFPmut3_40x_ref5max\",0]]\n",
    "# files_to_analyse = [[15,\"chr_P_sfGFP_20x_ref1max\",0,'all'],[4,\"chr_P_GFPmut3_20x_ref1max\",0,'all']]\n",
    "calculate = True\n",
    "date_stamp_data = \"20200729\"\n",
    "date_stamp_output = \"20200729\"\n",
    "\n",
    "\n",
    "for file in files_to_analyse:\n",
    "    nd2 = nd2reader.ND2Reader(filenames[file[0]])\n",
    "    fov_index = file[2]\n",
    "    name = file[1]\n",
    "    if not path.exists(date_stamp_data + \"/autocorr_\" + name) or calculate:\n",
    "        print(\"Calculating\")\n",
    "        phase_img = nd2.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "        fluor_img = nd2.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "        seg = segment_phase(phase_img)\n",
    "        autocorr(\n",
    "            seg,\n",
    "            fluor_img,\n",
    "            cell_indices=file[3],\n",
    "            time_allowed=80,\n",
    "            savetxt=date_stamp_output + \"/autocorr_\" + name,\n",
    "            ref_point_val=[\"max\", file[4]],\n",
    "            r_values=None,\n",
    "            gr_values=None,\n",
    "            intensity_weighted=True,\n",
    "            start_r=1,\n",
    "            dr=1,\n",
    "            rdfsavetxt=date_stamp_output + \"/rdf_\" + name,\n",
    "            stdevs=True,\n",
    "            stdevs_savetxt=date_stamp_output + \"/stdevs_\" + name,\n",
    "        )\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
    "    ax = axes.ravel()\n",
    "    plot_gr_from_file(\n",
    "        date_stamp_data + \"/rdf_\" + name, 1, savefig=None, line=[1], ax=ax[0]\n",
    "    )\n",
    "    ax[0].set_title(\"RDF\")\n",
    "\n",
    "    area_under_rdf = area_under_from_file(date_stamp_data + \"/rdf_\" + name, 1, 1)\n",
    "    ax[1].hist(area_under_rdf, bins=20, range=(0, 40))\n",
    "    ax[1].set_title(\"Integral RDF>1\")\n",
    "\n",
    "    area_under_rdf_frac = area_under_from_file(\n",
    "        date_stamp_data + \"/rdf_\" + name, 1, 1, as_frac_total=True\n",
    "    )\n",
    "    ax[2].hist(area_under_rdf_frac, bins=20, range=(0, 1))\n",
    "    ax[2].set_title(\"Integral RDF>1 as frac\")\n",
    "\n",
    "    expected_rdfs = expected_func_val_from_file(date_stamp_data + \"/rdf_\" + name, 1)\n",
    "    ax[3].hist(expected_rdfs, bins=20, range=(0, 40))\n",
    "    ax[3].set_title(\"Mean RDF\")\n",
    "\n",
    "    stdevs = np.genfromtxt(date_stamp_output + \"/stdevs_\" + name)\n",
    "    ax[4].hist(stdevs, bins=20)\n",
    "    ax[4].set_title(\"Stdevs of cell intensities\")\n",
    "\n",
    "    fig.suptitle(name + \" fov: \" + str(fov_index), fontsize=14, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(date_stamp_output + \"/plots_\" + name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_plots(files_to_analyse):\n",
    "    #     files_to_analyse is a list of lists.\n",
    "    # Each list contains the information about the file, in the order:\n",
    "    # [filename_index, base_filename, fov (rewrite in future to do multiple), date_stamp_data, date_stamp_output,\n",
    "    # ref_points, cell_indices, calculate (true if want to re-calculate, otherwise will check for existing data files)]\n",
    "    for file_details in files_to_analyse:\n",
    "        [\n",
    "            file_index,\n",
    "            name,\n",
    "            fov_index,\n",
    "            date_stamp_data,\n",
    "            date_stamp_output,\n",
    "            ref_points,\n",
    "            cell_indices,\n",
    "            calculate,\n",
    "        ] = file_details\n",
    "        nd2 = nd2reader.ND2Reader(filenames[file_index])\n",
    "        seg_available = False\n",
    "        if not path.exists(date_stamp_data + \"/autocorr_\" + name) or calculate:\n",
    "            print(\"Calculating\")\n",
    "            phase_img = nd2.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "            fluor_img = nd2.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "            signal.alarm(120)\n",
    "            try:\n",
    "                seg = segment_phase(phase_img)\n",
    "                seg_available = True\n",
    "            except TimeoutException:\n",
    "                print(\"timeout\")\n",
    "                continue\n",
    "            signal.alarm(0)\n",
    "            autocorr(\n",
    "                seg,\n",
    "                fluor_img,\n",
    "                cell_indices=cell_indices,\n",
    "                time_allowed=80,\n",
    "                savetxt=date_stamp_output + \"/autocorr_\" + name,\n",
    "                ref_point_val=[\"max\", ref_points],\n",
    "                r_values=None,\n",
    "                gr_values=None,\n",
    "                intensity_weighted=True,\n",
    "                start_r=1,\n",
    "                dr=1,\n",
    "                rdfsavetxt=date_stamp_output + \"/rdf_\" + name,\n",
    "                stdevs=True,\n",
    "                stdevs_savetxt=date_stamp_output + \"/stdevs_\" + name,\n",
    "            )\n",
    "        fig, axes = plt.subplots(6, 4, figsize=(12, 18))\n",
    "        ax = axes.ravel()\n",
    "        plot_gr_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name, 1, savefig=None, line=[1], ax=ax[0]\n",
    "        )\n",
    "        ax[0].set_title(\"RDF\")\n",
    "\n",
    "        val_first_rdf_cross = first_threshold_cross_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name, 1, 0, shift=1\n",
    "        )\n",
    "        area_under_rdf_shift1_thresh0 = area_under_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name,\n",
    "            1,\n",
    "            0,\n",
    "            shift=1,\n",
    "            as_frac_total=False,\n",
    "            below_thresh_zero=False,\n",
    "        )\n",
    "        area_under_rdf_shift1_thresh0_as_frac_total = area_under_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name,\n",
    "            1,\n",
    "            0,\n",
    "            shift=1,\n",
    "            as_frac_total=True,\n",
    "            below_thresh_zero=True,\n",
    "            as_frac_total_original=True,\n",
    "        )\n",
    "        number_rdf_crosses = number_threshold_crosses_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name, 1, 0, shift=1, rel_to_length=True\n",
    "        )\n",
    "        total_area_under_rdf_shift1_thresh0_as_frac_total = area_under_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name,\n",
    "            1,\n",
    "            0,\n",
    "            shift=1,\n",
    "            as_frac_total=True,\n",
    "            below_thresh_zero=True,\n",
    "            as_frac_total_original=True,\n",
    "            total_area_above_thresh=True,\n",
    "        )\n",
    "\n",
    "        stdevs = np.genfromtxt(date_stamp_output + \"/stdevs_\" + name)\n",
    "\n",
    "        to_plot = [\n",
    "            [\"First RDF-1=0\", val_first_rdf_cross, 20],\n",
    "            [\"Initial integral RDF-1>0\", area_under_rdf_shift1_thresh0, 25],\n",
    "            [\n",
    "                \"Initial integral RDF-1>0 as frac total\",\n",
    "                area_under_rdf_shift1_thresh0_as_frac_total,\n",
    "                1,\n",
    "            ],\n",
    "            [\"RDF-1 fluctuation frequency\", number_rdf_crosses, 1],\n",
    "            [\n",
    "                \"Total integral RDF-1>0 as frac total\",\n",
    "                total_area_under_rdf_shift1_thresh0_as_frac_total,\n",
    "                1,\n",
    "            ],\n",
    "            [\"Stdevs of cell intensity\", stdevs],\n",
    "        ]\n",
    "\n",
    "        for i in np.arange(1, 7):\n",
    "            if len(to_plot[i - 1]) > 2:\n",
    "                ax[i].hist(to_plot[i - 1][1], bins=20, range=(0, to_plot[i - 1][2]))\n",
    "            else:\n",
    "                ax[i].hist(to_plot[i - 1][1], bins=20)\n",
    "            ax[i].set_title(to_plot[i - 1][0])\n",
    "\n",
    "        combs = itertools.combinations([0, 1, 2, 3, 4, 5], 2)\n",
    "\n",
    "        for i, comb in enumerate(combs):\n",
    "            ax[i + 7].scatter(to_plot[comb[0]][1], to_plot[comb[1]][1])\n",
    "            ax[i + 7].set_xlabel(to_plot[comb[0]][0])\n",
    "            ax[i + 7].set_ylabel(to_plot[comb[1]][0])\n",
    "            if len(to_plot[comb[0]]) > 2:\n",
    "                ax[i + 7].set_xlim(0, to_plot[comb[0]][2])\n",
    "            if len(to_plot[comb[1]]) > 2:\n",
    "                ax[i + 7].set_ylim(0, to_plot[comb[1]][2])\n",
    "\n",
    "        if seg_available:\n",
    "            ax[-1].imshow(seg)\n",
    "\n",
    "        fig.suptitle(name + \" fov: \" + str(fov_index), fontsize=14, y=1.05)\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(date_stamp_output + \"/plots_\" + name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stdev_rdffrac_overlay(\n",
    "    stdev_files,\n",
    "    rdf_files,\n",
    "    legend_titles,\n",
    "    savefig,\n",
    "    plot_title,\n",
    "    stdev_lim=None,\n",
    "    rdf_frac_lim=None,\n",
    "    all_linlog=False,\n",
    "    axes=None,\n",
    "    fig=None,\n",
    "):\n",
    "    if all_linlog:\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "        ax = axes.ravel()\n",
    "    else:\n",
    "        if not axes and not fig:\n",
    "            fig, axes = plt.subplots(figsize=(6, 6))\n",
    "    colour = 0\n",
    "    for i, file in enumerate(stdev_files):\n",
    "        stdevs = np.genfromtxt(file)\n",
    "        rdf_fracs = area_under_from_file(\n",
    "            rdf_files[i],\n",
    "            1,\n",
    "            0,\n",
    "            shift=1,\n",
    "            as_frac_total=True,\n",
    "            below_thresh_zero=True,\n",
    "            as_frac_total_original=True,\n",
    "        )\n",
    "        edge_colours = [\n",
    "            \"xkcd:blue blue\",\n",
    "            \"xkcd:yellow orange\",\n",
    "            \"xkcd:lightish red\",\n",
    "            \"xkcd:grassy green\",\n",
    "        ]\n",
    "        if all_linlog:\n",
    "            for panel in ax:\n",
    "                panel.scatter(\n",
    "                    stdevs,\n",
    "                    rdf_fracs,\n",
    "                    label=legend_titles[i],\n",
    "                    facecolors=\"none\",\n",
    "                    edgecolors=edge_colours[colour],\n",
    "                    linewidths=0.75,\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "                panel.set_xlabel(\"Stdevs of cell intensity\")\n",
    "                panel.set_ylabel(\"Initial integral RDF-1>0 as frac total\")\n",
    "        else:\n",
    "            axes.scatter(\n",
    "                stdevs,\n",
    "                rdf_fracs,\n",
    "                label=legend_titles[i],\n",
    "                facecolors=\"none\",\n",
    "                edgecolors=edge_colours[colour],\n",
    "                linewidths=0.75,\n",
    "                alpha=0.8,\n",
    "            )\n",
    "            axes.set_xlabel(\"Stdevs of cell intensity\")\n",
    "            axes.set_ylabel(\"Initial integral RDF-1>0 as frac total\")\n",
    "        colour += 1\n",
    "    if all_linlog:\n",
    "        ax[1].set_xscale(\"log\")\n",
    "        ax[2].set_yscale(\"log\")\n",
    "        ax[2].set_ylim(ymin=5e-3, ymax=1)\n",
    "        ax[3].set_xscale(\"log\")\n",
    "        ax[3].set_yscale(\"log\")\n",
    "        ax[3].set_ylim(ymin=5e-3, ymax=1)\n",
    "    else:\n",
    "        axes.set_xscale(\"log\")\n",
    "        axes.set_yscale(\"log\")\n",
    "        axes.set_ylim(ymin=5e-3, ymax=1)\n",
    "    plt.legend()\n",
    "    fig.suptitle(plot_title, fontsize=14, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(savefig, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200803/stdevs_chr_P_Venus_100x_ref1max\",\n",
    "        \"20200803/stdevs_chr_P_Dendra2_100x_ref1max\",\n",
    "        \"20200729/stdevs_chr_P_sfGFP_100x_ref1max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_100x_ref1max\",\n",
    "    ],\n",
    "    [\n",
    "        \"20200803/rdf_chr_P_Venus_100x_ref1max\",\n",
    "        \"20200803/rdf_chr_P_Dendra2_100x_ref1max\",\n",
    "        \"20200729/rdf_chr_P_sfGFP_100x_ref1max\",\n",
    "        \"20200729/rdf_chr_P_GFPmut3_100x_ref1max\",\n",
    "    ],\n",
    "    [\"100x Venus ref1\", \"100x Dendra2 ref1\", \"100x sfGFP ref1\", \"100x GFPmut3 ref1\"],\n",
    "    \"20200803/all_100x_ref1\",\n",
    "    \"100x ref1\",\n",
    ")\n",
    "\n",
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200803/stdevs_chr_P_Venus_40x_ref1max\",\n",
    "        \"20200803/stdevs_chr_P_Dendra2_40x_ref1max\",\n",
    "        \"20200729/stdevs_chr_P_sfGFP_40x_ref1max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_40x_ref1max\",\n",
    "    ],\n",
    "    [\n",
    "        \"20200803/rdf_chr_P_Venus_40x_ref1max\",\n",
    "        \"20200803/rdf_chr_P_Dendra2_40x_ref1max\",\n",
    "        \"20200729/rdf_chr_P_sfGFP_40x_ref1max\",\n",
    "        \"20200729/rdf_chr_P_GFPmut3_40x_ref1max\",\n",
    "    ],\n",
    "    [\"40x Venus ref1\", \"40x Dendra2 ref1\", \"40x sfGFP ref1\", \"40x GFPmut3 ref1\"],\n",
    "    \"20200803/all_40x_ref1\",\n",
    "    \"40x ref1\",\n",
    ")\n",
    "\n",
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200803/stdevs_chr_P_Venus_20x_ref1max\",\n",
    "        \"20200803/stdevs_chr_P_Dendra2_20x_ref1max\",\n",
    "        \"20200729/stdevs_chr_P_sfGFP_20x_ref1max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_20x_ref1max\",\n",
    "    ],\n",
    "    [\n",
    "        \"20200803/rdf_chr_P_Venus_20x_ref1max\",\n",
    "        \"20200803/rdf_chr_P_Dendra2_20x_ref1max\",\n",
    "        \"20200729/rdf_chr_P_sfGFP_20x_ref1max\",\n",
    "        \"20200729/rdf_chr_P_GFPmut3_20x_ref1max\",\n",
    "    ],\n",
    "    [\"20x Venus ref1\", \"20x Dendra2 ref1\", \"20x sfGFP ref1\", \"20x GFPmut3 ref1\"],\n",
    "    \"20200803/all_20x_ref1\",\n",
    "    \"20x ref1\",\n",
    ")\n",
    "\n",
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200803/stdevs_chr_P_Venus_100x_ref5max\",\n",
    "        \"20200803/stdevs_chr_P_Dendra2_100x_ref5max\",\n",
    "        \"20200729/stdevs_chr_P_sfGFP_100x_ref5max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_100x_ref5max\",\n",
    "    ],\n",
    "    [\n",
    "        \"20200803/rdf_chr_P_Venus_100x_ref5max\",\n",
    "        \"20200803/rdf_chr_P_Dendra2_100x_ref5max\",\n",
    "        \"20200729/rdf_chr_P_sfGFP_100x_ref5max\",\n",
    "        \"20200729/rdf_chr_P_GFPmut3_100x_ref5max\",\n",
    "    ],\n",
    "    [\"100x Venus ref5\", \"100x Dendra2 ref5\", \"100x sfGFP ref5\", \"100x GFPmut3 ref5\"],\n",
    "    \"20200803/all_100x_ref5\",\n",
    "    \"100x ref5\",\n",
    ")\n",
    "\n",
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200803/stdevs_chr_P_Venus_40x_ref5max\",\n",
    "        \"20200803/stdevs_chr_P_Dendra2_40x_ref5max\",\n",
    "        \"20200729/stdevs_chr_P_sfGFP_40x_ref5max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_40x_ref5max\",\n",
    "    ],\n",
    "    [\n",
    "        \"20200803/rdf_chr_P_Venus_40x_ref5max\",\n",
    "        \"20200803/rdf_chr_P_Dendra2_40x_ref5max\",\n",
    "        \"20200729/rdf_chr_P_sfGFP_40x_ref5max\",\n",
    "        \"20200729/rdf_chr_P_GFPmut3_40x_ref5max\",\n",
    "    ],\n",
    "    [\"40x Venus ref5\", \"40x Dendra2 ref5\", \"40x sfGFP ref5\", \"40x GFPmut3 ref5\"],\n",
    "    \"20200803/all_40x_ref5\",\n",
    "    \"40x ref5\",\n",
    ")\n",
    "\n",
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200803/stdevs_chr_P_Venus_20x_ref5max\",\n",
    "        \"20200803/stdevs_chr_P_Dendra2_20x_ref5max\",\n",
    "        \"20200729/stdevs_chr_P_sfGFP_20x_ref5max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_20x_ref5max\",\n",
    "    ],\n",
    "    [\n",
    "        \"20200803/rdf_chr_P_Venus_20x_ref5max\",\n",
    "        \"20200803/rdf_chr_P_Dendra2_20x_ref5max\",\n",
    "        \"20200729/rdf_chr_P_sfGFP_20x_ref5max\",\n",
    "        \"20200729/rdf_chr_P_GFPmut3_20x_ref5max\",\n",
    "    ],\n",
    "    [\"20x Venus ref5\", \"20x Dendra2 ref5\", \"20x sfGFP ref5\", \"20x GFPmut3 ref5\"],\n",
    "    \"20200803/all_20x_ref5\",\n",
    "    \"20x ref5\",\n",
    ")\n",
    "\n",
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200803/stdevs_chr_P_Venus_100x_ref10max\",\n",
    "        \"20200803/stdevs_chr_P_Dendra2_100x_ref10max\",\n",
    "        \"20200729/stdevs_chr_P_sfGFP_100x_ref10max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_100x_ref10max\",\n",
    "    ],\n",
    "    [\n",
    "        \"20200803/rdf_chr_P_Venus_100x_ref10max\",\n",
    "        \"20200803/rdf_chr_P_Dendra2_100x_ref10max\",\n",
    "        \"20200729/rdf_chr_P_sfGFP_100x_ref10max\",\n",
    "        \"20200729/rdf_chr_P_GFPmut3_100x_ref10max\",\n",
    "    ],\n",
    "    [\n",
    "        \"100x Venus ref10\",\n",
    "        \"100x Dendra2 ref10\",\n",
    "        \"100x sfGFP ref10\",\n",
    "        \"100x GFPmut3 ref10\",\n",
    "    ],\n",
    "    \"20200803/all_100x_ref10\",\n",
    "    \"100x ref10\",\n",
    ")\n",
    "\n",
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200803/stdevs_chr_P_Venus_40x_ref10max\",\n",
    "        \"20200803/stdevs_chr_P_Dendra2_40x_ref10max\",\n",
    "        \"20200729/stdevs_chr_P_sfGFP_40x_ref10max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_40x_ref10max\",\n",
    "    ],\n",
    "    [\n",
    "        \"20200803/rdf_chr_P_Venus_40x_ref10max\",\n",
    "        \"20200803/rdf_chr_P_Dendra2_40x_ref10max\",\n",
    "        \"20200729/rdf_chr_P_sfGFP_40x_ref10max\",\n",
    "        \"20200729/rdf_chr_P_GFPmut3_40x_ref10max\",\n",
    "    ],\n",
    "    [\"40x Venus ref10\", \"40x Dendra2 ref10\", \"40x sfGFP ref10\", \"40x GFPmut3 ref10\"],\n",
    "    \"20200803/all_40x_ref10\",\n",
    "    \"40x ref10\",\n",
    ")\n",
    "\n",
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200803/stdevs_chr_P_Venus_20x_ref10max\",\n",
    "        \"20200803/stdevs_chr_P_Dendra2_20x_ref10max\",\n",
    "        \"20200729/stdevs_chr_P_sfGFP_20x_ref10max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_20x_ref10max\",\n",
    "    ],\n",
    "    [\n",
    "        \"20200803/rdf_chr_P_Venus_20x_ref10max\",\n",
    "        \"20200803/rdf_chr_P_Dendra2_20x_ref10max\",\n",
    "        \"20200729/rdf_chr_P_sfGFP_20x_ref10max\",\n",
    "        \"20200729/rdf_chr_P_GFPmut3_20x_ref10max\",\n",
    "    ],\n",
    "    [\"20x Venus ref10\", \"20x Dendra2 ref10\", \"20x sfGFP ref10\", \"20x GFPmut3 ref10\"],\n",
    "    \"20200803/all_20x_ref10\",\n",
    "    \"20x ref10\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20200803\n",
    "fig, ax = plt.subplots()\n",
    "plot_stdev_rdffrac_overlay(\n",
    "    [\n",
    "        \"20200729/stdevs_chr_P_sfGFP_20x_ref1max\",\n",
    "        \"20200729/stdevs_chr_P_GFPmut3_20x_ref1max\",\n",
    "    ],\n",
    "    [\"20200729/rdf_chr_P_sfGFP_20x_ref1max\", \"20200729/rdf_chr_P_GFPmut3_20x_ref1max\"],\n",
    "    [\"20x sfGFP ref1\", \"20x GFPmut3 ref1\"],\n",
    "    \"20200803/sf_mut3_20x_ref1\",\n",
    "    \"sfGFP and GFPmut3 20x ref1\",\n",
    "    axes=ax,\n",
    "    fig=fig,\n",
    ")\n",
    "ax.axhline(y=1.5e-1, ls=\":\", color=\"k\")\n",
    "ax.axvline(x=60, ls=\":\", color=\"k\")\n",
    "ax.axvline(x=200, ls=\":\", color=\"k\")\n",
    "ax.axvline(x=1000, ls=\":\", color=\"k\")\n",
    "\n",
    "fig.savefig(\"20200803/sf_mut3_20x_ref1\")\n",
    "\n",
    "stdevs_sfGFP = np.genfromtxt(\"20200729/stdevs_chr_P_sfGFP_20x_ref1max\")\n",
    "stdevs_mut3 = np.genfromtxt(\"20200729/stdevs_chr_P_GFPmut3_20x_ref1max\")\n",
    "ints_sfGFP = area_under_from_file(\n",
    "    \"20200729/rdf_chr_P_sfGFP_20x_ref1max\",\n",
    "    1,\n",
    "    0,\n",
    "    shift=1,\n",
    "    as_frac_total=True,\n",
    "    below_thresh_zero=True,\n",
    "    as_frac_total_original=True,\n",
    ")\n",
    "ints_mut3 = area_under_from_file(\n",
    "    \"20200729/rdf_chr_P_GFPmut3_20x_ref1max\",\n",
    "    1,\n",
    "    0,\n",
    "    shift=1,\n",
    "    as_frac_total=True,\n",
    "    below_thresh_zero=True,\n",
    "    as_frac_total_original=True,\n",
    ")\n",
    "\n",
    "A_sfGFP = []\n",
    "B_sfGFP = []\n",
    "C_sfGFP = []\n",
    "D_sfGFP = []\n",
    "E_sfGFP = []\n",
    "\n",
    "A_mut3 = []\n",
    "B_mut3 = []\n",
    "C_mut3 = []\n",
    "D_mut3 = []\n",
    "E_mut3 = []\n",
    "\n",
    "for i, stdev in enumerate(stdevs_sfGFP):\n",
    "    if stdev <= 60:\n",
    "        A_sfGFP.append(i)\n",
    "    elif stdev > 60 and stdev <= 200:\n",
    "        if ints_sfGFP[i] < 1.5e-1:\n",
    "            B_sfGFP.append(i)\n",
    "        else:\n",
    "            C_sfGFP.append(i)\n",
    "    elif stdev > 200 and stdev <= 1000:\n",
    "        D_sfGFP.append(i)\n",
    "    elif stdev > 1000:\n",
    "        E_sfGFP.append(i)\n",
    "\n",
    "for i, stdev in enumerate(stdevs_mut3):\n",
    "    if stdev <= 60:\n",
    "        A_mut3.append(i)\n",
    "    elif stdev > 60 and stdev <= 200:\n",
    "        if ints_mut3[i] < 1.5e-1:\n",
    "            B_mut3.append(i)\n",
    "        else:\n",
    "            C_mut3.append(i)\n",
    "    elif stdev > 200 and stdev <= 1000:\n",
    "        D_mut3.append(i)\n",
    "    elif stdev > 1000:\n",
    "        E_mut3.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfGFP_file = filenames[15]\n",
    "sfGFP_img = nd2reader.ND2Reader(sfGFP_file)\n",
    "fov_index = 0\n",
    "sfGFP_phase_img = sfGFP_img.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "sfGFP_fluor_img = sfGFP_img.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "sfGFP_seg = segment_phase(sfGFP_phase_img)\n",
    "\n",
    "mut3_file = filenames[4]\n",
    "mut3_img = nd2reader.ND2Reader(mut3_file)\n",
    "fov_index = 0\n",
    "mut3_phase_img = mut3_img.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "mut3_fluor_img = mut3_img.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "mut3_seg = segment_phase(mut3_phase_img)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(sfGFP_seg)\n",
    "ax[1].imshow(mut3_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images of cells from different regions of the 2d stdevs/frac RDF integrals for sfGFP and GFPmut3.\n",
    "columns = 10\n",
    "\n",
    "fig, axes = plt.subplots(7, columns, figsize=(columns * 3, 21))\n",
    "ax = axes.ravel()\n",
    "i = 0\n",
    "for plot in np.arange(0, columns):\n",
    "    cell_index = A_mut3[plot]\n",
    "    cell_indices = np.where(mut3_seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(mut3_seg != cell_index + 1, mut3_fluor_img)\n",
    "    ax[plot].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[plot].set_title(cell_index)\n",
    "    if plot == 0:\n",
    "        ax[plot].set_title(\"GFPmut3 class A \\n\" + str(cell_index))\n",
    "\n",
    "for plot in np.arange(columns, columns * 2):\n",
    "    cell_index = A_sfGFP[plot - columns]\n",
    "    cell_indices = np.where(sfGFP_seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(sfGFP_seg != cell_index + 1, sfGFP_fluor_img)\n",
    "    ax[plot].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[plot].set_title(cell_index)\n",
    "    if plot == columns:\n",
    "        ax[plot].set_title(\"sfGFP class A \\n\" + str(cell_index))\n",
    "\n",
    "for plot in np.arange(columns * 2, columns * 3):\n",
    "    try:\n",
    "        cell_index = B_mut3[plot - columns * 2]\n",
    "    except IndexError:\n",
    "        break\n",
    "    cell_indices = np.where(mut3_seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(mut3_seg != cell_index + 1, mut3_fluor_img)\n",
    "    ax[plot].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[plot].set_title(cell_index)\n",
    "    if plot == columns * 2:\n",
    "        ax[plot].set_title(\"GFPmut3 class B \\n\" + str(cell_index))\n",
    "\n",
    "for plot in np.arange(columns * 3, columns * 4):\n",
    "    cell_index = B_sfGFP[plot - columns * 3]\n",
    "    cell_indices = np.where(sfGFP_seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(sfGFP_seg != cell_index + 1, sfGFP_fluor_img)\n",
    "    ax[plot].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[plot].set_title(cell_index)\n",
    "    if plot == columns * 3:\n",
    "        ax[plot].set_title(\"sfGFP class B \\n\" + str(cell_index))\n",
    "\n",
    "for plot in np.arange(columns * 4, columns * 5):\n",
    "    cell_index = C_sfGFP[plot - columns * 4]\n",
    "    cell_indices = np.where(sfGFP_seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(sfGFP_seg != cell_index + 1, sfGFP_fluor_img)\n",
    "    ax[plot].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[plot].set_title(cell_index)\n",
    "    if plot == columns * 4:\n",
    "        ax[plot].set_title(\"sfGFP class C \\n\" + str(cell_index))\n",
    "\n",
    "for plot in np.arange(columns * 5, columns * 6):\n",
    "    cell_index = D_sfGFP[plot - columns * 5]\n",
    "    cell_indices = np.where(sfGFP_seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(sfGFP_seg != cell_index + 1, sfGFP_fluor_img)\n",
    "    ax[plot].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[plot].set_title(cell_index)\n",
    "    if plot == columns * 5:\n",
    "        ax[plot].set_title(\"sfGFP class D \\n\" + str(cell_index))\n",
    "\n",
    "for plot in np.arange(columns * 6, columns * 7):\n",
    "    try:\n",
    "        cell_index = E_sfGFP[plot - columns * 6]\n",
    "    except IndexError:\n",
    "        break\n",
    "    cell_indices = np.where(sfGFP_seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(sfGFP_seg != cell_index + 1, sfGFP_fluor_img)\n",
    "    ax[plot].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[plot].set_title(cell_index)\n",
    "    if plot == columns * 6:\n",
    "        ax[plot].set_title(\"sfGFP class E \\n\" + str(cell_index))\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"20200803/sf_mut3_20xref1_cellsAtoE\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_analyse = [[14,\"chr_P_sfGFP_100x_ref1max\",20,'20200724','20200725',\n",
    "#                     5,np.arange(200),False],\n",
    "#                     [3,\"chr_P_GFPmut3_100x_ref1max\",50,'20200724','20200725',\n",
    "#                     5,np.arange(200),False]]\n",
    "# files_to_analyse = [[16,\"chr_P_sfGFP_40x_ref1max\",10,'20200724','20200725',\n",
    "#                     5,np.arange(200),False],\n",
    "#                     [6,\"chr_P_GFPmut3_40x_ref1max\",0,'20200724','20200725',\n",
    "#                     5,np.arange(200),False]]\n",
    "# files_to_analyse = [[15,\"chr_P_sfGFP_20x_ref10max\",0,'20200724','20200727',\n",
    "#                     5,np.arange(200),False],\n",
    "#                     [4,\"chr_P_GFPmut3_20x_ref10max\",0,'20200724','20200727',\n",
    "#                     5,np.arange(200),False]]\n",
    "\n",
    "# files_to_analyse = [[14,\"chr_P_sfGFP_100x_ref5max\",20,'20200729','20200803',5,'all',False],\n",
    "#                     [3,\"chr_P_GFPmut3_100x_ref5max\",50,'20200729','20200803',5,'all',False],\n",
    "#                     [16,\"chr_P_sfGFP_40x_ref5max\",10,'20200729','20200803',5,np.arange(200),False],\n",
    "#                     [6,\"chr_P_GFPmut3_40x_ref5max\",0,'20200729','20200803',5,np.arange(200),False],\n",
    "#                    [15,\"chr_P_sfGFP_20x_ref5max\",0,'20200729','20200803',5,np.arange(200),False],\n",
    "#                     [4,\"chr_P_GFPmut3_20x_ref5max\",0,'20200729','20200803',5,np.arange(200),False],\n",
    "#                    [14,\"chr_P_sfGFP_100x_ref10max\",20,'20200729','20200803',10,'all',False],\n",
    "#                     [3,\"chr_P_GFPmut3_100x_ref10max\",50,'20200729','20200803',10,'all',False],\n",
    "#                     [16,\"chr_P_sfGFP_40x_ref10max\",10,'20200729','20200803',10,np.arange(100),False],\n",
    "#                     [6,\"chr_P_GFPmut3_40x_ref10max\",0,'20200729','20200803',10,np.arange(100),False],\n",
    "#                    [15,\"chr_P_sfGFP_20x_ref10max\",0,'20200729','20200803',10,np.arange(100),False],\n",
    "#                     [4,\"chr_P_GFPmut3_20x_ref10max\",0,'20200729','20200803',10,np.arange(100),False],\n",
    "#                     [14,\"chr_P_sfGFP_100x_ref1max\",20,'20200729','20200803',1,'all',False],\n",
    "#                     [3,\"chr_P_GFPmut3_100x_ref1max\",50,'20200729','20200803',1,'all',False],\n",
    "#                     [16,\"chr_P_sfGFP_40x_ref1max\",10,'20200729','20200803',1,'all',False],\n",
    "#                     [6,\"chr_P_GFPmut3_40x_ref1max\",0,'20200729','20200803',1,'all',False],\n",
    "#                    [15,\"chr_P_sfGFP_20x_ref1max\",0,'20200729','20200803',1,'all',False],\n",
    "#                     [4,\"chr_P_GFPmut3_20x_ref1max\",0,'20200729','20200803',1,'all',False]]\n",
    "\n",
    "# generate_analysis_plots(files_to_analyse)\n",
    "\n",
    "# files_to_analyse = [[38,\"plas_P_DHL_sfGFP_100x_ref1max\",78,'20200729','20200729',1,'all',False],\n",
    "#                    [40,\"plas_P_DHL_sfGFP_40x_ref1max\",15,'20200729','20200729',1,'all',False],\n",
    "#                    [39,\"plas_P_DHL_sfGFP_20x_ref1max\",0,'20200729','20200729',1,'all',False],\n",
    "#                    [44,\"plas_X_DHL_GFPmut3_100x_ref1max\",68,'20200729','20200729',1,'all',False],\n",
    "#                    [46,\"plas_X_DHL_GFPmut3_40x_ref1max\",23,'20200729','20200729',1,'all',False],\n",
    "#                    [45,\"plas_X_DHL_GFPmut3_20x_ref1max\",6,'20200729','20200729',1,'all',False]]\n",
    "\n",
    "# files_to_analyse = [[44,\"plas_X_DHL_GFPmut3_100x_ref1max\",68,'20200730','20200730',1,'all',False],\n",
    "#                    [46,\"plas_X_DHL_GFPmut3_40x_ref1max\",23,'20200730','20200730',1,np.arange(200),False],\n",
    "#                    [45,\"plas_X_DHL_GFPmut3_20x_ref1max\",6,'20200730','20200730',1,np.arange(200),False]]\n",
    "\n",
    "files_to_analyse = [\n",
    "    [8, \"chr_P_Venus_100x_ref5max\", 48, \"20200803\", \"20200803\", 5, \"all\", False],\n",
    "    [0, \"chr_P_Dendra2_100x_ref5max\", 44, \"20200803\", \"20200803\", 5, \"all\", False],\n",
    "    [10, \"chr_P_Venus_40x_ref5max\", 0, \"20200803\", \"20200803\", 5, \"all\", False],\n",
    "    [\n",
    "        2,\n",
    "        \"chr_P_Dendra2_40x_ref5max\",\n",
    "        2,\n",
    "        \"20200803\",\n",
    "        \"20200803\",\n",
    "        5,\n",
    "        np.arange(200),\n",
    "        False,\n",
    "    ],\n",
    "    [9, \"chr_P_Venus_20x_ref5max\", 8, \"20200803\", \"20200803\", 5, np.arange(200), False],\n",
    "    [\n",
    "        1,\n",
    "        \"chr_P_Dendra2_20x_ref5max\",\n",
    "        0,\n",
    "        \"20200803\",\n",
    "        \"20200803\",\n",
    "        5,\n",
    "        np.arange(200),\n",
    "        False,\n",
    "    ],\n",
    "    [8, \"chr_P_Venus_100x_ref10max\", 48, \"20200803\", \"20200803\", 10, \"all\", False],\n",
    "    [0, \"chr_P_Dendra2_100x_ref10max\", 44, \"20200803\", \"20200803\", 10, \"all\", False],\n",
    "    [\n",
    "        10,\n",
    "        \"chr_P_Venus_40x_ref10max\",\n",
    "        0,\n",
    "        \"20200803\",\n",
    "        \"20200803\",\n",
    "        10,\n",
    "        np.arange(100),\n",
    "        False,\n",
    "    ],\n",
    "    [\n",
    "        2,\n",
    "        \"chr_P_Dendra2_40x_ref10max\",\n",
    "        2,\n",
    "        \"20200803\",\n",
    "        \"20200803\",\n",
    "        10,\n",
    "        np.arange(100),\n",
    "        False,\n",
    "    ],\n",
    "    [\n",
    "        9,\n",
    "        \"chr_P_Venus_20x_ref10max\",\n",
    "        8,\n",
    "        \"20200803\",\n",
    "        \"20200803\",\n",
    "        10,\n",
    "        np.arange(100),\n",
    "        False,\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        \"chr_P_Dendra2_20x_ref10max\",\n",
    "        0,\n",
    "        \"20200803\",\n",
    "        \"20200803\",\n",
    "        10,\n",
    "        np.arange(100),\n",
    "        False,\n",
    "    ],\n",
    "    [8, \"chr_P_Venus_100x_ref1max\", 48, \"20200803\", \"20200803\", 1, \"all\", False],\n",
    "    [0, \"chr_P_Dendra2_100x_ref1max\", 44, \"20200803\", \"20200803\", 1, \"all\", False],\n",
    "    [10, \"chr_P_Venus_40x_ref1max\", 0, \"20200803\", \"20200803\", 1, \"all\", False],\n",
    "    [2, \"chr_P_Dendra2_40x_ref1max\", 2, \"20200803\", \"20200803\", 1, \"all\", False],\n",
    "    [9, \"chr_P_Venus_20x_ref1max\", 8, \"20200803\", \"20200803\", 1, \"all\", False],\n",
    "    [1, \"chr_P_Dendra2_20x_ref1max\", 0, \"20200803\", \"20200803\", 1, \"all\", False],\n",
    "]\n",
    "\n",
    "generate_analysis_plots(files_to_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_image(\n",
    "    size=(200, 200),\n",
    "    mask=None,\n",
    "    shapes=[[\"circle\", [100, 100], 10, 100]],\n",
    "    savename=\"test\",\n",
    "    background=None,\n",
    "    cell_background=None,\n",
    "):\n",
    "    # shape = ['rings'=concentric circles, 'circle'=circle, 'gaussian'=2d gaussian]\n",
    "    # shape == 'circle': ['circle',centre position indices,radius,intensity]\n",
    "    # shape == 'rings': ['rings',centre position indices,\n",
    "    # radius of smallest circle, intensity, width of rings, distance between rings]\n",
    "    # shape == 'gaussian': ['gaussian', centre position indices, stdevs, intensity] (mean = position)\n",
    "    # mask should be False where the cell is.\n",
    "    if not background:\n",
    "        image = np.zeros(size)\n",
    "    elif background[0] == \"gaussian\":\n",
    "        mean, stdev = background[1:]\n",
    "        image = np.random.normal(loc=mean, scale=stdev, size=size)\n",
    "    if np.size(mask) > 1:\n",
    "        image = np.ma.array(image, mask=mask)\n",
    "        if cell_background:\n",
    "            if cell_background[0] == \"gaussian\":\n",
    "                mean, stdev = cell_background[1:]\n",
    "                cell_noise = np.random.normal(loc=mean, scale=stdev, size=size)\n",
    "                image += cell_noise\n",
    "    for shape in shapes:\n",
    "        if shape[0] == \"circle\" or shape[0] == \"rings\":\n",
    "            image_to_add = np.zeros(size)\n",
    "            position, r, intensity = shape[1:]\n",
    "            ranges = np.arange(np.floor(-r), np.ceil(r) + 1)\n",
    "            rel_points = np.where(\n",
    "                (ranges[np.newaxis, :]) ** 2 + (ranges[:, np.newaxis]) ** 2 < r**2\n",
    "            )\n",
    "            points = [\n",
    "                rel_points[0] + position[0] - np.ceil(r),\n",
    "                rel_points[1] + position[1] - np.ceil(r),\n",
    "            ]\n",
    "            image_to_add[\n",
    "                list(map(int, points[0])), list(map(int, points[1]))\n",
    "            ] = intensity\n",
    "        #         if shape[0] == 'rings':\n",
    "\n",
    "        elif shape[0] == \"gaussian\":\n",
    "            position, stdevs, intensity = shape[1:]\n",
    "            vals0, vals1 = np.meshgrid(np.arange(size[0]), np.arange(size[1]))\n",
    "            image_to_add = np.exp(\n",
    "                -(\n",
    "                    (vals0 - position[0]) ** 2 / (2 * stdevs[0]) ** 2\n",
    "                    + (vals1 - position[1]) ** 2 / (2 * stdevs[1]) ** 2\n",
    "                )\n",
    "            )\n",
    "            image_to_add *= intensity\n",
    "        image += image_to_add\n",
    "    if savename:\n",
    "        np.savetxt(savename, image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filenames[14]\n",
    "print(\"file\", file)\n",
    "nd2 = nd2reader.ND2Reader(file)\n",
    "fov_index = 20\n",
    "phase_img = nd2.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "fluor_img = nd2.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "# phase_img = nd2.get_frame_2D(v=0, c=0, z=0)[1100:3000,500:2250]\n",
    "# fluor_img = nd2.get_frame_2D(v=0, c=1, z=0)[1100:3000,500:2250]\n",
    "fig, axes = plt.subplots(1, 5, sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(phase_img)\n",
    "ax[1].imshow(fluor_img, cmap=\"RdGy\")\n",
    "seg = segment_phase(phase_img)\n",
    "ax[2].imshow(seg)\n",
    "ax[3].imshow(seg[700:850, 425:575])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.genfromtxt(\"cellmask\")\n",
    "mask = np.ma.masked_array(mask, np.logical_not(mask)).mask\n",
    "ax[4].imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdevs = []\n",
    "rdf_fracs = []\n",
    "\n",
    "base_name = \"20200731/refpoint1_bg100stdev25_stdev2_int100_2blobs\"\n",
    "# testing = np.linspace(1,500,50)\n",
    "# testing = np.linspace(0.01,20,50)\n",
    "# testing = np.linspace(0,100,50)\n",
    "testing = np.arange(45)\n",
    "test_param = \"distance from centre\"\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "ax = axes.ravel()\n",
    "\n",
    "for value in testing:\n",
    "    test_image = generate_test_image(\n",
    "        size=(150, 150),\n",
    "        shapes=[\n",
    "            [\"gaussian\", [70 - value, 70], [2, 2], 100],\n",
    "            [\"gaussian\", [70 + value, 70], [2, 2], 100],\n",
    "        ],\n",
    "        background=[\"gaussian\", 100, 25],\n",
    "        savename=None,\n",
    "        mask=mask,\n",
    "        cell_background=None,\n",
    "    )\n",
    "    r_vals, gr_vals = rdf(\n",
    "        np.genfromtxt(\"cellmask\"),\n",
    "        test_image,\n",
    "        ref_point_val=[\"max\", 1],\n",
    "        cell_indices=[20],\n",
    "        time_allowed=80,\n",
    "        savetxt=None,\n",
    "        start_r=1,\n",
    "        dr=1,\n",
    "        intensity_weighted=True,\n",
    "        stdevs=True,\n",
    "        stdevs_savetxt=\"20200731/stdevtemp\",\n",
    "    )\n",
    "    r_vals, gr_vals = np.array(r_vals[0]), np.array(gr_vals[0])\n",
    "    rdf_fracs.append(\n",
    "        area_under(\n",
    "            r_vals,\n",
    "            gr_vals,\n",
    "            0,\n",
    "            shift=1,\n",
    "            as_frac_total=True,\n",
    "            below_thresh_zero=True,\n",
    "            as_frac_total_original=True,\n",
    "        )\n",
    "    )\n",
    "    stdevs.append(float(np.genfromtxt(\"20200731/stdevtemp\")))\n",
    "    np.savetxt(base_name + \"_rdffracs\", rdf_fracs)\n",
    "    np.savetxt(base_name + \"_stdevs\", stdevs)\n",
    "    if value == testing[0]:\n",
    "        ax[1].imshow(test_image)\n",
    "        ax[1].set_title(test_param + \" = \" + \"{:.2f}\".format(testing[0]))\n",
    "    elif value == testing[16]:\n",
    "        ax[2].imshow(test_image)\n",
    "        ax[2].set_title(test_param + \" = \" + \"{:.2f}\".format(testing[16]))\n",
    "    elif value == testing[30]:\n",
    "        ax[3].imshow(test_image)\n",
    "        ax[3].set_title(test_param + \" = \" + \"{:.2f}\".format(testing[30]))\n",
    "    elif value == testing[-1]:\n",
    "        ax[4].imshow(test_image)\n",
    "        ax[4].set_title(test_param + \" = \" + \"{:.2f}\".format(testing[-1]))\n",
    "\n",
    "for_colorbar = ax[0].scatter(stdevs, rdf_fracs, c=testing, cmap=\"viridis\")\n",
    "ax[0].set_xlabel(\"Stdevs of cell intensity\")\n",
    "ax[0].set_ylabel(\"Initial integral RDF-1>0 as frac total\")\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_ylim(ymin=5e-3, ymax=1)\n",
    "fig.suptitle(base_name[9:], fontsize=14, y=1.05)\n",
    "plt.colorbar(for_colorbar, ax=ax[0])\n",
    "plt.tight_layout()\n",
    "fig.savefig(base_name[:9] + \"/testplot_\" + base_name[9:], bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now determine the values of these metrics in different test cases, to check that we get values that correspond\n",
    "# with what we expect by eye.\n",
    "\n",
    "# Test intensities (how high above background noise) and stdevs (how diffuse) of centred blobs. Then repeat for\n",
    "# blobs near the edge.\n",
    "\n",
    "# Looks weird? Why is initial int the opposite of initial int as frac? Check the zero_below_thresh etc to be\n",
    "# certain about what these are computing.\n",
    "\n",
    "base_name = \"20200727/refpoint1_nonoise/refpoint1_nonoise\"\n",
    "\n",
    "val_first_rdf_cross = []\n",
    "area_under_rdf_shift1_thresh0 = []\n",
    "area_under_rdf_shift1_thresh0_as_frac_total = []\n",
    "number_rdf_crosses = []\n",
    "total_area_under_rdf_shift1_thresh0_as_frac_total = []\n",
    "\n",
    "intensities = np.linspace(1, 500, 20)\n",
    "stdevs = np.linspace(0.5, 3, 20)\n",
    "\n",
    "for intensity in intensities:\n",
    "    val_first_rdf_cross_toadd = []\n",
    "    area_under_rdf_shift1_thresh0_toadd = []\n",
    "    area_under_rdf_shift1_thresh0_as_frac_total_toadd = []\n",
    "    number_rdf_crosses_toadd = []\n",
    "    total_area_under_rdf_shift1_thresh0_as_frac_total_toadd = []\n",
    "    for stdev in stdevs:\n",
    "        test_image = generate_test_image(\n",
    "            size=(150, 150),\n",
    "            shapes=[[\"gaussian\", [70, 70], [stdev, stdev], intensity]],\n",
    "            background=None,\n",
    "            savename=None,\n",
    "            mask=mask,\n",
    "            cell_background=None,\n",
    "        )\n",
    "        #         autocorr(np.genfromtxt('cellmask'), test_image, cell_indices=[20], time_allowed=80,\n",
    "        #         savetxt=None,ref_point_val = ['max',10],r_values = None,\n",
    "        #             gr_values = None, intensity_weighted = True,start_r=1,dr=1,\n",
    "        #             rdfsavetxt=None)\n",
    "        r_vals, gr_vals = rdf(\n",
    "            np.genfromtxt(\"cellmask\"),\n",
    "            test_image,\n",
    "            ref_point_val=[\"max\", 1],\n",
    "            cell_indices=[20],\n",
    "            time_allowed=80,\n",
    "            savetxt=None,\n",
    "            start_r=1,\n",
    "            dr=1,\n",
    "            intensity_weighted=True,\n",
    "        )\n",
    "        r_vals, gr_vals = np.array(r_vals[0]), np.array(gr_vals[0])\n",
    "        val_first_rdf_cross_toadd.append(\n",
    "            first_threshold_cross(r_vals, gr_vals, 0, shift=1)\n",
    "        )\n",
    "        area_under_rdf_shift1_thresh0_toadd.append(\n",
    "            area_under(\n",
    "                r_vals,\n",
    "                gr_vals,\n",
    "                0,\n",
    "                shift=1,\n",
    "                as_frac_total=False,\n",
    "                below_thresh_zero=False,\n",
    "            )\n",
    "        )\n",
    "        area_under_rdf_shift1_thresh0_as_frac_total_toadd.append(\n",
    "            area_under(\n",
    "                r_vals,\n",
    "                gr_vals,\n",
    "                0,\n",
    "                shift=1,\n",
    "                as_frac_total=True,\n",
    "                below_thresh_zero=True,\n",
    "                as_frac_total_original=True,\n",
    "            )\n",
    "        )\n",
    "        number_rdf_crosses_toadd.append(\n",
    "            number_threshold_crosses(r_vals, gr_vals, 0, shift=1, rel_to_length=True)\n",
    "        )\n",
    "        total_area_under_rdf_shift1_thresh0_as_frac_total_toadd.append(\n",
    "            area_under(\n",
    "                r_vals,\n",
    "                gr_vals,\n",
    "                0,\n",
    "                shift=1,\n",
    "                as_frac_total=True,\n",
    "                below_thresh_zero=True,\n",
    "                as_frac_total_original=True,\n",
    "                total_area_above_thresh=True,\n",
    "            )\n",
    "        )\n",
    "    val_first_rdf_cross.append(val_first_rdf_cross_toadd)\n",
    "    area_under_rdf_shift1_thresh0.append(area_under_rdf_shift1_thresh0_toadd)\n",
    "    area_under_rdf_shift1_thresh0_as_frac_total.append(\n",
    "        area_under_rdf_shift1_thresh0_as_frac_total_toadd\n",
    "    )\n",
    "    number_rdf_crosses.append(number_rdf_crosses_toadd)\n",
    "    total_area_under_rdf_shift1_thresh0_as_frac_total.append(\n",
    "        total_area_under_rdf_shift1_thresh0_as_frac_total_toadd\n",
    "    )\n",
    "\n",
    "np.savetxt(base_name + \"_intensities\", intensities)\n",
    "np.savetxt(base_name + \"_stdevs\", stdevs)\n",
    "np.savetxt(base_name + \"_firstrdfcross\", val_first_rdf_cross)\n",
    "np.savetxt(base_name + \"_initialintegral\", area_under_rdf_shift1_thresh0)\n",
    "np.savetxt(\n",
    "    base_name + \"_initialintegralasfrac\", area_under_rdf_shift1_thresh0_as_frac_total\n",
    ")\n",
    "np.savetxt(base_name + \"_rdfcrosses\", number_rdf_crosses)\n",
    "np.savetxt(\n",
    "    base_name + \"_totalintegral\", total_area_under_rdf_shift1_thresh0_as_frac_total\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(9, 6))\n",
    "ax = axes.ravel()\n",
    "ax[0].pcolormesh(stdevs, intensities, val_first_rdf_cross)\n",
    "ax[0].set_title(\"First RDF-1=0\")\n",
    "ax[1].pcolormesh(stdevs, intensities, area_under_rdf_shift1_thresh0)\n",
    "ax[1].set_title(\"Initial integral RDF-1>0\")\n",
    "ax[2].pcolormesh(stdevs, intensities, area_under_rdf_shift1_thresh0_as_frac_total)\n",
    "ax[2].set_title(\"Initial integral RDF-1>0 as frac total\")\n",
    "ax[3].pcolormesh(stdevs, intensities, number_rdf_crosses)\n",
    "ax[3].set_title(\"Frequency RDF-1=0\")\n",
    "ax[4].pcolormesh(stdevs, intensities, total_area_under_rdf_shift1_thresh0_as_frac_total)\n",
    "ax[4].set_title(\"Total integral RDF-1>0\")\n",
    "for axis in ax:\n",
    "    axis.set_xlabel(\"Stdev\")\n",
    "    axis.set_ylabel(\"Intensity\")\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"refpoint1 no noise\", y=1.05, fontsize=14)\n",
    "fig.savefig(\"20200727/refpoint1_nonoise.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20200731\n",
    "\n",
    "r, gr, pixels = rdf(\n",
    "    seg,\n",
    "    fluor_img,\n",
    "    cell_indices=np.arange(100),\n",
    "    ref_point_val=[\"max\", 1],\n",
    "    dr=1,\n",
    "    intensity_weighted=True,\n",
    "    savetxt=None,\n",
    ")\n",
    "int_rdf = []\n",
    "int_rdf_volfactor = []\n",
    "\n",
    "for i, cell in enumerate(pixels):\n",
    "    print(i)\n",
    "    int_rdf.append(np.trapz(gr[i], x=r[i]))\n",
    "    sum_gr.append(np.sum(gr[i]))\n",
    "    int_rdf_volfactor.append(np.trapz(gr[i] * np.pi * (2 * np.array(r[i]) + 1), x=r[i]))\n",
    "\n",
    "values = [int_rdf, int_rdf_volfactor, pixels]\n",
    "names = [\"int_rdf\", \"int_rdf_volfactor\", \"pixels\"]\n",
    "\n",
    "combs = itertools.combinations([0, 1, 2], 2)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
    "ax = axes.ravel()\n",
    "for i, comb in enumerate(combs):\n",
    "    ax[i].scatter(values[comb[0]], values[comb[1]])\n",
    "    ax[i].set_xlabel(names[comb[0]])\n",
    "    ax[i].set_ylabel(names[comb[1]])\n",
    "\n",
    "fig.savefig(\"20200731/integralrdf_sfGFP100xfov20_100cellsref1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg[700:850, 425:575])\n",
    "print(np.amax(seg[700:850, 425:575]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf(seg[700:850,425:575], test_image, ref_point_val = 'max', cell_indices=[20], time_allowed=80,\n",
    "#         savetxt='20200714',start_r=1,dr=1, intensity_weighted = True)\n",
    "%run Testcreator.ipynb\n",
    "name = \"randomblobs\"\n",
    "\n",
    "autocorr(\n",
    "    np.genfromtxt(\"cellmask\"),\n",
    "    test_image,\n",
    "    cell_indices=[20],\n",
    "    time_allowed=80,\n",
    "    savetxt=\"20200714/gr_as_Y/autocorr_\" + name,\n",
    "    ref_point_val=\"max\",\n",
    "    r_values=None,\n",
    "    gr_values=None,\n",
    "    intensity_weighted=True,\n",
    "    start_r=1,\n",
    "    dr=1,\n",
    "    rdfsavetxt=\"20200714/gr_as_Y/rdf_\" + name,\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(test_image.data)\n",
    "ax[0].set_title(\"fluor_img\")\n",
    "\n",
    "ax[1].imshow(np.ma.masked_where(seg[700:850, 425:575] == 0, test_image))\n",
    "ax[1].set_title(\"segmented\")\n",
    "\n",
    "plot_gr_from_file(\n",
    "    \"20200714/gr_as_Y/autocorr_\" + name, 1, savefig=None, line=[0], ax=ax[2]\n",
    ")\n",
    "ax[2].set_title(\"autocorr\")\n",
    "\n",
    "plot_gr_from_file(\"20200714/gr_as_Y/rdf_\" + name, 1, savefig=None, line=[1], ax=ax[3])\n",
    "ax[3].set_title(\"rdf\")\n",
    "\n",
    "fig.suptitle(name, fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"20200714/gr_as_Y/plots_\" + name, y=1)\n",
    "np.savetxt(\"cellmask\", seg[700:850, 425:575])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals, autocorr = autocorr(\n",
    "    seg,\n",
    "    fluor_img,\n",
    "    cell_indices=\"all\",\n",
    "    time_allowed=80,\n",
    "    savetxt=\"20200713autocorr\",\n",
    "    ref_point_val=\"max\",\n",
    "    r_values=None,\n",
    "    gr_values=None,\n",
    "    intensity_weighted=True,\n",
    "    start_r=1,\n",
    "    dr=1,\n",
    "    rdfsavetxt=\"20200713autocorrrdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gr_from_file(\"20200713autocorr\", 1, savefig=\"20200713autocorr\", line_1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grs from file\n",
    "# fig,axes = plt.subplots(2,2,figsize=(20,20))\n",
    "# ax = axes.ravel()\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    ")\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue_foci\",\n",
    "    indices_to_plot=[1, 2, 11, 25, 27, 28, 33, 52],\n",
    "    legend=True,\n",
    "    title=\"Foci\",\n",
    ")\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue_maybefoci\",\n",
    "    indices_to_plot=[5, 8, 14, 20, 22, 30, 32, 40, 55],\n",
    "    legend=True,\n",
    "    title=\"Maybe foci\",\n",
    ")\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue_nofoci\",\n",
    "    indices_to_plot=[0, 3, 4, 6, 9, 13, 23, 29, 31, 36, 37, 44, 51, 58],\n",
    "    legend=True,\n",
    "    title=\"No foci\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rough_sqrt = int(np.ceil(np.sqrt(62)))\n",
    "fig, axes = plt.subplots(rough_sqrt, rough_sqrt, figsize=(25, 25))\n",
    "ax = axes.ravel()\n",
    "i = 0\n",
    "for cell_index in range(62):\n",
    "    cell_indices = np.where(seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(seg != cell_index + 1, fluor_img)\n",
    "    #     fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax[i].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[i].set_title(cell_index)\n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"20200626/sfGFP_100x_fov20/cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check:\n",
    "#     single point vs gradual gradient (i.e. size of the blob)\n",
    "#     gradient of the intensity of the blob (i.e. one clear blob and no background or more diffuse blob)\n",
    "#     different cell shape\n",
    "#     position of blob within cell\n",
    "#     intensity of the blob vs background of cell\n",
    "# Test on 2d Gaussian and hat function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
