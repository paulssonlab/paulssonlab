{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "from cytoolz import compose\n",
    "import skimage\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from paulssonlab.projects.molecule_counting.segmentation import segment, invert\n",
    "from paulssonlab.projects.molecule_counting.matriarch_stub import permute_labels\n",
    "import itertools\n",
    "import os.path\n",
    "from os import path\n",
    "import itertools\n",
    "\n",
    "# import cv2\n",
    "from matplotlib.offsetbox import TextArea, DrawingArea, OffsetImage, AnnotationBbox\n",
    "import signal\n",
    "import time\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_phase = compose(segment, invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up timers so that functions timeout and move on if something is weird and they don't run properly.\n",
    "# Should diagnose this issue properly eventually, but for testing this should be ok.\n",
    "class TimeoutException(Exception):  # Custom exception class\n",
    "    pass\n",
    "\n",
    "\n",
    "def timeout_handler(signum, frame):  # Custom signal handler\n",
    "    raise TimeoutException\n",
    "\n",
    "\n",
    "# Change the behavior of SIGALRM\n",
    "signal.signal(signal.SIGALRM, timeout_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = glob.glob(\"/n/scratch2/jqs1/200228/*.nd2\") + glob.glob(\n",
    "#     \"/n/scratch2/jqs1/200305/*.nd2\")\n",
    "\n",
    "filenames = glob.glob(\"/n/scratch3/users/j/jqs1/200228/*.nd2\") + glob.glob(\n",
    "    \"/n/scratch3/users/j/jqs1/200305/*.nd2\"\n",
    ")\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    print(i, filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filenames[15]\n",
    "print(\"file\", file)\n",
    "nd2 = nd2reader.ND2Reader(file)\n",
    "fov_index = 0\n",
    "phase_img = nd2.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "fluor_img = nd2.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "# phase_img = nd2.get_frame_2D(v=0, c=0, z=0)[1100:3000,500:2250]\n",
    "# fluor_img = nd2.get_frame_2D(v=0, c=1, z=0)[1100:3000,500:2250]\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(phase_img)\n",
    "ax[1].imshow(fluor_img, cmap=\"RdGy\")\n",
    "# seg = segment_phase(phase_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = segment_phase(phase_img)\n",
    "fig, ax = plt.subplots()\n",
    "# ax.imshow(seg)\n",
    "ax.imshow(permute_labels(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_in_r(ref_indices, r):\n",
    "    # ref_indices is a list of the indices that define the location of the reference point.\n",
    "    # r is the radius within which we want to collect indices.\n",
    "    ranges = np.arange(np.floor(-r), np.ceil(r) + 1)\n",
    "    rel_points = np.where(\n",
    "        (ranges[np.newaxis, :]) ** 2 + (ranges[:, np.newaxis]) ** 2 < r**2\n",
    "    )\n",
    "    points = [\n",
    "        rel_points[0] + ref_indices[0] - np.ceil(r),\n",
    "        rel_points[1] + ref_indices[1] - np.ceil(r),\n",
    "    ]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf_single_ref_point_single_cell(cell, ref_point, time_allowed=80, start_r=1, dr=1):\n",
    "    #     returns rdf for a single reference point in a single cell.\n",
    "    #     cell is a masked array, where the mask is False where the cell is, and True everywhere else.\n",
    "    #     cell.data is the fluorescence intensity array.\n",
    "    #     ref_point is a tuple of 2 arrays, corresponding to the indices of the location of the 'nucleus'\n",
    "    # rho is the average 'particle' density, where a particle corresponds to an intensity unit.\n",
    "    rho = np.mean(cell)\n",
    "    r = start_r\n",
    "    r_values = []\n",
    "    #         masked_norm_fluor_img.mask is False where the cell is, and True outside.\n",
    "    #         mask = np.copy(cell.mask)\n",
    "    gr_values = []\n",
    "    previous_r_vol = 0\n",
    "    while np.count_nonzero(cell.mask == 0) > 0:\n",
    "        #         print('points remaining',np.count_nonzero(cell.mask==0))\n",
    "        #             While the cell mask still has 'False' values i.e. not all values have been used in the\n",
    "        #             pair correlation function calculation somewhere.\n",
    "        #             Get indices of the points within the current radius (r) of the ref point.\n",
    "        indices_in_r = get_indices_in_r(ref_point, r)\n",
    "        flat_indices_in_r = [item for sublist in indices_in_r for item in sublist]\n",
    "        img_shape = np.shape(cell)\n",
    "        #         Remove indices pairs which fall outside the image.\n",
    "        if any(flat_indices_in_r >= np.min(img_shape)):\n",
    "            indices_to_delete_0 = np.where(indices_in_r[0] >= img_shape[0])[0]\n",
    "            indices_to_delete_1 = np.where(indices_in_r[1] >= img_shape[1])[0]\n",
    "            indices_to_delete = np.concatenate(\n",
    "                (indices_to_delete_0, indices_to_delete_1)\n",
    "            )\n",
    "            indices_to_delete = np.unique(indices_to_delete)\n",
    "            indices_in_r[0] = np.delete(indices_in_r[0], indices_to_delete)\n",
    "            indices_in_r[1] = np.delete(indices_in_r[1], indices_to_delete)\n",
    "        # Calculate numerator (gr_num) and volume element (gr_vol)\n",
    "        # gr_num should be the sum total of intensities of points in the current shell.\n",
    "        #             Since the cell is masked, we don't need to worry about the non-cell regions.\n",
    "        gr_num = np.sum(\n",
    "            cell[list(map(int, indices_in_r[0])), list(map(int, indices_in_r[1]))]\n",
    "        )\n",
    "        #         print('grnum',gr_num)\n",
    "        # gr_vol should be the number of points in the current shell.\n",
    "        #             Note that the mask masks both the background and the previous regions that we have considered,\n",
    "        #             so we simply subtract these from our list of indices in the current radius.\n",
    "        gr_vol = len(indices_in_r[0]) - np.count_nonzero(\n",
    "            cell.mask[list(map(int, indices_in_r[0])), list(map(int, indices_in_r[1]))]\n",
    "        )\n",
    "        #         print('gr vol',gr_vol)\n",
    "        #             update the 'previous_r_vol' for the next radius shell.\n",
    "        previous_r_vol = gr_vol\n",
    "        #             Update the cell mask so that the values we have now included are not included\n",
    "        #             in the next dr calculation.\n",
    "        cell.mask[\n",
    "            list(map(int, indices_in_r[0])), list(map(int, indices_in_r[1]))\n",
    "        ] = True\n",
    "        #             print('number of non masked values',np.count_nonzero(cell.mask==0))\n",
    "        gr_values.append(gr_num / gr_vol)\n",
    "        r_values.append(r)\n",
    "        r += dr\n",
    "    # Since rho is constant for all r, divide all at the same time to save on number of computations.\n",
    "    gr_values = np.array(gr_values)\n",
    "    gr_values = np.divide(gr_values, rho)\n",
    "    return r_values, gr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf_multi_ref_point_single_cell(\n",
    "    cell, ref_points, time_allowed=80, start_r=1, dr=1, intensity_weighted=True\n",
    "):\n",
    "    #     cell is a masked array, where the mask is False where the cell is, and True everywhere else.\n",
    "    #     returns r_values, gr_values for one cell, where gr_values is the average gr over the\n",
    "    #     ref_points.\n",
    "    #     ref_points should be a tuple of 2 arrays, where the first array is the axis 0\n",
    "    #     indices, and second array is the axis 1 indices, as we would get from np.where\n",
    "    max_r_values = []\n",
    "    all_gr_values = []\n",
    "    if intensity_weighted:\n",
    "        total_ref_point_intensity = np.sum(\n",
    "            cell[list(map(int, ref_points[0])), list(map(int, ref_points[1]))]\n",
    "        )\n",
    "        num_ref_points = len(ref_points[0])\n",
    "    #         total_cell_intensity = np.sum(cell)\n",
    "    #         pixels_in_cell = np.count_nonzero(cell.mask == 0)\n",
    "    for i in range(len(ref_points[0])):\n",
    "        cell_for_analysis = np.ma.copy(cell)\n",
    "        ref_point_0, ref_point_1 = ref_points[0][i], ref_points[1][i]\n",
    "        r_values, gr_values = rdf_single_ref_point_single_cell(\n",
    "            cell_for_analysis,\n",
    "            (np.array(ref_point_0), np.array(ref_point_1)),\n",
    "            time_allowed=80,\n",
    "            start_r=start_r,\n",
    "            dr=dr,\n",
    "        )\n",
    "        if intensity_weighted:\n",
    "            gr_values *= cell.data[ref_point_0][ref_point_1]\n",
    "        if len(r_values) > len(max_r_values):\n",
    "            max_r_values = r_values\n",
    "        all_gr_values.append(gr_values)\n",
    "    gr_values_length_corrected = list(\n",
    "        itertools.zip_longest(*all_gr_values, fillvalue=np.nan)\n",
    "    )\n",
    "    mean_gr_values = [np.nanmean(i) for i in gr_values_length_corrected]\n",
    "    if intensity_weighted:\n",
    "        #         mean_gr_values = np.multiply(pixels_in_cell,mean_gr_values/total_cell_intensity)\n",
    "        mean_gr_values = np.multiply(\n",
    "            num_ref_points, mean_gr_values / total_ref_point_intensity\n",
    "        )\n",
    "    return max_r_values, mean_gr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf(\n",
    "    seg,\n",
    "    fluor_img,\n",
    "    ref_point_val=\"max\",\n",
    "    cell_indices=[0],\n",
    "    time_allowed=80,\n",
    "    savetxt=\"rdf\",\n",
    "    start_r=1,\n",
    "    dr=1,\n",
    "    intensity_weighted=True,\n",
    "):\n",
    "    # Seg is the segmentation array.\n",
    "    #     Get the background fluorescence of the image, to subtract from all cell fluorescence.\n",
    "    min_fluor = np.amin(fluor_img)\n",
    "    # Get number of cells in the image.\n",
    "    cells = np.amax(seg)\n",
    "    if cell_indices == \"all\":\n",
    "        cell_indices = np.arange(cells)\n",
    "    # all_r_values will be a list of lists of r values, while all_gr_values will be a list of lists, with\n",
    "    # the corresponding g(r) (pair correlation function) values. The overall function will return\n",
    "    # all_r_values, all_gr_values.\n",
    "    all_r_values = []\n",
    "    all_gr_values = []\n",
    "    for cell_index in cell_indices:\n",
    "        print(\"cell index\", cell_index)\n",
    "        if cell_index > cells:\n",
    "            print(\"Error in rdf: cell_index larger than number of cells in fov.\")\n",
    "            pass\n",
    "        #         Mask the fluorescence image everywhere except for the cell.\n",
    "        cell = np.ma.masked_where(seg != cell_index + 1, fluor_img)\n",
    "        # Normalise the intensities of the cell. The mean_int_cell isn't needed since everything gets normalised\n",
    "        #         wrt total cell intensity anyway.\n",
    "        #         mean_int_cell = np.mean(cell)\n",
    "        cell -= min_fluor\n",
    "        #         ref_point is the 'nucleus' i.e. the point relative to which the pair\n",
    "        #         correlation function is to be calculated. For now, we set it to the\n",
    "        #         maximum fluorescence intensity point of the cell.\n",
    "        if ref_point_val == \"max\":\n",
    "            ref_point = np.ma.where(cell == np.amax(cell))\n",
    "            #         If there is more than one maximum fluorescence point, take the first one of these.\n",
    "            if len(ref_point[0]) > 1:\n",
    "                ref_point = (np.array([ref_point[0][0]]), np.array([ref_point[1][0]]))\n",
    "        elif ref_point_val == \"all\":\n",
    "            ref_point = np.where(cell.mask == 0)\n",
    "        elif ref_point_val[0] == \"sample\":\n",
    "            points_in_cell = np.where(cell.mask == 0)\n",
    "            ref_point = (\n",
    "                points_in_cell[0][:: ref_point_val[1]],\n",
    "                points_in_cell[1][:: ref_point_val[1]],\n",
    "            )\n",
    "        elif (\n",
    "            ref_point_val[0] == \"max\"\n",
    "        ):  # ref_point_val=['max',10] to take mean of 10 most intense pixels\n",
    "            cell_for_maxs = np.ma.copy(cell)\n",
    "            ref_point = [[], []]\n",
    "            for i in range(ref_point_val[1]):\n",
    "                current_max = np.ma.where(cell_for_maxs == np.amax(cell_for_maxs))\n",
    "                cell_for_maxs.mask[current_max] = 1\n",
    "                ref_point[0].append(current_max[0][0])\n",
    "                ref_point[1].append(current_max[1][0])\n",
    "            ref_point = np.array(ref_point)\n",
    "        else:\n",
    "            ref_point = ref_point_val\n",
    "        r_values, gr_values = rdf_multi_ref_point_single_cell(\n",
    "            cell,\n",
    "            ref_point,\n",
    "            time_allowed=80,\n",
    "            start_r=start_r,\n",
    "            dr=dr,\n",
    "            intensity_weighted=intensity_weighted,\n",
    "        )\n",
    "        all_gr_values.append(gr_values)\n",
    "        all_r_values.append(r_values)\n",
    "    if savetxt:\n",
    "        all_r_to_save = np.concatenate(all_r_values).ravel()\n",
    "        all_gr_to_save = np.concatenate(all_gr_values).ravel()\n",
    "        np.savetxt(savetxt, np.transpose(np.array([all_r_to_save, all_gr_to_save])))\n",
    "    return all_r_values, all_gr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using seg as the fluor image, since this should return g(r) = 1 for all r.\n",
    "# Everything is 1 in this case\n",
    "# r_values_list, gr_values_list = rdf(seg,seg,cell_indices=np.arange(6),\n",
    "#                                     ref_point_val=['sample',10],dr=10,\n",
    "#                                    intensity_weighted=True)\n",
    "# Everything is also 1 in this case\n",
    "# r_values_list, gr_values_list = rdf(seg,seg,cell_indices=np.arange(6),\n",
    "#                                     ref_point_val=['sample',10],dr=10,\n",
    "#                                    intensity_weighted=False)\n",
    "\n",
    "# print('20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue')\n",
    "# r,gr=rdf(seg,fluor_img,cell_indices='all',ref_point_val='max',dr=1,\n",
    "#                                    intensity_weighted=True,\n",
    "#                                    savetxt='20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue')\n",
    "\n",
    "# r,gr=rdf(seg,fluor_img,cell_indices='all',ref_point_val=['max',2],dr=1,\n",
    "#                                    intensity_weighted=True,\n",
    "#                                    savetxt='20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue')\n",
    "\n",
    "# print(r_values_list)\n",
    "# print(gr_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_funcvals_from_txt(filename, start_r):\n",
    "    # start_r is the start value of r in that dataset, so we can identify where each cell dataset starts.\n",
    "    values = np.genfromtxt(filename)\n",
    "    all_r_values = values[:, 0]\n",
    "    all_func_values = values[:, 1]\n",
    "    start_indices = np.where(all_r_values == start_r)[0]\n",
    "    r_values_list = []\n",
    "    func_values_list = []\n",
    "    for i, val in enumerate(start_indices):\n",
    "        if i != len(start_indices) - 1:\n",
    "            r_values_list.append(all_r_values[val : start_indices[i + 1]])\n",
    "            func_values_list.append(all_func_values[val : start_indices[i + 1]])\n",
    "        else:\n",
    "            r_values_list.append(all_r_values[val:])\n",
    "            func_values_list.append(all_func_values[val:])\n",
    "    return r_values_list, func_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot gr from file\n",
    "def plot_gr_from_file(\n",
    "    filename,\n",
    "    start_r,\n",
    "    ax=None,\n",
    "    savefig=None,\n",
    "    indices_to_plot=None,\n",
    "    legend=False,\n",
    "    title=None,\n",
    "    line=[1],\n",
    "):\n",
    "    r_values_list, gr_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots()\n",
    "    if not indices_to_plot:\n",
    "        indices_to_plot = np.arange(len(r_values_list))\n",
    "    for i in indices_to_plot:\n",
    "        ax.plot(r_values_list[i], gr_values_list[i])\n",
    "    if legend:\n",
    "        ax.legend([i for i in indices_to_plot])\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    if line:\n",
    "        for line_val in line:\n",
    "            ax.axhline(y=line_val, ls=\":\", color=\"k\")\n",
    "    if savefig:\n",
    "        fig.savefig(savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation function\n",
    "# Can do multiple cells in same image\n",
    "def autocorr(\n",
    "    seg,\n",
    "    fluor_img,\n",
    "    cell_indices=[0],\n",
    "    time_allowed=80,\n",
    "    savetxt=\"autocorr\",\n",
    "    ref_point_val=\"max\",\n",
    "    r_values=None,\n",
    "    gr_values=None,\n",
    "    intensity_weighted=True,\n",
    "    start_r=1,\n",
    "    dr=1,\n",
    "    rdfsavetxt=\"rdf\",\n",
    "):\n",
    "    if not r_values or not gr_values:\n",
    "        r_values, gr_values = rdf(\n",
    "            seg,\n",
    "            fluor_img,\n",
    "            ref_point_val=ref_point_val,\n",
    "            cell_indices=cell_indices,\n",
    "            time_allowed=80,\n",
    "            savetxt=rdfsavetxt,\n",
    "            start_r=start_r,\n",
    "            dr=dr,\n",
    "            intensity_weighted=intensity_weighted,\n",
    "        )\n",
    "    if cell_indices == \"all\":\n",
    "        cell_indices = np.arange(np.amax(seg))\n",
    "    for cell_index in cell_indices:\n",
    "        min_fluor = np.amin(fluor_img)\n",
    "        cell = np.ma.masked_where(seg != cell_index + 1, fluor_img)\n",
    "        cell -= min_fluor\n",
    "    all_auto_corr = []\n",
    "    all_k_values = []\n",
    "    for i, cell_index in enumerate(cell_indices):\n",
    "        r_vals = r_values[i]\n",
    "        gr_vals = gr_values[i]\n",
    "        gr_mean = np.mean(gr_values[i])\n",
    "        k_vals = np.arange(dr, r_vals[-1], dr)\n",
    "        all_k_values.append(k_vals)\n",
    "        auto_corr = []\n",
    "        denom = 0\n",
    "        for i in range(len(r_vals)):\n",
    "            denom += np.power(gr_vals[i] - gr_mean, 2)\n",
    "        for ki, k in enumerate(k_vals):\n",
    "            num = 0\n",
    "            contrib_to_num = 0\n",
    "            for i in k_vals[: len(k_vals) - ki]:\n",
    "                contrib_to_num += 1\n",
    "                num += (gr_vals[i - 1] - gr_mean) * (gr_vals[i + ki] - gr_mean)\n",
    "            num = num / contrib_to_num\n",
    "            auto_corr.append(num / denom)\n",
    "        all_auto_corr.append(auto_corr)\n",
    "    if savetxt:\n",
    "        all_r_to_save = np.concatenate(\n",
    "            np.array([r_vals[:-1] for r_vals in r_values])\n",
    "        ).ravel()\n",
    "        all_autocorr_to_save = np.concatenate(all_auto_corr).ravel()\n",
    "        np.savetxt(\n",
    "            savetxt, np.transpose(np.array([all_r_to_save, all_autocorr_to_save]))\n",
    "        )\n",
    "    return all_k_values, all_auto_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial gradient of rdf or autocorr might not be that good - if we have a random high intensity point,\n",
    "# it will very quickly drop since it's not a real blob, so this would increase the gradient artificially.\n",
    "# Instead, calculate area under curve before autocorr = 0 or rdf = 1.\n",
    "\n",
    "# def gradients(r_vals, func_vals, savetxt = 'gradients'):\n",
    "# # r_vals is a list of lists of r_values, and func_vals is a list of lists of function values\n",
    "#     all_gradient_vals = []\n",
    "#     for i,r_val_list in enumerate(r_vals):\n",
    "#         gradient_vals = np.gradient(func_vals[i], r_val_list)\n",
    "#         all_gradient_vals.append(gradient_vals)\n",
    "#     if savetxt:\n",
    "\n",
    "#     return all_gradient_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_under(\n",
    "    r_vals,\n",
    "    func_vals,\n",
    "    threshold,\n",
    "    as_frac_total=False,\n",
    "    shift=None,\n",
    "    below_thresh_zero=False,\n",
    "    as_frac_total_original=False,\n",
    "    total_area_above_thresh=False,\n",
    "):\n",
    "    #     threshold = area above the first crossing of which we want to integrate.\n",
    "    # as_frac_total = True means our output will be the above area divided by the total integral of the shifted function.\n",
    "    # shift = if we want to integrate RDF-1, then shift = 1\n",
    "    # below_thresh_zero = True means all values below the threshold (of the shifted function)\n",
    "    # will be set to 0 and so be ignore in the integration.\n",
    "    # as_frac_total_original = True means our output will be the above area divided\n",
    "    # by the total integral of the UNshifted function.\n",
    "    # total_area_above_thresh = True means instead of just integrating above the first cross,\n",
    "    # we integrate everything above the threshold.\n",
    "    func_vals_original = np.copy(func_vals)\n",
    "    if shift:\n",
    "        func_vals -= shift\n",
    "    if not total_area_above_thresh:\n",
    "        i = 0\n",
    "        while i < len(func_vals) and func_vals[i] > threshold:\n",
    "            i += 1\n",
    "        r_vals_thresh, func_vals_thresh = r_vals[:i], func_vals[:i]\n",
    "        area = np.trapz(func_vals_thresh, x=r_vals_thresh)\n",
    "    else:\n",
    "        f_vals = np.copy(func_vals)\n",
    "        for i, val in enumerate(f_vals):\n",
    "            if val < threshold:\n",
    "                f_vals[i] = 0\n",
    "        area = np.trapz(f_vals, x=r_vals)\n",
    "    if below_thresh_zero:\n",
    "        for i, val in enumerate(func_vals):\n",
    "            if val < threshold:\n",
    "                func_vals[i] = 0\n",
    "    if as_frac_total:\n",
    "        if as_frac_total_original:\n",
    "            total_int = np.trapz(func_vals_original, x=r_vals)\n",
    "        else:\n",
    "            total_int = np.trapz(func_vals, x=r_vals)\n",
    "        area /= total_int\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_under_from_file(\n",
    "    filename,\n",
    "    start_r,\n",
    "    threshold,\n",
    "    as_frac_total=False,\n",
    "    shift=None,\n",
    "    below_thresh_zero=False,\n",
    "    as_frac_total_original=False,\n",
    "    total_area_above_thresh=False,\n",
    "):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    area_under_list = []\n",
    "    for i in range(len(r_values_list)):\n",
    "        area_under_list.append(\n",
    "            area_under(\n",
    "                r_values_list[i],\n",
    "                func_values_list[i],\n",
    "                threshold,\n",
    "                as_frac_total=as_frac_total,\n",
    "                shift=shift,\n",
    "                below_thresh_zero=below_thresh_zero,\n",
    "                as_frac_total_original=as_frac_total_original,\n",
    "                total_area_above_thresh=total_area_above_thresh,\n",
    "            )\n",
    "        )\n",
    "    return area_under_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_threshold_cross(r_vals, func_vals, threshold, shift=None):\n",
    "    if shift:\n",
    "        func_vals -= shift\n",
    "    i = 0\n",
    "    while i < len(func_vals) and func_vals[i] > threshold:\n",
    "        i += 1\n",
    "    return r_vals[i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_threshold_cross_from_file(filename, start_r, threshold, shift=None):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    results_list = []\n",
    "    for i in range(len(r_values_list)):\n",
    "        results_list.append(\n",
    "            first_threshold_cross(\n",
    "                r_values_list[i], func_values_list[i], threshold, shift=shift\n",
    "            )\n",
    "        )\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_threshold_crosses(\n",
    "    r_vals, func_vals, threshold, shift=None, rel_to_length=False\n",
    "):\n",
    "    if shift:\n",
    "        func_vals -= shift\n",
    "    crosses_count = 0\n",
    "    for i in range(len(r_vals) - 1):\n",
    "        if func_vals[i] <= threshold and func_vals[i + 1] > threshold:\n",
    "            crosses_count += 1\n",
    "        elif func_vals[i] > threshold and func_vals[i + 1] <= threshold:\n",
    "            crosses_count += 1\n",
    "    if rel_to_length:\n",
    "        crosses_count /= len(r_vals)\n",
    "    return crosses_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_threshold_crosses_from_file(\n",
    "    filename, start_r, threshold, shift=None, rel_to_length=False\n",
    "):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    results_list = []\n",
    "    for i in range(len(r_values_list)):\n",
    "        results_list.append(\n",
    "            number_threshold_crosses(\n",
    "                r_values_list[i],\n",
    "                func_values_list[i],\n",
    "                threshold,\n",
    "                shift=shift,\n",
    "                rel_to_length=rel_to_length,\n",
    "            )\n",
    "        )\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_func_val(r_vals, func_vals):\n",
    "    inside = np.multiply(r_vals, func_vals)\n",
    "    expected_val = np.trapz(inside, x=r_vals)\n",
    "    norm_factor = np.trapz(func_vals, x=r_vals)\n",
    "    expected_val /= norm_factor\n",
    "    return expected_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_func_val_from_file(filename, start_r):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    expected_val_list = []\n",
    "    for i in range(len(r_values_list)):\n",
    "        expected_val_list.append(\n",
    "            expected_func_val(r_values_list[i], func_values_list[i])\n",
    "        )\n",
    "    return expected_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_func_from_file(filename, start_r, savetxt=None):\n",
    "    r_values_list, func_values_list = get_funcvals_from_txt(filename, start_r)\n",
    "    norm_func_values_list = []\n",
    "    for i, r_vals in enumerate(r_values_list):\n",
    "        norm_factor = np.trapz(func_values_list[i], x=r_vals)\n",
    "        norm_func_values_list.append(func_values_list[i] / norm_factor)\n",
    "    if savetxt:\n",
    "        all_r_to_save = np.concatenate(r_values_list).ravel()\n",
    "        all_norm_func_to_save = np.concatenate(norm_func_values_list).ravel()\n",
    "        np.savetxt(\n",
    "            savetxt, np.transpose(np.array([all_r_to_save, all_norm_func_to_save]))\n",
    "        )\n",
    "    return r_values_list, norm_func_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def smooth_func_data_from_file(filename, start_r, smooth_window):\n",
    "#     r_values_list, func_values_list = get_funcvals_from_txt(filename,start_r)\n",
    "#     for i,r_vals in enumerate(r_values_list):\n",
    "\n",
    "\n",
    "#     def moving_average(a, n=3) :\n",
    "#     ret = np.cumsum(a, dtype=float)\n",
    "#     ret[n:] = ret[n:] - ret[:-n]\n",
    "#     return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_analyse = [[14,\"chr_P_sfGFP_100x_ref10max\",20],[3,\"chr_P_GFPmut3_100x_ref10max\",50]]\n",
    "files_to_analyse = [\n",
    "    [16, \"chr_P_sfGFP_40x_ref5max\", 10],\n",
    "    [6, \"chr_P_GFPmut3_40x_ref5max\", 0],\n",
    "]\n",
    "# files_to_analyse = [[15,\"chr_P_sfGFP_20x_ref1max\",0],[4,\"chr_P_GFPmut3_20x_ref1max\",0]]\n",
    "calculate = False\n",
    "date_stamp_data = \"20200724\"\n",
    "date_stamp_output = \"20200725\"\n",
    "ref_points = 5\n",
    "cell_indices = np.arange(200)\n",
    "\n",
    "\n",
    "for file in files_to_analyse:\n",
    "    nd2 = nd2reader.ND2Reader(filenames[file[0]])\n",
    "    fov_index = file[-1]\n",
    "    name = file[1]\n",
    "    if not path.exists(date_stamp_data + \"/autocorr_\" + name) or calculate:\n",
    "        print(\"Calculating\")\n",
    "        phase_img = nd2.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "        fluor_img = nd2.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "        seg = segment_phase(phase_img)\n",
    "        autocorr(\n",
    "            seg,\n",
    "            fluor_img,\n",
    "            cell_indices=cell_indices,\n",
    "            time_allowed=80,\n",
    "            savetxt=date_stamp_output + \"/autocorr_\" + name,\n",
    "            ref_point_val=[\"max\", ref_points],\n",
    "            r_values=None,\n",
    "            gr_values=None,\n",
    "            intensity_weighted=True,\n",
    "            start_r=1,\n",
    "            dr=1,\n",
    "            rdfsavetxt=date_stamp_output + \"/rdf_\" + name,\n",
    "        )\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "    ax = axes.ravel()\n",
    "    plot_gr_from_file(\n",
    "        date_stamp_data + \"/rdf_\" + name, 1, savefig=None, line=[1], ax=ax[0]\n",
    "    )\n",
    "    ax[0].set_title(\"RDF\")\n",
    "\n",
    "    area_under_rdf = area_under_from_file(date_stamp_data + \"/rdf_\" + name, 1, 1)\n",
    "    ax[1].hist(area_under_rdf, bins=20, range=(0, 40))\n",
    "    ax[1].set_title(\"Integral RDF>1\")\n",
    "\n",
    "    area_under_rdf_frac = area_under_from_file(\n",
    "        date_stamp_data + \"/rdf_\" + name, 1, 1, as_frac_total=True\n",
    "    )\n",
    "    ax[2].hist(area_under_rdf_frac, bins=20, range=(0, 1))\n",
    "    ax[2].set_title(\"Integral RDF>1 as frac\")\n",
    "\n",
    "    expected_rdfs = expected_func_val_from_file(date_stamp_data + \"/rdf_\" + name, 1)\n",
    "    ax[3].hist(expected_rdfs, bins=20, range=(0, 40))\n",
    "    ax[3].set_title(\"Mean RDF\")\n",
    "\n",
    "    fig.suptitle(name + \" fov: \" + str(fov_index), fontsize=14, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(date_stamp_output + \"/plots_\" + name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_plots(files_to_analyse):\n",
    "    #     files_to_analyse is a list of lists.\n",
    "    # Each list contains the information about the file, in the order:\n",
    "    # [filename_index, base_filename, fov (rewrite in future to do multiple), date_stamp_data, date_stamp_output,\n",
    "    # ref_points, cell_indices, calculate (true if want to re-calculate, otherwise will check for existing data files)]\n",
    "    for file_details in files_to_analyse:\n",
    "        [\n",
    "            file_index,\n",
    "            name,\n",
    "            fov_index,\n",
    "            date_stamp_data,\n",
    "            date_stamp_output,\n",
    "            ref_points,\n",
    "            cell_indices,\n",
    "            calculate,\n",
    "        ] = file_details\n",
    "        nd2 = nd2reader.ND2Reader(filenames[file_index])\n",
    "        if not path.exists(date_stamp_data + \"/autocorr_\" + name) or calculate:\n",
    "            print(\"Calculating\")\n",
    "            phase_img = nd2.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "            fluor_img = nd2.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "            seg = segment_phase(phase_img)\n",
    "            autocorr(\n",
    "                seg,\n",
    "                fluor_img,\n",
    "                cell_indices=cell_indices,\n",
    "                time_allowed=80,\n",
    "                savetxt=date_stamp_output + \"/autocorr_\" + name,\n",
    "                ref_point_val=[\"max\", ref_points],\n",
    "                r_values=None,\n",
    "                gr_values=None,\n",
    "                intensity_weighted=True,\n",
    "                start_r=1,\n",
    "                dr=1,\n",
    "                rdfsavetxt=date_stamp_output + \"/rdf_\" + name,\n",
    "            )\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "        ax = axes.ravel()\n",
    "        plot_gr_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name, 1, savefig=None, line=[1], ax=ax[0]\n",
    "        )\n",
    "        ax[0].set_title(\"RDF\")\n",
    "\n",
    "        val_first_rdf_cross = first_threshold_cross_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name, 1, 0, shift=1\n",
    "        )\n",
    "        area_under_rdf_shift1_thresh0 = area_under_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name,\n",
    "            1,\n",
    "            0,\n",
    "            shift=1,\n",
    "            as_frac_total=False,\n",
    "            below_thresh_zero=False,\n",
    "        )\n",
    "        area_under_rdf_shift1_thresh0_as_frac_total = area_under_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name,\n",
    "            1,\n",
    "            0,\n",
    "            shift=1,\n",
    "            as_frac_total=True,\n",
    "            below_thresh_zero=True,\n",
    "            as_frac_total_original=True,\n",
    "        )\n",
    "        number_rdf_crosses = number_threshold_crosses_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name, 1, 0, shift=1, rel_to_length=True\n",
    "        )\n",
    "        total_area_under_rdf_shift1_thresh0_as_frac_total = area_under_from_file(\n",
    "            date_stamp_data + \"/rdf_\" + name,\n",
    "            1,\n",
    "            0,\n",
    "            shift=1,\n",
    "            as_frac_total=True,\n",
    "            below_thresh_zero=True,\n",
    "            as_frac_total_original=True,\n",
    "            total_area_above_thresh=True,\n",
    "        )\n",
    "\n",
    "        to_plot = [\n",
    "            [\"First RDF-1=0\", val_first_rdf_cross, 20],\n",
    "            [\"Initial integral RDF-1>0\", area_under_rdf_shift1_thresh0, 25],\n",
    "            [\n",
    "                \"Initial integral RDF-1>0 as frac total\",\n",
    "                area_under_rdf_shift1_thresh0_as_frac_total,\n",
    "                1,\n",
    "            ],\n",
    "            [\"RDF-1 fluctuation frequency\", number_rdf_crosses, 1],\n",
    "            [\n",
    "                \"Total integral RDF-1>0 as frac total\",\n",
    "                total_area_under_rdf_shift1_thresh0_as_frac_total,\n",
    "                1,\n",
    "            ],\n",
    "        ]\n",
    "\n",
    "        for i in np.arange(1, 6):\n",
    "            ax[i].hist(to_plot[i - 1][1], bins=20, range=(0, to_plot[i - 1][2]))\n",
    "            ax[i].set_title(to_plot[i - 1][0])\n",
    "\n",
    "        combs = itertools.combinations([0, 1, 2, 3, 4], 2)\n",
    "\n",
    "        for i, comb in enumerate(combs):\n",
    "            ax[i + 6].scatter(to_plot[comb[0]][1], to_plot[comb[1]][1])\n",
    "            ax[i + 6].set_xlabel(to_plot[comb[0]][0])\n",
    "            ax[i + 6].set_ylabel(to_plot[comb[1]][0])\n",
    "            ax[i + 6].set_xlim(0, to_plot[comb[0]][2])\n",
    "            ax[i + 6].set_ylim(0, to_plot[comb[1]][2])\n",
    "\n",
    "        fig.suptitle(name + \" fov: \" + str(fov_index), fontsize=14, y=1.05)\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(date_stamp_output + \"/plots_\" + name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_analyse = [[14,\"chr_P_sfGFP_100x_ref1max\",20,'20200724','20200725',\n",
    "#                     5,np.arange(200),False],\n",
    "#                     [3,\"chr_P_GFPmut3_100x_ref1max\",50,'20200724','20200725',\n",
    "#                     5,np.arange(200),False]]\n",
    "# files_to_analyse = [[16,\"chr_P_sfGFP_40x_ref1max\",10,'20200724','20200725',\n",
    "#                     5,np.arange(200),False],\n",
    "#                     [6,\"chr_P_GFPmut3_40x_ref1max\",0,'20200724','20200725',\n",
    "#                     5,np.arange(200),False]]\n",
    "files_to_analyse = [\n",
    "    [\n",
    "        15,\n",
    "        \"chr_P_sfGFP_20x_ref10max\",\n",
    "        0,\n",
    "        \"20200724\",\n",
    "        \"20200727\",\n",
    "        5,\n",
    "        np.arange(200),\n",
    "        False,\n",
    "    ],\n",
    "    [\n",
    "        4,\n",
    "        \"chr_P_GFPmut3_20x_ref10max\",\n",
    "        0,\n",
    "        \"20200724\",\n",
    "        \"20200727\",\n",
    "        5,\n",
    "        np.arange(200),\n",
    "        False,\n",
    "    ],\n",
    "]\n",
    "\n",
    "generate_analysis_plots(files_to_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_image(\n",
    "    size=(200, 200),\n",
    "    mask=None,\n",
    "    shapes=[[\"circle\", [100, 100], 10, 100]],\n",
    "    savename=\"test\",\n",
    "    background=None,\n",
    "    cell_background=None,\n",
    "):\n",
    "    # shape = ['rings'=concentric circles, 'circle'=circle, 'gaussian'=2d gaussian]\n",
    "    # shape == 'circle': ['circle',centre position indices,radius,intensity]\n",
    "    # shape == 'rings': ['rings',centre position indices,\n",
    "    # radius of smallest circle, intensity, width of rings, distance between rings]\n",
    "    # shape == 'gaussian': ['gaussian', centre position indices, stdevs, intensity] (mean = position)\n",
    "    # mask should be False where the cell is.\n",
    "    if not background:\n",
    "        image = np.zeros(size)\n",
    "    elif background[0] == \"gaussian\":\n",
    "        mean, stdev = background[1:]\n",
    "        image = np.random.normal(loc=mean, scale=stdev, size=size)\n",
    "    if np.size(mask) > 1:\n",
    "        image = np.ma.array(image, mask=mask)\n",
    "        if cell_background:\n",
    "            if cell_background[0] == \"gaussian\":\n",
    "                mean, stdev = cell_background[1:]\n",
    "                cell_noise = np.random.normal(loc=mean, scale=stdev, size=size)\n",
    "                image += cell_noise\n",
    "    for shape in shapes:\n",
    "        if shape[0] == \"circle\" or shape[0] == \"rings\":\n",
    "            image_to_add = np.zeros(size)\n",
    "            position, r, intensity = shape[1:]\n",
    "            ranges = np.arange(np.floor(-r), np.ceil(r) + 1)\n",
    "            rel_points = np.where(\n",
    "                (ranges[np.newaxis, :]) ** 2 + (ranges[:, np.newaxis]) ** 2 < r**2\n",
    "            )\n",
    "            points = [\n",
    "                rel_points[0] + position[0] - np.ceil(r),\n",
    "                rel_points[1] + position[1] - np.ceil(r),\n",
    "            ]\n",
    "            image_to_add[\n",
    "                list(map(int, points[0])), list(map(int, points[1]))\n",
    "            ] = intensity\n",
    "        #         if shape[0] == 'rings':\n",
    "\n",
    "        elif shape[0] == \"gaussian\":\n",
    "            position, stdevs, intensity = shape[1:]\n",
    "            vals0, vals1 = np.meshgrid(np.arange(size[0]), np.arange(size[1]))\n",
    "            image_to_add = np.exp(\n",
    "                -(\n",
    "                    (vals0 - position[0]) ** 2 / (2 * stdevs[0]) ** 2\n",
    "                    + (vals1 - position[1]) ** 2 / (2 * stdevs[1]) ** 2\n",
    "                )\n",
    "            )\n",
    "            image_to_add *= intensity\n",
    "        image += image_to_add\n",
    "    if savename:\n",
    "        np.savetxt(savename, image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filenames[14]\n",
    "print(\"file\", file)\n",
    "nd2 = nd2reader.ND2Reader(file)\n",
    "fov_index = 20\n",
    "phase_img = nd2.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "fluor_img = nd2.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "# phase_img = nd2.get_frame_2D(v=0, c=0, z=0)[1100:3000,500:2250]\n",
    "# fluor_img = nd2.get_frame_2D(v=0, c=1, z=0)[1100:3000,500:2250]\n",
    "fig, axes = plt.subplots(1, 5, sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(phase_img)\n",
    "ax[1].imshow(fluor_img, cmap=\"RdGy\")\n",
    "seg = segment_phase(phase_img)\n",
    "ax[2].imshow(seg)\n",
    "ax[3].imshow(seg[700:850, 425:575])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.genfromtxt(\"cellmask\")\n",
    "mask = np.ma.masked_array(mask, np.logical_not(mask)).mask\n",
    "ax[4].imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now determine the values of these metrics in different test cases, to check that we get values that correspond\n",
    "# with what we expect by eye.\n",
    "\n",
    "# Test intensities (how high above background noise) and stdevs (how diffuse) of centred blobs. Then repeat for\n",
    "# blobs near the edge.\n",
    "\n",
    "# Looks weird? Why is initial int the opposite of initial int as frac? Check the zero_below_thresh etc to be\n",
    "# certain about what these are computing.\n",
    "\n",
    "base_name = \"20200727/refpoint1_nonoise/refpoint1_nonoise\"\n",
    "\n",
    "val_first_rdf_cross = []\n",
    "area_under_rdf_shift1_thresh0 = []\n",
    "area_under_rdf_shift1_thresh0_as_frac_total = []\n",
    "number_rdf_crosses = []\n",
    "total_area_under_rdf_shift1_thresh0_as_frac_total = []\n",
    "\n",
    "intensities = np.linspace(1, 500, 20)\n",
    "stdevs = np.linspace(0.5, 3, 20)\n",
    "\n",
    "for intensity in intensities:\n",
    "    val_first_rdf_cross_toadd = []\n",
    "    area_under_rdf_shift1_thresh0_toadd = []\n",
    "    area_under_rdf_shift1_thresh0_as_frac_total_toadd = []\n",
    "    number_rdf_crosses_toadd = []\n",
    "    total_area_under_rdf_shift1_thresh0_as_frac_total_toadd = []\n",
    "    for stdev in stdevs:\n",
    "        test_image = generate_test_image(\n",
    "            size=(150, 150),\n",
    "            shapes=[[\"gaussian\", [70, 70], [stdev, stdev], intensity]],\n",
    "            background=None,\n",
    "            savename=None,\n",
    "            mask=mask,\n",
    "            cell_background=None,\n",
    "        )\n",
    "        #         autocorr(np.genfromtxt('cellmask'), test_image, cell_indices=[20], time_allowed=80,\n",
    "        #         savetxt=None,ref_point_val = ['max',10],r_values = None,\n",
    "        #             gr_values = None, intensity_weighted = True,start_r=1,dr=1,\n",
    "        #             rdfsavetxt=None)\n",
    "        r_vals, gr_vals = rdf(\n",
    "            np.genfromtxt(\"cellmask\"),\n",
    "            test_image,\n",
    "            ref_point_val=[\"max\", 1],\n",
    "            cell_indices=[20],\n",
    "            time_allowed=80,\n",
    "            savetxt=None,\n",
    "            start_r=1,\n",
    "            dr=1,\n",
    "            intensity_weighted=True,\n",
    "        )\n",
    "        r_vals, gr_vals = np.array(r_vals[0]), np.array(gr_vals[0])\n",
    "        val_first_rdf_cross_toadd.append(\n",
    "            first_threshold_cross(r_vals, gr_vals, 0, shift=1)\n",
    "        )\n",
    "        area_under_rdf_shift1_thresh0_toadd.append(\n",
    "            area_under(\n",
    "                r_vals,\n",
    "                gr_vals,\n",
    "                0,\n",
    "                shift=1,\n",
    "                as_frac_total=False,\n",
    "                below_thresh_zero=False,\n",
    "            )\n",
    "        )\n",
    "        area_under_rdf_shift1_thresh0_as_frac_total_toadd.append(\n",
    "            area_under(\n",
    "                r_vals,\n",
    "                gr_vals,\n",
    "                0,\n",
    "                shift=1,\n",
    "                as_frac_total=True,\n",
    "                below_thresh_zero=True,\n",
    "                as_frac_total_original=True,\n",
    "            )\n",
    "        )\n",
    "        number_rdf_crosses_toadd.append(\n",
    "            number_threshold_crosses(r_vals, gr_vals, 0, shift=1, rel_to_length=True)\n",
    "        )\n",
    "        total_area_under_rdf_shift1_thresh0_as_frac_total_toadd.append(\n",
    "            area_under(\n",
    "                r_vals,\n",
    "                gr_vals,\n",
    "                0,\n",
    "                shift=1,\n",
    "                as_frac_total=True,\n",
    "                below_thresh_zero=True,\n",
    "                as_frac_total_original=True,\n",
    "                total_area_above_thresh=True,\n",
    "            )\n",
    "        )\n",
    "    val_first_rdf_cross.append(val_first_rdf_cross_toadd)\n",
    "    area_under_rdf_shift1_thresh0.append(area_under_rdf_shift1_thresh0_toadd)\n",
    "    area_under_rdf_shift1_thresh0_as_frac_total.append(\n",
    "        area_under_rdf_shift1_thresh0_as_frac_total_toadd\n",
    "    )\n",
    "    number_rdf_crosses.append(number_rdf_crosses_toadd)\n",
    "    total_area_under_rdf_shift1_thresh0_as_frac_total.append(\n",
    "        total_area_under_rdf_shift1_thresh0_as_frac_total_toadd\n",
    "    )\n",
    "\n",
    "np.savetxt(base_name + \"_intensities\", intensities)\n",
    "np.savetxt(base_name + \"_stdevs\", stdevs)\n",
    "np.savetxt(base_name + \"_firstrdfcross\", val_first_rdf_cross)\n",
    "np.savetxt(base_name + \"_initialintegral\", area_under_rdf_shift1_thresh0)\n",
    "np.savetxt(\n",
    "    base_name + \"_initialintegralasfrac\", area_under_rdf_shift1_thresh0_as_frac_total\n",
    ")\n",
    "np.savetxt(base_name + \"_rdfcrosses\", number_rdf_crosses)\n",
    "np.savetxt(\n",
    "    base_name + \"_totalintegral\", total_area_under_rdf_shift1_thresh0_as_frac_total\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(9, 6))\n",
    "ax = axes.ravel()\n",
    "ax[0].pcolormesh(stdevs, intensities, val_first_rdf_cross)\n",
    "ax[0].set_title(\"First RDF-1=0\")\n",
    "ax[1].pcolormesh(stdevs, intensities, area_under_rdf_shift1_thresh0)\n",
    "ax[1].set_title(\"Initial integral RDF-1>0\")\n",
    "ax[2].pcolormesh(stdevs, intensities, area_under_rdf_shift1_thresh0_as_frac_total)\n",
    "ax[2].set_title(\"Initial integral RDF-1>0 as frac total\")\n",
    "ax[3].pcolormesh(stdevs, intensities, number_rdf_crosses)\n",
    "ax[3].set_title(\"Frequency RDF-1=0\")\n",
    "ax[4].pcolormesh(stdevs, intensities, total_area_under_rdf_shift1_thresh0_as_frac_total)\n",
    "ax[4].set_title(\"Total integral RDF-1>0\")\n",
    "for axis in ax:\n",
    "    axis.set_xlabel(\"Stdev\")\n",
    "    axis.set_ylabel(\"Intensity\")\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"refpoint1 no noise\", y=1.05, fontsize=14)\n",
    "fig.savefig(\"20200727/refpoint1_nonoise.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg[700:850, 425:575])\n",
    "print(np.amax(seg[700:850, 425:575]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf(seg[700:850,425:575], test_image, ref_point_val = 'max', cell_indices=[20], time_allowed=80,\n",
    "#         savetxt='20200714',start_r=1,dr=1, intensity_weighted = True)\n",
    "%run Testcreator.ipynb\n",
    "name = \"randomblobs\"\n",
    "\n",
    "autocorr(\n",
    "    np.genfromtxt(\"cellmask\"),\n",
    "    test_image,\n",
    "    cell_indices=[20],\n",
    "    time_allowed=80,\n",
    "    savetxt=\"20200714/gr_as_Y/autocorr_\" + name,\n",
    "    ref_point_val=\"max\",\n",
    "    r_values=None,\n",
    "    gr_values=None,\n",
    "    intensity_weighted=True,\n",
    "    start_r=1,\n",
    "    dr=1,\n",
    "    rdfsavetxt=\"20200714/gr_as_Y/rdf_\" + name,\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(test_image.data)\n",
    "ax[0].set_title(\"fluor_img\")\n",
    "\n",
    "ax[1].imshow(np.ma.masked_where(seg[700:850, 425:575] == 0, test_image))\n",
    "ax[1].set_title(\"segmented\")\n",
    "\n",
    "plot_gr_from_file(\n",
    "    \"20200714/gr_as_Y/autocorr_\" + name, 1, savefig=None, line=[0], ax=ax[2]\n",
    ")\n",
    "ax[2].set_title(\"autocorr\")\n",
    "\n",
    "plot_gr_from_file(\"20200714/gr_as_Y/rdf_\" + name, 1, savefig=None, line=[1], ax=ax[3])\n",
    "ax[3].set_title(\"rdf\")\n",
    "\n",
    "fig.suptitle(name, fontsize=14, y=1.05)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"20200714/gr_as_Y/plots_\" + name, y=1)\n",
    "np.savetxt(\"cellmask\", seg[700:850, 425:575])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals, autocorr = autocorr(\n",
    "    seg,\n",
    "    fluor_img,\n",
    "    cell_indices=\"all\",\n",
    "    time_allowed=80,\n",
    "    savetxt=\"20200713autocorr\",\n",
    "    ref_point_val=\"max\",\n",
    "    r_values=None,\n",
    "    gr_values=None,\n",
    "    intensity_weighted=True,\n",
    "    start_r=1,\n",
    "    dr=1,\n",
    "    rdfsavetxt=\"20200713autocorrrdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gr_from_file(\"20200713autocorr\", 1, savefig=\"20200713autocorr\", line_1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grs from file\n",
    "# fig,axes = plt.subplots(2,2,figsize=(20,20))\n",
    "# ax = axes.ravel()\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    ")\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue_foci\",\n",
    "    indices_to_plot=[1, 2, 11, 25, 27, 28, 33, 52],\n",
    "    legend=True,\n",
    "    title=\"Foci\",\n",
    ")\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue_maybefoci\",\n",
    "    indices_to_plot=[5, 8, 14, 20, 22, 30, 32, 40, 55],\n",
    "    legend=True,\n",
    "    title=\"Maybe foci\",\n",
    ")\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue_nofoci\",\n",
    "    indices_to_plot=[0, 3, 4, 6, 9, 13, 23, 29, 31, 36, 37, 44, 51, 58],\n",
    "    legend=True,\n",
    "    title=\"No foci\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rough_sqrt = int(np.ceil(np.sqrt(62)))\n",
    "fig, axes = plt.subplots(rough_sqrt, rough_sqrt, figsize=(25, 25))\n",
    "ax = axes.ravel()\n",
    "i = 0\n",
    "for cell_index in range(62):\n",
    "    cell_indices = np.where(seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(seg != cell_index + 1, fluor_img)\n",
    "    #     fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax[i].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[i].set_title(cell_index)\n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"20200626/sfGFP_100x_fov20/cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check:\n",
    "#     single point vs gradual gradient (i.e. size of the blob)\n",
    "#     gradient of the intensity of the blob (i.e. one clear blob and no background or more diffuse blob)\n",
    "#     different cell shape\n",
    "#     position of blob within cell\n",
    "#     intensity of the blob vs background of cell\n",
    "# Test on 2d Gaussian and hat function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
