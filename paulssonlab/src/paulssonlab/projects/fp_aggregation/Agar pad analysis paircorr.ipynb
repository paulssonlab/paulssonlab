{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "from cytoolz import compose\n",
    "import skimage\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from paulssonlab.projects.molecule_counting.segmentation import segment, invert\n",
    "from paulssonlab.projects.molecule_counting.matriarch_stub import permute_labels\n",
    "import itertools\n",
    "\n",
    "# import cv2\n",
    "from matplotlib.offsetbox import TextArea, DrawingArea, OffsetImage, AnnotationBbox\n",
    "import signal\n",
    "import time\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_phase = compose(segment, invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up timers so that functions timeout and move on if something is weird and they don't run properly.\n",
    "# Should diagnose this issue properly eventually, but for testing this should be ok.\n",
    "class TimeoutException(Exception):  # Custom exception class\n",
    "    pass\n",
    "\n",
    "\n",
    "def timeout_handler(signum, frame):  # Custom signal handler\n",
    "    raise TimeoutException\n",
    "\n",
    "\n",
    "# Change the behavior of SIGALRM\n",
    "signal.signal(signal.SIGALRM, timeout_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"/n/scratch2/jqs1/200228/*.nd2\") + glob.glob(\n",
    "    \"/n/scratch2/jqs1/200305/*.nd2\"\n",
    ")\n",
    "for i in range(len(filenames)):\n",
    "    print(i, filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filenames[2]\n",
    "print(\"file\", file)\n",
    "nd2 = nd2reader.ND2Reader(file)\n",
    "fov_index = 20\n",
    "phase_img = nd2.get_frame_2D(v=0, c=0, z=fov_index)\n",
    "fluor_img = nd2.get_frame_2D(v=0, c=1, z=fov_index)\n",
    "# phase_img = nd2.get_frame_2D(v=0, c=0, z=0)[1100:3000,500:2250]\n",
    "# fluor_img = nd2.get_frame_2D(v=0, c=1, z=0)[1100:3000,500:2250]\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(phase_img)\n",
    "ax[1].imshow(fluor_img, cmap=\"RdGy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = segment_phase(phase_img)\n",
    "fig, ax = plt.subplots()\n",
    "# ax.imshow(seg)\n",
    "ax.imshow(permute_labels(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_in_r(ref_indices, r):\n",
    "    # ref_indices is a list of the indices that define the location of the reference point.\n",
    "    # r is the radius within which we want to collect indices.\n",
    "    ranges = np.arange(np.floor(-r), np.ceil(r) + 1)\n",
    "    rel_points = np.where(\n",
    "        (ranges[np.newaxis, :]) ** 2 + (ranges[:, np.newaxis]) ** 2 < r**2\n",
    "    )\n",
    "    points = [\n",
    "        rel_points[0] + ref_indices[0] - np.ceil(r),\n",
    "        rel_points[1] + ref_indices[1] - np.ceil(r),\n",
    "    ]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf_single_ref_point_single_cell(cell, ref_point, time_allowed=80, start_r=1, dr=1):\n",
    "    #     returns rdf for a single reference point in a single cell.\n",
    "    #     cell is a masked array, where the mask is False where the cell is, and True everywhere else.\n",
    "    #     cell.data is the fluorescence intensity array.\n",
    "    #     ref_point is a tuple of 2 arrays, corresponding to the indices of the location of the 'nucleus'\n",
    "    # rho is the average 'particle' density, where a particle corresponds to an intensity unit.\n",
    "    rho = np.mean(cell)\n",
    "    r = start_r\n",
    "    r_values = []\n",
    "    #         masked_norm_fluor_img.mask is False where the cell is, and True outside.\n",
    "    #         mask = np.copy(cell.mask)\n",
    "    gr_values = []\n",
    "    previous_r_vol = 0\n",
    "    while np.count_nonzero(cell.mask == 0) > 0:\n",
    "        #         print('points remaining',np.count_nonzero(cell.mask==0))\n",
    "        #             While the cell mask still has 'False' values i.e. not all values have been used in the\n",
    "        #             pair correlation function calculation somewhere.\n",
    "        #             Get indices of the points within the current radius (r) of the ref point.\n",
    "        indices_in_r = get_indices_in_r(ref_point, r)\n",
    "        flat_indices_in_r = [item for sublist in indices_in_r for item in sublist]\n",
    "        img_shape = np.shape(cell)\n",
    "        #         Remove indices pairs which fall outside the image.\n",
    "        if any(flat_indices_in_r >= np.min(img_shape)):\n",
    "            indices_to_delete_0 = np.where(indices_in_r[0] >= img_shape[0])[0]\n",
    "            indices_to_delete_1 = np.where(indices_in_r[1] >= img_shape[1])[0]\n",
    "            indices_to_delete = np.concatenate(\n",
    "                (indices_to_delete_0, indices_to_delete_1)\n",
    "            )\n",
    "            indices_to_delete = np.unique(indices_to_delete)\n",
    "            indices_in_r[0] = np.delete(indices_in_r[0], indices_to_delete)\n",
    "            indices_in_r[1] = np.delete(indices_in_r[1], indices_to_delete)\n",
    "        # Calculate numerator (gr_num) and volume element (gr_vol)\n",
    "        # gr_num should be the sum total of intensities of points in the current shell.\n",
    "        #             Since the cell is masked, we don't need to worry about the non-cell regions.\n",
    "        gr_num = np.sum(\n",
    "            cell[list(map(int, indices_in_r[0])), list(map(int, indices_in_r[1]))]\n",
    "        )\n",
    "        #         print('grnum',gr_num)\n",
    "        # gr_vol should be the number of points in the current shell.\n",
    "        #             Note that the mask masks both the background and the previous regions that we have considered,\n",
    "        #             so we simply subtract these from our list of indices in the current radius.\n",
    "        gr_vol = len(indices_in_r[0]) - np.count_nonzero(\n",
    "            cell.mask[list(map(int, indices_in_r[0])), list(map(int, indices_in_r[1]))]\n",
    "        )\n",
    "        #         print('gr vol',gr_vol)\n",
    "        #             update the 'previous_r_vol' for the next radius shell.\n",
    "        previous_r_vol = gr_vol\n",
    "        #             Update the cell mask so that the values we have now included are not included\n",
    "        #             in the next dr calculation.\n",
    "        cell.mask[\n",
    "            list(map(int, indices_in_r[0])), list(map(int, indices_in_r[1]))\n",
    "        ] = True\n",
    "        #             print('number of non masked values',np.count_nonzero(cell.mask==0))\n",
    "        gr_values.append(gr_num / gr_vol)\n",
    "        r_values.append(r)\n",
    "        r += dr\n",
    "    # Since rho is constant for all r, divide all at the same time to save on number of computations.\n",
    "    gr_values = np.array(gr_values)\n",
    "    gr_values = np.divide(gr_values, rho)\n",
    "    return r_values, gr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf_multi_ref_point_single_cell(\n",
    "    cell, ref_points, time_allowed=80, start_r=1, dr=1, intensity_weighted=True\n",
    "):\n",
    "    #     cell is a masked array, where the mask is False where the cell is, and True everywhere else.\n",
    "    #     returns r_values, gr_values for one cell, where gr_values is the average gr over the\n",
    "    #     ref_points.\n",
    "    #     ref_points should be a tuple of 2 arrays, where the first array is the axis 0\n",
    "    #     indices, and second array is the axis 1 indices, as we would get from np.where\n",
    "    max_r_values = []\n",
    "    all_gr_values = []\n",
    "    if intensity_weighted:\n",
    "        total_ref_point_intensity = np.sum(\n",
    "            cell[list(map(int, ref_points[0])), list(map(int, ref_points[1]))]\n",
    "        )\n",
    "        num_ref_points = len(ref_points[0])\n",
    "    #         total_cell_intensity = np.sum(cell)\n",
    "    #         pixels_in_cell = np.count_nonzero(cell.mask == 0)\n",
    "    for i in range(len(ref_points[0])):\n",
    "        cell_for_analysis = np.ma.copy(cell)\n",
    "        ref_point_0, ref_point_1 = ref_points[0][i], ref_points[1][i]\n",
    "        r_values, gr_values = rdf_single_ref_point_single_cell(\n",
    "            cell_for_analysis,\n",
    "            (np.array(ref_point_0), np.array(ref_point_1)),\n",
    "            time_allowed=80,\n",
    "            start_r=start_r,\n",
    "            dr=dr,\n",
    "        )\n",
    "        if intensity_weighted:\n",
    "            gr_values *= cell.data[ref_point_0][ref_point_1]\n",
    "        if len(r_values) > len(max_r_values):\n",
    "            max_r_values = r_values\n",
    "        all_gr_values.append(gr_values)\n",
    "    gr_values_length_corrected = list(\n",
    "        itertools.zip_longest(*all_gr_values, fillvalue=np.nan)\n",
    "    )\n",
    "    mean_gr_values = [np.nanmean(i) for i in gr_values_length_corrected]\n",
    "    if intensity_weighted:\n",
    "        #         mean_gr_values = np.multiply(pixels_in_cell,mean_gr_values/total_cell_intensity)\n",
    "        mean_gr_values = np.multiply(\n",
    "            num_ref_points, mean_gr_values / total_ref_point_intensity\n",
    "        )\n",
    "    return max_r_values, mean_gr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf(seg, fluor_img, ref_point_val = 'max', cell_indices=[0], time_allowed=80, \n",
    "        savetxt='rdf',start_r=1,dr=1, intensity_weighted = True):\n",
    "# Seg is the segmentation array.\n",
    "#     Get the background fluorescence of the image, to subtract from all cell fluorescence.\n",
    "    min_fluor = np.amin(fluor_img)\n",
    "    # Get number of cells in the image.\n",
    "    cells = np.amax(seg)\n",
    "    if cell_indices == 'all':\n",
    "        cell_indices = np.arange(cells)\n",
    "# all_r_values will be a list of lists of r values, while all_gr_values will be a list of lists, with\n",
    "# the corresponding g(r) (pair correlation function) values. The overall function will return\n",
    "# all_r_values, all_gr_values.\n",
    "    all_r_values = []\n",
    "    all_gr_values = []\n",
    "    for cell_index in cell_indices:\n",
    "        print('cell index',cell_index)\n",
    "        if cell_index>cells:\n",
    "            print('Error in rdf: cell_index larger than number of cells in fov.')\n",
    "            pass\n",
    "#         Mask the fluorescence image everywhere except for the cell.\n",
    "        cell = np.ma.masked_where(seg != cell_index + 1, fluor_img)\n",
    "        # Normalise the intensities of the cell.\n",
    "#         mean_int_cell = np.mean(cell)\n",
    "        cell -= min_fluor\n",
    "#         ref_point is the 'nucleus' i.e. the point relative to which the pair\n",
    "#         correlation function is to be calculated. For now, we set it to the \n",
    "#         maximum fluorescence intensity point of the cell.\n",
    "        if ref_point_val == 'max':\n",
    "            ref_point = np.where(cell == np.amax(cell))\n",
    "#         If there is more than one maximum fluorescence point, take the first one of these.\n",
    "            if len(ref_point[0])>1:\n",
    "                ref_point = (np.array([ref_point[0][0]]),np.array([ref_point[1][0]]))\n",
    "        elif ref_point_val == 'all':\n",
    "            ref_point = np.where(cell.mask == 0)\n",
    "        elif ref_point_val[0] == 'sample':\n",
    "            points_in_cell = np.where(cell.mask == 0)\n",
    "            ref_point = (points_in_cell[0][::ref_point_val[1]],points_in_cell[1][::ref_point_val[1]])\n",
    "        elif ref_point_val[0] == 'max':\n",
    "            \n",
    "        else:\n",
    "            ref_point = ref_point_val\n",
    "        r_values, gr_values = rdf_multi_ref_point_single_cell(cell, ref_point, \n",
    "                                                              time_allowed=80, start_r=start_r, dr=dr,\n",
    "                                                             intensity_weighted = intensity_weighted)\n",
    "        all_gr_values.append(gr_values)\n",
    "        all_r_values.append(r_values)\n",
    "    if savetxt:\n",
    "        all_r_to_save = np.concatenate(all_r_values).ravel()\n",
    "        all_gr_to_save = np.concatenate(all_gr_values).ravel()\n",
    "        np.savetxt(savetxt, np.transpose(np.array([all_r_to_save,all_gr_to_save])))\n",
    "    return all_r_values,all_gr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using seg as the fluor image, since this should return g(r) = 1 for all r.\n",
    "# Everything is 1 in this case\n",
    "# r_values_list, gr_values_list = rdf(seg,seg,cell_indices=np.arange(6),\n",
    "#                                     ref_point_val=['sample',10],dr=10,\n",
    "#                                    intensity_weighted=True)\n",
    "# Everything is also 1 in this case\n",
    "# r_values_list, gr_values_list = rdf(seg,seg,cell_indices=np.arange(6),\n",
    "#                                     ref_point_val=['sample',10],dr=10,\n",
    "#                                    intensity_weighted=False)\n",
    "\n",
    "print(\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\")\n",
    "rdf(\n",
    "    seg,\n",
    "    fluor_img,\n",
    "    cell_indices=\"all\",\n",
    "    ref_point_val=\"max\",\n",
    "    dr=1,\n",
    "    intensity_weighted=True,\n",
    "    savetxt=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    ")\n",
    "\n",
    "# print(r_values_list)\n",
    "# print(gr_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_rdfs_from_txt(filename, start_r):\n",
    "    # start_r is the start value of r in that dataset, so we can identify where each cell dataset starts.\n",
    "    values = np.genfromtxt(filename)\n",
    "    all_r_values = values[:, 0]\n",
    "    all_gr_values = values[:, 1]\n",
    "    start_indices = np.where(all_r_values == start_r)[0]\n",
    "    r_values_list = []\n",
    "    gr_values_list = []\n",
    "    for i, val in enumerate(start_indices):\n",
    "        if i != len(start_indices) - 1:\n",
    "            r_values_list.append(all_r_values[val : start_indices[i + 1]])\n",
    "            gr_values_list.append(all_gr_values[val : start_indices[i + 1]])\n",
    "        else:\n",
    "            r_values_list.append(all_r_values[val:])\n",
    "            gr_values_list.append(all_gr_values[val:])\n",
    "    return r_values_list, gr_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot gr from file\n",
    "def plot_gr_from_file(\n",
    "    filename,\n",
    "    start_r,\n",
    "    ax=None,\n",
    "    savefig=None,\n",
    "    indices_to_plot=None,\n",
    "    legend=False,\n",
    "    title=None,\n",
    "):\n",
    "    r_values_list, gr_values_list = get_cell_rdfs_from_txt(filename, start_r)\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots()\n",
    "    if not indices_to_plot:\n",
    "        indices_to_plot = np.arange(len(r_values_list))\n",
    "    for i in indices_to_plot:\n",
    "        ax.plot(r_values_list[i], gr_values_list[i])\n",
    "    if legend:\n",
    "        ax.legend([i for i in indices_to_plot])\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    ax.axhline(y=1, ls=\":\", color=\"k\")\n",
    "    if savefig:\n",
    "        fig.savefig(savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grs from file\n",
    "# fig,axes = plt.subplots(2,2,figsize=(20,20))\n",
    "# ax = axes.ravel()\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    ")\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue_foci\",\n",
    "    indices_to_plot=[1, 2, 11, 25, 27, 28, 33, 52],\n",
    "    legend=True,\n",
    "    title=\"Foci\",\n",
    ")\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue_maybefoci\",\n",
    "    indices_to_plot=[5, 8, 14, 20, 22, 30, 32, 40, 55],\n",
    "    legend=True,\n",
    "    title=\"Maybe foci\",\n",
    ")\n",
    "plot_gr_from_file(\n",
    "    \"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue\",\n",
    "    1,\n",
    "    savefig=\"20200626/sfGFP_100x_fov20/refmax_dr1_intweighttrue_nofoci\",\n",
    "    indices_to_plot=[0, 3, 4, 6, 9, 13, 23, 29, 31, 36, 37, 44, 51, 58],\n",
    "    legend=True,\n",
    "    title=\"No foci\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rough_sqrt = int(np.ceil(np.sqrt(62)))\n",
    "fig, axes = plt.subplots(rough_sqrt, rough_sqrt, figsize=(25, 25))\n",
    "ax = axes.ravel()\n",
    "i = 0\n",
    "for cell_index in range(62):\n",
    "    cell_indices = np.where(seg == cell_index + 1)\n",
    "    cell = np.ma.masked_where(seg != cell_index + 1, fluor_img)\n",
    "    #     fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax[i].imshow(\n",
    "        cell[\n",
    "            int(np.min(cell_indices[0])) : int(np.max(cell_indices[0])) + 1,\n",
    "            int(np.min(cell_indices[1])) : int(np.max(cell_indices[1])) + 1,\n",
    "        ]\n",
    "    )\n",
    "    ax[i].set_title(cell_index)\n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"20200626/sfGFP_100x_fov20/cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check:\n",
    "#     single point vs gradual gradient (i.e. size of the blob)\n",
    "#     gradient of the intensity of the blob (i.e. one clear blob and no background or more diffuse blob)\n",
    "#     different cell shape\n",
    "#     position of blob within cell\n",
    "#     intensity of the blob vs background of cell\n",
    "# Test on 2d Gaussian and hat function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
