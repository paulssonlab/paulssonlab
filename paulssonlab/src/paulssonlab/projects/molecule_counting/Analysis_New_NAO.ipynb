{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "import panel as pn\n",
    "import hvplot.pandas  # noqa: API import\n",
    "import hvplot.xarray\n",
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize\n",
    "import datashader.transfer_functions as tf\n",
    "import datashader as ds\n",
    "\n",
    "import pickle\n",
    "import molecule_counting_v2 as molco\n",
    "\n",
    "from scipy import stats\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('190311photobleaching.pickle', 'rb') as f:\n",
    "# with open('all_data.pickle', 'rb') as f:\n",
    "# with open('190313photobleaching_noflatcorr.pickle', 'rb') as f:\n",
    "# with open('190326photobleaching_flatcorr_fluoronly.pickle', 'rb') as f:\n",
    "with open(\n",
    "    \"/n/groups/paulsson/nao5/molecule-counting/190604_mothermachine.pickle\", \"rb\"\n",
    ") as f:\n",
    "    d = pickle.load(f)\n",
    "list(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation\n",
    "\n",
    "%output size=200\n",
    "mkate100_dir = \"/n/scratch2/jqs1/190604/mkate_mcherry_100ms_100pct.nd2\"\n",
    "\n",
    "# fov = 2\n",
    "# tabs = {}\n",
    "tabs = pn.Tabs()\n",
    "for fov in range(len(d[mkate100_dir])):\n",
    "    seg_frame = np.asarray(d[mkate100_dir][fov][\"segmentation_frame\"])\n",
    "    label_frame = segmentation.permute_labels(\n",
    "        np.asarray(d[mkate100_dir][fov][\"labels\"])\n",
    "    )\n",
    "    #     label_frame = np.asarray(d[mkate100_dir][fov]['labels'])\n",
    "\n",
    "    x_coord = np.arange(seg_frame.shape[0])\n",
    "    y_coord = np.arange(seg_frame.shape[1])\n",
    "    seg_frame = hv.Dataset((x_coord, y_coord, seg_frame), [\"x\", \"y\"], \"Fluor\")\n",
    "    label_frame = hv.Dataset((x_coord, y_coord, label_frame), [\"x\", \"y\"], \"label\")\n",
    "    img = datashade(seg_frame.to(hv.Image, [\"x\", \"y\"], \"Fluor\"), cmap=cm.jet).opts(\n",
    "        bgcolor=\"black\", active_tools=[\"wheel_zoom\"]\n",
    "    )\n",
    "    labels = datashade(label_frame.to(hv.Image, [\"x\", \"y\"], \"label\"), cmap=cm.hot).opts(\n",
    "        bgcolor=\"black\", active_tools=[\"wheel_zoom\"]\n",
    "    )\n",
    "\n",
    "    #     img = seg_frame.to(hv.Image,['x','y'],'Fluor')\n",
    "    #     labels = label_frame.to(hv.Image,['x','y'],'label')\n",
    "    combo = img + labels\n",
    "    tabs.append((f\"FOV: {fov}\", combo))\n",
    "# measurements, regionprops, labels, img = data[ '/n/scratch2/jqs1/190604/GFP_FITC_100ms_60pct.nd2'][4]\n",
    "# t = pn.Tabs(('FOV 0',tabs[0]), ('FOV 1',tabs[1]))\n",
    "tabs.clone(closable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(molco)\n",
    "\n",
    "mvenus_dir = \"/n/scratch2/jqs1/190604/mVenus_YFP_100ms_10pct.nd2\"\n",
    "mkate50_dir = \"/n/scratch2/jqs1/190604/mkate_mcherry_100ms_50pct.nd2\"\n",
    "mkate100_dir = \"/n/scratch2/jqs1/190604/mkate_mcherry_100ms_100pct.nd2\"\n",
    "gfp_dir = \"/n/scratch2/jqs1/190604/GFP_FITC_100ms_60pct.nd2\"\n",
    "\n",
    "mkate50_bad_fov = [0, 3, 5, 6, 7]\n",
    "mkate100_bad_fov = [1, 8, 10, 17, 19, 20]\n",
    "mvenus_bad_fov = [0]\n",
    "# mvenus_bad_fov = [0,8,9,10,11,12,13,14,15,16,17]\n",
    "gfp_bad_fov = [8, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "\n",
    "# data = molco.process_df(d,mkate50_dir,mkate50_bad_fov,6,1.8,.9)\n",
    "data, meta_data = molco.process_df(d, mkate100_dir, mkate100_bad_fov, 6, 1.3, 0.90)\n",
    "# data = molco.process_df(d,mvenus_dir,mvenus_bad_fov,6,1.5,.9)\n",
    "# data = molco.process_df(d,gfp_dir,gfp_bad_fov,6,1.2,.95)\n",
    "N = data[\"cell_id\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%output size=150\n",
    "\n",
    "\n",
    "def line(ds):\n",
    "    return ds.dframe().hvplot.line(\n",
    "        x=\"time\", y=\"normed\", by=\"cell_id\", line_width=6, alpha=0.7\n",
    "    )\n",
    "\n",
    "\n",
    "def sample(ds, n_samp=100):\n",
    "    samp = list(np.random.choice(N, n_samp))\n",
    "    return ds.select(cell_id=samp)\n",
    "\n",
    "\n",
    "def good(ds, meta_ds, thresh=1):\n",
    "    good_cells = list(meta_ds.select(dy=(0, thresh)).dframe().cell_id)\n",
    "    good_ds = ds.select(cell_id=good_cells)\n",
    "\n",
    "    return good_ds\n",
    "\n",
    "\n",
    "def bad(ds, meta_ds, thresh=1):\n",
    "    bad_cells = list(meta_ds.select(dy=(thresh, 1000)).dframe().cell_id)\n",
    "    bad_ds = ds.select(cell_id=bad_cells)\n",
    "    return bad_ds\n",
    "\n",
    "\n",
    "sample_slider = pn.widgets.IntSlider(\n",
    "    name=\"Number of Samples\", value=50, start=1, end=500\n",
    ")\n",
    "\n",
    "ds_small = data.apply(sample, n_samp=sample_slider.param.value)\n",
    "\n",
    "thresh_slider = pn.widgets.FloatSlider(\n",
    "    name=\"Filter Threshold\", value=1.2, start=1, end=3, step=0.01\n",
    ")\n",
    "good_ds = ds_small.apply(good, meta_ds=meta_data, thresh=thresh_slider.param.value)\n",
    "bad_ds = ds_small.apply(bad, meta_ds=meta_data, thresh=thresh_slider.param.value)\n",
    "\n",
    "dynamic_line = pn.panel(\n",
    "    datashade(ds_small.apply(line)).opts(\n",
    "        width=500, height=400, logy=True, tools=[\"hover\"], ylim=(0.01, 1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# good_curves = pn.panel(datashade(good_ds.apply(line)).opts(width=400,height=400,tools=['hover'],ylim=(0.01,1)))\n",
    "# bad_curves = pn.panel(datashade(bad_ds.apply(line)).opts(width=400,height=400,tools=['hover'],ylim=(0.01,1)))\n",
    "good_curves = good_ds.apply(line)\n",
    "bad_curves = bad_ds.apply(line)\n",
    "# r = datashade(good_curves + bad_curves)\n",
    "c1 = pn.Column(\n",
    "    sample_slider,\n",
    "    thresh_slider,\n",
    "    datashade((ds_small.apply(line) + good_curves * bad_curves).cols(1)),\n",
    ")\n",
    "# pn.Row(good_curves, bad_curves)\n",
    "# c2 = pn.Column(thresh_slider, r)\n",
    "# dash = pn.Column(c1,c2)\n",
    "# dash\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=250\n",
    "traces = data.iloc[:, :950].values\n",
    "idxs = np.random.permutation(traces.shape[0])\n",
    "downsample = 100  # set to 1 to show all traces (instead odata.k.hist()f 10%); this will make your browser slow\n",
    "curves = [\n",
    "    {\"x\": np.arange(traces.shape[1]), \"y\": traces[i], \"i\": idxs[i]}\n",
    "    for i in range(traces.shape[0] // downsample)\n",
    "]\n",
    "hv.Contours(curves, vdims=[\"i\"]).options(color_index=\"i\", cmap=\"Category20\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(ds):\n",
    "    return ds.dframe().hvplot.line(\n",
    "        x=\"time\", y=\"Fluorescence\", by=\"cell_id\", line_width=6\n",
    "    )\n",
    "\n",
    "\n",
    "def sample(ds, n_samp=100):\n",
    "    samp = list(np.random.choice(N, n_samp))\n",
    "    return ds.select(cell_id=samp)\n",
    "\n",
    "\n",
    "sample_slider = pn.widgets.IntSlider(\n",
    "    name=\"Number of Samples\", value=50, start=1, end=500\n",
    ")\n",
    "\n",
    "ds_small = ds.apply(sample, n_samp=sample_slider.param.value)\n",
    "# print(type(ds_small))\n",
    "dynamic_line = pn.panel(\n",
    "    datashade(ds_small.apply(line)).opts(\n",
    "        width=700, height=400, logy=True, tools=[\"hover\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "r = pn.Column(sample_slider, dynamic_line)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation\n",
    "\n",
    "%output size=200\n",
    "fov = 2\n",
    "img = np.asarray(d[mkate100_dir][fov][\"segmentation_frame\"])\n",
    "labels = np.asarray(d[mkate100_dir][fov][\"labels\"])\n",
    "# measurements, regionprops, labels, img = data[ '/n/scratch2/jqs1/190604/GFP_FITC_100ms_60pct.nd2'][4]\n",
    "labels = segmentation.permute_labels(labels)\n",
    "hv.Image(img / img.max()).options(cmap=\"hot\") + hv.Image(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(molco)\n",
    "# prop_dict = {'area': [data.area.median() - 2*data.area.std(), data.area.median() + 2*data.area.std()],\n",
    "#               0: [2000, 4500], t_end-1: [500,1000],\n",
    "#              'k': [.003,.0045]}\n",
    "# prop_dict = {\n",
    "#             'centroid_y': [0, 2000],\n",
    "#              'centroid_x': [0, 2000],\n",
    "#              'area': [data.area.median() - 2*data.area.std(), data.area.median() + 2*data.area.std()],\n",
    "#              0: [500, 6000],'k': [.002,.01]}\n",
    "prop_dict = {\n",
    "    \"centroid_y\": [400, 1600],\n",
    "    \"centroid_x\": [700, 1800],\n",
    "    \"area\": [\n",
    "        data.area.median() - 2 * data.area.std(),\n",
    "        data.area.median() + 2 * data.area.std(),\n",
    "    ],\n",
    "    0: [500, 3000],\n",
    "    \"k\": [0.001, 0.02],\n",
    "}  # , 1150:[0,350]}\n",
    "df = molco.filter_df(data, prop_dict)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.hist(df.k, bins=30)\n",
    "ax2.hist(df[0], bins=30)\n",
    "\n",
    "q = 1\n",
    "\n",
    "f_predicted, fbar, p, mu, sigma2, y = molco.fluct_plot(df, n=3)\n",
    "\n",
    "# plt.figure(figsize=(12,8))\n",
    "# yn = y.apply(lambda col: col/col.iloc[0],axis=1)\n",
    "# plt.semilogy(yn.T.values[:,::20])\n",
    "# plt.ylim(bottom=1e-3,top=1.1)\n",
    "# plt.xlim(left=0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "yn = y.apply(lambda col: col / col.iloc[0], axis=1)\n",
    "tp = np.arange(yn.shape[1]) / 10\n",
    "plt.semilogy(tp, yn.T.values[:, ::10], linewidth=3)\n",
    "plt.semilogy(tp, mu / mu[0], \"b\", linewidth=7, alpha=0.7, label=r\"$\\mu$\")\n",
    "plt.xlabel(\"Time\", fontsize=28)\n",
    "plt.ylabel(\"Fluorescence\", fontsize=28)\n",
    "plt.legend(fontsize=20)\n",
    "plt.ylim(bottom=1e-3, top=1.1)\n",
    "plt.xlim(left=0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "molco.kmaps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.rc(\"xtick\", labelsize=24)\n",
    "plt.rc(\"ytick\", labelsize=24)\n",
    "t = 0.1 * np.arange(y.shape[1])\n",
    "plt.semilogy(t, y.T.values[:, ::20])\n",
    "plt.ylim(bottom=1e1, top=6e3)\n",
    "plt.xlim(left=0)\n",
    "plt.xlabel(\"Time (seconds)\", fontsize=28)\n",
    "plt.ylabel(\"Fluorescence (A.U.)\", fontsize=28)\n",
    "# plt.title('Photobleach Time Series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
