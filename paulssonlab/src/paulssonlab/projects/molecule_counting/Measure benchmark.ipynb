{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nd2reader\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "import dask\n",
    "import dask.array as da\n",
    "from cytoolz import partial, compose, juxt\n",
    "import numpy_indexed\n",
    "import segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(\n",
    "    \"/n/scratch2/jqs1/190922/190922_photobleaching_greens/GFP_photobleaching_100pct_100ms_0001.nd2\"\n",
    ")\n",
    "img_stack = np.stack([nd2.get_frame_2D(v=0, t=t) for t in range(10)])\n",
    "img = img_stack[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = segmentation.segment(img_stack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.ravel()[np.arange(img.size)].reshape(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_naive(labels, img_stack, skip0=True):\n",
    "    labels_list = np.arange(1 if skip0 else 0, labels.max() + 1)\n",
    "    for img in img_stack:\n",
    "        for label in labels_list:\n",
    "            img[labels == label].mean()\n",
    "\n",
    "\n",
    "def mean_pandas(labels, img_stack):\n",
    "    for img in img_stack:\n",
    "        pd.DataFrame({\"label\": labels.ravel(), \"value\": img.ravel()}).groupby(\n",
    "            \"label\"\n",
    "        ).agg([\"mean\"])\n",
    "\n",
    "\n",
    "def mean_npi(labels, img_stack):\n",
    "    for img in img_stack:\n",
    "        numpy_indexed.group_by(labels.ravel(), img_stack.ravel(), reduction=np.mean)\n",
    "\n",
    "\n",
    "def mean_npi2(labels, img_stack, skip0=True):\n",
    "    for img in img_stack:\n",
    "        g = numpy_indexed.GroupBy(labels.ravel())\n",
    "        groups = g.split(img.ravel())\n",
    "        ret = [\n",
    "            (key, np.mean(group))\n",
    "            for key, group in zip(g.unique, groups)\n",
    "            if key != 0 or not skip0\n",
    "        ]\n",
    "\n",
    "\n",
    "def mean_npi3(labels, img_stack, skip0=True):\n",
    "    g = numpy_indexed.GroupBy(labels.ravel())\n",
    "    for img in img_stack:\n",
    "        groups = g.split(img.ravel())\n",
    "        ret = [\n",
    "            (key, np.mean(group))\n",
    "            for key, group in zip(g.unique, groups)\n",
    "            if key != 0 or not skip0\n",
    "        ]\n",
    "\n",
    "\n",
    "def mean_split(labels, img_stack, skip0=True):\n",
    "    # g = numpy_indexed.GroupBy(labels.ravel())\n",
    "    keys = labels.ravel()\n",
    "    sorter = np.argsort(keys, kind=\"mergesort\")\n",
    "    sorted_ = keys[sorter]\n",
    "    flag = sorted_[:-1] != sorted_[1:]\n",
    "    slices = np.concatenate(([0], np.flatnonzero(flag) + 1, [keys.size]))\n",
    "    unique = sorted_[slices[:-1]]\n",
    "    for img in img_stack:\n",
    "        # groups = g.split(img.ravel())\n",
    "        values = img.ravel()\n",
    "        values = values[sorter]\n",
    "        groups = np.split(values, slices[1:-1], axis=0)\n",
    "        ret = [\n",
    "            (key, np.mean(group))\n",
    "            for key, group in zip(unique, groups)\n",
    "            if key != 0 or not skip0\n",
    "        ]\n",
    "\n",
    "\n",
    "def mean_split2(labels, img_stack, skip0=True):\n",
    "    # g = numpy_indexed.GroupBy(labels.ravel())\n",
    "    keys = labels.ravel()\n",
    "    sorter = np.argsort(keys, kind=\"mergesort\")\n",
    "    sorted_ = keys[sorter]\n",
    "    flag = sorted_[:-1] != sorted_[1:]\n",
    "    slices = np.concatenate(([0], np.flatnonzero(flag) + 1, [keys.size]))\n",
    "    unique = sorted_[slices[:-1]]\n",
    "    # for img in img_stack:\n",
    "    # groups = g.split(img.ravel())\n",
    "    values = img_stack.reshape((img_stack.shape[0], -1))[\n",
    "        :, sorter\n",
    "    ]  # .reshape(img_stack.shape)\n",
    "    # values = img.ravel()\n",
    "    # values = values[sorter]\n",
    "    groups = np.split(values, slices[1:-1], axis=1)\n",
    "    ret = [\n",
    "        (key, np.mean(group, axis=1))\n",
    "        for key, group in zip(unique, groups)\n",
    "        if key != 0 or not skip0\n",
    "    ]\n",
    "\n",
    "\n",
    "from numba import prange\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True, parallel=True)\n",
    "def mean_vectorized(labels, img_stack, skip0=True):\n",
    "    max_label = labels.max()\n",
    "    sums = np.zeros((max_label + 1, img_stack.shape[0]), dtype=img_stack.dtype)\n",
    "    counts = np.zeros((max_label + 1, 1), dtype=np.uint64)\n",
    "    for y in prange(img_stack.shape[1]):\n",
    "        for x in prange(img_stack.shape[2]):\n",
    "            label = labels[y, x]\n",
    "            if label == 0 and skip0:\n",
    "                continue\n",
    "            sums[label] += img_stack[:, y, x]\n",
    "            counts[label, 0] += 1\n",
    "    return sums / counts\n",
    "\n",
    "\n",
    "from numba import prange\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True, parallel=True)\n",
    "def mean_vectorized2(labels, img_stack, skip0=True):\n",
    "    max_label = labels.max()\n",
    "    sums = np.zeros((max_label + 1, img_stack.shape[2]), dtype=img_stack.dtype)\n",
    "    counts = np.zeros((max_label + 1, 1), dtype=np.uint64)\n",
    "    for y in prange(img_stack.shape[0]):\n",
    "        for x in prange(img_stack.shape[1]):\n",
    "            label = labels[y, x]\n",
    "            if label == 0 and skip0:\n",
    "                continue\n",
    "            sums[label] += img_stack[y, x, :]\n",
    "            counts[label, 0] += 1\n",
    "    return sums / counts\n",
    "\n",
    "\n",
    "# def mean_npi2(labels, img_stack):\n",
    "#    numpy_indexed.group_by(labels.ravel(), img_stack.ravel(), reduction=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_pandas(labels, img_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_npi(labels, img_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_npi2(labels, img_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_npi3(labels, img_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_split(labels, img_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_split2(labels, img_stack, skip0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_vectorized(labels, img_stack, skip0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_stack_T = np.ascontiguousarray(np.moveaxis(img_stack, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_vectorized2(labels, img_stack_T, skip0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy_groupies as npg\n",
    "\n",
    "%timeit npg.aggregate(labels.ravel(), img_stack.reshape((img_stack.shape[0],-1)), func='mean', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun mean_npi3(labels, img_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mean_naive(labels, img_stack[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
