{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from scipy.integrate import simps, trapz\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /n/groups/paulsson/jqs1/molecule-counting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"/n/groups/paulsson/jqs1/molecule-counting/200302photobleaching.pickle\", \"rb\"\n",
    ") as f:\n",
    "    d = pickle.load(f)\n",
    "    print(f\"File is {sys.getsizeof(f)/1e6} MB\")\n",
    "list(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_rates(data, t_end):\n",
    "    return data.apply(\n",
    "        lambda y: (y.values[0] - y.values[t_end - 1])\n",
    "        / np.sum(y[:t_end].values - y.values[t_end - 1]),\n",
    "        axis=1,\n",
    "    ).values\n",
    "\n",
    "\n",
    "def process_df(full_data, bad_fovs=[], trunc=0, dy_max=10, dy_min=0):\n",
    "    traces_list = []\n",
    "    rp_list = []\n",
    "    for fp_dir in full_data.keys():\n",
    "        print(f\"FP directory is {fp_dir}\")\n",
    "        for i, fov in enumerate(list(full_data[fp_dir].keys())):\n",
    "            if i not in bad_fovs:\n",
    "                print(f\"FOV {i}\")\n",
    "                for channel in full_data[fp_dir][fov][\"traces\"].keys():\n",
    "                    print(f\"Channel {channel}\")\n",
    "                    regionprops = full_data[fp_dir][fov][\"regionprops\"]\n",
    "                    timeseries = pd.DataFrame(\n",
    "                        full_data[fp_dir][fov][\"traces\"][channel][\"mean\"][1:, 1:]\n",
    "                    )\n",
    "\n",
    "                    traces_list.append(timeseries)\n",
    "\n",
    "                    regionprops[\"FOV\"] = i\n",
    "                    regionprops[\"experiment\"] = os.path.basename(\n",
    "                        os.path.dirname(fp_dir)\n",
    "                    )\n",
    "                    regionprops[\"channel\"] = channel\n",
    "                    rp_list.append(regionprops)\n",
    "\n",
    "                    print(timeseries.shape)\n",
    "\n",
    "    traces = pd.concat(traces_list)\n",
    "    df_meta = pd.concat(rp_list, sort=False)\n",
    "    df_meta.reset_index(inplace=True)\n",
    "    print(df_meta.columns)\n",
    "    print(traces.shape)\n",
    "\n",
    "    df_data = pd.DataFrame(traces)\n",
    "    #     data = pd.concat([data,rp_df],axis=1,sort=False)\n",
    "    print(\"computing k\")\n",
    "    t_end = traces.shape[1] - trunc\n",
    "    cell_id = df_meta.index.tolist()\n",
    "    df_meta[\"cell_id\"] = cell_id\n",
    "    df_meta[\"k\"] = decay_rates(df_data, t_end)\n",
    "    dt = 10\n",
    "    df_meta[\"dy\"] = df_data.apply(\n",
    "        lambda y: np.abs((y.values[: t_end - dt] / y.values[dt:t_end])).max(), axis=1\n",
    "    )\n",
    "    df_n = df_data.apply(lambda x: x / x[0], axis=1)\n",
    "    print(\"hv stuff\")\n",
    "    time = np.arange(df_data.shape[1])\n",
    "    data = hv.Table(\n",
    "        (time, cell_id, df_data, df_n), [\"time\", \"cell_id\"], [\"fluor\", \"normed\"]\n",
    "    )  # TODO Fix that\n",
    "\n",
    "    kdims = [\"centroid-0\", \"centroid-1\"]\n",
    "    vdims = [\n",
    "        \"label\",\n",
    "        \"area\",\n",
    "        \"eccentricity\",\n",
    "        \"min_intensity\",\n",
    "        \"mean_intensity\",\n",
    "        \"max_intensity\",\n",
    "        \"major_axis_length\",\n",
    "        \"minor_axis_length\",\n",
    "        \"orientation\",\n",
    "        \"perimeter\",\n",
    "        \"solidity\",\n",
    "        \"weighted_centroid-0\",\n",
    "        \"weighted_centroid-1\",\n",
    "        \"FOV\",\n",
    "        \"cell_id\",\n",
    "        \"k\",\n",
    "        \"dy\",\n",
    "    ]\n",
    "    meta_data = hv.Table(df_meta, kdims, vdims)\n",
    "    return data, meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkate_dir = \"200227/mKate2hyb_genomic/*.nd2\"\n",
    "data, meta_data = process_df(d, [], 6, 1.3, 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
