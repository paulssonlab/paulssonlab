{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import re\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "import pygsheets\n",
    "import benchlingapi\n",
    "import requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paulssonlab.api as api\n",
    "from paulssonlab.api.util import base_url\n",
    "import paulssonlab.cloning.workflow as workflow\n",
    "import paulssonlab.cloning.util as cloning_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = benchlingapi.Session(config[\"benchling\"][\"api_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = pygsheets.authorize(service_account_file=\"credentials.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = workflow.get_strain_collection_sheets(gc.drive.service, \"LIB\")\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_sheet = gc.open_by_key(col[\"strains\"]).worksheet()\n",
    "plasmid_sheet = gc.open_by_key(col[\"plasmids\"]).worksheet()\n",
    "part_sheet = gc.open_by_key(col[\"parts\"]).worksheet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3G/JUMP/Densmore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeg_kit = \"https://www.addgene.org/1000000161/\"\n",
    "marionette_kit = \"https://www.addgene.org/1000000137/\"\n",
    "jump_plasmids = [\n",
    "    \"https://www.addgene.org/126956/\",\n",
    "    \"https://www.addgene.org/126959/\",\n",
    "    \"https://www.addgene.org/126960/\",\n",
    "    \"https://www.addgene.org/126961/\",\n",
    "    \"https://www.addgene.org/126962/\",\n",
    "    \"https://www.addgene.org/126963/\",\n",
    "    \"https://www.addgene.org/126964/\",\n",
    "    \"https://www.addgene.org/126965/\",\n",
    "    \"https://www.addgene.org/126966/\",\n",
    "    \"https://www.addgene.org/126967/\",\n",
    "    \"https://www.addgene.org/126973/\",\n",
    "    \"https://www.addgene.org/126974/\",\n",
    "    \"https://www.addgene.org/126975/\",\n",
    "    \"https://www.addgene.org/126976/\",\n",
    "    \"https://www.addgene.org/126991/\",\n",
    "    \"https://www.addgene.org/126996/\",\n",
    "    \"https://www.addgene.org/127015/\",\n",
    "    \"https://www.addgene.org/127047/\",\n",
    "    \"https://www.addgene.org/127051/\",\n",
    "    \"https://www.addgene.org/127025/\",\n",
    "    \"https://www.addgene.org/127000/\",\n",
    "    \"https://www.addgene.org/126983/\",\n",
    "]\n",
    "jump_plasmids = sorted(jump_plasmids)\n",
    "densmore_kit = \"https://www.addgene.org/1000000059/\"\n",
    "densmore_wells = [\n",
    "    \"A1\",\n",
    "    \"A5\",\n",
    "    \"A9\",\n",
    "    \"B1\",\n",
    "    \"B5\",\n",
    "    \"B9\",\n",
    "    \"C1\",\n",
    "    \"C5\",\n",
    "    \"C9\",\n",
    "    \"D1\",\n",
    "    \"D5\",\n",
    "    \"D6\",\n",
    "    \"D7\",\n",
    "    \"D8\",\n",
    "    \"D9\",\n",
    "    \"D10\",\n",
    "    \"D11\",\n",
    "    \"D12\",\n",
    "    \"E1\",\n",
    "    \"E2\",\n",
    "    \"E3\",\n",
    "    \"E4\",\n",
    "    \"E5\",\n",
    "    \"E6\",\n",
    "    \"E7\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densmore renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in (strain_sheet, plasmid_sheet):\n",
    "    rows = sheet.get_all_records()\n",
    "    # sheet.unlink()\n",
    "    col_idx = list(rows[0].keys()).index(\"Aliases*\") + 1\n",
    "    for idx, row in enumerate(rows):\n",
    "        if base_url(densmore_kit) in row[\"Source*\"]:\n",
    "            new_aliases = re.sub(\n",
    "                r\"([^()]*)\\s\\(([^()]*)\\)([^()]*)\", r\"\\1\\3,\\2\\3\", row[\"Aliases*\"]\n",
    "            )\n",
    "            sheet.update_value((idx + 2, col_idx), new_aliases, parse=False)\n",
    "    # sheet.link() # TODO: this gives 500 error, not sure why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = plasmid_sheet.get_all_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = plasmid_sheet.client.drive.service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_threeg_part(plasmid, seq_file):\n",
    "    part = plasmid_to_part(plasmid)\n",
    "    # MoClo golden gate assembly BC part for BCD24 (low expression bi-cistronic RBS, engineered for downstream context-independence; see https://doi.org/10.1038/nmeth.2404).\n",
    "    name = {\n",
    "        \"P18m\": \"pT7\",\n",
    "        \"P33m\": \"pMutalik_med\",\n",
    "        \"P34m\": \"pMutalik_weak\",\n",
    "        \"C31m\": \"Bxb1\",\n",
    "        \"C40m\": \"random_blank\",\n",
    "        \"C71m\": \"CinR-CIDDHYRTC\",\n",
    "        \"C95m\": \"T7_RNAP\",\n",
    "        \"C114m\": \"Cas9_recoded\",\n",
    "        \"UC16m\": \"gQi_gRNA_BD\",\n",
    "        \"UC17m\": \"gV1_gRNA_BD\",\n",
    "        \"UC20m\": \"gN2_gRNA_BD\",\n",
    "        \"UCT1m\": \"gQi_gRNA_BE\",\n",
    "    }.get(part[\"Name*\"])\n",
    "    if name is not None:\n",
    "        part[\"Name*\"] = name\n",
    "    else:\n",
    "        part[\"Name*\"] = re.search(\n",
    "            r\"(\\S+)(?: (?:RBS|terminator|integrase|fusion|protease))? \\(\",\n",
    "            plasmid[\"Description\"],\n",
    "        ).group(1)\n",
    "    part[\"Author*\"] = \"Richard Murray lab\"\n",
    "    return part\n",
    "\n",
    "\n",
    "def import_densmore_part(plasmid, seq_file):\n",
    "    part = plasmid_to_part(plasmid)\n",
    "    part[\"Author*\"] = \"Douglas Densmore lab\"\n",
    "    return part\n",
    "\n",
    "\n",
    "def import_jump_part(plasmid, seq_file):\n",
    "    part = plasmid_to_part(plasmid)\n",
    "    part[\"Name*\"] = re.sub(r\"^pJUMP\\d+-\", \"\", plasmid[\"Names\"])\n",
    "    part[\"Author*\"] = \"Marcos Valenzuela-Ortega, Christopher French\"\n",
    "    return part\n",
    "\n",
    "\n",
    "# accept extra columns via overrides={\"Tags\": \"foo\"}\n",
    "# pass through tags from plasmid\n",
    "\n",
    "\n",
    "def plasmid_to_part(plasmid):\n",
    "    part = {}\n",
    "    part[\"Name*\"] = plasmid[\"Names\"].split(\",\")[-1]\n",
    "    part[\"Tags\"] = plasmid[\"Tags\"]\n",
    "    # part[\"Plasmid/Oligos (Cutter)*\"] = \"\"\n",
    "    # part[\"Author*\"] = \"\"\n",
    "    part[\"Date*\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    part[\"Upstream overhang*\"] = \"aaa\"\n",
    "    part[\"Downstream overhang*\"] = \"bbb\"\n",
    "    part[\"Sequence*\"] = \"aaaseqbbb\"\n",
    "    part[\"Organism/codon usage*\"] = \"E. coli\"\n",
    "    part[\"Description\"] = plasmid[\"Description\"]\n",
    "    return part\n",
    "\n",
    "\n",
    "part_rules = [\n",
    "    (\n",
    "        lambda x: (base_url(threeg_kit) in x[\"Source*\"]) and (x[\"Names\"][0] != \"V\"),\n",
    "        import_threeg_part,\n",
    "    ),\n",
    "    (lambda x: base_url(densmore_kit) in x[\"Source*\"], import_densmore_part),\n",
    "    (\n",
    "        lambda x: (any(base_url(j) in x[\"Source*\"] for j in jump_plasmids))\n",
    "        and (\"(Empty Backbone)\" not in x[\"Description\"]),\n",
    "        import_jump_part,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plasmid_folder = col[\"plasmid_maps\"]\n",
    "plasmid_maps = api.google.list_drive(service, root=plasmid_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.util.regex_key(plasmid_maps, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    for predicate, rule in part_rules:\n",
    "        if predicate(row):\n",
    "            seq_file = api.util.regex_key(\n",
    "                plasmid_maps, f'{row[\"ID*\"]}\\\\.', check_duplicates=True\n",
    "            )[\"id\"]\n",
    "            part = rule(row, seq_file)\n",
    "            # print(row[\"Names\"], part[\"Name*\"])\n",
    "            print(part)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part cutting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = api.read_sequence(\n",
    "    service.files()\n",
    "    .get_media(\n",
    "        fileId=api.util.regex_key(plasmid_maps, r\"pLIB1\\.\", check_duplicates=True)[\"id\"]\n",
    "    )\n",
    "    .execute()\n",
    "    .decode(\"utf8\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqt = SeqRecord.SeqRecord(\n",
    "    \"atttctggaattcgcggccgcttctagagactagtgggtctcaggagtttacagctagctcagtcctaggtattatgctagctactagagacctactagtagcg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_re(Restriction.BsaI, seqt, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.elucidate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme.site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _search_re(enzyme, seq, linear=True):\n",
    "    compsite = re.compile(\n",
    "        enzyme.compsite.pattern, enzyme.compsite.flags | re.IGNORECASE\n",
    "    )\n",
    "    if not linear:\n",
    "        seq = seq + seq[1 : enzyme.size]\n",
    "    re_sites = [\n",
    "        (i.start(), i.group(1) is not None) for i in re.finditer(compsite, str(seq.seq))\n",
    "    ]\n",
    "    return re_sites\n",
    "\n",
    "\n",
    "def _re_digest_cuts(binding_locs, enzyme):\n",
    "    cuts = []\n",
    "    for loc, sense in binding_locs:\n",
    "        for cut5, cut3 in ((enzyme.fst5, enzyme.fst3), (enzyme.scd5, enzyme.scd3)):\n",
    "            if cut5 is None and cut3 is None:\n",
    "                continue\n",
    "            if sense:\n",
    "                if cut5 is not None:\n",
    "                    cut5_loc = loc + cut5\n",
    "                else:\n",
    "                    cut5_loc = None\n",
    "                if cut3 is not None:\n",
    "                    cut3_loc = loc + enzyme.size + cut3\n",
    "                else:\n",
    "                    cut3_loc = None\n",
    "            else:\n",
    "                if cut3 is not None:\n",
    "                    cut5_loc = loc - cut3\n",
    "                else:\n",
    "                    cut5_loc = None\n",
    "                if cut5 is not None:\n",
    "                    cut3_loc = loc + enzyme.size - cut5\n",
    "                else:\n",
    "                    cut3_loc = None\n",
    "            # is_5prime_overhang is true if cut5 is upstream of cut3\n",
    "            if cut5 is not None and cut3 is not None:\n",
    "                is_5prime_overhang = cut5_loc > cut3_loc\n",
    "            else:\n",
    "                is_5prime_overhang = None\n",
    "            cuts.append((cut5_loc, cut3_loc, is_5prime_overhang))\n",
    "    return cuts\n",
    "\n",
    "\n",
    "def re_digest(seq, enzyme, linear=True):\n",
    "    binding_locs = _search_re(enzyme, seq, linear=linear)\n",
    "    cuts = _re_digest_cuts(binding_locs, enzyme)\n",
    "    length = len(seq)\n",
    "    return sorted([(c[0] % length, c[1] % length, c[2]) for c in cuts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_digest(seq1, Restriction.BsaI, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 44/48, 83/87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anneal_oligos():\n",
    "    # align, find overhangs\n",
    "    # add feature to seqrecord with name of part (?)\n",
    "    pass\n",
    "    # return (overhang1, SeqRecord, overhang2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[0 : (-1 % len(seq)) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1 % 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq.Seq?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def _get_overhang(seq, cut5, cut3, is_5prime_overhang):\n",
    "    if not is_5prime_overhang:\n",
    "        loc = cut5\n",
    "    else:\n",
    "        loc = cut3\n",
    "    return ((cloning_util.slice_seq(seq, cut5, cut3), is_5prime_overhang), loc)\n",
    "\n",
    "\n",
    "def _digest_for_assembly(seq, cuts):\n",
    "    cuts.append(cuts[0])\n",
    "    seqs = []\n",
    "    for cut1, cut2 in zip(cuts[:-1], cuts[1:]):\n",
    "        if cut1[2] == True and cut2[2] == False:\n",
    "            overhang1, loc1 = _get_overhang(seq.seq, *cut1)\n",
    "            overhang2, loc2 = _get_overhang(seq.seq, *cut2)\n",
    "            seq = cloning_util.slice_seq(seq, loc1, loc2)\n",
    "            print(\"SEQ\", len(seq), overhang1, overhang2)\n",
    "            seqs.append((seq, overhang1, overhang2))\n",
    "    seqs = sorted(seqs, key=lambda x: len(x[0]))\n",
    "    return seqs\n",
    "\n",
    "\n",
    "def digest_for_assembly(seq, enzyme, linear=False):\n",
    "    cuts = re_digest(seq, enzyme, linear=linear)\n",
    "    return _digest_for_assembly(seq, cuts)\n",
    "\n",
    "\n",
    "def join_seqs(seqs):\n",
    "    # every element of seqs could be a Seq or SeqRecord\n",
    "    # join all annotations\n",
    "    # join all letter_annotations (intersection of all)\n",
    "    # assembly = Seq.SeqRecord(\"\", alphabet)\n",
    "    # assembly = deepcopy(seqs[0][0])\n",
    "    return seqs\n",
    "\n",
    "\n",
    "def _check_seq_compatibility(seq1, seq2):\n",
    "    _, overhang1_1, overhang1_2 = seq1\n",
    "    _, overhang2_1, overhang2_2 = seq2\n",
    "    print(\"CHECK\", overhang1_2, overhang2_1)\n",
    "    return (overhang1_2[0], not overhang1_2[1]) == overhang2_1\n",
    "\n",
    "\n",
    "def _reverse_complement_overhangs(seq_with_overhangs):\n",
    "    seq, overhang1, overhang2 = seq_with_overhangs\n",
    "    overhang1_rc = (overhang1[0].reverse_complement(), not overhang1[1])\n",
    "    overhang2_rc = (overhang2[0].reverse_complement(), not overhang2[1])\n",
    "    return (seq.reverse_complement(), overhang2_rc, overhang1_rc)\n",
    "\n",
    "\n",
    "def _5prime_overhang(overhang):\n",
    "    if not overhang[1]:\n",
    "        return overhang[0].reverse_complement()\n",
    "    else:\n",
    "        return overhang[0]\n",
    "\n",
    "\n",
    "def assemble_sequences(seqs, linear=True):\n",
    "    alphabet = seqs[0][0].seq.alphabet\n",
    "    if len(seqs) < 2:\n",
    "        raise ValueError(\"need at least two sequences to assemble\")\n",
    "    seq1 = seqs[0]\n",
    "    seq2 = seqs[1]\n",
    "    seq1_rc = _reverse_complement_overhangs(seq1)\n",
    "    seq2_rc = _reverse_complement_overhangs(seq2)\n",
    "    if _check_seq_compatibility(seq1, seq2):\n",
    "        pass\n",
    "    elif _check_seq_compatibility(seq1, seq2_rc):\n",
    "        seqs[1] = seq2_rc\n",
    "    elif _check_seq_compatibility(seq1_rc, seq2):\n",
    "        seqs[0] = seq1_rc\n",
    "    elif _check_seq_compatibility(seq2_rc, seq2_rc):\n",
    "        seqs[0] = seq1_rc\n",
    "        seqs[1] = seq2_rc\n",
    "    else:\n",
    "        raise ValueError(f\"overhang mismatch when assembling sequences 0 and 1\")\n",
    "    if linear:\n",
    "        seqs = [*seqs, None]\n",
    "    else:\n",
    "        seqs = [*seqs, seqs[0], None]\n",
    "    seqs_to_join = []\n",
    "    for idx, (seq1, seq2) in enumerate(zip(seqs[:-1], seqs[1:])):\n",
    "        if seq2 is not None:\n",
    "            seq2_rc = _reverse_complement_overhangs(seq2)\n",
    "            if _check_seq_compatibility(seq1, seq2):\n",
    "                pass\n",
    "            elif _check_seq_compatibility(seq1, seq2_rc):\n",
    "                seq2 = seqs[idx + 1] = seq2_rc  # TODO: does this change zip?\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"overhang mismatch when assembling sequences {idx} and {idx + 1}: {seq1[2]} does not match {seq2[1]} or {seq2_rc[1]}\"\n",
    "                )\n",
    "        # seq, overhang1, overhang2 = seq1\n",
    "        seqs_to_join.append(_5prime_overhang(seq1[1]))\n",
    "        seqs_to_join.append(seq1[0])\n",
    "        if seq2 is None:\n",
    "            seqs_to_join.append(_5prime_overhang(seq1[2]))\n",
    "    # copy SeqRecords, add annotations for each part?? (including overhangs)\n",
    "    joined_seq = join_seqs(seqs_to_join)\n",
    "    # circularize?\n",
    "    return joined_seq\n",
    "\n",
    "\n",
    "to_join = [\n",
    "    (seq1.reverse_complement(), Restriction.BsaI),\n",
    "    (seq2, Restriction.BsaI),\n",
    "    (seq3, Restriction.BsaI),\n",
    "    (seq4, Restriction.BsaI),\n",
    "    # (seq5, Restriction.BsaI),\n",
    "]\n",
    "# check sticky end sequence/orientation compatibility = (\"AATG\", \"\")\n",
    "# enumerate sequences with RE binding site outside (sense=True then sense=False?)\n",
    "seqs_to_assemble = []\n",
    "for seq, enzyme in to_join:\n",
    "    seqs = digest_for_assembly(seq, enzyme, linear=False)\n",
    "    # TODO: ensure we choose the sequence with inward-pointing restriction sites (kwarg!)\n",
    "    seqs_to_assemble.append(seqs[0])\n",
    "assemble_sequences(seqs_to_assemble)\n",
    "\n",
    "# print(digest_for_assembly(seq1, Restriction.BsaI, linear=False))\n",
    "# 35/AGTA/CTCC\n",
    "# digest_for_assembly(seq1.reverse_complement(), Restriction.BsaI, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1.reverse_complement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_digest(seq1, Restriction.BsaI, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re_digest(seq1.reverse_complement(), Restriction.BsaI, linear=False)\n",
    "\n",
    "digest_for_assembly(seq1.reverse_complement(), Restriction.BsaI, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloning_util.slice_seq(seq1.reverse_complement(), 2139, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqc = cloning_util.slice_seq(seq1, 10, None) + cloning_util.slice_seq(seq1, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(seq1), len(seqc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloning_util.slice_seq(\n",
    "    seq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq) - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.overhang()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.ovhg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BbsI.charac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.AarI.charac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.AarI.elucidate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsmBI.charac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.SapI.charac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.SapI.elucidate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.charac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.characteristic??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.compsite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    cloning_util.slice_seq(seq, 0, 55, 0, 100)\n",
    "    + cloning_util.slice_seq(seq, 55, 70, 0, 100)\n",
    ").features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloning_util.slice_seq(seq, 5, 10, 0, 15).features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.letter_annotations??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.__add__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.__getitem__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydna.dseqrecord import Dseqrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dseq = Dseqrecord.from_SeqRecord(seq, circular=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dseq[:100].cut(Restriction.BsaI)[0].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dseq[:100].cut(Restriction.BsaI)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dseq.cut(Restriction.BsaI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.compsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finditer(pattern, size):\n",
    "    if self.is_linear():\n",
    "        data = self.data\n",
    "    else:\n",
    "        data = self.data + self.data[1:size]\n",
    "    return\n",
    "\n",
    "\n",
    "def search_re(enzyme, seq, linear=True):\n",
    "    # cuts = re.dna.finditer(re.compsite, re.size)\n",
    "    if not linear:\n",
    "        seq = seq + seq[1 : enzyme.size]\n",
    "    cuts = [(i.start(), i.group(1)) for i in re.finditer(enzyme.compsite, str(seq.seq))]\n",
    "    return list(cuts)\n",
    "\n",
    "\n",
    "search_re(Restriction.BsaI, seq, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sense-binding: sense cuts, antisense cuts\n",
    "# antisense-binding: antisense cuts, sense cuts\n",
    "# circular handling\n",
    "# for each cut: (sense cut, antisense cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1][1]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI._search??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.charac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dseq.seq.cut??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts = sorted(Restriction.BsaI.search(seq.seq, linear=False))\n",
    "cuts = cuts + cuts[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = [slice_seq(seq, x1 - 1, x2 - 1) for x1, x2 in zip(cuts[:-1], cuts[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include overhangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.characteristic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.fst5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restriction.BsaI.elucidate??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
