{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import toml\n",
    "import re\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "import string\n",
    "import pygsheets\n",
    "from tqdm.auto import tqdm\n",
    "import Bio.Restriction as Restriction\n",
    "from Bio.Seq import Seq\n",
    "import benchlingapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paulssonlab.api as api\n",
    "from paulssonlab.api.util import base_url\n",
    "import paulssonlab.cloning.workflow as workflow\n",
    "import paulssonlab.cloning.util as cloning_util\n",
    "import paulssonlab.cloning.sequence as sequence\n",
    "import paulssonlab.cloning.golden_gate as golden_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = benchlingapi.Session(config[\"benchling\"][\"api_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = pygsheets.authorize(service_account_file=\"credentials.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = workflow.get_strain_collection_sheets(gc.drive.service, \"LIB\")\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_sheet = gc.open_by_key(col[\"strains\"]).worksheet()\n",
    "plasmid_sheet = gc.open_by_key(col[\"plasmids\"]).worksheet()\n",
    "part_sheet = gc.open_by_key(col[\"parts\"]).worksheet()\n",
    "part_sequences_sheet = gc.open_by_key(col[\"parts\"]).worksheet_by_title(\"Sequences\")\n",
    "oligo_sheet = gc.open_by_key(col[\"oligos\"]).worksheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_service = plasmid_sheet.client.drive.service\n",
    "plasmid_folder = col[\"plasmid_maps\"]\n",
    "plasmid_maps = api.google.list_drive(drive_service, root=plasmid_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df = part_sheet.get_as_df().set_index(\"Name*\")\n",
    "df.loc[\"YFP_CD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "names = part_sheet.get_col(1)[1:]\n",
    "idx = names.index(\"YFP_CD\")\n",
    "part_sheet.get_row(idx + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oligo0_sheet = gc.open_by_key(col[\"oligos\"]).worksheet_by_title(\"Special (oLIB0.x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if clear=False, RENAME ^oLIB -> oTESTA in first column\n",
    "# temp: get parts, plasmid seqs\n",
    "# check that GG works\n",
    "# gibson\n",
    "# command: primer design for plasmid -> part storage vector (oligodest=oLIT)\n",
    "# PCR with flanks\n",
    "# primer design for fusion parts\n",
    "# commands: GG, Gib (need to specify recipient strain!)\n",
    "# get parts, plasmid seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.api.google import (\n",
    "    get_drive_by_path,\n",
    "    ensure_drive_folder,\n",
    "    make_drive_folder,\n",
    "    copy_drive_file,\n",
    "    list_drive,\n",
    "    clear_sheet,\n",
    "    FOLDER_MIMETYPE,\n",
    ")\n",
    "from paulssonlab.cloning.workflow import rename_ids\n",
    "\n",
    "FOLDER_TYPES = [\"plasmid_maps\", \"sequencing\"]\n",
    "COLLECTION_REGEX = r\"^(.*)_(strains|plasmids|oligos|parts|sequencing|plasmid_maps)$\"\n",
    "ENABLE_AUTOMATION_FILENAME = \"ENABLE_AUTOMATION.txt\"\n",
    "\n",
    "\n",
    "class Registry(object):\n",
    "    def __init__(self, sheets_client, registry_folder):\n",
    "        self.sheets_client = sheets_client\n",
    "        self.registry_folder = registry_folder\n",
    "        self.refresh()\n",
    "\n",
    "    def refresh(self):\n",
    "        collection_folders = list_drive(\n",
    "            self.sheets_client.drive.service, root=self.registry_folder, folder=True\n",
    "        )\n",
    "        registry = {}\n",
    "        for collection_folder in collection_folders.values():\n",
    "            new_registry = self.get_collection(collection_folder[\"id\"])\n",
    "            duplicate_keys = registry.keys() & new_registry.keys()\n",
    "            if len(duplicate_keys):\n",
    "                raise ValueError(f\"found duplicate prefixes: {list(duplicate_keys)}\")\n",
    "            registry = {**registry, **new_registry}\n",
    "        self.registry = registry\n",
    "\n",
    "    def get_collection(self, collection_folder):\n",
    "        files = list_drive(self.sheets_client.drive.service, root=collection_folder)\n",
    "        if ENABLE_AUTOMATION_FILENAME not in files:\n",
    "            return {}\n",
    "        registry = {}\n",
    "        for file in files.values():\n",
    "            name = file[\"name\"]\n",
    "            match = re.match(COLLECTION_REGEX, name)\n",
    "            if match:\n",
    "                prefix = match.group(1)\n",
    "                type_ = match.group(2)\n",
    "                ensure_drive_folder(file, type_ in FOLDER_TYPES)\n",
    "                key = (prefix, type_)\n",
    "                if key in registry:\n",
    "                    raise ValueError(f\"found duplicate prefix: {key}\")\n",
    "                registry[key] = file[\"id\"]\n",
    "        return registry\n",
    "\n",
    "    def duplicate_collection(\n",
    "        self,\n",
    "        source_prefix,\n",
    "        dest_prefix,\n",
    "        source_folder_name=None,\n",
    "        dest_folder_name=None,\n",
    "        clear=True,\n",
    "    ):\n",
    "        # TODO: handle parts spreadsheet clearing (keep formulae)\n",
    "        if source_folder_name is None:\n",
    "            source_folder_name = f\"{source_prefix}_collection\"\n",
    "        if dest_folder_name is None:\n",
    "            dest_folder_name = f\"{dest_prefix}_collection\"\n",
    "        drive_service = self.sheets_client.drive.service\n",
    "        collections = list_drive(drive_service, root=self.registry_folder)\n",
    "        if dest_folder_name in collections:\n",
    "            raise ValueError(f\"collection '{dest_folder_name}' already exists\")\n",
    "        if source_folder_name not in collections:\n",
    "            raise ValueError(f\"collection '{source_folder_name}' not found\")\n",
    "        source_folder = collections[source_folder_name].get(\"id\")\n",
    "        source_files = list_drive(drive_service, root=source_folder, folder=True)\n",
    "        dest_folder = make_drive_folder(\n",
    "            drive_service, dest_folder_name, self.registry_folder\n",
    "        )\n",
    "        for source_file in source_files.values():\n",
    "            if source_file[\"mimeType\"] == FOLDER_MIMETYPE:\n",
    "                continue\n",
    "            dest_file_name = None\n",
    "            if source_file[\"name\"] == ENABLE_AUTOMATION_FILENAME:\n",
    "                dest_file_name = ENABLE_AUTOMATION_FILENAME\n",
    "            else:\n",
    "                match = re.match(COLLECTION_REGEX, source_file[\"name\"])\n",
    "                if match:\n",
    "                    dest_type_prefix = re.sub(\n",
    "                        f\"{re.escape(source_prefix)}$\", dest_prefix, match.group(1)\n",
    "                    )\n",
    "                    dest_file_name = f\"{dest_type_prefix}_{match.group(2)}\"\n",
    "            if dest_file_name is not None:\n",
    "                dest_body = {\"name\": dest_file_name, \"parents\": [dest_folder]}\n",
    "                dest_file = (\n",
    "                    drive_service.files()\n",
    "                    .copy(fileId=source_file[\"id\"], body=dest_body)\n",
    "                    .execute()\n",
    "                )\n",
    "                if match:\n",
    "                    name_mapper = 0  # pass\n",
    "                    if match.group(2) in (\"plasmids\", \"strains\"):\n",
    "                        source_seq_folder_name = f\"{source_prefix}_sequencing\"\n",
    "                        dest_seq_folder_name = f\"{dest_type_prefix}_sequencing\"\n",
    "                        dest_seq_folder = make_drive_folder(\n",
    "                            drive_service, dest_seq_folder_name, dest_folder\n",
    "                        )\n",
    "                        if source_seq_folder_name in source_files:\n",
    "                            recursive_copy(\n",
    "                                drive_service,\n",
    "                                source_files[source_seq_folder_name],\n",
    "                                dest_seq_folder,\n",
    "                                transform_names=name_mapper,\n",
    "                            )\n",
    "                    if match.group(2) == \"plasmids\":\n",
    "                        source_map_folder_name = f\"{source_prefix}_maps\"\n",
    "                        dest_map_folder_name = f\"{dest_type_prefix}_maps\"\n",
    "                        dest_map_folder = make_drive_folder(\n",
    "                            drive_service, dest_map_folder_name, dest_folder\n",
    "                        )\n",
    "                        if source_map_folder_name in source_files:\n",
    "                            recursive_copy(\n",
    "                                drive_service,\n",
    "                                source_files[source_map_folder_name],\n",
    "                                dest_map_folder,\n",
    "                                transform_names=name_mapper,\n",
    "                            )\n",
    "                    if clear:\n",
    "                        # get first worksheet\n",
    "                        dest_sheet = self.sheets_client.open_by_key(\n",
    "                            dest_file[\"id\"]\n",
    "                        ).worksheet()\n",
    "                        clear_sheet(dest_sheet)\n",
    "                    elif match.group(2) not in (\"parts\",):\n",
    "                        # get first worksheet\n",
    "                        dest_sheet = self.sheets_client.open_by_key(\n",
    "                            dest_file[\"id\"]\n",
    "                        ).worksheet()\n",
    "                        rename_ids(dest_sheet, source_prefix, dest_type_prefix)\n",
    "        return dest_folder\n",
    "\n",
    "    def get_loc(self, name):\n",
    "        pass\n",
    "        # pull number off, try to match to prefix (plasmid, strain, oligo)\n",
    "        # get spreadsheet file, worksheet index\n",
    "        # return worksheet, row\n",
    "\n",
    "    def get_sequence(self, name):\n",
    "        # name = pLIB99, oLIB99, Part_Name\n",
    "        # try plasmid, strain, part\n",
    "        # return\n",
    "        # (\"plasmid\", SeqRecord)\n",
    "        # (\"part\", (\"5prime\", SeqRecord(\"AAA\"), \"3prime\"))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_copy(service, source_folder, dest_folder, folders_only=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = Registry(gc, config[\"registry\"][\"folder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry.duplicate_collection(\"LIB\", \"TESTA\", clear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = gc.open_by_key(\"1ZQubxSLcMyaIbcAbk286KwCIpmrKjMh6-_ApWxjSYYI\").worksheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.rename_ids(w, \"pLIB\", \"pTESTA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.google.clear_sheet(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry.registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gibson.assemble -> hhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = get_plib_seq(drive_service, 1)\n",
    "seq2 = get_plib_seq(drive_service, 82)\n",
    "seq3 = get_plib_seq(drive_service, 23)\n",
    "seq4 = get_plib_seq(drive_service, 95)\n",
    "seq5 = get_plib_seq(drive_service, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_join = [\n",
    "    (sequence.reverse_complement(seq1), Restriction.BsaI, \"Name1\", \"promoter\"),\n",
    "    (sequence.reverse_complement(seq2), Restriction.BsaI, \"Name2\", \"RBS\"),\n",
    "    (seq3, Restriction.BsaI, \"Name3\", \"CDS\"),\n",
    "    (seq4, Restriction.BsaI, \"Name4\", \"terminator\"),\n",
    "    (sequence.reverse_complement(seq5), Restriction.BsaI, \"Name5\", \"misc_feature\"),\n",
    "]\n",
    "\n",
    "assembly = golden_gate.assemble(to_join, linear=False)\n",
    "assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/jacob/Downloads/test3.gb\", \"w\") as f:\n",
    "    f.write(assembly.format(\"gb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tatsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_preamble = \"\"\"@@grammar::CLONING\n",
    "@@whitespace :: //\"\"\"\n",
    "\n",
    "reference_grammar = \"\"\"reference\n",
    "    =\n",
    "    | pcr\n",
    "    | restriction_digest\n",
    "#    | assembly\n",
    "    | name\n",
    "    ;\n",
    "\n",
    "name = name:/\\w+/ ;\n",
    "\n",
    "pcr = template:reference '~' ~ primer1:name ',' primer2:name ;\n",
    "\n",
    "restriction_digest = input:reference '/' ~ enzyme:name ;\n",
    "\n",
    "#assembly = assembly+:name {'-' ~ assembly+:name}+ ;\n",
    "\"\"\"\n",
    "\n",
    "grammar = f\"\"\"start = command $ ;\n",
    "\n",
    "argument\n",
    "    =\n",
    "    | quoted_string\n",
    "    | command\n",
    "    | float\n",
    "    | int\n",
    "    | lookup\n",
    "    | reference\n",
    "    ;\n",
    "\n",
    "ws = /\\s*/ ;\n",
    "\n",
    "command_name = '@' ~ @:/\\w+/ ;\n",
    "\n",
    "command_arglist = '(' ~ ws @+:argument ws {{',' ws @+:argument ws }}* ')' ;\n",
    "\n",
    "command = command_name:command_name arguments:command_arglist ;\n",
    "\n",
    "quoted_string = '\"' ~ quoted_string:/[^\"]*/ '\"' ;\n",
    "\n",
    "float = float:/\\d+\\.\\d+/ ;\n",
    "\n",
    "int = int:/\\d+/ ;\n",
    "\n",
    "lookup = '$' ~ name ;\n",
    "\n",
    "{reference_grammar}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = tatsu.compile(grammar)\n",
    "command = \"@Gib(@GG(UNS1, J23101, BCD11, UNS5), pLIB47~oLIB22,oLIB24/BsaI)\"\n",
    "ast = parser.parse(command)\n",
    "ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command = (\n",
    "#     \"@3G(UNS1-J23101-BCD11-mVenus-L3S3P11-UNS5, UNS5-J23150-CFP-BCD16-L3S2P55-UNS10)\"\n",
    "# )\n",
    "# command = \"@Gib(@GG(UNS1, J23101, BCD11, UNS5), pLIB47~oLIB22,oLIB24/BsaI)\"\n",
    "# command = \"@Gib(@GG(UNS1, J23101, BCD11, UNS5), @PCR(pLIB47, oLIB22, oLIB24)/BsaI)\"\n",
    "# command = (\n",
    "#     \"@Gib(@GG(UNS1, J23101, BCD11, UNS5), @RE(@PCR(pLIB47, oLIB22, oLIB24), BsaI))\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_sheet.sync?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_sequence(name, part_sheet, plasmid_maps):\n",
    "    # try plasmid, strain, part\n",
    "    pass\n",
    "\n",
    "\n",
    "def goldengate(*args):\n",
    "    return \"gg\", args\n",
    "\n",
    "\n",
    "def threeg(*args):\n",
    "    return \"3g\", args\n",
    "\n",
    "\n",
    "commands = {\"GG\": goldengate, \"3G\": threeg}\n",
    "\n",
    "get_named_sequence(\"pLIB27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_parser = tatsu.compile(grammar_preamble + reference_grammar)\n",
    "\n",
    "\n",
    "class CloningCommandSemantics(object):\n",
    "    def __init__(self, commands):\n",
    "        self.commands = commands\n",
    "\n",
    "    def command(self, ast):\n",
    "        if ast.command_name not in self.commands:\n",
    "            raise tatsu.semantics.SemanticError(\n",
    "                \"command must be one of: {}\".format(\n",
    "                    \", \".join([f\"@{k}\" for k in commands.keys()])\n",
    "                )\n",
    "            )\n",
    "        command = self.commands[ast.command_name]\n",
    "        return command(ast.arguments)\n",
    "\n",
    "    def int_(self, ast):\n",
    "        return int(s)\n",
    "\n",
    "    def float_(self, ast):\n",
    "        return float(s)\n",
    "\n",
    "    def name(self, ast):\n",
    "        return ast.name\n",
    "\n",
    "    def assembly(self, ast):\n",
    "        return ast.assembly\n",
    "\n",
    "\n",
    "# parser.parse(command, semantics=CloningCommandSemantics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GG\n",
    "command = \"@GG(J23101, BCD11, mVenus, L3S3P11, p121/BsaI)\"\n",
    "# 3G\n",
    "# command = \"@3G(@GG(UNS1, J23101, BCD11, mVenus, L3S3P11, UNS5), @GG(UNS5, J23150, CFP, BCD16, L3S2P55, UNS10), JUMP_p15a_UNS1_UNS10)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(command, semantics=CloningCommandSemantics(commands))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
