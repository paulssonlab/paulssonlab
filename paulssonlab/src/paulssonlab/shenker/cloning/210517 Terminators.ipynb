{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import toml\n",
    "import re\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "import string\n",
    "import pygsheets\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import Bio.Restriction as Restriction\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import benchlingapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paulssonlab.api as api\n",
    "import paulssonlab.api.benchling as bapi\n",
    "from paulssonlab.api.util import base_url\n",
    "import paulssonlab.cloning.registry as registry\n",
    "import paulssonlab.cloning.workflow as workflow\n",
    "import paulssonlab.cloning.sequence as sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = pygsheets.authorize(service_account_file=\"credentials.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_session = benchlingapi.Session(config[\"benchling\"][\"api_key\"])\n",
    "benchling_folder = bapi.get_project_root(bench_session, config[\"benchling\"][\"project\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = registry.Registry(gc, config[\"registry\"][\"folder\"], benchling_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_sheet = reg.get_sheet((\"LT\", \"strains\"))\n",
    "plasmid_sheet = reg.get_sheet((\"pLT\", \"plasmids\"))\n",
    "part_sheet = reg.get_sheet((\"LT\", \"parts\"))\n",
    "part_type_sheet = gc.open_by_key(col[\"parts\"]).worksheet_by_title(\"Part types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_service = plasmid_sheet.client.drive.service\n",
    "plasmid_folder = col[\"plasmid_maps\"]\n",
    "plasmid_maps = api.google.list_drive(drive_service, root=plasmid_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.get_sheet_by_id((\"LT\", \"parts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.get_sheet_by_id((\"LT\", \"parts\", \"Part types\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.get_sheet((\"LT\", \"parts\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voigt terminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/2013terminators_supp\n",
    "!curl -b does_not_exist -Lo data/2013terminators_supp/supptable2.xlsx \"https://static-content.springer.com/esm/art%3A10.1038%2Fnmeth.2515/MediaObjects/41592_2013_BFnmeth2515_MOESM206_ESM.xlsx\"\n",
    "!curl -b does_not_exist -Lo data/2013terminators_supp/supptable3.xlsx \"https://static-content.springer.com/esm/art%3A10.1038%2Fnmeth.2515/MediaObjects/41592_2013_BFnmeth2515_MOESM207_ESM.xlsx\"\n",
    "!curl -b does_not_exist -Lo data/2013terminators_supp/supptable4.xlsx \"https://static-content.springer.com/esm/art%3A10.1038%2Fnmeth.2515/MediaObjects/41592_2013_BFnmeth2515_MOESM208_ESM.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM: used https://www.adobe.com/acrobat/online/pdf-to-excel.html to convert\n",
    "# Table S1 (p. 23) from https://www.embopress.org/action/downloadSupplement?doi=10.15252%2Fmsb.20209584&file=msb209584-sup-0001-AppendixFig.pdf\n",
    "\n",
    "voigt_bidirectional_terms_tsv = \"\"\"\n",
    "name\tsequence\tTs_forward\tTs_reverse\n",
    "DT3\t\"CCGGCTTATCGGTCAGTTTCACCTGATTTACGTAAAAACCCGCTTCGGCGGGTTTTTGCTTTTGGAGGGGCAGAAAGATGAATGACTGTCCACGACGCTATACCCAAAAGAAAAAAAAAAAACCCCGCCCCTGACAGGGCGGGGTTTTTTTT\"\t\t3000\t\t\t\t120\t\t\n",
    "DT5\t\"TCCGGCAATTAAAAAAGCGGCTAACCACGCCGCTTTTTTTACGTCTGCACTCGGTACCAAATTCCAGAAAAGAGGCCTCCCGAAAGGGGGGCCTTTTTTCGTTTTGGTCC\"\t\t4700\t\t\t\t50\t\t\n",
    "DT19\tTTCAGCCAAAAAACTTAAGACCGCCGGTCTTGTCCACTACCTTGCAGTAATGCGGTGGACAGGATCGGCGGTTTTCTTTTCTCTTCTCAACTCGGTACCAAAGACGAACAATAAGACGCTGAAAAGCGTCTTTTTTCGTTTTGGTCC\t770\t\t\t\t1.2\t\t\t\n",
    "DT34\tGCTGATGCCAGAAAGGGTCCTGAATTTCAGGGCCCTTTTTTTACATGGATTGCTCGGTACCAAATTCCAGAAAAGAGACGCTTTCGAGCGTCTTTTTTCGTTTTGGTCC\t570\t\t\t\t1.4\t\t\t\n",
    "DT36\tGATCTAACTAAAAAGGCCGCTCTGCGGCCTTTTTTCTTTTCACTGTAACAACGGAAACCGGCCATTGCGCCGGTTTTTTTTGGCCT\t680\t\t\t\t3.2\t\t\t\n",
    "DT42\t\"AGTTAACCAAAAAGGGGGGATTTTATCTCCCCTTTAATTTTTCCTCGCAGATAGCAAAAAAGCGCCTTTAGGGCGCTTTTTTACATTG\n",
    "GTGG\"\t2500\t\t\t\t2.2\t\t\t\n",
    "DT54\t\"GGAAACACAGAAAAAAGCCCGCACCTGACAGTGCGGGCTTTTTTTTTCGACCAAAGGCTCGGTACCAAATTCCAGAAAAGACACCCGAAAGGGTGTTTTTTCGTTTTGGTCC\"\t\t1800\t\t\t\t30\t\t\n",
    "DT56\tTACCACCGTCAAAAAAAACGGCGCTTTTTAGCGCCGTTTTTATTTTTCAACCTTCCAGGCATCAAATAAAACGAAAGGCTCAGTCGAAAGACTGGGCCTTTCGTTTTATCTGTTGTTTGTCGGTGAACGCTCTC\t240\t\t\t\t11\t\t\t\n",
    "DT60\tACATTTAATAAAAAAAGGGCGGTCGCAAGATCGCCCTTTTTTACGTATGACACAGTGAAAAATGGCGCCCATCGGCGCCATTTTTTTATG\t110\t\t\t\t29\t\t\t\n",
    "DT65\tTGCTCGTACCAGGCCCCTGCAATTTCAACAGGGGCCTTTTTTTATCCAATTCCATCGGGTCCGAATTTTCGGACCTTTTCTCCGC\t400\t\t\t\t1.0\t\t\t\n",
    "DT82\t\"CTTATTCCATAACAAAGCCGGGTAATTCCCGGCTTTGTTGTATCTGAACAATAAATGGATGCCCTGCGTAAGCGGGGCATTTTTCTTCCT\"\t170\t\t\t\t2.8\t\t\t\n",
    "DT83\tAGCGTCAAAAGGCCGGATTTTCCGGCCTTTTTTATTAGGCAGCATGCTGCCAGGTGATCCCCCTGGCCACCTCTTTT\t600\t\t\t\t4.4\t\t\t\n",
    "DT86\tTAATCATTCTTAGCGTGACCGGGAAGTCGGTCACGCTACCTCTTCTGAAGAAACAGCAAACAATCCAAAACGCCGCGTTCAGCGGCGTTTTTTCTGCTTTTCT\t210\t\t\t\t0.4\t\t\t\n",
    "DT100\t\"GTGAAGTGAAAAATGGCGCACATTGTGCGCCATTTTTTTTGTCTGCCGTTTACCGCTTCTCTGAAAATCAACGGGCAGGTCACTGACTTGCCCGTTTTTTTATCCCTTCTCCACACCG\"\t4700\t\t\t\t12\t\t\t\n",
    "DT101\t\"TCTTTAAAAAGAAACCTCCGCATTGCGGAGGTTTCGCCTTTTGATACTCTGTCTGAAGTAATTCTTGCCGCAGTGAAAAATGGCGCCCATCGGCGCCATTTTTTTATGCTTCCATTAGAAAGCAAAAAGCCTGCTAGAAAGCAGGCTTTTTTGAATTTGGCTCCTCTGAC\"\t\t2800\t\t\t\t160\t\t\n",
    "DT103\t\"AAAGTTCTGAAAAAGGGTCACTTCGGTGGCCCTTTTTTATCGCCACGGTTTGAGCAGTGCACTTGCTTAAAATCCCGCCAGCGGCGGGATTTTTTATTGTCCGGTTTAAGACA\"\t790\t\t\t\t4.0\t\t\t\n",
    "DT104\t\"GCAGACAAAAAAAATGGCGCACAATGTGCGCCATTTTTCACTTCACAGGTACTATTGTTTTGAATTGAAAAGGGCGCTTCGGCGCCCTTTTTGCATTTGTTGACGGCATATATTTGTATATCGAAGCGCCCTGATGGGCGCTTTTTTTATTTAATCGATAACCAGA\"\t\t580\t\t\t\t101\t\t\n",
    "\"\"\"\n",
    "\n",
    "import io\n",
    "\n",
    "voigt_bidirectional_terms = pd.read_csv(\n",
    "    io.StringIO(voigt_bidirectional_terms_tsv), sep=\"\\s+\", index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_terms = voigt_bidirectional_terms[\n",
    "    voigt_bidirectional_terms[\"Ts_reverse\"] >= 10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makeshift oligo orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_seq(seq):\n",
    "    return str(sequence.get_seq(seq)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_GBLOCK = [\"DT3\", \"DT56\", \"DT60\"]\n",
    "# NO_GBLOCK = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overhangs = [\"aggt\", \"gctt\"]\n",
    "random_bases = (\n",
    "    \"GCTTCA\",\n",
    "    \"TGCTAA\",\n",
    ")  # to add between BsmBI recognition site and ends of oligos\n",
    "flanks = (\"CGTCTCGGTCTCa\", \"tGAGACCgGAGACG\")  # storage vector BsmBI flanks\n",
    "seqs_to_order = {}\n",
    "for term_name, row in selected_terms.iterrows():\n",
    "    seq = row[\"sequence\"]\n",
    "    seq = workflow.add_flanks(\n",
    "        workflow.add_overhangs(seq.lower(), overhangs),\n",
    "        [flanks, random_bases],\n",
    "    )\n",
    "    seqs_to_order[term_name] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_to_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"oLT\"\n",
    "id_num = 37\n",
    "for term_name, seq in seqs_to_order.items():\n",
    "    if term_name in NO_GBLOCK:\n",
    "        continue\n",
    "    # for sense in (False, True):\n",
    "    for sense in (True,):\n",
    "        if sense:\n",
    "            oligo_seq = seq\n",
    "        else:\n",
    "            oligo_seq = sequence.reverse_complement(seq)\n",
    "        id_ = f\"{prefix}{id_num}\"\n",
    "        name = f\"Voigt_{term_name}\"\n",
    "        print(f\"{id_}\\t{name}\\t{_format_seq(oligo_seq)}\")\n",
    "        # print(f\"{name}\\t{_format_seq(oligo_seq)}\")\n",
    "        id_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term_name, seq in seqs_to_order.items():\n",
    "    if term_name not in NO_GBLOCK:\n",
    "        continue\n",
    "    for sense in (True, False):\n",
    "        if sense:\n",
    "            oligo_seq = seq\n",
    "        else:\n",
    "            oligo_seq = sequence.reverse_complement(seq)\n",
    "        id_ = f\"{prefix}{id_num}\"\n",
    "        name = f\"Voigt_{term_name}_{'sense' if sense else 'antisense'}\"\n",
    "        print(f\"{id_}\\t{name}\\t{_format_seq(oligo_seq)}\")\n",
    "        id_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_type = \"Terminator_DE\"\n",
    "random_bases = (\"GCTTCA\", \"TGCTAA\")\n",
    "flanks = (\"CGTCTCGGTCTCa\", \"tGAGACCgGAGACG\")\n",
    "part_enzyme = Restriction.BsaI\n",
    "storage_enzyme = Restriction.BsmBI\n",
    "storage_vector_id = \"pLIB112\"\n",
    "\n",
    "background_strain = \"DH5alpha\"\n",
    "tags = \"bidirectional-terminators terminators\"\n",
    "author = \"Jacob Quinn Shenker\"\n",
    "date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "species = \"E. coli\"\n",
    "reference = \"Park, Y., Espah Borujeni, A., Gorochowski, T. E., Shin, J., & Voigt, C. A. (2020). Precision design of stable genetic circuits carried in highly‐insulated E. coli genomic landing pads. Molecular systems biology, 16(8), e9584.\"\n",
    "confirmation_notes = \"Sanger sequencing with oLIB203+oLIB204.\"\n",
    "\n",
    "oligo_description = \"Annealed oligos for Voigt bidirectional terminator parts.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_types = part_type_sheet.get_as_df().set_index(\"Type*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overhangs = part_types.loc[part_type, [\"Upstream overhang\", \"Downstream overhang\"]]\n",
    "overhangs = [o.upper() for o in overhangs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: defaults to E. coli\n",
    "aa_to_codons = codon.codons_by_relative_frequency()\n",
    "# force only using TAA as stop codon\n",
    "aa_to_codons = {**aa_to_codons, \"*\": {\"TAA\": 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_sequences_to_order = dict(\n",
    "    sigmas.loc[sigma_subset_info[\"Sigma\"], \"Sequence\"].items()\n",
    ")\n",
    "antisigma_sequences_to_order = dict(\n",
    "    antisigmas.loc[sigma_subset_info[\"Antisigma\"], \"Sequence\"].items()\n",
    ")\n",
    "promoter_sequences_to_order = dict(\n",
    "    sigma_promoters.loc[\n",
    "        sigma_subset_info[\"Promoter\"], \"Promoter sequence (-60 to +20)\"\n",
    "    ].items()\n",
    ")\n",
    "_sequences_to_order = {\n",
    "    \"promoter\": promoter_sequences_to_order,\n",
    "    \"sigma\": sigma_sequences_to_order,\n",
    "    \"antisigma\": antisigma_sequences_to_order,\n",
    "}\n",
    "sequences_to_order = {}\n",
    "# prepare seq\n",
    "for kind, seqs in _sequences_to_order.items():\n",
    "    for name, seq in seqs.items():\n",
    "        item = {}\n",
    "        item[\"name\"] = name\n",
    "        item[\"kind\"] = kind\n",
    "        if kind == \"promoter\":\n",
    "            seq = workflow.add_flanks(\n",
    "                workflow.add_overhangs(seq.upper(), promoter_overhangs),\n",
    "                [flanks, random_bases],\n",
    "            )\n",
    "            item[\"cds_location\"] = None\n",
    "        else:\n",
    "            aa_seq = seq + cds_aa_suffix\n",
    "            item[\"aa_seq\"] = aa_seq\n",
    "            seq = codon.back_translate(aa_seq, aa_to_codons)\n",
    "            cds_length = len(seq)\n",
    "            seq = workflow.add_flanks(\n",
    "                workflow.add_overhangs(seq.upper(), cds_overhangs), [flanks]\n",
    "            )\n",
    "            # because overhang (aATG) has an extra a\n",
    "            cds_start = len(flanks[0]) + cds_overhang_shift\n",
    "            cds_end = cds_start + cds_length\n",
    "            item[\"cds_location\"] = (cds_start, cds_end)\n",
    "        seq = SeqRecord(Seq(seq))  # ensure our pipeline propagates features correctly\n",
    "        item[\"initial_seq\"] = seq\n",
    "        sequences_to_order[name] = item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use DnaChisel to optimize sequences ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(sequences_to_order.values()):\n",
    "    # if cds_location is defined\n",
    "    if item[\"cds_location\"] is not None:\n",
    "        seq = item[\"initial_seq\"]\n",
    "        new_seq = optimization.dnachisel(\n",
    "            seq,\n",
    "            *optimization.dnachisel_constraints_for_twist(\n",
    "                seq,\n",
    "                cds_location=item[\"cds_location\"],\n",
    "                avoid_enzymes=avoid_enzymes,\n",
    "                aa_to_codons=aa_to_codons,\n",
    "                genetic_table=\"Bacterial\",\n",
    "            ),\n",
    "        )\n",
    "        item[\"optimized_seq\"] = new_seq\n",
    "        item[\"final_seq\"] = workflow.add_flanks(new_seq, [twist_adaptors])\n",
    "    else:\n",
    "        item[\"final_seq\"] = item[\"optimized_seq\"] = item[\"initial_seq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitute sequences with Twist-optimized sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only needed if using Twist web interface to manually optimize sequences. Otherwise use DnaChisel and/or Twist API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_seq(seq):\n",
    "    return str(sequence.get_seq(seq)).lower()\n",
    "\n",
    "\n",
    "for item in sequences_to_order.values():\n",
    "    if item[\"kind\"] != \"promoter\":\n",
    "        print(f\"{item['name']}\\t{_format_seq(item['optimized_seq'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: we're cheating and manually running Twist codon optimization through the web interface\n",
    "twist_seqs = pd.read_csv(\"201013voigtsigmas.csv\").set_index(\"Name\")\n",
    "for item in sequences_to_order.values():\n",
    "    name = item[\"name\"]\n",
    "    if item[\"kind\"] != \"promoter\":\n",
    "        try:\n",
    "            if (\n",
    "                _format_seq(item[\"optimized_seq\"]).lower()\n",
    "                != twist_seqs.loc[name, \"Insert sequence\"].lower()\n",
    "            ):\n",
    "                print(f\"substituting codon-optimized Twist sequence for {name}\")\n",
    "            else:\n",
    "                print(f\"adding Twist adapters for {name}\")\n",
    "            # TODO: copy features\n",
    "            item[\"optimized_seq\"] = SeqRecord(\n",
    "                Seq(twist_seqs.loc[name, \"Insert sequence\"])\n",
    "            )\n",
    "        except:\n",
    "            print(f\"could not find Twist sequence for {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check restriction sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_re_site_counts = {\"BsaI\": 2, \"BsmBI\": 2, \"AarI\": 0, \"BbsI\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in sequences_to_order.values():\n",
    "    for enzyme, expected_count in correct_re_site_counts.items():\n",
    "        cuts = golden_gate.re_search(\n",
    "            item[\"optimized_seq\"], getattr(Restriction, enzyme)\n",
    "        )\n",
    "        if len(cuts) != expected_count:\n",
    "            print(\n",
    "                f\"Expected {expected_count} {enzyme} cuts in {item['name']}, instead found cuts at: {cuts}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that CDSes match expected translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in sequences_to_order.values():\n",
    "    if \"aa_seq\" in item:\n",
    "        aa_seq = item[\"aa_seq\"]\n",
    "        translation = item[\"optimized_seq\"][slice(*item[\"cds_location\"])].translate()\n",
    "        if aa_seq != translation.seq:\n",
    "            print(\n",
    "                f\"{item['name']}: translation did not match expected amino acid sequence\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to strain collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligo0_sheet = gc.open_by_key(col[\"oligos\"]).worksheet_by_title(\"Special (oLIB0.x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptions listing corresponding promoter/sigma/antisigma/fold change/growth rates.; with double-stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_vector_seq = workflow.get_drive_seq(\n",
    "    drive_service, col[\"plasmid_maps\"], storage_vector_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plasmids_df = plasmid_sheet.get_as_df().set_index(\"ID*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_oligo = {\"Date*\": date, \"Author*\": author, \"Description\": oligo_description}\n",
    "\n",
    "base_part = {\n",
    "    \"Tags\": tags,\n",
    "    \"Author\": author,\n",
    "    \"Date*\": date,\n",
    "    \"Species/codon usage*\": species,\n",
    "    \"Reference\": reference,\n",
    "}\n",
    "\n",
    "base_plasmid = {\n",
    "    \"Origin*\": plasmids_df.loc[storage_vector_id, \"Origin*\"],\n",
    "    \"Marker*\": plasmids_df.loc[storage_vector_id, \"Marker*\"],\n",
    "}\n",
    "\n",
    "base_strain = {\n",
    "    \"Species*\": species,\n",
    "    \"Background*\": background_strain,\n",
    "    \"Parent*\": background_strain,\n",
    "    \"Marker*\": plasmids_df.loc[storage_vector_id, \"Marker*\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(oligo_prefix, oligo_num), oligo_row = workflow.get_next_collection_id(oligo0_sheet)\n",
    "(plasmid_prefix, plasmid_num), plasmid_row = workflow.get_next_collection_id(\n",
    "    plasmid_sheet\n",
    ")\n",
    "(strain_prefix, strain_num), strain_row = workflow.get_next_collection_id(strain_sheet)\n",
    "part_row = workflow.get_next_empty_row(part_sheet)\n",
    "parts = []\n",
    "oligos = []\n",
    "plasmids = []\n",
    "plasmid_maps = {}\n",
    "strains = []\n",
    "\n",
    "\n",
    "def _format_seq(seq):\n",
    "    return str(sequence.get_seq(seq)).lower()\n",
    "\n",
    "\n",
    "for item in sequences_to_order.values():\n",
    "    name = item[\"name\"]\n",
    "    kind = item[\"kind\"]\n",
    "    seq = item[\"final_seq\"]\n",
    "    # description\n",
    "    row = sigma_subset_info.loc[\n",
    "        sigma_subset_info.loc[:, kind.capitalize()] == name\n",
    "    ].iloc[0]\n",
    "    description = f\"\"\"Sigma/antisigma/promoter: {row[\"Sigma\"]}/{row[\"Antisigma\"]}/{row[\"Promoter\"]}\n",
    "    Sigma/antisigma fold change at max induction: {row[\"Sigma max\"]:.0f}x / {row[\"Antisigma max\"]:.0f}x\n",
    "    Sigma/antisigma growth rate: {row[\"Sigma growth\"]:.0f}% / {row[\"Antisigma growth\"]:.0f}%\"\"\"\n",
    "    if kind != \"promoter\":\n",
    "        description += \"\\nCDS with double stop codon.\"\n",
    "    # part\n",
    "    part_digest = golden_gate.re_digest(seq, part_enzyme, linear=True)\n",
    "    part_seq, overhang1, overhang2 = part_digest[0]\n",
    "    usage = f\"{plasmid_prefix}{plasmid_num}/{part_enzyme.__name__}\"\n",
    "    if kind == \"promoter\":\n",
    "        usage += f\",{oligo_prefix}{oligo_num}={oligo_prefix}{oligo_num+1}/{part_enzyme.__name__}\"\n",
    "    part = {\n",
    "        \"Name*\": name,\n",
    "        \"Usage*\": usage,\n",
    "        \"Upstream overhang*\": _format_seq(overhang1[0]),\n",
    "        \"Downstream overhang*\": _format_seq(overhang2[0]),\n",
    "        \"Sequence*\": _format_seq(overhang1[0] + part_seq + overhang2[0]),\n",
    "        \"Description\": description,\n",
    "        **base_part,\n",
    "    }\n",
    "    parts.append(part)\n",
    "    # strain\n",
    "    plasmid_id = f\"{plasmid_prefix}{plasmid_num}\"\n",
    "    strain = {\n",
    "        \"ID*\": f\"{strain_prefix}{strain_num}\",\n",
    "        \"Names\": name,\n",
    "        \"Plasmid(s)*\": plasmid_id,\n",
    "        **base_strain,\n",
    "    }\n",
    "    strains.append(strain)\n",
    "    strain_num += 1\n",
    "    # plasmid map\n",
    "    to_join = [\n",
    "        (seq, storage_enzyme),\n",
    "        (storage_vector_seq, storage_enzyme),\n",
    "    ]\n",
    "    plasmid_map = golden_gate.assemble(to_join, linear=False)\n",
    "    filename = f\"{plasmid_id}.gbk\"\n",
    "    content = plasmid_map.format(\"genbank\")\n",
    "    plasmid_maps[filename] = {\n",
    "        \"content\": content,\n",
    "        \"mimetype\": \"chemical/seq-na-genbank\",\n",
    "    }\n",
    "    # plasmid\n",
    "    command = f\"@GG({oligo_prefix}{oligo_num}={oligo_prefix}{oligo_num+1}/{storage_enzyme.__name__}, {storage_vector_id}/{storage_enzyme.__name__})\"\n",
    "    if kind == \"promoter\":\n",
    "        construction_notes = f\"{storage_enzyme.__name__} golden gate of annealed oligos {oligo_prefix}{oligo_num}={oligo_prefix}{oligo_num+1} into storage vector {storage_vector_id}.\"\n",
    "    else:\n",
    "        construction_notes = f\"{storage_enzyme.__name__} golden gate of {oligo_prefix}{oligo_num} into storage vector {storage_vector_id}.\"\n",
    "    plasmid = {\n",
    "        \"Command\": command,\n",
    "        \"ID*\": plasmid_id,\n",
    "        \"Names\": name,\n",
    "        \"Description\": description,\n",
    "        \"Size (bp)\": len(plasmid_map),\n",
    "        \"Construction Notes\": construction_notes,\n",
    "        \"Confirmation Notes\": confirmation_notes,\n",
    "        **base_plasmid,\n",
    "    }\n",
    "    plasmids.append(plasmid)\n",
    "    plasmid_num += 1\n",
    "    # oligo\n",
    "    item[\n",
    "        \"oligo_id\"\n",
    "    ] = f\"{oligo_prefix}{oligo_num}\"  # for promoters, this only records the first (top) annealed oligo\n",
    "    if kind == \"promoter\":\n",
    "        for strand, oligo_seq in [(\"top\", seq), (\"bottom\", seq.reverse_complement())]:\n",
    "            oligo = {\n",
    "                \"ID*\": f\"{oligo_prefix}{oligo_num}\",\n",
    "                \"Name\": f\"{name}_{strand}\",\n",
    "                \"Vendor*\": \"Genewiz\",\n",
    "                \"Type\": \"Primer\",\n",
    "                \"Sequence*\": _format_seq(oligo_seq),\n",
    "                **base_oligo,\n",
    "            }\n",
    "            oligos.append(oligo)\n",
    "            oligo_num += 1\n",
    "    else:\n",
    "        oligo = {\n",
    "            \"ID*\": f\"{oligo_prefix}{oligo_num}\",\n",
    "            \"Name\": f\"{name}\",\n",
    "            \"Vendor*\": \"Twist\",\n",
    "            \"Type\": \"Twist Gene Fragment\",\n",
    "            \"Sequence*\": _format_seq(item[\"optimized_seq\"]),\n",
    "            **base_oligo,\n",
    "        }\n",
    "        oligos.append(oligo)\n",
    "        oligo_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genewiz sequences to order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product, repeat\n",
    "\n",
    "for well, oligo in zip(cloning_util.well_iterator(), oligos):\n",
    "    if oligo[\"Vendor*\"] == \"Genewiz\":\n",
    "        print(f\"{oligo['ID*'].replace('.', '_')}\\t{oligo['Sequence*']}\")\n",
    "        # print(f\"{well}\\t{oligo['ID*']}\\t{oligo['Sequence*']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twist sequences to order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for oligo in oligos:\n",
    "#     if oligo[\"Vendor*\"] == \"Twist\":\n",
    "#         print(f\"{oligo['ID*']}\\t{oligo['Sequence*']}\")\n",
    "for item in sequences_to_order.values():\n",
    "    if item[\"kind\"] != \"promoter\":\n",
    "        print(f\"{item['oligo_id']}\\t{_format_seq(item['optimized_seq'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = {\n",
    "    \"oligos\": oligos,\n",
    "    \"plasmids\": plasmids,\n",
    "    \"plasmid_maps\": plasmid_maps,\n",
    "    \"strains\": strains,\n",
    "    \"parts\": parts,\n",
    "    \"sequences_to_order\": sequences_to_order,\n",
    "    \"oligo_row\": oligo_row,\n",
    "    \"plasmid_row\": plasmid_row,\n",
    "    \"strain_row\": strain_row,\n",
    "    \"part_row\": part_row,\n",
    "}\n",
    "with open(\"201013voigtsigmas.json\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.google.insert_sheet_rows(plasmid_sheet, plasmid_row, plasmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.google.insert_sheet_rows(strain_sheet, strain_row, strains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.google.insert_sheet_rows(oligo0_sheet, oligo_row, oligos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.upload_plasmid_maps(drive_service, plasmid_maps, plasmid_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plasmid_maps.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
