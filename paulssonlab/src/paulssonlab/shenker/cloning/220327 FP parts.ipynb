{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import toml\n",
    "import pygsheets\n",
    "from tqdm.auto import tqdm\n",
    "import Bio.Restriction as Restriction\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paulssonlab.api as api\n",
    "from paulssonlab.api.util import base_url\n",
    "import paulssonlab.cloning.registry as registry\n",
    "import paulssonlab.cloning.workflow as workflow\n",
    "import paulssonlab.cloning.sequence as sequence\n",
    "import paulssonlab.cloning.enzyme as enzyme\n",
    "import paulssonlab.cloning.design as design\n",
    "import paulssonlab.cloning.primers as primers\n",
    "import paulssonlab.cloning.io as cio\n",
    "import paulssonlab.api.geneious as geneious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = pygsheets.authorize(service_account_file=\"credentials.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneious_sessionmaker = geneious.connect(**config[\"geneious\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = registry.Registry(\n",
    "    gc,\n",
    "    config[\"registry\"][\"folder\"],\n",
    "    geneious_sessionmaker=geneious_sessionmaker,\n",
    "    geneious_folder=\"registry\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olib_oligos = reg[(\"oLIB\", \"oligos\")]\n",
    "plib_plasmids = reg[(\"pLIB\", \"plasmids\")]\n",
    "plib_maps = reg[(\"pLIB\", \"maps\")]\n",
    "flib_fragments = reg[(\"fLIB\", \"fragments\")]\n",
    "part_types = reg[(\"fLIB\", \"fragments\", \"Part types\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primers to make FP parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg_overhangs = workflow.overhangs_for(part_types[\"CDS_CD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_flanks = (\n",
    "    flib_fragments.find({\"Name\": \"JUMP_storage_vector_prefix\"})[\"Sequence\"],\n",
    "    flib_fragments.find({\"Name\": \"JUMP_storage_vector_suffix\"})[\"Sequence\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua_rbs = \"tctagatttaagaaggagatatacat\"\n",
    "cluzel_cterm = \"atgtccagacctgcaggcatgcaagctctagaggcat\"\n",
    "flanks = (ua_rbs + \"atg\", \"taa\" + cluzel_cterm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source plasmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# plasmids = {\n",
    "#     row[\"Names\"]: plib_maps[id_]\n",
    "#     for id_, row in plib_plasmids.items()\n",
    "#     if \"cluzel-fp\" in row[\"Tags\"]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "addgene_publication = api.addgene.get_addgene(\n",
    "    \"https://www.addgene.org/browse/article/28192043/\"\n",
    ")\n",
    "plasmids = {}\n",
    "for item in tqdm(addgene_publication[\"items\"]):\n",
    "    name = item[\"plasmid\"]\n",
    "    plasmids[name] = cio.read_http(item[\"sequence_urls\"][\"addgene_full\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plasmids.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract FP inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "locations = {\n",
    "    name: sequence.amplicon_location(\n",
    "        seq, flanks[0], sequence.reverse_complement(flanks[1])\n",
    "    )\n",
    "    for name, seq in plasmids.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inserts = {name: seq.slice(*locations[name]) for name, seq in plasmids.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check restriction sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for enzyme_name in (\"BsaI\", \"BsmBI\", \"BbsI\", \"AarI\"):\n",
    "    names_with_cuts = []\n",
    "    for name, seq in inserts.items():\n",
    "        cuts = enzyme.re_search(seq, enzyme_name)\n",
    "        if cuts:\n",
    "            names_with_cuts.append(name)\n",
    "    print(f\"{enzyme_name} ({len(names_with_cuts)}): {', '.join(names_with_cuts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find FP common ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_end_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_ends = {\n",
    "    name: (\n",
    "        seq.seq_lower()[:max_end_length],\n",
    "        seq.seq_lower()[-max_end_length:][::-1],\n",
    "    )\n",
    "    for name, seq in inserts.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import ChainMap\n",
    "\n",
    "\n",
    "def cluster_by_prefix(d, start_index=0, num_subseqs=None, max_length=None):\n",
    "    seqs = list(d.values())\n",
    "    if num_subseqs is None:\n",
    "        num_subseqs = min(len(seq) for seq in seqs)\n",
    "    if max_length is None:\n",
    "        max_length = max(len(subseq) for seq in seqs for subseq in seq[:num_subseqs])\n",
    "    mismatch = False\n",
    "    for idx in range(max_length):\n",
    "        for subseq_idx in range(num_subseqs):\n",
    "            base0 = seqs[0][subseq_idx][idx]\n",
    "            if not all(seq[subseq_idx][idx] == base0 for seq in seqs[1:]):\n",
    "                mismatch = True\n",
    "                break\n",
    "        if mismatch:\n",
    "            break\n",
    "    if not mismatch:\n",
    "        # idx refers to the first mismatched base, so if no mismatches found, set to max_length\n",
    "        idx += 1\n",
    "    common_key = tuple(\n",
    "        seqs[0][subseq_idx][start_index:idx] for subseq_idx in range(num_subseqs)\n",
    "    )\n",
    "    if idx > start_index:\n",
    "        if idx == max_length:\n",
    "            values = tuple(d.keys())\n",
    "        else:\n",
    "            values = cluster_by_prefix(\n",
    "                d,\n",
    "                start_index=idx,\n",
    "                num_subseqs=num_subseqs,\n",
    "                max_length=max_length,\n",
    "            )\n",
    "        res = {common_key: values, \"_size\": len(d)}\n",
    "        return res\n",
    "    else:\n",
    "        clusters = {}\n",
    "        for name, seq in d.items():\n",
    "            key = tuple(\n",
    "                seq[subseq_idx][start_index : idx + 1]\n",
    "                for subseq_idx in range(num_subseqs)\n",
    "            )\n",
    "            clusters.setdefault(key, {})\n",
    "            clusters[key][name] = seq\n",
    "        res = ChainMap(\n",
    "            {\"_size\": len(d)},\n",
    "            *[\n",
    "                cluster_by_prefix(\n",
    "                    cluster,\n",
    "                    start_index=idx,\n",
    "                    num_subseqs=num_subseqs,\n",
    "                    max_length=max_length,\n",
    "                )\n",
    "                for cluster in clusters.values()\n",
    "            ],\n",
    "        )\n",
    "        return res\n",
    "\n",
    "\n",
    "c = cluster_by_prefix(insert_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "\n",
    "def print_clusters(clusters, length=0, indent_level=0, extra_indent=4, wrap_width=100):\n",
    "    indent_str = \" \" * indent_level\n",
    "    for key, cluster in clusters.items():\n",
    "        if key == \"_size\":\n",
    "            continue\n",
    "        segment = \"/\".join(key)\n",
    "        if isinstance(cluster, tuple):\n",
    "            num_seqs = len(cluster)\n",
    "        else:\n",
    "            num_seqs = cluster[\"_size\"]\n",
    "        new_length = length + len(key[0])\n",
    "        print(f\"{indent_str}{segment} ({new_length}nt x {num_seqs}):\")\n",
    "        if isinstance(cluster, tuple):\n",
    "            print(\n",
    "                textwrap.fill(\n",
    "                    \", \".join(cluster),\n",
    "                    width=wrap_width,\n",
    "                    initial_indent=\" \" * (indent_level + extra_indent),\n",
    "                    subsequent_indent=\" \" * (indent_level + extra_indent),\n",
    "                    break_long_words=True,\n",
    "                )\n",
    "            )\n",
    "            print()\n",
    "        else:\n",
    "            print_clusters(cluster, length=new_length, indent_level=indent_level + 2)\n",
    "\n",
    "\n",
    "print_clusters(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design primers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import primer3plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flanks = workflow.concatenate_flanks(gg_overhangs, storage_flanks)\n",
    "primers.primer3_amplicon(inserts[\"pEB1-SCFP3A\"], flanks, return_many=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make find_primer_binding_site more general,\n",
    "# allow specifying score func so can find amplicons with overhangs on both sides?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USE CASES:\n",
    "# 1) take desired product, template seq, find overhangs\n",
    "# 2) take amplicon, optional overhangs\n",
    "\n",
    "# TODO:\n",
    "# tm/ta settings for Q5/phusion\n",
    "\n",
    "\n",
    "primer3_amplicon_primers(\n",
    "    inserts[\"pEB1-SCFP3A\"], [gg_overhangs, storage_flanks], return_many=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
