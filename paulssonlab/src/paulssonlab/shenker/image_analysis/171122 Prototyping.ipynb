{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import Counter\n",
    "\n",
    "import datashader as ds\n",
    "import holoviews as hv\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import peakutils\n",
    "import scipy.interpolate\n",
    "import scipy.stats\n",
    "import skimage\n",
    "import skimage.morphology\n",
    "import sklearn\n",
    "import zarr\n",
    "from bokeh.io import output_notebook, push_notebook, show\n",
    "from bokeh.models import WheelZoomTool\n",
    "from holoviews.operation import decimate\n",
    "from holoviews.operation.datashader import (\n",
    "    aggregate,\n",
    "    datashade,\n",
    "    dynspread,\n",
    "    regrid,\n",
    "    shade,\n",
    ")\n",
    "from holoviews.streams import Stream, param\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import fixed, interact, interact_manual, interactive\n",
    "from matplotlib.colors import hex2color\n",
    "from numcodecs import Blosc, Delta\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# from sklearn import metrics\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from bokeh.layouts import row\n",
    "# from bokeh.plotting import figure\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "hv.notebook_extension(\"bokeh\")\n",
    "renderer = hv.renderer(\"bokeh\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_z = zarr.open_array(\"/home/jqs1/scratch/fidelity/test/171018.zarr\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = nd2reader.ND2Reader(\n",
    "    \"/home/jqs1/scratch/fidelity/171018/20171018_TrxnError_ID.nd2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"MCHERRY\": \"#e22400\",\n",
    "    \"GFP\": \"#76ba40\",\n",
    "    \"CY5\": \"#e292fe\",\n",
    "    \"BFP\": \"#3a87fd\",\n",
    "    \"YFP\": \"#f5eb00\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=250\n",
    "\n",
    "channels = frames_z.attrs[\"metadata\"][\"channels\"]\n",
    "n_channels = len(channels)\n",
    "colors = [hex2color(channel_colors[channel]) for channel in channels]\n",
    "num_timepoints = len(frames_z.attrs[\"metadata\"][\"frames\"])\n",
    "num_fovs = len(frames_z.attrs[\"metadata\"][\"fields_of_view\"])\n",
    "\n",
    "channel_boxes = []\n",
    "channel_widgets = []\n",
    "for channel in channels:\n",
    "    solo_button = widgets.Button(description=\"S\", layout=widgets.Layout(width=\"10%\"))\n",
    "    enabled_button = widgets.ToggleButton(description=channel, value=True)\n",
    "    solo_button._button_to_enable = enabled_button\n",
    "    color_picker = widgets.ColorPicker(concise=True, value=channel_colors[channel])\n",
    "    channel_box = widgets.HBox([solo_button, enabled_button, color_picker])\n",
    "    channel_widgets.append([solo_button, enabled_button, color_picker, channel_box])\n",
    "solo_buttons, enabled_buttons, color_pickers, channel_boxes = zip(*channel_widgets)\n",
    "channels_box = widgets.VBox(channel_boxes)\n",
    "t_slider = widgets.IntSlider(\n",
    "    label=\"t\", min=0, max=num_timepoints, step=1, value=0, continuous_update=False\n",
    ")\n",
    "v_slider = widgets.IntSlider(\n",
    "    min=0, max=num_fovs, step=1, value=0, continuous_update=False\n",
    ")\n",
    "slider_box = widgets.VBox([v_slider, t_slider])\n",
    "control_box = widgets.HBox([channels_box, slider_box])\n",
    "output = widgets.Output()\n",
    "main_box = widgets.VBox([control_box, output])\n",
    "display(main_box)\n",
    "\n",
    "max_val = 2**14\n",
    "\n",
    "Frame = Stream.define(\"Frame\", t=0, v=0)\n",
    "frame = Frame()\n",
    "DisplaySettings = Stream.define(\n",
    "    \"DisplaySettings\", channel_enabled=np.array([True] * n_channels)\n",
    ")\n",
    "display_settings = DisplaySettings()\n",
    "\n",
    "\n",
    "def composite_image(t, v, channel_enabled):\n",
    "    # def composite_image(t, v):\n",
    "    # channel_enabled = [True] * n_channels\n",
    "    # channel_imgs = [frames.get_frame_2D(c=i, t=t, v=v) for i in range(n_channels)]\n",
    "    channel_imgs = [frames_z[v, c, t, :, :] for c in range(n_channels)]\n",
    "    scaled_imgs = [\n",
    "        channel_imgs[i][:, :, np.newaxis] / np.percentile(channel_imgs[i], 99.9)\n",
    "        for i in range(n_channels)\n",
    "    ]\n",
    "    for scaled_img in scaled_imgs:\n",
    "        np.clip(scaled_img, 0, 1, scaled_img)  # clip in place\n",
    "    colored_imgs = [scaled_imgs[i] * np.array(colors[i]) for i in range(n_channels)]\n",
    "    imgs_to_combine = [colored_imgs[i] for i in range(n_channels) if channel_enabled[i]]\n",
    "    if not len(imgs_to_combine):\n",
    "        imgs_to_combine = [np.ones(colored_imgs[0].shape)]  # white placeholder\n",
    "    img = imgs_to_combine[0]\n",
    "    for img2 in imgs_to_combine[1:]:\n",
    "        img = 1 - (1 - img) * (1 - img2)\n",
    "    return hv.RGB(img, bounds=(-1, -1, 1, 1))  # .opts(plot={'size': 250}, tools=[''])\n",
    "\n",
    "\n",
    "t_slider.observe(lambda change: frame.event(t=change[\"new\"]), names=\"value\")\n",
    "v_slider.observe(lambda change: frame.event(v=change[\"new\"]), names=\"value\")\n",
    "\n",
    "\n",
    "def update_enabled_channels(change):\n",
    "    channel_enabled = np.array([button.value for button in enabled_buttons])\n",
    "    display_settings.event(channel_enabled=channel_enabled)\n",
    "\n",
    "\n",
    "def update_solo(solo_button):\n",
    "    if (\n",
    "        solo_button._button_to_enable.value\n",
    "        and sum([b.value for b in enabled_buttons]) == 1\n",
    "    ):\n",
    "        for enabled_button in enabled_buttons:\n",
    "            enabled_button.value = True\n",
    "    else:\n",
    "        for enabled_button in enabled_buttons:\n",
    "            enabled_button.value = enabled_button == solo_button._button_to_enable\n",
    "    # update_enabled_channels(None)\n",
    "\n",
    "\n",
    "for solo_button in solo_buttons:\n",
    "    solo_button.on_click(update_solo)\n",
    "\n",
    "for enabled_button in enabled_buttons:\n",
    "    enabled_button.observe(update_enabled_channels, names=\"value\")\n",
    "# for color_picker in color_pickers:\n",
    "#    color_picker.observe(update_image, names='value')\n",
    "\n",
    "# hv.DynamicMap(composite_image, kdims=['t', 'v', 'channel_enabled']).select(t=0,v=0,channel_enabled=np.array([True,False,False,False,False]))\n",
    "image_viewer = hv.DynamicMap(composite_image, streams=[frame, display_settings])\n",
    "regrid(image_viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_stack = frames_z[0, :, :, 300:500, :1000]\n",
    "a = a_stack[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f0 = frames_z[0, 0, :].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f01 = frames_z[0, 1, :].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f0 - np.percentile(f0, 0.5, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_b = skimage.filters.gaussian(f1, 3)\n",
    "f1_v = skimage.filters.sobel_v(f1_b)\n",
    "f1_v2 = skimage.filters.sobel_v(f1_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_eigenvalues(img):\n",
    "    I = skimage.filters.gaussian(img, 1.5)\n",
    "    I_x = skimage.filters.sobel_h(I)\n",
    "    I_y = skimage.filters.sobel_v(I)\n",
    "    I_xx = skimage.filters.sobel_h(I_x)\n",
    "    I_xy = skimage.filters.sobel_v(I_x)\n",
    "    I_yx = skimage.filters.sobel_h(I_y)\n",
    "    I_yy = skimage.filters.sobel_v(I_y)\n",
    "    kappa_1 = (I_xx + I_yy) / 2\n",
    "    kappa_2 = (np.sqrt((I_xx + I_yy) ** 2 - 4 * (I_xx * I_yy - I_xy * I_yx))) / 2\n",
    "    k1 = kappa_1 + kappa_2\n",
    "    k2 = kappa_1 - kappa_2\n",
    "    k1[np.isnan(k1)] = 0\n",
    "    k2[np.isnan(k2)] = 0\n",
    "    return k1, k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_k1, f1_k2 = hessian_eigenvalues(f1_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = f1 > skimage.filters.threshold_otsu(f1)\n",
    "# f2 = skimage.morphology.convex_hull_object(f2)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(np.where(f2)).T\n",
    "X2 = StandardScaler().fit_transform(X.astype(np.float32))\n",
    "fit = sklearn.cluster.MiniBatchKMeans(\n",
    "    init=\"k-means++\", n_clusters=2, n_init=10, max_no_improvement=10, verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit.fit(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_img = np.zeros_like(f1)\n",
    "for i in range(len(fit.labels_)):\n",
    "    label_img[X[i, 0], X[i, 1]] = fit.labels_[i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(fit.labels_)\n",
    "total = sum(counter.values())\n",
    "good_labels = []\n",
    "for label, count in counter.items():\n",
    "    print(count / total)\n",
    "    if count / total > 0.01:\n",
    "        good_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Trench detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_img_rot = skimage.transform.rotate(label_img, 15, cval=0)  # , resize=True)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(label_img_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_trenches2(thresholded_img):\n",
    "    h, theta, d = skimage.transform.hough_line(thresholded_img)\n",
    "    abs_diff_h = np.diff(h.astype(np.int32), axis=1).var(axis=0)\n",
    "    theta_idx = abs_diff_h.argmax()\n",
    "    angle1 = theta[theta_idx]\n",
    "    h2, theta2, d2 = skimage.transform.hough_line(\n",
    "        thresholded_img, theta=np.linspace(0.9 * angle1, 1.1 * angle1, 200)\n",
    "    )\n",
    "    abs_diff_h2 = np.diff(h2.astype(np.int32), axis=1).var(axis=0)\n",
    "    theta_idx2 = abs_diff_h2.argmax()\n",
    "    angle2 = theta2[theta_idx2]\n",
    "    d_profile = h2[:, theta_idx2].astype(np.int32)\n",
    "    # plt.figure(figsize=(8,8))\n",
    "    # plt.imshow(h, aspect=0.1)\n",
    "    # plt.plot(d_profile[3000:3300])\n",
    "    # plt.figure(figsize=(8,8))\n",
    "    freqs = np.abs(np.fft.fft(d_profile))\n",
    "    # plt.plot(freqs)\n",
    "    peak_idxs = peakutils.indexes(d_profile, thres=0.4)\n",
    "    peaks = d2[peak_idxs]\n",
    "    spacing = scipy.stats.mode(np.diff(peaks)).mode[0]\n",
    "    # print(spacing)\n",
    "    # print(peaks[0], peaks[-1], angle2)\n",
    "    # return angle2, peaks\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.imshow(thresholded_img)\n",
    "    angle = angle2\n",
    "    y_min = 0\n",
    "    y_max = thresholded_img.shape[1]\n",
    "    # peak0 = peaks[0]\n",
    "    # peak1 = peaks[-1]\n",
    "    # peaks = np.linspace(peak0, peak1, (peak1-peak0) // spacing-2)\n",
    "    # trench_profiles = []\n",
    "    for dist in peaks:\n",
    "        # print(angle, dist)\n",
    "        y0 = (dist - y_min * np.cos(angle)) / np.sin(angle)\n",
    "        y1 = (dist - y_max * np.cos(angle)) / np.sin(angle)\n",
    "        plt.plot((0, y_max), (y0, y1), \"-r\")\n",
    "    #    length = int(np.hypot(y_max - 0, y1 - y0))\n",
    "    #    xs = np.linspace(0, y_max-1, length).astype(np.int)\n",
    "    #    ys = np.linspace(y0, y1-1, length).astype(np.int)\n",
    "    #    #trench_profiles.append(img[xs, ys])\n",
    "    plt.xlim((0, thresholded_img.shape[1]))\n",
    "    plt.ylim((thresholded_img.shape[0], 0))\n",
    "    # plt.figure(figsize=(8,8))\n",
    "    # plt.plot(trench_profiles)\n",
    "\n",
    "\n",
    "# detect_trenches2(img_labels == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_binary_image(bin_img):\n",
    "    X = np.array(np.where(bin_img)).T\n",
    "    X2 = StandardScaler().fit_transform(X.astype(np.float32))\n",
    "    fit = sklearn.cluster.MiniBatchKMeans(\n",
    "        init=\"k-means++\", n_clusters=2, n_init=10, max_no_improvement=10, verbose=0\n",
    "    )\n",
    "    fit.fit(X2)\n",
    "    return X, fit\n",
    "\n",
    "\n",
    "def label_binary_image(bin_img):\n",
    "    X, fit = cluster_binary_image(bin_img)\n",
    "    label_img = np.zeros_like(bin_img)\n",
    "    for i in range(len(fit.labels_)):\n",
    "        label_img[X[i, 0], X[i, 1]] = fit.labels_[i] + 1\n",
    "    return label_img\n",
    "\n",
    "\n",
    "def drop_rare_labels(labels):\n",
    "    total = fit.labels_.sum()\n",
    "    good_labels = []\n",
    "    for label, count in enumerate(fit.labels_):\n",
    "        print(count / total)\n",
    "        if count / total > 0.01:\n",
    "            good_labels.append(label)\n",
    "    return good_labels\n",
    "\n",
    "\n",
    "def detect_trenches(bin_img):\n",
    "    h, theta, d = skimage.transform.hough_line(bin_img)\n",
    "    abs_diff_h = np.diff(h.astype(np.int32), axis=1).var(axis=0)\n",
    "    theta_idx = abs_diff_h.argmax()\n",
    "    angle1 = theta[theta_idx]\n",
    "    h2, theta2, d2 = skimage.transform.hough_line(\n",
    "        bin_img, theta=np.linspace(0.9 * angle1, 1.1 * angle1, 200)\n",
    "    )\n",
    "    abs_diff_h2 = np.diff(h2.astype(np.int32), axis=1).var(axis=0)\n",
    "    theta_idx2 = abs_diff_h2.argmax()\n",
    "    angle2 = theta2[theta_idx2]\n",
    "    d_profile = h2[:, theta_idx2].astype(np.int32)\n",
    "    freqs = np.abs(np.fft.fft(d_profile))\n",
    "    peak_idxs = peakutils.indexes(d_profile, thres=0.4, min_dist=5)\n",
    "    peaks = d2[peak_idxs]\n",
    "    spacing = scipy.stats.mode(np.diff(peaks)).mode[0]\n",
    "    return angle2, peaks\n",
    "\n",
    "\n",
    "def get_rough_spacing(dists):\n",
    "    spacing = scipy.stats.mode(np.diff(dists).astype(int)).mode[0]\n",
    "    return spacing\n",
    "\n",
    "\n",
    "def point_linspace(anchor0, anchor1, num_points):\n",
    "    for s in np.linspace(0, 1, num_points)[1:-1]:\n",
    "        anchor = (1 - s) * anchor0 + s * anchor1\n",
    "        yield anchor\n",
    "\n",
    "\n",
    "def get_anchors(theta, x_lim, y_lim):\n",
    "    x_min, x_max = x_lim\n",
    "    y_min, y_max = y_lim\n",
    "    if 0 <= (theta % np.pi) < np.pi / 4 or 3 / 4 * np.pi <= (theta % np.pi) < np.pi:\n",
    "        y0 = (y_max - y_min) / 2 + y_min\n",
    "        dy = (x_max - x_min) / 2 * np.tan(theta)\n",
    "        anchor0 = np.array([x_min, y0 - dy])\n",
    "        anchor1 = np.array([x_max, y0 + dy])\n",
    "    return anchor0, anchor1\n",
    "\n",
    "\n",
    "def coords_along(x0, x1):\n",
    "    length = int(np.sqrt(np.sum((x1 - x0) ** 2)))\n",
    "    xs = np.linspace(x0[0], x1[0], length).astype(np.int_)[1:-1]\n",
    "    ys = np.linspace(x0[1], x1[1], length).astype(np.int_)[1:-1]\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_array(anchors, theta, x_lim, y_lim, start=None, stop=None):\n",
    "    if start is None:\n",
    "        start = 0\n",
    "    if stop is None:\n",
    "        stop = 0\n",
    "    if not stop >= start >= 0:\n",
    "        raise ValueError(\"need stop >= start >= 0\")\n",
    "    for anchor in anchors:\n",
    "        x0 = anchor\n",
    "        if -3 / 4 * np.pi < theta < np.pi / 4:\n",
    "            x, y = x_min, y_min\n",
    "            angle_to_corner = np.arctan2(-anchor[0], anchor[1])\n",
    "        else:\n",
    "            x, y = x_max, y_max\n",
    "            angle_to_corner = -np.arctan2(anchor[0] - x_max, -(y_max - anchor[1]))\n",
    "        if angle_to_corner < theta:\n",
    "            # endpoint at top/bottom\n",
    "            x1 = np.array([anchor[0] + (anchor[1] - y) * np.tan(theta), y])\n",
    "            # length = (anchor[1] - y)/np.cos(theta)\n",
    "            # x1 = np.array([anchor[0] + length*np.sin(theta), y])\n",
    "        else:\n",
    "            # endpoint on side\n",
    "            x1 = np.array([x, anchor[1] + (anchor[0] - x) / np.tan(theta)])\n",
    "        max_length = np.sqrt(((x1 - x0) ** 2).sum())\n",
    "        y0, y1 = x0, x1\n",
    "        if start:\n",
    "            y0 = min(start / max_length, 1) * (x1 - x0) + x0\n",
    "        if stop:\n",
    "            y1 = min(stop / max_length, 1) * (x1 - x0) + x0\n",
    "        if not np.array_equal(y0, y1):\n",
    "            yield y0, y1\n",
    "\n",
    "\n",
    "def point_linspace_fine(anchor0, anchor1, spacing, offset):\n",
    "    for s in np.linspace(0, 1, N)[1:-1]:\n",
    "        anchor = (1 - s) * anchor0 + s * anchor1\n",
    "        yield anchor\n",
    "\n",
    "\n",
    "def refine_trenches(img, theta, spacing):\n",
    "    x_min = y_min = 0\n",
    "    x_max, y_max = img.shape\n",
    "    x_lim = (x_min, x_max)\n",
    "    y_lim = (y_min, y_max)\n",
    "    anchor0, anchor1 = get_anchors(theta, x_lim, y_lim)\n",
    "\n",
    "    def objective(spacing_, offset):\n",
    "        s = 0\n",
    "        for x0, x1 in line_array(\n",
    "            point_linspace_fine(anchor0, anchor1, spacing_, offset), theta, x_lim, y_lim\n",
    "        ):\n",
    "            xs, ys = coords_along(x0, x1)\n",
    "            s += img[ys, xs].sum()\n",
    "        return s\n",
    "\n",
    "    spacings = np.linspace(0.8 * spacing, 1.2 * spacing, 20)\n",
    "    offsets = np.linspace(0, 1.2 * spacing, 20)\n",
    "\n",
    "\n",
    "img = skimage.transform.rotate(f1, 15, cval=0)\n",
    "img_thresh = img > skimage.filters.threshold_otsu(img)\n",
    "img_labels = label_binary_image(img_thresh)\n",
    "theta, dists = detect_trenches(img_labels == 1)\n",
    "spacing = get_rough_spacing(dists)\n",
    "# anchors\n",
    "x_min = y_min = 0\n",
    "x_max, y_max = img.shape\n",
    "x_lim = (x_min, x_max)\n",
    "y_lim = (y_min, y_max)\n",
    "anchor0, anchor1 = get_anchors(theta, x_lim, y_lim)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img)\n",
    "plt.gca().add_artist(plt.Circle(anchor0, 50, color=\"g\"))\n",
    "plt.gca().add_artist(plt.Circle(anchor1, 50, color=\"gray\"))\n",
    "trench_profiles = []\n",
    "for x0, x1 in line_array(\n",
    "    point_linspace(anchor0, anchor1, int((anchor1[0] - anchor0[0]) // spacing)),\n",
    "    theta,\n",
    "    x_lim,\n",
    "    y_lim,\n",
    "    start=500,\n",
    "    stop=700,\n",
    "):\n",
    "    xs, ys = coords_along(x0, x1)\n",
    "    trench_profiles.append(img[ys, xs])\n",
    "    line = np.vstack((x0, x1)).T\n",
    "    plt.plot(*line, color=\"w\")\n",
    "    plt.gca().add_artist(plt.Circle(x0, 10, color=\"r\", zorder=2))\n",
    "    plt.gca().add_artist(plt.Circle(x1, 10, color=\"r\", zorder=2))\n",
    "plt.figure(figsize=(12, 12))\n",
    "for trench_profile in trench_profiles:\n",
    "    plt.plot(trench_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ((dists - dists[:, np.newaxis]) % 24.001).flat\n",
    "plt.hist(x, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.diff(dists), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "kt = k2 > 0.5 * skimage.filters.threshold_otsu(k2)\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "kt = k1 > 0.5 * skimage.filters.threshold_otsu(k1)\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rough trench finding using linear hough on thresholded k2 or thresholded intensity (?)\n",
    "# oval hough transform to find cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(skimage.measure.label(1 - kt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.measure.label(1 - kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = a_stack.shape[1]\n",
    "play = widgets.Play(\n",
    "    # interval=10,\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=num_timesteps,\n",
    "    step=1,\n",
    "    description=\"Press play\",\n",
    "    disabled=False,\n",
    ")\n",
    "time_slider = widgets.IntSlider(min=0, max=num_timesteps, continuous_update=False)\n",
    "widgets.jslink((play, \"value\"), (time_slider, \"value\"))\n",
    "output = widgets.Output()\n",
    "box = widgets.VBox([widgets.HBox([play, time_slider]), output])\n",
    "\n",
    "\n",
    "def f(t):\n",
    "    with output:\n",
    "        z = hessian_eigenvalues(a_stack[0, t])[0]\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        plt.imshow(z)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "interactive(f, t=time_slider)\n",
    "box"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
