{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import Counter\n",
    "from itertools import zip_longest\n",
    "\n",
    "import datashader as ds\n",
    "import holoviews as hv\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import peakutils\n",
    "import scipy.interpolate\n",
    "import scipy.stats\n",
    "import skimage\n",
    "import skimage.morphology\n",
    "import sklearn\n",
    "import zarr\n",
    "from bokeh.io import output_notebook, push_notebook, show\n",
    "from bokeh.models import WheelZoomTool\n",
    "from holoborodko_diff import holo_diff\n",
    "from holoviews.operation import decimate\n",
    "from holoviews.operation.datashader import (\n",
    "    aggregate,\n",
    "    datashade,\n",
    "    dynspread,\n",
    "    regrid,\n",
    "    shade,\n",
    ")\n",
    "from holoviews.streams import Stream, param\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import fixed, interact, interact_manual, interactive\n",
    "from matplotlib.colors import hex2color\n",
    "from numcodecs import Blosc, Delta\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# from sklearn import metrics\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from bokeh.layouts import row\n",
    "# from bokeh.plotting import figure\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "hv.notebook_extension(\"bokeh\")\n",
    "renderer = hv.renderer(\"bokeh\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_z = zarr.open_array(\"/home/jqs1/scratch/fidelity/test/171018.zarr\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = nd2reader.ND2Reader('/home/jqs1/scratch/fidelity/171018/20171018_TrxnError_ID.nd2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"MCHERRY\": \"#e22400\",\n",
    "    \"GFP\": \"#76ba40\",\n",
    "    \"CY5\": \"#e292fe\",\n",
    "    \"BFP\": \"#3a87fd\",\n",
    "    \"YFP\": \"#f5eb00\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=250\n",
    "\n",
    "channels = frames_z.attrs[\"metadata\"][\"channels\"]\n",
    "n_channels = len(channels)\n",
    "colors = [hex2color(channel_colors[channel]) for channel in channels]\n",
    "num_timepoints = len(frames_z.attrs[\"metadata\"][\"frames\"])\n",
    "num_fovs = len(frames_z.attrs[\"metadata\"][\"fields_of_view\"])\n",
    "\n",
    "channel_boxes = []\n",
    "channel_widgets = []\n",
    "for channel in channels:\n",
    "    solo_button = widgets.Button(description=\"S\", layout=widgets.Layout(width=\"10%\"))\n",
    "    enabled_button = widgets.ToggleButton(description=channel, value=True)\n",
    "    solo_button._button_to_enable = enabled_button\n",
    "    color_picker = widgets.ColorPicker(concise=True, value=channel_colors[channel])\n",
    "    channel_box = widgets.HBox([solo_button, enabled_button, color_picker])\n",
    "    channel_widgets.append([solo_button, enabled_button, color_picker, channel_box])\n",
    "solo_buttons, enabled_buttons, color_pickers, channel_boxes = zip(*channel_widgets)\n",
    "channels_box = widgets.VBox(channel_boxes)\n",
    "t_slider = widgets.IntSlider(\n",
    "    label=\"t\", min=0, max=num_timepoints, step=1, value=0, continuous_update=False\n",
    ")\n",
    "v_slider = widgets.IntSlider(\n",
    "    min=0, max=num_fovs, step=1, value=0, continuous_update=False\n",
    ")\n",
    "slider_box = widgets.VBox([v_slider, t_slider])\n",
    "control_box = widgets.HBox([channels_box, slider_box])\n",
    "output = widgets.Output()\n",
    "main_box = widgets.VBox([control_box, output])\n",
    "display(main_box)\n",
    "\n",
    "max_val = 2**14\n",
    "\n",
    "Frame = Stream.define(\"Frame\", t=0, v=0)\n",
    "frame = Frame()\n",
    "DisplaySettings = Stream.define(\n",
    "    \"DisplaySettings\", channel_enabled=np.array([True] * n_channels)\n",
    ")\n",
    "display_settings = DisplaySettings()\n",
    "\n",
    "\n",
    "def composite_image(t, v, channel_enabled):\n",
    "    # def composite_image(t, v):\n",
    "    # channel_enabled = [True] * n_channels\n",
    "    # channel_imgs = [frames.get_frame_2D(c=i, t=t, v=v) for i in range(n_channels)]\n",
    "    channel_imgs = [frames_z[v, c, t, :, :] for c in range(n_channels)]\n",
    "    scaled_imgs = [\n",
    "        channel_imgs[i][:, :, np.newaxis] / np.percentile(channel_imgs[i], 99.9)\n",
    "        for i in range(n_channels)\n",
    "    ]\n",
    "    for scaled_img in scaled_imgs:\n",
    "        np.clip(scaled_img, 0, 1, scaled_img)  # clip in place\n",
    "    colored_imgs = [scaled_imgs[i] * np.array(colors[i]) for i in range(n_channels)]\n",
    "    imgs_to_combine = [colored_imgs[i] for i in range(n_channels) if channel_enabled[i]]\n",
    "    if not len(imgs_to_combine):\n",
    "        imgs_to_combine = [np.ones(colored_imgs[0].shape)]  # white placeholder\n",
    "    img = imgs_to_combine[0]\n",
    "    for img2 in imgs_to_combine[1:]:\n",
    "        img = 1 - (1 - img) * (1 - img2)\n",
    "    return hv.RGB(img, bounds=(-1, -1, 1, 1))  # .opts(plot={'size': 250}, tools=[''])\n",
    "\n",
    "\n",
    "t_slider.observe(lambda change: frame.event(t=change[\"new\"]), names=\"value\")\n",
    "v_slider.observe(lambda change: frame.event(v=change[\"new\"]), names=\"value\")\n",
    "\n",
    "\n",
    "def update_enabled_channels(change):\n",
    "    channel_enabled = np.array([button.value for button in enabled_buttons])\n",
    "    display_settings.event(channel_enabled=channel_enabled)\n",
    "\n",
    "\n",
    "def update_solo(solo_button):\n",
    "    if (\n",
    "        solo_button._button_to_enable.value\n",
    "        and sum([b.value for b in enabled_buttons]) == 1\n",
    "    ):\n",
    "        for enabled_button in enabled_buttons:\n",
    "            enabled_button.value = True\n",
    "    else:\n",
    "        for enabled_button in enabled_buttons:\n",
    "            enabled_button.value = enabled_button == solo_button._button_to_enable\n",
    "    # update_enabled_channels(None)\n",
    "\n",
    "\n",
    "for solo_button in solo_buttons:\n",
    "    solo_button.on_click(update_solo)\n",
    "\n",
    "for enabled_button in enabled_buttons:\n",
    "    enabled_button.observe(update_enabled_channels, names=\"value\")\n",
    "# for color_picker in color_pickers:\n",
    "#    color_picker.observe(update_image, names='value')\n",
    "\n",
    "# hv.DynamicMap(composite_image, kdims=['t', 'v', 'channel_enabled']).select(t=0,v=0,channel_enabled=np.array([True,False,False,False,False]))\n",
    "image_viewer = hv.DynamicMap(composite_image, streams=[frame, display_settings])\n",
    "regrid(image_viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Trench detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_limits(img):\n",
    "    x_min = y_min = 0\n",
    "    x_max, y_max = img.shape\n",
    "    x_lim = (x_min, x_max)\n",
    "    y_lim = (y_min, y_max)\n",
    "    return x_lim, y_lim\n",
    "\n",
    "\n",
    "def cluster_binary_image(bin_img):\n",
    "    X = np.array(np.where(bin_img)).T\n",
    "    X2 = StandardScaler().fit_transform(X.astype(np.float32))\n",
    "    fit = sklearn.cluster.MiniBatchKMeans(\n",
    "        init=\"k-means++\", n_clusters=2, n_init=10, max_no_improvement=10, verbose=0\n",
    "    )\n",
    "    fit.fit(X2)\n",
    "    return X, fit\n",
    "\n",
    "\n",
    "def label_binary_image(bin_img):\n",
    "    X, fit = cluster_binary_image(bin_img)\n",
    "    label_img = np.zeros_like(bin_img, dtype=np.int8)  # TODO: fixing dtype\n",
    "    for i in range(len(fit.labels_)):\n",
    "        label_img[X[i, 0], X[i, 1]] = fit.labels_[i] + 1\n",
    "    return label_img\n",
    "\n",
    "\n",
    "def drop_rare_labels(labels):\n",
    "    counter = Counter(labels)\n",
    "    total = sum(counter)\n",
    "    good_labels = []\n",
    "    for label, count in counter.iteritems():\n",
    "        print(count / total)\n",
    "        if count / total > 0.01:\n",
    "            good_labels.append(label)\n",
    "    return good_labels\n",
    "\n",
    "\n",
    "def detect_rotation(bin_img):\n",
    "    h, theta, d = skimage.transform.hough_line(bin_img)\n",
    "    abs_diff_h = np.diff(h.astype(np.int32), axis=1).var(axis=0)\n",
    "    theta_idx = abs_diff_h.argmax()\n",
    "    angle1 = theta[theta_idx]\n",
    "    h2, theta2, d2 = skimage.transform.hough_line(\n",
    "        bin_img, theta=np.linspace(0.9 * angle1, 1.1 * angle1, 200)\n",
    "    )\n",
    "    abs_diff_h2 = np.diff(h2.astype(np.int32), axis=1).var(axis=0)\n",
    "    theta_idx2 = abs_diff_h2.argmax()\n",
    "    angle2 = theta2[theta_idx2]\n",
    "    d_profile = h2[:, theta_idx2].astype(np.int32)\n",
    "    freqs = np.abs(np.fft.fft(d_profile))\n",
    "    peak_idxs = peakutils.indexes(d_profile, thres=0.4, min_dist=5)\n",
    "    peaks = d2[peak_idxs]\n",
    "    spacing = scipy.stats.mode(np.diff(peaks)).mode[0]\n",
    "    return np.pi / 2 - angle2, peaks\n",
    "\n",
    "\n",
    "def get_rough_spacing(dists):\n",
    "    spacing = scipy.stats.mode(np.diff(dists).astype(int)).mode[0]\n",
    "    return spacing\n",
    "\n",
    "\n",
    "def point_linspace(anchor0, anchor1, num_points):\n",
    "    for s in np.linspace(0, 1, num_points)[1:-1]:\n",
    "        anchor = (1 - s) * anchor0 + s * anchor1\n",
    "        yield anchor\n",
    "\n",
    "\n",
    "def coords_along(x0, x1):\n",
    "    length = int(np.sqrt(np.sum((x1 - x0) ** 2)))\n",
    "    xs = np.linspace(x0[0], x1[0], length).astype(np.int_)[1:-1]\n",
    "    ys = np.linspace(x0[1], x1[1], length).astype(np.int_)[1:-1]\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def edge_point(x0, theta, x_lim, y_lim):\n",
    "    x_min, x_max = x_lim\n",
    "    y_min, y_max = y_lim\n",
    "    theta = theta % (2 * np.pi)\n",
    "    if 0 <= theta < np.pi / 2:\n",
    "        corner_x, corner_y = x_min, y_max\n",
    "    elif np.pi / 2 <= theta < np.pi:\n",
    "        corner_x, corner_y = x_max, y_max\n",
    "    elif np.pi <= theta < 3 / 2 * np.pi:\n",
    "        corner_x, corner_y = x_max, y_min\n",
    "    elif 3 / 2 * np.pi <= theta <= 2 * np.pi:\n",
    "        corner_x, corner_y = x_min, y_min\n",
    "    angle_to_corner = np.arctan2(corner_y - x0[1], x0[0] - corner_x) % (2 * np.pi)\n",
    "    if (\n",
    "        (theta >= angle_to_corner and 0 <= theta < np.pi / 2)\n",
    "        or (theta < angle_to_corner and np.pi / 2 <= theta < np.pi)\n",
    "        or (theta >= angle_to_corner and np.pi <= theta < 3 / 2 * np.pi)\n",
    "        or (theta < angle_to_corner and 3 / 2 * np.pi <= theta < 2 * np.pi)\n",
    "    ):\n",
    "        # top/bottom\n",
    "        x1 = np.array([x0[0] - (corner_y - x0[1]) / np.tan(theta), corner_y])\n",
    "    else:\n",
    "        # left/right\n",
    "        x1 = np.array([corner_x, x0[1] - (corner_x - x0[0]) * np.tan(theta)])\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_array(\n",
    "    anchors, theta, x_lim, y_lim, start=None, stop=None, bidirectional=False\n",
    "):\n",
    "    if bidirectional:\n",
    "        line_array1 = line_array(\n",
    "            anchors, theta, x_lim, y_lim, start=start, stop=stop, bidirectional=False\n",
    "        )\n",
    "        line_array2 = line_array(\n",
    "            anchors,\n",
    "            theta + np.pi,\n",
    "            x_lim,\n",
    "            y_lim,\n",
    "            start=start,\n",
    "            stop=stop,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "        for (x0, x1), (y0, y1) in zip(line_array1, line_array2):\n",
    "            yield x0, x1, y1\n",
    "        return\n",
    "    if start is None:\n",
    "        start = 0\n",
    "    if stop is None:\n",
    "        stop = 0\n",
    "    if not stop >= start >= 0:\n",
    "        raise ValueError(\"need stop >= start >= 0\")\n",
    "    theta = theta % (2 * np.pi)\n",
    "    for anchor in anchors:\n",
    "        x0 = anchor\n",
    "        x1 = edge_point(x0, theta, x_lim, y_lim)\n",
    "        max_length = np.sqrt(((x1 - x0) ** 2).sum())\n",
    "        y0, y1 = x0, x1\n",
    "        if start:\n",
    "            y0 = min(start / max_length, 1) * (x1 - x0) + x0\n",
    "        if stop:\n",
    "            y1 = min(stop / max_length, 1) * (x1 - x0) + x0\n",
    "        if not np.array_equal(y0, y1):\n",
    "            yield y0, y1\n",
    "\n",
    "\n",
    "def get_anchors(theta, x_lim, y_lim):\n",
    "    x_min = np.array([x_lim[0], y_lim[0]])\n",
    "    x_max = np.array([x_lim[1], y_lim[1]])\n",
    "    x0 = x_min + (x_max - x_min) / 2\n",
    "    anchor0 = edge_point(x0, theta, x_lim, y_lim)\n",
    "    anchor1 = edge_point(x0, theta + np.pi, x_lim, y_lim)\n",
    "    return anchor0, anchor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_trench_region(bin_img, theta):\n",
    "    x_lim, y_lim = get_img_limits(bin_img)\n",
    "    anchor0, anchor1 = get_anchors(theta, x_lim, y_lim)\n",
    "    cross_sections = []\n",
    "    anchors = list(point_linspace(anchor0, anchor1, 40))[3:-3]  # TODO: parameterize\n",
    "    lines = list(\n",
    "        line_array(anchors, np.pi / 2 + theta, x_lim, y_lim, bidirectional=True)\n",
    "    )\n",
    "    for x0, x1, x2 in lines:\n",
    "        xs, ys = coords_along(x1, x2)\n",
    "        cross_sections.append(bin_img[ys, xs])\n",
    "    cross_section_vars = np.array([cs.var() for cs in cross_sections])\n",
    "    idx = cross_section_vars.argmax()\n",
    "    return anchors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM: https://stackoverflow.com/questions/23815327/numpy-one-liner-for-combining-unequal-length-np-array-to-a-matrixor-2d-array\n",
    "def stack_jagged(arys, fill=0):\n",
    "    return np.array(list(zip_longest(*arys, fillvalue=fill))).T\n",
    "\n",
    "\n",
    "def detect_periodic_peaks(signal):\n",
    "    idxs = peakutils.indexes(signal, thres=0.1, min_dist=5)\n",
    "    xs = peakutils.interpolate(np.arange(len(signal)), signal, ind=idxs)\n",
    "    dxs = np.diff(xs)\n",
    "    period_min = np.percentile(dxs, 10)\n",
    "    period_max = dxs.max()\n",
    "    num_periods = 100\n",
    "    periods = np.linspace(period_min, period_max, num_periods)\n",
    "    # std = ((dxs + periods[:,np.newaxis]/2) % periods[:,np.newaxis]).std(axis=1)\n",
    "    std = scipy.stats.iqr(((xs) % periods[:, np.newaxis]), axis=1) / periods\n",
    "    period_idx = std.argmin()\n",
    "    period = periods[period_idx]\n",
    "    plt.figure()\n",
    "    plt.plot(std)\n",
    "    plt.scatter([period_idx], [std[period_idx]], c=\"r\")\n",
    "    periods2 = np.linspace(period * 0.98, period * 1.02, num_periods)\n",
    "    std2 = scipy.stats.iqr(((xs) % periods2[:, np.newaxis]), axis=1) / periods2\n",
    "    period_idx2 = std2.argmin()\n",
    "    period2 = periods2[period_idx2]\n",
    "    plt.figure()\n",
    "    plt.plot(std2)\n",
    "    plt.scatter([period_idx2], [std2[period_idx2]], c=\"r\")\n",
    "    offsets = np.linspace(0, period2, num_periods)\n",
    "    offset_idxs = (\n",
    "        np.arange(0, len(signal) - period2, period2) + offsets[:, np.newaxis]\n",
    "    ).astype(np.int_)\n",
    "    objective = signal[offset_idxs].sum(axis=1)\n",
    "    offset_idx = objective.argmax()\n",
    "    offset = offsets[offset_idx]\n",
    "    plt.figure()\n",
    "    plt.plot(objective)\n",
    "    plt.scatter([offset_idx], [objective[offset_idx]], c=\"r\")\n",
    "    return period2, offset\n",
    "\n",
    "\n",
    "def detect_trench_anchors(img, t0, theta):\n",
    "    x_lim, y_lim = get_img_limits(img)\n",
    "    x1 = edge_point(t0, theta - np.pi / 2, x_lim, y_lim)\n",
    "    x2 = edge_point(t0, theta + np.pi / 2, x_lim, y_lim)\n",
    "    xs, ys = coords_along(x1, x2)\n",
    "    profile = img[ys, xs]\n",
    "    period, offset = detect_periodic_peaks(profile)\n",
    "    idxs = np.arange(offset, len(profile), period).astype(np.int_)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(profile)\n",
    "    plt.scatter(idxs, profile[idxs], c=\"r\")\n",
    "    return np.vstack((xs[idxs], ys[idxs])).T\n",
    "\n",
    "\n",
    "def _detect_trench_end(img, anchors, theta):\n",
    "    x_lim, y_lim = get_img_limits(img)\n",
    "    xss = []\n",
    "    yss = []\n",
    "    trench_profiles = []\n",
    "    for anchor in anchors:\n",
    "        x_end = edge_point(anchor, theta, x_lim, y_lim)\n",
    "        xs, ys = coords_along(anchor, x_end)\n",
    "        xss.append(xs)\n",
    "        yss.append(ys)\n",
    "        trench_profiles.append(img[ys, xs])\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for trench_profile in trench_profiles:\n",
    "        plt.plot(trench_profile)\n",
    "    stacked_profile = np.percentile(stack_jagged(trench_profiles), 80, axis=0)\n",
    "    # cum_profile = np.cumsum(stacked_profile)\n",
    "    # cum_profile /= cum_profile[-1]\n",
    "    # end = np.where(cum_profile > 0.8)[0][0]\n",
    "    stacked_profile_diff = holo_diff(1, stacked_profile)\n",
    "    end = stacked_profile_diff.argmin()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(stacked_profile)\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.plot(stacked_profile_diff, color=\"g\")\n",
    "    plt.axvline(end, c=\"r\")\n",
    "    end_points = []\n",
    "    for xs, ys in zip(xss, yss):\n",
    "        idx = end\n",
    "        if len(xs) <= end:\n",
    "            idx = -1\n",
    "        end_points.append((xs[idx], ys[idx]))\n",
    "    return np.array(end_points)\n",
    "\n",
    "\n",
    "def detect_trench_ends(img, bin_img, anchors, theta):\n",
    "    img_masked = np.where(\n",
    "        skimage.morphology.binary_dilation(bin_img), img, np.percentile(img, 5)\n",
    "    )\n",
    "    top_points = _detect_trench_end(img_masked, anchors, theta)\n",
    "    bottom_points = _detect_trench_end(img_masked, anchors, theta + np.pi)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(img_masked)\n",
    "    plt.scatter(*anchors.T, s=3, c=\"w\")\n",
    "    plt.scatter(*top_points.T, s=3, c=\"g\")\n",
    "    plt.scatter(*bottom_points.T, s=3, c=\"r\")\n",
    "    return top_points, bottom_points\n",
    "\n",
    "\n",
    "def detect_trenches(img, bin_img, theta):\n",
    "    t0 = detect_trench_region(bin_img, theta)\n",
    "    trench_anchors = detect_trench_anchors(img, t0, theta)\n",
    "    trench_points = detect_trench_ends(img, bin_img, trench_anchors, theta)\n",
    "    return trench_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_eigenvalues(img):\n",
    "    I = skimage.filters.gaussian(img, 1.5)\n",
    "    I_x = skimage.filters.sobel_h(I)\n",
    "    I_y = skimage.filters.sobel_v(I)\n",
    "    I_xx = skimage.filters.sobel_h(I_x)\n",
    "    I_xy = skimage.filters.sobel_v(I_x)\n",
    "    I_yx = skimage.filters.sobel_h(I_y)\n",
    "    I_yy = skimage.filters.sobel_v(I_y)\n",
    "    kappa_1 = (I_xx + I_yy) / 2\n",
    "    kappa_2 = (np.sqrt((I_xx + I_yy) ** 2 - 4 * (I_xx * I_yy - I_xy * I_yx))) / 2\n",
    "    k1 = kappa_1 + kappa_2\n",
    "    k2 = kappa_1 - kappa_2\n",
    "    k1[np.isnan(k1)] = 0\n",
    "    k2[np.isnan(k2)] = 0\n",
    "    return k1, k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_series_trenches(img_series):\n",
    "    img = img_series.max(axis=0)\n",
    "    # TODO: need rotation-invariant detrending\n",
    "    img = img - np.percentile(img, 3, axis=1)[:, np.newaxis]\n",
    "    img_thresh = img > skimage.filters.threshold_otsu(img)\n",
    "    img_labels = label_binary_image(img_thresh)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img_labels)\n",
    "    theta, dists = detect_rotation(img_labels == 1)\n",
    "    trench_points = detect_trenches(img, img_labels == 1, theta)\n",
    "    return trench_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "frame_series = frames_z[0, 0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_points = get_image_series_trenches(frame_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kymograph(img_series, x0, x1):\n",
    "    num_timepoints = img_series.shape[0]\n",
    "    xs, ys = coords_along(x0, x1)\n",
    "    kymo = np.zeros((len(xs), num_timepoints))\n",
    "    for t in range(num_timepoints):\n",
    "        kymo[:, t] = img_series[t, ys, xs]\n",
    "    return kymo\n",
    "\n",
    "\n",
    "def get_image_series_segmentation(img_series, x0, x1):\n",
    "    pass  # list of trenches, for each trench, a list of cell masks\n",
    "\n",
    "\n",
    "def map_over_segmentation(img_series, cell_seg, func):\n",
    "    pass\n",
    "\n",
    "\n",
    "trench_idx = 12\n",
    "kymo = extract_kymograph(\n",
    "    f_series, trench_points[0][trench_idx], trench_points[1][trench_idx]\n",
    ")\n",
    "plt.figure()\n",
    "plt.imshow(kymo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_b = skimage.filters.gaussian(f1, 3)\n",
    "f1_k1, f1_k2 = hessian_eigenvalues(f1_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = skimage.transform.rotate(f1, 15, cval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(f1_k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(kymo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_series = frames_z[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(f_series[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
