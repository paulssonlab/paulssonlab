{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import warnings\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "from operator import getitem\n",
    "\n",
    "import dask\n",
    "import holoplot.pandas\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamz\n",
    "import zarr\n",
    "from bokeh.models.tools import HoverTool\n",
    "from cytoolz import compose, get_in\n",
    "from dask import delayed\n",
    "from dask.distributed import Client, LocalCluster, progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from holoviews.streams import Stream, param\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from processing import *\n",
    "# from trench_detection import *\n",
    "# from trench_segmentation import *\n",
    "# from trench_segmentation.watershed import *\n",
    "# from util import *\n",
    "# from ui import *\n",
    "import common\n",
    "import diagnostics\n",
    "import metadata\n",
    "import trench_detection\n",
    "import ui\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "hv.extension(\"bokeh\")\n",
    "%matplotlib inline\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"5:00:00\",\n",
    "    # job_extra=['-p transfer'],\n",
    "    # job_extra=['--cores-per-socket=8'],\n",
    "    # interface='ib0',\n",
    "    memory=\"64GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    threads=1,\n",
    "    processes=1,\n",
    "    # diagnostics_port=('127.0.0.1', 8787),\n",
    "    env_extra=['export PYTHONPATH=\"/home/jqs1/projects/matriarch\"'],\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster._widget().children[1].children[1].children[0].children[0].layout.width = \"200px\"\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.stop_workers(cluster.jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/180405_txnerr.nd2', '/n/scratch2/jqs1/fidelity/all/180405_txnerr001.nd2']\n",
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2']#, '/n/scratch2/jqs1/fidelity/all/TrErr002_Exp.nd2']\n",
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/TrErr002_Exp.nd2']\n",
    "nd2_filenames = [\n",
    "    \"/n/scratch2/jqs1/fidelity/all/180405_txnerr.nd2\",\n",
    "    \"/n/scratch2/jqs1/fidelity/all/180405_txnerr001.nd2\",\n",
    "    \"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\",\n",
    "    \"/n/scratch2/jqs1/fidelity/all/TrErr002_Exp.nd2\",\n",
    "]\n",
    "# nd2_filenames = ['/home/jqs1/scratch/fidelity/180518_triplegrowthcurve/PHASE_GC001.nd2', '/home/jqs1/scratch/fidelity/180518_triplegrowthcurve/PHASE_GC002.nd2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2s = {\n",
    "    filename: client.submit(nd2reader.ND2Reader, filename, memmap=False)\n",
    "    for filename in nd2_filenames\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2_sizes = util.gather_futures(\n",
    "    client, util.map_futures(partial(client.submit, lambda nd2: nd2.sizes), nd2s)\n",
    ")\n",
    "nd2_parsed_metadata = util.gather_futures(\n",
    "    client, util.map_futures(partial(client.submit, lambda nd2: nd2.metadata), nd2s)\n",
    ")\n",
    "nd2_metadata = util.gather_futures(\n",
    "    client, util.map_futures(partial(client.submit, metadata.parse_nd2_metadata), nd2s)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2_channels = {\n",
    "    filename: md[\"channels\"] for filename, md in nd2_parsed_metadata.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_dataframe(d):\n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"dPosName\": \"position\",\n",
    "            \"dPosX\": \"x\",\n",
    "            \"dPosY\": \"y\",\n",
    "            \"dPosZ\": \"z\",\n",
    "            \"dPFSOffset\": \"pfs_offset\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    df = df[[\"position\", \"x\", \"y\", \"z\", \"pfs_offset\"]]\n",
    "    return df\n",
    "\n",
    "\n",
    "nd2_positions = pd.concat(\n",
    "    {\n",
    "        filename: position_dataframe(\n",
    "            [\n",
    "                p\n",
    "                for p in get_in(\n",
    "                    [\n",
    "                        \"image_metadata\",\n",
    "                        \"SLxExperiment\",\n",
    "                        \"ppNextLevelEx\",\n",
    "                        \"\",\n",
    "                        \"uLoopPars\",\n",
    "                        \"Points\",\n",
    "                        \"\",\n",
    "                    ],\n",
    "                    md,\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        for filename, md in nd2_metadata.items()\n",
    "    }\n",
    ")\n",
    "nd2_positions.set_index(\"position\", append=True, inplace=True)\n",
    "nd2_positions.index = nd2_positions.index.droplevel(1)\n",
    "nd2_positions.index.names = [\"filename\", \"position\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_file(\"diagnostics.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_reload():\n",
    "    from importlib import reload\n",
    "\n",
    "    import diagnostics\n",
    "    import trench_detection\n",
    "    import util\n",
    "\n",
    "    reload(util)\n",
    "    reload(trench_detection)\n",
    "    reload(diagnostics)\n",
    "\n",
    "\n",
    "client.run(do_reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(trench_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# Finding trenches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_trenches = util.wrap_diagnostics(trench_detection.get_trenches)\n",
    "trench_data = {\n",
    "    filename: {\n",
    "        nd2_positions.loc[filename]\n",
    "        .iloc[v]\n",
    "        .name: {\n",
    "            channel: {\n",
    "                t: client.submit(\n",
    "                    trench_detection.get_trenches_diagnostics,\n",
    "                    client.submit(\n",
    "                        lambda x: x.get_frame_2D(\n",
    "                            t=t, v=v, c=channels.index(channel), memmap=False\n",
    "                        ),\n",
    "                        nd2,\n",
    "                    ),\n",
    "                )\n",
    "                for t in range(min(sizes[\"t\"], 50))\n",
    "            }\n",
    "            for channel in (\"MCHERRY\",)\n",
    "        }\n",
    "        for v in range(10)\n",
    "    }\n",
    "    for filename, nd2, sizes, metadata, channels in util.zip_dicts(\n",
    "        nd2s, nd2_sizes, nd2_metadata, nd2_channels\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(trench_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(trench_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_rows = util.map_futures(\n",
    "    partial(client.submit, diagnostics.wrapped_diagnostics_to_dataframe), trench_data\n",
    ")\n",
    "# trench_rows = util.map_futures(partial(client.submit,\n",
    "#                                       compose(util.expand_diagnostics_by_label,\n",
    "#                                               util.diagnostics_to_dataframe,\n",
    "#                                               partial(util.getitem_r, 1))),\n",
    "#                               trench_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(trench_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(trench_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(trench_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_rows_combined = util.gather_futures(client, trench_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_df = util.map_collections(\n",
    "    partial(pd.concat, axis=0), trench_rows_combined, max_level=4\n",
    ")\n",
    "trench_df.index = trench_df.index.droplevel(-2)\n",
    "trench_df.index.names = [\"filename\", \"position\", \"channel\", \"t\", \"trench_set\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_periods = ~(\n",
    "    (trench_df[\"trench_anchors.periodogram_1.period\"] < 25)\n",
    "    & (trench_df[\"trench_anchors.periodogram_1.period\"] > 23)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM: https://stackoverflow.com/questions/23937433/efficiently-joining-two-dataframes-based-on-multiple-levels-of-a-multiindex?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n",
    "def multi_join(left, right):\n",
    "    return pd.merge(\n",
    "        left.reset_index(), right.reset_index(), on=right.index.names, how=\"inner\"\n",
    "    ).set_index(left.index.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_df2 = multi_join(trench_df, nd2_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_df2[bad_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_df2[~bad_periods].reset_index().holoplot(\n",
    "    y=\"trench_anchors.periodogram_1.period\",\n",
    "    x=\"x\",\n",
    "    by=[\"filename\", \"channel\"],\n",
    "    kind=\"scatter\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_df2[~bad_periods].reset_index().holoplot(\n",
    "    y=\"trench_anchors.periodogram_1.period\",\n",
    "    x=\"t\",\n",
    "    by=[\"filename\", \"channel\", \"position\"],\n",
    "    kind=\"scatter\",\n",
    "    legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = df[bad_periods].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_futures = [\n",
    "    client.submit(\n",
    "        lambda x: x.get_frame_2D(\n",
    "            v=idx[1], t=idx[2], c=nd2_metadata[idx[0]][\"channels\"].index(\"MCHERRY\")\n",
    "        ),\n",
    "        nd2s[idx[0]],\n",
    "    )\n",
    "    for idx in idxs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(frame_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = client.gather(frame_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [\n",
    "    nd2reader.ND2Reader(idx[0]).get_frame_2D(\n",
    "        v=idx[1], t=idx[2], c=nd2_metadata[idx[0]][\"channels\"].index(\"MCHERRY\")\n",
    "    )\n",
    "    for idx in idxs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.HoloMap({str(idx): ui.RevImage(frame) for idx, frame in zip(idxs, frames)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nd2reader.ND2Reader(\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = metadata.parse_nd2_metadata(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_trenches(root_group[\"raw\"][str(pos)][1, 30], diagnostics=diag_pos[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = tree()\n",
    "_ = get_trenches(root_group[\"raw\"][str(pos)][0, 1], diagnostics=diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(img_stack):\n",
    "    ary = np.stack(\n",
    "        [\n",
    "            segment_trench(img_stack[t], diagnostics=None)\n",
    "            for t in range(img_stack.shape[0])\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    ary = zarr.array(ary, compressor=DEFAULT_FRAME_COMPRESSOR)\n",
    "    return ary\n",
    "\n",
    "\n",
    "trench_seg_masks = positionwise_trenchwise_map(\n",
    "    root_group[\"raw\"],\n",
    "    trench_points_pos,\n",
    "    f,\n",
    "    channel_slice=1,\n",
    "    preload=True,\n",
    "    time_slice=slice(None),\n",
    "    positions=range(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(img_stack):\n",
    "    return pd.Series(np.percentile(img_stack, 95, axis=(1, 2)))\n",
    "    # return pd.Series(np.max(img_stack, axis=(1,2)))\n",
    "\n",
    "\n",
    "trench_traces_all = positionwise_trenchwise_map(\n",
    "    root_group[\"raw\"],\n",
    "    trench_points_pos,\n",
    "    f,\n",
    "    channel_slice=2,\n",
    "    preload=True,\n",
    "    time_slice=slice(None),\n",
    "    positions=range(100),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
