{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import dask\n",
    "from dask import delayed\n",
    "import distributed\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import streamz\n",
    "import streamz.dataframe as sdf\n",
    "import holoviews as hv\n",
    "from holoviews.streams import Stream, param\n",
    "from holoviews.operation.datashader import regrid\n",
    "from bokeh.models.tools import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "import qgrid\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook\n",
    "import warnings\n",
    "from functools import partial\n",
    "from cytoolz import *\n",
    "from operator import getitem\n",
    "import nd2reader\n",
    "from importlib import reload\n",
    "import traceback\n",
    "import hvplot.pandas\n",
    "import param\n",
    "import parambokeh\n",
    "from traitlets import All\n",
    "import cachetools\n",
    "from collections import namedtuple, defaultdict\n",
    "from collections.abc import Mapping, Sequence\n",
    "from numbers import Number\n",
    "import skimage.morphology\n",
    "import scipy\n",
    "from glob import glob\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from processing import *\n",
    "# from trench_detection import *\n",
    "# from trench_segmentation import *\n",
    "# from trench_segmentation.watershed import *\n",
    "# from util import *\n",
    "# from ui import *\n",
    "import common, trench_detection, util\n",
    "import ui, diagnostics, metadata\n",
    "import workflow, image, geometry\n",
    "import trench_detection.hough, trench_detection.core\n",
    "import trench_segmentation.watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "hv.extension(\"bokeh\")\n",
    "%matplotlib inline\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r trench_points\n",
    "%store -r trench_diag\n",
    "%store -r trench_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"00:30:00\",\n",
    "    # job_extra=['-p transfer'],\n",
    "    # job_extra=['--cores-per-socket=8'],\n",
    "    # interface='ib0',\n",
    "    memory=\"8GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    "    # diagnostics_port=('127.0.0.1', 8787),\n",
    "    env_extra=['export PYTHONPATH=\"/home/jqs1/projects/matriarch\"'],\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster._widget().children[1].children[1].children[0].children[0].layout.width = \"200px\"\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.stop_jobs(cluster.running_jobs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/180405_txnerr.nd2', '/n/scratch2/jqs1/fidelity/all/180405_txnerr001.nd2']\n",
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2']#, '/n/scratch2/jqs1/fidelity/all/TrErr002_Exp.nd2']\n",
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/TrErr002_Exp.nd2']\n",
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/180405_txnerr.nd2', '/n/scratch2/jqs1/fidelity/all/180405_txnerr001.nd2',\n",
    "#                 '/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2', '/n/scratch2/jqs1/fidelity/all/TrErr002_Exp.nd2']\n",
    "# nd2_filenames = ['/home/jqs1/scratch/fidelity/180518_triplegrowthcurve/PHASE_GC001.nd2', '/home/jqs1/scratch/fidelity/180518_triplegrowthcurve/PHASE_GC002.nd2']\n",
    "nd2_filenames = glob(\"/n/scratch2/jqs1/fidelity/all/180405_*.nd2\") + glob(\n",
    "    \"/n/scratch2/jqs1/fidelity/all/TrErr*.nd2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames, metadata, parsed_metadata = workflow.get_nd2_frame_list(nd2_filenames)\n",
    "image_limits = workflow.get_filename_image_limits(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_reload():\n",
    "    from importlib import reload\n",
    "    import util, trench_detection, diagnostics, workflow, image\n",
    "\n",
    "    # reload(util)\n",
    "    reload(trench_detection.hough)\n",
    "    # reload(diagnostics)\n",
    "    # reload(workflow)\n",
    "    # reload(image)\n",
    "\n",
    "\n",
    "client.run(do_reload)\n",
    "do_reload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding trenches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_process = all_frames.loc[IDX[:, :, [\"MCHERRY\"], 0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run trench finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "find_trenches_diag = diagnostics.wrap_diagnostics(\n",
    "    trench_detection.hough.find_trenches, ignore_exceptions=True, pandas=True\n",
    ")\n",
    "trench_info_futures = {\n",
    "    idx: client.submit(\n",
    "        find_trenches_diag, client.submit(workflow.get_nd2_frame, **idx._asdict())\n",
    "    )\n",
    "    for idx, row in util.iter_index(frames_to_process)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(trench_info_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_completed(obj, with_results=True):\n",
    "    if isinstance(obj, Mapping):\n",
    "        futures = obj.values()\n",
    "        dask_to_keys = {future.key: k for k, future in obj.items()}\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    for res in distributed.as_completed(futures, with_results=with_results):\n",
    "        if with_results:\n",
    "            future, result = res\n",
    "            yield dask_to_keys[future.key], future, result\n",
    "        else:\n",
    "            future = res\n",
    "            yield dask_to_keys[future.key], future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_info = {}\n",
    "for key, fut, res in as_completed(trench_info_futures):\n",
    "    trench_info[key] = res\n",
    "    client.cancel(fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(trench_info_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_info = util.apply_map_futures(\n",
    "    client.gather, trench_info_futures, predicate=lambda x: x.status == \"error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%store trench_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trench_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = {k: v[2] for k, v in trench_info.items() if v[2] is not None}\n",
    "errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_points, trench_diag, trench_err = workflow.unzip_trench_info(trench_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trench_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%store trench_points\n",
    "%store trench_diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_angle = trench_diag[\"find_trench_lines.hough_2.angle\"].abs() > 2\n",
    "bad_angle.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_pitch = (trench_diag[\"find_trench_lines.hough_2.peak_func.pitch\"] - 24).abs() > 1\n",
    "bad_pitch.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = trench_diag[bad_pitch]  # trench_diag[bad_angle | bad_period]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_stream.event(_df=selected.index.to_frame(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_points_good = trench_points[~util.multi_join(trench_points.index, bad_pitch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(trench_points_good), len(trench_points_good) / len(trench_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_bbox_futures = []\n",
    "for _, trenches in trench_points_good.groupby([\"filename\", \"position\", \"t\"]):\n",
    "    trench_bbox_futures.append(\n",
    "        client.submit(workflow.get_trench_bboxes, trenches, image_limits)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_bbox_results = util.apply_map_futures(\n",
    "    client.gather, trench_bbox_futures, predicate=lambda x: x.status == \"finished\"\n",
    ")\n",
    "trench_bboxes = pd.concat(\n",
    "    [trench_points_good, pd.concat(trench_bbox_results, axis=0)], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%store trench_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r trench_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_bboxes_t0 = util.get_one(trench_bboxes.groupby(\"t\"))[1]\n",
    "# trench_bboxes_t0.index = trench_points_good_t0.index.droplevel('t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trench finding QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = all_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameStream = ui.DataframeStream.define(\n",
    "    \"FrameStream\", selected.index.to_frame(index=False)\n",
    ")\n",
    "frame_stream = FrameStream()\n",
    "\n",
    "box = ui.dataframe_browser(frame_stream)\n",
    "frame_stream.event()\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.image_viewer(frame_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_frame_info(trench_diag, frame_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ui.show_grid(selected, stream=frame_stream)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = workflow.get_nd2_frame(**dict(frame_stream.get_param_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, diag, _ = diagnostics.wrap_diagnostics(\n",
    "    trench_detection.hough.find_trenches, ignore_exceptions=False\n",
    ")(frame_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_browser(diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches_segmentation = trench_bboxes[\n",
    "    trench_bboxes[(\"info\", \"hough_value\")] > 90\n",
    "].loc[IDX[:, :3, [\"MCHERRY\"], 0, :, :], :]\n",
    "# selected_trenches_index = next(iter(selected_trenches_segmarker.groupby('t')))[1].index.droplevel('t')\n",
    "# selected_trenches_reporter = selected_trenches_segmarker.rename(index={'MCHERRY': 'YFP'}, level='channel', copy=False)\n",
    "# selected_trenches_all = pd.concat([selected_trenches_segmarker, selected_trenches_reporter]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches_index.to_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches_segmarker.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpt_stream = streamz.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx, trenches in take(\n",
    "    2,\n",
    "    util.iter_index(\n",
    "        selected_trenches_index.to_series().groupby([\"filename\", \"position\"])\n",
    "    ),\n",
    "):\n",
    "    # display(selected_trenches_all.xs((frame_idx.filename,frame_idx.position), drop_level=False).tail())\n",
    "    display(trenches.to_frame().tail())\n",
    "    print(frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_segment_trench(img_stack):\n",
    "    label_stack = np.stack([segment_trench(img) for img in img_stack])\n",
    "    return zarr.array(\n",
    "        label_stack,\n",
    "        compressor=Blosc(cname=\"zstd\", clevel=5, shuffle=Blosc.NOSHUFFLE, blocksize=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[all_frames_future] = client.scatter([all_frames], broadcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = all_frames_t.get_group(\n",
    "    (\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\", 0)\n",
    ").groupby(\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames_t.groups[(\"/n/scratch2/jqs1/fidelity/all/180405_txnerr.nd2\", 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_funcs = {\n",
    "    \"mean\": np.mean,\n",
    "    \"min\": np.min,\n",
    "    \"max\": np.max,\n",
    "    (\"p0.1\", \"p0.3\", \"p0.5\", \"p0.7\", \"p0.9\"): partial(\n",
    "        np.percentile, q=(0.1, 0.3, 0.5, 0.7, 0.9)\n",
    "    ),\n",
    "}\n",
    "trenchwise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "framewise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "\n",
    "segmentation_channel = \"MCHERRY\"\n",
    "reporter_channels = [\"MCHERRY\", \"YFP\"]\n",
    "\n",
    "all_frames_t = all_frames.groupby([\"filename\", \"position\"])\n",
    "# for frame_idx, trenches in take(2, util.iter_index(selected_trenches_all.groupby(['filename', 'position']))):\n",
    "# for frame_idx, trenches in take(2, util.iter_index(selected_trenches_index.to_series().groupby(['filename', 'position']))):\n",
    "position_trenchwise_dfs = {}\n",
    "position_labelwise_dfs = {}\n",
    "for frame_idx, trenches in take(\n",
    "    2, util.iter_index(selected_trenches_segmentation.groupby([\"filename\", \"position\"]))\n",
    "):\n",
    "    # display(trenches)\n",
    "    uls = trenches[\"upper_left\"].values\n",
    "    lrs = trenches[\"lower_right\"].values\n",
    "    trench_idxs = trenches.index.get_level_values(\"trench\")\n",
    "    # get timepoints/channels for this position\n",
    "    fp_frames = all_frames_t.get_group((frame_idx.filename, frame_idx.position))\n",
    "    position_t_trenchwise_dfs = {}\n",
    "    position_t_labelwise_dfs = {}\n",
    "    for t, frames in take(2, fp_frames.groupby(\"t\")):\n",
    "        # TODO: make sure frames contains MCHERRY, YFP\n",
    "        channels = {segmentation_channel, *reporter_channels}\n",
    "        images = {\n",
    "            channel: workflow.get_nd2_frame(channel=channel, t=t, **frame_idx._asdict())\n",
    "            for channel in channels\n",
    "        }\n",
    "        trench_trenchwise_dfs = {}\n",
    "        trench_labelwise_dfs = {}\n",
    "        for trench_idx in take(2, trench_idxs):\n",
    "            ul = uls[trench_idx]\n",
    "            lr = lrs[trench_idx]\n",
    "            trench_images = {\n",
    "                channel: images[channel][ul[1] : lr[1] + 1, ul[0] : lr[0] + 1]\n",
    "                for channel in channels\n",
    "            }\n",
    "            trench_trenchwise_df = pd.concat(\n",
    "                {\n",
    "                    channel: workflow.map_frame(\n",
    "                        trenchwise_funcs, trench_images[channel]\n",
    "                    )\n",
    "                    for channel in reporter_channels\n",
    "                },\n",
    "                axis=0,\n",
    "            )\n",
    "            trench_trenchwise_dfs[trench_idx] = trench_trenchwise_df\n",
    "            label_trench_image = trench_segmentation.watershed.segment_trench(\n",
    "                trench_images[segmentation_channel]\n",
    "            )\n",
    "            trench_labelwise_df = pd.concat(\n",
    "                {\n",
    "                    channel: pd.concat(\n",
    "                        {\n",
    "                            \"labelwise\": workflow.map_frame_over_labels(\n",
    "                                funcs, label_trench_image, trench_images[channel]\n",
    "                            ),\n",
    "                            \"regionprops\": image.regionprops(\n",
    "                                label_trench_image, trench_images[channel]\n",
    "                            ),\n",
    "                        },\n",
    "                        axis=1,\n",
    "                    )\n",
    "                    for channel in reporter_channels\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "            trench_labelwise_dfs[trench_idx] = trench_labelwise_df\n",
    "        position_t_trenchwise_df = pd.concat(trench_trenchwise_dfs, axis=1).T\n",
    "        position_t_trenchwise_df.index.name = \"trench\"\n",
    "        position_t_trenchwise_dfs[t] = position_t_trenchwise_df\n",
    "        position_t_labelwise_df = pd.concat(trench_labelwise_dfs, axis=0)\n",
    "        position_t_labelwise_df.index.set_names(\"trench\", level=0, inplace=True)\n",
    "        position_t_labelwise_dfs[t] = position_t_labelwise_df\n",
    "    position_trenchwise_df = pd.concat(position_t_trenchwise_dfs, axis=0)\n",
    "    position_trenchwise_df.index.set_names(\"t\", level=0, inplace=True)\n",
    "    position_trenchwise_dfs[tuple(frame_idx)] = position_trenchwise_df\n",
    "    position_labelwise_df = pd.concat(position_t_labelwise_dfs, axis=0)\n",
    "    position_labelwise_df.index.set_names(\"t\", level=0, inplace=True)\n",
    "    position_labelwise_dfs[tuple(frame_idx)] = position_labelwise_df\n",
    "trenchwise_df = pd.concat(position_trenchwise_dfs, axis=0)\n",
    "trenchwise_df.index.names = [\"filename\", \"position\", *trenchwise_df.index.names[2:]]\n",
    "labelwise_df = pd.concat(position_labelwise_dfs, axis=0)\n",
    "labelwise_df.index.names = [\"filename\", \"position\", *labelwise_df.index.names[2:]]\n",
    "display(trenchwise_df)\n",
    "display(labelwise_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_funcs = {\n",
    "    \"mean\": np.mean,\n",
    "    \"min\": np.min,\n",
    "    \"max\": np.max,\n",
    "    (\"p0.1\", \"p0.3\", \"p0.5\", \"p0.7\", \"p0.9\"): partial(\n",
    "        np.percentile, q=(0.1, 0.3, 0.5, 0.7, 0.9)\n",
    "    ),\n",
    "}\n",
    "trenchwise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "framewise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "\n",
    "segmentation_channel = \"MCHERRY\"\n",
    "reporter_channels = [\"MCHERRY\", \"YFP\"]\n",
    "\n",
    "\n",
    "def per_trench(trench_idx, uls, lrs, channels):\n",
    "    ul = uls[trench_idx]\n",
    "    lr = lrs[trench_idx]\n",
    "    trench_images = {\n",
    "        channel: images[channel][ul[1] : lr[1] + 1, ul[0] : lr[0] + 1]\n",
    "        for channel in channels\n",
    "    }\n",
    "    trench_trenchwise_df = pd.concat(\n",
    "        {\n",
    "            channel: workflow.map_frame(trenchwise_funcs, trench_images[channel])\n",
    "            for channel in reporter_channels\n",
    "        },\n",
    "        axis=0,\n",
    "    )\n",
    "    return trench_trenchwise_df\n",
    "\n",
    "\n",
    "def finalize_trench(trench_trenchwise_dfs):\n",
    "    position_t_trenchwise_df = pd.concat(trench_trenchwise_dfs, axis=1).T\n",
    "    position_t_trenchwise_df.index.name = \"trench\"\n",
    "    return position_t_trenchwise_df\n",
    "\n",
    "\n",
    "def finalize_position_t(position_t_trenchwise_df):\n",
    "    position_trenchwise_df = pd.concat(position_t_trenchwise_dfs, axis=0)\n",
    "    position_trenchwise_df.index.set_names(\"t\", level=0, inplace=True)\n",
    "    return position_trenchwise_df\n",
    "\n",
    "\n",
    "def finalize(position_trenchwise_dfs):\n",
    "    trenchwise_df = pd.concat(position_trenchwise_dfs, axis=0)\n",
    "    trenchwise_df.index.names = [\"filename\", \"position\", *trenchwise_df.index.names[2:]]\n",
    "    return trenchwise_df\n",
    "\n",
    "\n",
    "all_frames_t = all_frames.groupby([\"filename\", \"position\"])\n",
    "position_trenchwise_dfs = {}\n",
    "for frame_idx, trenches in take(\n",
    "    2, util.iter_index(selected_trenches_segmentation.groupby([\"filename\", \"position\"]))\n",
    "):\n",
    "    uls = trenches[\"upper_left\"].values\n",
    "    lrs = trenches[\"lower_right\"].values\n",
    "    trench_idxs = trenches.index.get_level_values(\"trench\")\n",
    "    fp_frames = all_frames_t.get_group((frame_idx.filename, frame_idx.position))\n",
    "    position_t_trenchwise_dfs = {}\n",
    "    position_t_labelwise_dfs = {}\n",
    "    for t, frames in take(2, fp_frames.groupby(\"t\")):\n",
    "        channels = {segmentation_channel, *reporter_channels}\n",
    "        images = {\n",
    "            channel: workflow.get_nd2_frame(channel=channel, t=t, **frame_idx._asdict())\n",
    "            for channel in channels\n",
    "        }\n",
    "        trench_trenchwise_dfs = {}\n",
    "        for trench_idx in take(2, trench_idxs):\n",
    "            trench_trenchwise_dfs[trench_idx] = per_trench(\n",
    "                trench_idx, uls, lrs, channels\n",
    "            )\n",
    "        position_t_trenchwise_dfs[t] = finalize_trench(trench_trenchwise_dfs)\n",
    "    position_trenchwise_dfs[tuple(frame_idx)] = finalize_position_t(\n",
    "        position_t_trenchwise_dfs\n",
    "    )\n",
    "trenchwise_df = finalize(position_trenchwise_dfs)\n",
    "display(trenchwise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_funcs = {\n",
    "    \"mean\": np.mean,\n",
    "    \"min\": np.min,\n",
    "    \"max\": np.max,\n",
    "    (\"p0.1\", \"p0.3\", \"p0.5\", \"p0.7\", \"p0.9\"): partial(\n",
    "        np.percentile, q=(0.1, 0.3, 0.5, 0.7, 0.9)\n",
    "    ),\n",
    "}\n",
    "trenchwise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "framewise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "\n",
    "segmentation_channel = \"MCHERRY\"\n",
    "reporter_channels = [\"MCHERRY\", \"YFP\"]\n",
    "\n",
    "\n",
    "def per_trench(trench_idx, uls, lrs, images, channels, reporter_channels=None):\n",
    "    ul = uls[trench_idx]\n",
    "    lr = lrs[trench_idx]\n",
    "    trench_images = {\n",
    "        channel: images[channel][ul[1] : lr[1] + 1, ul[0] : lr[0] + 1]\n",
    "        for channel in channels\n",
    "    }\n",
    "    trench_trenchwise_df = pd.concat(\n",
    "        {\n",
    "            channel: workflow.map_frame(trenchwise_funcs, trench_images[channel])\n",
    "            for channel in reporter_channels\n",
    "        },\n",
    "        axis=0,\n",
    "    )\n",
    "    return trench_trenchwise_df\n",
    "\n",
    "\n",
    "def per_t(frame_idx, t, trench_idxs, uls, lrs, channels=None, per_trench_func=None):\n",
    "    images = {\n",
    "        channel: workflow.get_nd2_frame(channel=channel, t=t, **frame_idx._asdict())\n",
    "        for channel in channels\n",
    "    }\n",
    "    trench_dfs = {}\n",
    "    for trench_idx in take(2, trench_idxs):\n",
    "        trench_dfs[trench_idx] = per_trench_func(trench_idx, uls, lrs, images, channels)\n",
    "    df = pd.concat(trench_dfs, axis=1).T\n",
    "    df.index.name = \"trench\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def finalize(dfs):\n",
    "    trenchwise_df = pd.concat(dfs, axis=0)\n",
    "    trenchwise_df.index.names = [\n",
    "        \"filename\",\n",
    "        \"position\",\n",
    "        \"t\",\n",
    "        *trenchwise_df.index.names[3:],\n",
    "    ]\n",
    "    return trenchwise_df\n",
    "\n",
    "\n",
    "channels = {segmentation_channel, *reporter_channels}\n",
    "per_t_func = partial(\n",
    "    per_t,\n",
    "    channels=channels,\n",
    "    per_trench_func=partial(per_trench, reporter_channels=reporter_channels),\n",
    ")\n",
    "\n",
    "all_frames_t = all_frames.groupby([\"filename\", \"position\"])\n",
    "dfs = {}\n",
    "for frame_idx, trenches in take(\n",
    "    2, util.iter_index(selected_trenches_segmentation.groupby([\"filename\", \"position\"]))\n",
    "):\n",
    "    uls = trenches[\"upper_left\"].values\n",
    "    lrs = trenches[\"lower_right\"].values\n",
    "    trench_idxs = trenches.index.get_level_values(\"trench\")\n",
    "    fp_frames = all_frames_t.get_group((frame_idx.filename, frame_idx.position))\n",
    "    for t, frames in take(2, fp_frames.groupby(\"t\")):\n",
    "        dfs[(*frame_idx, t)] = per_t_func(frame_idx, t, trench_idxs, uls, lrs)\n",
    "trenchwise_df = finalize(dfs)\n",
    "display(trenchwise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _analyze_trench(\n",
    "    trench_images,\n",
    "    channels=None,\n",
    "    trenchwise_funcs=None,\n",
    "    labelwise_funcs=None,\n",
    "    regionprops=True,\n",
    "):\n",
    "    if trenchwise_funcs:\n",
    "        trenchwise_df = pd.concat(\n",
    "            {\n",
    "                channel: workflow.map_frame(trenchwise_funcs, trench_images[channel])\n",
    "                for channel in reporter_channels\n",
    "            },\n",
    "            axis=0,\n",
    "        )\n",
    "    else:\n",
    "        trenchwise_df = None\n",
    "    if labelwise_funcs or regionprops:\n",
    "        label_trench_image = trench_segmentation.watershed.segment_trench(\n",
    "            trench_images[segmentation_channel]\n",
    "        )\n",
    "        labelwise_df = pd.concat(\n",
    "            {\n",
    "                channel: pd.concat(\n",
    "                    {\n",
    "                        \"labelwise\": workflow.map_frame_over_labels(\n",
    "                            funcs, label_trench_image, trench_images[channel]\n",
    "                        ),\n",
    "                        \"regionprops\": image.regionprops(\n",
    "                            label_trench_image, trench_images[channel]\n",
    "                        ),\n",
    "                    },\n",
    "                    axis=1,\n",
    "                )\n",
    "                for channel in reporter_channels\n",
    "            },\n",
    "            axis=1,\n",
    "        )\n",
    "    else:\n",
    "        labelwise_df = None\n",
    "    return trenchwise_df, labelwise_df\n",
    "\n",
    "\n",
    "def _get_trench_crops(images, trench_idx, uls, lrs):\n",
    "    ul = uls[trench_idx]\n",
    "    lr = lrs[trench_idx]\n",
    "    trench_images = {\n",
    "        channel: images[channel][ul[1] : lr[1] + 1, ul[0] : lr[0] + 1]\n",
    "        for channel in images.keys()\n",
    "    }\n",
    "    return trench_images\n",
    "\n",
    "\n",
    "def analyze_trenches(\n",
    "    frame_idx,\n",
    "    t,\n",
    "    trenches,\n",
    "    channels=None,\n",
    "    framewise_funcs=None,\n",
    "    trenchwise_funcs=None,\n",
    "    labelwise_funcs=None,\n",
    "    regionprops=True,\n",
    "):\n",
    "    trench_idxs = trenches.index.get_level_values(\"trench\")\n",
    "    uls = trenches[\"upper_left\"].values\n",
    "    lrs = trenches[\"lower_right\"].values\n",
    "    images = {\n",
    "        channel: workflow.get_nd2_frame(channel=channel, t=t, **frame_idx._asdict())\n",
    "        for channel in channels\n",
    "    }\n",
    "    if framewise_funcs:\n",
    "        framewise_df = pd.concat(\n",
    "            {\n",
    "                channel: workflow.map_frame(framewise_funcs, images[channel])\n",
    "                for channel in reporter_channels\n",
    "            },\n",
    "            axis=0,\n",
    "        )\n",
    "    else:\n",
    "        framewise_df = None\n",
    "    trenchwise_dfs = {}\n",
    "    labelwise_dfs = {}\n",
    "    for trench_idx in take(2, trench_idxs):\n",
    "        trench_images = _get_trench_crops(images, trench_idx, uls, lrs)\n",
    "        trench_trenchwise_df, trench_labelwise_df = _analyze_trench(\n",
    "            trench_images,\n",
    "            channels=channels,\n",
    "            trenchwise_funcs=trenchwise_funcs,\n",
    "            labelwise_funcs=labelwise_funcs,\n",
    "        )\n",
    "        trenchwise_dfs[(*frame_idx, t, trench_idx)] = trench_trenchwise_df\n",
    "        labelwise_dfs[(*frame_idx, t, trench_idx)] = trench_labelwise_df\n",
    "    framewise_df = pd.concat({(*frame_idx, t): framewise_df}, axis=1).T\n",
    "    trenchwise_df = pd.concat(trenchwise_dfs, axis=1).T\n",
    "    labelwise_df = pd.concat(labelwise_dfs, axis=0)\n",
    "    framewise_df.index.names = [\n",
    "        \"filename\",\n",
    "        \"position\",\n",
    "        \"t\",\n",
    "        *framewise_df.index.names[3:],\n",
    "    ]\n",
    "    for df in (trenchwise_df, labelwise_df):\n",
    "        df.index.names = [\"filename\", \"position\", \"t\", \"trench\", *df.index.names[4:]]\n",
    "    return framewise_df, trenchwise_df, labelwise_df\n",
    "\n",
    "\n",
    "def analyze_frames_and_trenches(selected_trenches, all_frames, func):\n",
    "    all_frames_t = all_frames.groupby([\"filename\", \"position\"])\n",
    "    res = []\n",
    "    for frame_idx, trenches in take(\n",
    "        2, util.iter_index(selected_trenches.groupby([\"filename\", \"position\"]))\n",
    "    ):\n",
    "        fp_frames = all_frames_t.get_group((frame_idx.filename, frame_idx.position))\n",
    "        for t, frames in take(2, fp_frames.groupby(\"t\")):\n",
    "            res.append(func(frame_idx, t, trenches))\n",
    "    return [\n",
    "        pd.concat(filter(lambda x: x is not None, dfs), axis=0) for dfs in zip(*res)\n",
    "    ]\n",
    "\n",
    "\n",
    "labelwise_funcs = {\n",
    "    \"mean\": np.mean,\n",
    "    \"min\": np.min,\n",
    "    \"max\": np.max,\n",
    "    (\"p0.1\", \"p0.3\", \"p0.5\", \"p0.7\", \"p0.9\"): partial(\n",
    "        np.percentile, q=(0.1, 0.3, 0.5, 0.7, 0.9)\n",
    "    ),\n",
    "}\n",
    "trenchwise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "framewise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "\n",
    "analyze_channels = [\"MCHERRY\", \"YFP\"]\n",
    "\n",
    "res0 = analyze_frames_and_trenches(\n",
    "    selected_trenches_segmentation,\n",
    "    all_frames,\n",
    "    partial(\n",
    "        analyze_trenches,\n",
    "        channels=analyze_channels,\n",
    "        framewise_funcs=framewise_funcs,\n",
    "        trenchwise_funcs=trenchwise_funcs,\n",
    "        labelwise_funcs=labelwise_funcs,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# display(trenchwise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0[2].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches_segmentation.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_bboxes[(\"info\", \"hough_value\")].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trench_bboxes[(\"info\", \"hough_value\")] > 90).sum() / len(trench_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches_segmarker = trench_bboxes[\n",
    "    trench_bboxes[(\"info\", \"hough_value\")] > 90\n",
    "].loc[IDX[:, :3, [\"MCHERRY\"], 0, :, :], :]\n",
    "selected_trenches_index = next(iter(selected_trenches_segmarker.groupby(\"t\")))[\n",
    "    1\n",
    "].index.droplevel(\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trench_bboxes) / len(selected_trenches_segmarker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches_reporter = selected_trenches_segmarker.rename(\n",
    "    index={\"MCHERRY\": \"YFP\"}, level=\"channel\", copy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches_all = pd.concat(\n",
    "    [selected_trenches_segmarker, selected_trenches_reporter]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[all_frames_future] = client.scatter([all_frames], broadcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_stacks_futures = {}\n",
    "for frame_idx, trenches in util.iter_index(\n",
    "    selected_trenches_all.groupby([\"filename\", \"position\"])\n",
    "):\n",
    "    frame_stacks_futures[frame_idx] = client.submit(\n",
    "        workflow.get_trench_stacks, trenches, all_frames_future, image_limits\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_segment_trench(img_stack):\n",
    "    label_stack = np.stack([segment_trench(img) for img in img_stack])\n",
    "    return zarr.array(\n",
    "        label_stack,\n",
    "        compressor=Blosc(cname=\"zstd\", clevel=5, shuffle=Blosc.NOSHUFFLE, blocksize=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_segs_futures = {}\n",
    "for frame_idx, trenches in util.iter_index(\n",
    "    selected_trenches_index.to_series().groupby([\"filename\", \"position\"])\n",
    "):\n",
    "    frame_segs_futures[frame_idx] = client.submit(\n",
    "        partial(workflow.map_trenchwise, do_segment_trench),\n",
    "        frame_stacks_futures[frame_idx],\n",
    "        trenches,\n",
    "    )\n",
    "# frame_segs_futures = valmap(partial(client.submit, partial(valmap, do_segment_trench)), frame_stacks_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_frame_stacks2 = workflow.get_trench_stacks(\n",
    "    selected_trenches_all.xs(\n",
    "        (\"/n/scratch2/jqs1/fidelity/all/180405_txnerr.nd2\", 0), drop_level=False\n",
    "    ),\n",
    "    all_frames,\n",
    "    image_limits,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial(map_trenchwise, compute_regionprops, channels=[\"YFP\"])(_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_regionprops_futures = {}\n",
    "for frame_idx, trenches in util.iter_index(\n",
    "    selected_trenches_index.to_series().groupby([\"filename\", \"position\"])\n",
    "):\n",
    "    frame_regionprops_futures[frame_idx] = client.submit(\n",
    "        partial(map_trenchwise, compute_regionprops, channels=[\"YFP\"]),\n",
    "        frame_stacks_futures[frame_idx],\n",
    "        trenches,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_regionprops = util.apply_map_futures(\n",
    "    client.gather, frame_regionprops_futures, predicate=lambda x: x.status == \"error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_segs = util.apply_map_futures(\n",
    "    client.gather, frame_segs_futures, predicate=lambda x: x.status == \"finished\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = util.get_one(util.get_one(frame_segs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "segs, seg_diags, seg_errs = zip(\n",
    "    *[\n",
    "        diagnostics.wrap_diagnostics(trench_segmentation.watershed.segment_trench)(img)\n",
    "        for img in img_stack\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit map_stack({'focus': image.sharpness, ('p0.1','p0.5','p0.9'): partial(np.percentile, q=(0.1,0.5,0.9))}, _frame_stacks[_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_frame_stacks[_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = {\n",
    "    \"mean\": np.mean,\n",
    "    \"min\": np.min,\n",
    "    \"max\": np.max,\n",
    "    (\"p0.1\", \"p0.5\", \"p0.9\"): partial(np.percentile, q=(0.1, 0.5, 0.9)),\n",
    "}\n",
    "a = map_stack_over_labels(funcs, _seg_masks[_key], _frame_stacks[_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.loc[IDX[:, 1:], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_frame_over_labels(\n",
    "    {\n",
    "        \"mean\": np.mean,\n",
    "        \"min\": np.min,\n",
    "        \"max\": np.max,\n",
    "        (\"p0.1\", \"p0.5\", \"p0.9\"): partial(np.percentile, q=(0.1, 0.5, 0.9)),\n",
    "    },\n",
    "    _seg_masks[_key],\n",
    "    _frame_stacks[_key],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_frame_over_labels(\n",
    "    {\n",
    "        \"mean\": np.mean,\n",
    "        \"min\": np.min,\n",
    "        \"max\": np.max,\n",
    "        (\"p0.1\", \"p0.5\", \"p0.9\"): partial(np.percentile, q=(0.1, 0.5, 0.9)),\n",
    "    },\n",
    "    l0,\n",
    "    i0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit map_frame_over_labels({'mean': np.mean, 'min': np.min, 'max': np.max, ('p0.1','p0.5','p0.9'): partial(np.percentile, q=(0.1,0.5,0.9))}, l0, i0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit map_frame_over_labels({'mean': np.mean, 'min': np.min, 'max': np.max}, l0, i0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pd.DataFrame({'label': l0.ravel(), 'value': i0.ravel()}).groupby('label').agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"label\": l0.ravel(), \"value\": i0.ravel()}).groupby(\"label\").agg(\n",
    "    [\"mean\", \"min\", \"max\", partial(np.percentile, q=(0.1, 0.5, 0.9))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = _seg_masks[_key][0]\n",
    "i0 = _frame_stacks[_key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for l in range(l0.max()):\n",
    "    i0[l0 == l].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit numpy_indexed.group_by(l0.ravel(), i0.ravel(), reduction=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rps = compute_regionprops(\n",
    "    _seg_masks[_key], _frame_stacks[_key]\n",
    ")  # , _frame_stacks[_key._replace(channel='YFP')])\n",
    "_rps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_trenches_segmarker = selected_trenches_segmarker.loc[\n",
    "    IDX[[\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\"]], :\n",
    "].iloc[10:12]\n",
    "_trenches_segmarker_index = util.get_one(_trenches_segmarker.groupby(\"t\"))[\n",
    "    1\n",
    "].index.droplevel(\"t\")\n",
    "_trenches_reporter = _trenches_segmarker.rename(\n",
    "    index={\"MCHERRY\": \"YFP\"}, level=\"channel\", copy=False\n",
    ")\n",
    "_trenches_all = pd.concat([_trenches_segmarker, _trenches_reporter]).sort_index()\n",
    "_trenches_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_frame_stacks = workflow.get_trench_stacks(_trenches_all, all_frames, image_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seg_masks = map_trenchwise(do_segment_trench, _frame_stacks, _trenches_segmarker_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seg_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_key = util.get_one(_seg_masks.keys())\n",
    "_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rps = compute_regionprops(\n",
    "    _seg_masks[_key], _frame_stacks[_key]\n",
    ")  # , _frame_stacks[_key._replace(channel='YFP')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trench_segmentation.watershed import _trench_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "segment_trench_diag = diagnostics.wrap_diagnostics_stack(\n",
    "    trench_segmentation.watershed.segment_trench\n",
    ")\n",
    "segs, seg_diags, seg_errs = segment_trench_diag(util.get_one(_frame_stacks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_stack(seg_diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = seg_diags[31][\"img_k1_frangi\"].data\n",
    "b = seg_diags[31][\"img\"].data\n",
    "c = seg_diags[31][\"img_k1\"].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(c)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(skimage.filters.rank.gradient(c, skimage.morphology.disk(1.5)))\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(skimage.filters.rank.percentile(c, skimage.morphology.disk(3), p0=0.7))\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(\n",
    "    skimage.filters.rank.mean_bilateral(c, skimage.morphology.disk(3), s0=5, s1=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(a)\n",
    "plt.figure(figsize=(12, 12))\n",
    "# plt.imshow(skimage.filters.rank.gradient(a, skimage.morphology.disk(5)))\n",
    "plt.imshow(b)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(skimage.filters.rank.median(b, skimage.morphology.disk(2)))\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(skimage.filters.gaussian(a, 1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_stacks_futures = {}\n",
    "for frame_idx, trenches in util.iter_index(\n",
    "    selected_trenches_all.groupby([\"filename\", \"position\"])\n",
    "):\n",
    "    frame_stacks_futures[frame_idx] = client.submit(\n",
    "        workflow.get_trench_stacks, trenches, all_frames_future, image_limits\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_segs_futures = {}\n",
    "for frame_idx, trenches in util.iter_index(\n",
    "    selected_trenches_index.to_series().groupby([\"filename\", \"position\"])\n",
    "):\n",
    "    frame_segs_futures[frame_idx] = client.submit(\n",
    "        partial(map_trenchwise, do_segment_trench),\n",
    "        frame_stacks_futures[frame_idx],\n",
    "        trenches,\n",
    "    )\n",
    "# frame_segs_futures = valmap(partial(client.submit, partial(valmap, do_segment_trench)), frame_stacks_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_regionprops_futures = {}\n",
    "for frame_idx, trenches in util.iter_index(\n",
    "    selected_trenches_index.to_series().groupby([\"filename\", \"position\"])\n",
    "):\n",
    "    frame_regionprops_futures[frame_idx] = client.submit(\n",
    "        partial(map_trenchwise, compute_regionprops, channels=[\"YFP\"]),\n",
    "        frame_stacks_futures[frame_idx],\n",
    "        trenches,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rps = compute_regionprops(\n",
    "    _seg_masks[_key], _frame_stacks[_key]\n",
    ")  # , _frame_stacks[_key._replace(channel='YFP')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial(map_trenchwise, compute_regionprops, channels=[\"YFP\"])(_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_trenches(root_group[\"raw\"][str(pos)][1, 30], diagnostics=diag_pos[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = tree()\n",
    "_ = get_trenches(root_group[\"raw\"][str(pos)][0, 1], diagnostics=diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(img_stack):\n",
    "    ary = np.stack(\n",
    "        [\n",
    "            segment_trench(img_stack[t], diagnostics=None)\n",
    "            for t in range(img_stack.shape[0])\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    ary = zarr.array(ary, compressor=DEFAULT_FRAME_COMPRESSOR)\n",
    "    return ary\n",
    "\n",
    "\n",
    "trench_seg_masks = positionwise_trenchwise_map(\n",
    "    root_group[\"raw\"],\n",
    "    trench_points_pos,\n",
    "    f,\n",
    "    channel_slice=1,\n",
    "    preload=True,\n",
    "    time_slice=slice(None),\n",
    "    positions=range(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(img_stack):\n",
    "    return pd.Series(np.percentile(img_stack, 95, axis=(1, 2)))\n",
    "    # return pd.Series(np.max(img_stack, axis=(1,2)))\n",
    "\n",
    "\n",
    "trench_traces_all = positionwise_trenchwise_map(\n",
    "    root_group[\"raw\"],\n",
    "    trench_points_pos,\n",
    "    f,\n",
    "    channel_slice=2,\n",
    "    preload=True,\n",
    "    time_slice=slice(None),\n",
    "    positions=range(100),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
