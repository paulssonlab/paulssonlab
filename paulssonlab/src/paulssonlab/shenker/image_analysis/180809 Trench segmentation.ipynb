{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import traceback\n",
    "import warnings\n",
    "from collections import defaultdict, namedtuple\n",
    "from collections.abc import Mapping, Sequence\n",
    "from functools import partial\n",
    "from glob import glob\n",
    "from importlib import reload\n",
    "from numbers import Number\n",
    "from operator import getitem\n",
    "\n",
    "import cachetools\n",
    "import dask\n",
    "import distributed\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import param\n",
    "import parambokeh\n",
    "import pyarrow as pa\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.parquet as pq\n",
    "import qgrid\n",
    "import scipy\n",
    "import skimage.morphology\n",
    "import streamz\n",
    "import streamz.dataframe as sdf\n",
    "import zarr\n",
    "from bokeh.models.tools import HoverTool, TapTool\n",
    "from cytoolz import *\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from holoviews.operation.datashader import regrid\n",
    "from holoviews.streams import Selection1D, Stream, param\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook\n",
    "from traitlets import All\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from processing import *\n",
    "# from trench_detection import *\n",
    "# from trench_segmentation import *\n",
    "# from trench_segmentation.watershed import *\n",
    "# from util import *\n",
    "# from ui import *\n",
    "import common\n",
    "import diagnostics\n",
    "import geometry\n",
    "import image\n",
    "import metadata\n",
    "import trench_detection\n",
    "import trench_detection.core\n",
    "import trench_detection.hough\n",
    "import trench_segmentation.watershed\n",
    "import ui\n",
    "import util\n",
    "import workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "hv.extension(\"bokeh\")\n",
    "%matplotlib inline\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Restore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r trench_points\n",
    "%store -r trench_diag\n",
    "%store -r trench_bboxes\n",
    "trench_bboxes_t0 = util.get_one(trench_bboxes.groupby(\"t\"))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"03:00:00\",\n",
    "    # job_extra=['-p transfer'],\n",
    "    # job_extra=['--cores-per-socket=8'],\n",
    "    # job_extra=['--exclude=compute-e-16-181,compute-e-16-186'],\n",
    "    # interface='ib0',\n",
    "    memory=\"3GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    cores=4,\n",
    "    processes=1,\n",
    "    # diagnostics_port=('127.0.0.1', 8787),\n",
    "    env_extra=['export PYTHONPATH=\"/home/jqs1/projects/matriarch\"'],\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = LocalCluster(n_workers=1)\n",
    "# client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster._widget().children[1].children[1].children[0].children[0].layout.width = \"200px\"\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.stop_jobs(cluster.running_jobs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scheduler.stop_services()\n",
    "cluster.scheduler.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/180405_txnerr.nd2', '/n/scratch2/jqs1/fidelity/all/180405_txnerr001.nd2']\n",
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2']#, '/n/scratch2/jqs1/fidelity/all/TrErr002_Exp.nd2']\n",
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/TrErr002_Exp.nd2']\n",
    "# nd2_filenames = ['/n/scratch2/jqs1/fidelity/all/180405_txnerr.nd2', '/n/scratch2/jqs1/fidelity/all/180405_txnerr001.nd2',\n",
    "#                 '/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2', '/n/scratch2/jqs1/fidelity/all/TrErr002_Exp.nd2']\n",
    "# nd2_filenames = ['/home/jqs1/scratch/fidelity/180518_triplegrowthcurve/PHASE_GC001.nd2', '/home/jqs1/scratch/fidelity/180518_triplegrowthcurve/PHASE_GC002.nd2']\n",
    "nd2_filenames = glob(\"/n/scratch2/jqs1/fidelity/all/180405_*.nd2\") + glob(\n",
    "    \"/n/scratch2/jqs1/fidelity/all/TrErr*.nd2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames, metadata, parsed_metadata = workflow.get_nd2_frame_list(nd2_filenames)\n",
    "image_limits = workflow.get_filename_image_limits(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check():\n",
    "    import os\n",
    "\n",
    "    return os.path.exists(\n",
    "        \"/n/scratch2/jqs1/fidelity/all/180405_txnerr_loweronly_fast.nd2\"\n",
    "    )\n",
    "\n",
    "\n",
    "[k for k, v in client.run(_check).items() if v is False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_reload():\n",
    "    from importlib import reload\n",
    "\n",
    "    import diagnostics\n",
    "    import image\n",
    "    import trench_detection\n",
    "    import util\n",
    "    import workflow\n",
    "\n",
    "    # reload(util)\n",
    "    # reload(trench_detection.hough)\n",
    "    # reload(diagnostics)\n",
    "    reload(workflow)\n",
    "    # reload(image)\n",
    "\n",
    "\n",
    "client.run(do_reload)\n",
    "do_reload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Finding trenches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_to_process = all_frames.loc[IDX[:, :, [\"MCHERRY\"], 0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Run trench finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "find_trenches_diag = diagnostics.wrap_diagnostics(\n",
    "    trench_detection.hough.find_trenches, ignore_exceptions=True, pandas=True\n",
    ")\n",
    "trench_info_futures = {\n",
    "    idx: client.submit(\n",
    "        find_trenches_diag, client.submit(workflow.get_nd2_frame, **idx._asdict())\n",
    "    )\n",
    "    for idx, row in util.iter_index(frames_to_process)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(trench_info_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(trench_info_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_completed(obj, with_results=True):\n",
    "    if isinstance(obj, Mapping):\n",
    "        futures = obj.values()\n",
    "        dask_to_keys = {future.key: k for k, future in obj.items()}\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    for res in distributed.as_completed(futures, with_results=with_results):\n",
    "        if with_results:\n",
    "            future, result = res\n",
    "            yield dask_to_keys[future.key], future, result\n",
    "        else:\n",
    "            future = res\n",
    "            yield dask_to_keys[future.key], future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_info = {}\n",
    "for key, fut, res in as_completed(trench_info_futures):\n",
    "    trench_info[key] = res\n",
    "    client.cancel(fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_info = util.apply_map_futures(\n",
    "    client.gather, trench_info_futures, predicate=lambda x: x.status == \"finished\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_points, trench_diag, trench_err = workflow.unzip_trench_info(trench_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trench_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%store trench_points\n",
    "%store trench_diag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_angle = trench_diag[\"find_trench_lines.hough_2.angle\"].abs() > 2\n",
    "bad_angle.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_pitch = (trench_diag[\"find_trench_lines.hough_2.peak_func.pitch\"] - 24).abs() > 1\n",
    "bad_pitch.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = trench_diag[bad_pitch]  # trench_diag[bad_angle | bad_period]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_stream.event(_df=selected.index.to_frame(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_points_good = trench_points[~util.multi_join(trench_points.index, bad_pitch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(trench_points_good), len(trench_points_good) / len(trench_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_bbox_futures = []\n",
    "for _, trenches in trench_points_good.groupby([\"filename\", \"position\", \"t\"]):\n",
    "    trench_bbox_futures.append(\n",
    "        client.submit(workflow.get_trench_bboxes, trenches, image_limits)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_bbox_results = util.apply_map_futures(\n",
    "    client.gather, trench_bbox_futures, predicate=lambda x: x.status == \"finished\"\n",
    ")\n",
    "trench_bboxes = pd.concat(\n",
    "    [trench_points_good, pd.concat(trench_bbox_results, axis=0)], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%store trench_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r trench_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_bboxes_t0 = util.get_one(trench_bboxes.groupby(\"t\"))[1]\n",
    "# trench_bboxes_t0.index = trench_points_good_t0.index.droplevel('t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "# Trench finding QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = all_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameStream = ui.DataFrameStream.define(\n",
    "    \"FrameStream\", selected.index.to_frame(index=False)\n",
    ")\n",
    "frame_stream = FrameStream()\n",
    "\n",
    "box = ui.dataframe_browser(frame_stream)\n",
    "frame_stream.event()\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.image_viewer(frame_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_frame_info(trench_diag, frame_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ui.show_grid(selected, stream=frame_stream)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = workflow.get_nd2_frame_anyargs(**dict(frame_stream.get_param_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, diag, _ = diagnostics.wrap_diagnostics(\n",
    "    trench_detection.hough.find_trenches, ignore_exceptions=False\n",
    ")(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_browser(diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches_segmentation = trench_bboxes_t0[\n",
    "    trench_bboxes_t0[(\"info\", \"hough_value\")] > 90\n",
    "].loc[IDX[:, :, [\"MCHERRY\"], 0, :, :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(trench_bboxes_t0), len(selected_trenches_segmentation) / len(trench_bboxes_t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames_to_analyze = all_frames.loc[IDX[:,:1,['MCHERRY','YFP'],1:5],:]\n",
    "frames_to_analyze = all_frames.loc[IDX[:, :1, [\"MCHERRY\", \"YFP\"], 1:5], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    len(frames_to_analyze),\n",
    "    len(all_frames.loc[IDX[:, :, [\"MCHERRY\", \"YFP\"], :], :]) / len(frames_to_analyze),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labelwise_funcs = {\n",
    "    \"mean\": np.mean,\n",
    "    \"min\": np.min,\n",
    "    \"max\": np.max,\n",
    "    (\"p0.3\", \"p0.5\", \"p0.7\", \"p0.9\", \"p0.95\"): partial(\n",
    "        np.percentile, q=(30, 50, 70, 90, 95)\n",
    "    ),\n",
    "}\n",
    "trenchwise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "framewise_funcs = {\"sharpness\": image.sharpness, **labelwise_funcs}\n",
    "\n",
    "analyze_trench_func = partial(\n",
    "    workflow.analyze_trenches,\n",
    "    framewise_funcs=framewise_funcs,\n",
    "    trenchwise_funcs=trenchwise_funcs,\n",
    "    labelwise_funcs=labelwise_funcs,\n",
    "    regionprops=False,\n",
    "    segment_func=trench_segmentation.watershed.segment_trench,\n",
    ")\n",
    "analyze_trench_func = compose(\n",
    "    list, partial(map, pa.RecordBatch.from_pandas), analyze_trench_func\n",
    ")\n",
    "\n",
    "analyze_trench_func = partial(client.submit, analyze_trench_func)\n",
    "\n",
    "analysis_futures = workflow.analyze_frames_and_trenches(\n",
    "    selected_trenches_segmentation, frames_to_analyze, analyze_trench_func\n",
    ")\n",
    "\n",
    "# display(trenchwise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(analysis_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(analysis_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f pd.core.groupby.groupby.BaseGrouper.get_iterator -f workflow.analyze_frames_and_trenches -f util.iter_index workflow.analyze_frames_and_trenches(selected_trenches_segmentation, frames_to_analyze, analyze_trench_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun workflow.analyze_frames_and_trenches(selected_trenches_segmentation, frames_to_analyze, analyze_trench_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(analysis_futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## New new collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.get_event_loop().set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_stream(source, futures):\n",
    "    ac = distributed.as_completed(futures, with_results=False)\n",
    "    async for future in ac:\n",
    "        await source.emit(future)\n",
    "\n",
    "\n",
    "from distributed.client import default_client\n",
    "from tornado import gen\n",
    "\n",
    "\n",
    "@streamz.Stream.register_api()\n",
    "class gather_and_cancel(streamz.Stream):\n",
    "    def __init__(self, upstream, stream_name=None, client=None, cancel=True):\n",
    "        if client is None:\n",
    "            client = default_client()\n",
    "        self.client = client\n",
    "        self.cancel = cancel\n",
    "        streamz.Stream.__init__(self, upstream, stream_name=stream_name)\n",
    "\n",
    "    @gen.coroutine\n",
    "    def update(self, x, who=None):\n",
    "        result = yield self.client.gather(x, asynchronous=True)\n",
    "        # if self.cancel:\n",
    "        #    self.client.cancel(x)\n",
    "        result2 = yield self._emit(result)\n",
    "        raise gen.Return(result2)\n",
    "\n",
    "\n",
    "def sink_to_arrow(batches, sinks, writers):\n",
    "    for i, batch in enumerate(batches):\n",
    "        if i not in writers:\n",
    "            sinks[i] = pa.BufferOutputStream()\n",
    "            writers[i] = pa.RecordBatchStreamWriter(sinks[i], batch.schema)\n",
    "        writers[i].write_batch(batch)\n",
    "\n",
    "\n",
    "source = streamz.Stream(asynchronous=True)\n",
    "\n",
    "stream_sinks = {}\n",
    "stream_writers = {}\n",
    "\n",
    "# source.rate_limit(0.0004).timed_window(1).map(partial(gather_and_cancel, cancel=True)).flatten().sink(partial(sink_to_arrow, sinks=stream_sinks, writers=stream_writers))\n",
    "# source.rate_limit(0.0004).timed_window(1).gather_and_cancel(client=client, cancel=False).flatten().sink(partial(sink_to_arrow, sinks=stream_sinks, writers=stream_writers))\n",
    "source.gather_and_cancel(client=client, cancel=True).sink(\n",
    "    lambda x: print(np.random.randint(10))\n",
    ")\n",
    "\n",
    "t = asyncio.get_event_loop().create_task(gather_stream(source, analysis_futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(AssertionError(), Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed.client import default_client\n",
    "from tornado import gen\n",
    "\n",
    "\n",
    "@streamz.Stream.register_api()\n",
    "class gather_and_cancel(streamz.Stream):\n",
    "    def __init__(self, upstream, stream_name=None, client=None, cancel=True):\n",
    "        if client is None:\n",
    "            client = default_client()\n",
    "        self.client = client\n",
    "        self.cancel = cancel\n",
    "        streamz.Stream.__init__(self, upstream, stream_name=stream_name)\n",
    "\n",
    "    @gen.coroutine\n",
    "    def update(self, x, who=None):\n",
    "        try:\n",
    "            result = yield self.client.gather(x, asynchronous=True)\n",
    "        except Exception as exc:\n",
    "            result = exc\n",
    "        if self.cancel:\n",
    "            self.client.cancel(x)\n",
    "        result2 = yield self._emit(result)\n",
    "        raise gen.Return(result2)\n",
    "\n",
    "\n",
    "source = streamz.Stream(asynchronous=True)\n",
    "\n",
    "stream_sinks = {}\n",
    "stream_writers = {}\n",
    "\n",
    "source2 = source.rate_limit(0.001).timed_window(0.1)\n",
    "source3 = streamz.buffer(source2, 100).gather_and_cancel(client=client, cancel=True)\n",
    "source3.filter(lambda x: not isinstance(x, Exception)).sink(\n",
    "    partial(sink_to_arrow, sinks=stream_sinks, writers=stream_writers)\n",
    ")\n",
    "exceptions = source3.filter(lambda x: isinstance(x, Exception)).sink_to_list()\n",
    "t = asyncio.get_event_loop().create_task(source.emit(analysis_futures[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pa.open_stream(stream_sinks[2].getvalue()).read_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "## New collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_sinks = {}\n",
    "stream_writers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_stream(source, futures):\n",
    "    ac = distributed.as_completed(futures, with_results=False)\n",
    "    async for future in ac:\n",
    "        await source.emit(future)\n",
    "        # source.emit(future)\n",
    "\n",
    "\n",
    "def gather_and_cancel(futures, cancel=True):\n",
    "    results = client.gather(futures)\n",
    "    if cancel:\n",
    "        client.cancel(futures)\n",
    "    return results\n",
    "\n",
    "\n",
    "# async def gather_and_cancel_async(futures, cancel=True):\n",
    "#     results = await client.gather(futures, asynchronous=True)\n",
    "#     if cancel:\n",
    "#         asyncio.ensure_future(client.cancel(futures, asynchronous=True))\n",
    "#     return results\n",
    "\n",
    "# async def gather_cancel_map(futures, func, cancel=True):\n",
    "#     results = await gather_and_cancel_async(futures, cancel=cancel)\n",
    "#     func(results)\n",
    "\n",
    "\n",
    "def pandas_to_arrow(dfs, sinks, writers):\n",
    "    for i, df in enumerate(dfs):\n",
    "        batch = pa.RecordBatch.from_pandas(df)\n",
    "        if i not in writers:\n",
    "            sinks[i] = pa.BufferOutputStream()\n",
    "            writers[i] = pa.RecordBatchStreamWriter(sinks[i], batch.schema)\n",
    "        writers[i].write_batch(batch)\n",
    "\n",
    "\n",
    "source = streamz.Stream(asynchronous=True)\n",
    "\n",
    "# source.rate_limit(0.1).timed_window(1).map(partial(gather_and_cancel, cancel=True)).sink(analysis_res.extend)\n",
    "# source.rate_limit(0.0004).timed_window(1).sink(partial(gather_cancel_map, func=analysis_res.extend))\n",
    "# source.rate_limit(0.0004).timed_window(1).map(partial(gather_and_cancel, cancel=True)).flatten().sink(partial(pandas_to_arrow, sinks=stream_sinks, writers=stream_writers))\n",
    "# source.rate_limit(0.1).timed_window(1).sink(lambda x: 0)\n",
    "source.rate_limit(0.0004).timed_window(1).map(\n",
    "    partial(gather_and_cancel, cancel=True)\n",
    ").flatten().sink(partial(pandas_to_arrow, sinks=stream_sinks, writers=stream_writers))\n",
    "\n",
    "t = asyncio.get_event_loop().create_task(gather_stream(source, analysis_futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(analysis_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# started 8pm sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, sink in stream_sinks.items():\n",
    "    out = pa.OSFile(\n",
    "        \"/n/scratch2/jqs1/fidelity/all/output/analysis100_stream_{}.arrow\".format(i),\n",
    "        \"w\",\n",
    "    )\n",
    "    out.write(sink.getvalue())\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pa.open_stream(stream_sinks[2].getvalue()).read_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.MemoryMappedFile(, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(analysis_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.apply_map_futures(\n",
    "    client.gather, analysis_futures, predicate=lambda x: x.status == \"error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labelwise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "framewise_df = pq.read_pandas(\n",
    "    \"/n/scratch2/jqs1/fidelity/all/output/analysis50_full_0.parquet\"\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trenchwise_df = pq.read_pandas(\n",
    "    \"/n/scratch2/jqs1/fidelity/all/output/analysis50_full_1.parquet\"\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labelwise_df = pq.read_pandas(\n",
    "    \"/n/scratch2/jqs1/fidelity/all/output/analysis50_full_2.parquet\"\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelwise_df.index.names = ['filename', 'position', 't', 'trench_set', 'trench', 'label']\n",
    "# labelwise_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labelwise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "framewise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenchwise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "## Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelwise_df2 = labelwise_df.copy()\n",
    "labelwise_df.columns = [\"_\".join(col).strip() for col in labelwise_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df.loc[:, \"MCHERRY_regionprops_area\"].plot(kind=\"hist\", bins=100, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cells = labelwise_df2[\n",
    "    (50 < labelwise_df2[\"MCHERRY_regionprops_area\"])\n",
    "    & (labelwise_df2[\"MCHERRY_regionprops_area\"] < 300)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cells.loc[:, \"MCHERRY_regionprops_area\"].plot(kind=\"hist\", bins=100, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cells.loc[:, \"MCHERRY_labelwise_p0.5\"].plot(kind=\"hist\", bins=100, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cells.loc[:, \"YFP_labelwise_p0.5\"].plot(kind=\"hist\", bins=100, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df[:10000].hvplot(\n",
    "    x=\"MCHERRY_labelwise_p0.5\", y=\"YFP_labelwise_p0.5\", kind=\"scatter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp_cols = [c for c in labelwise_df.columns if c.startswith(\"YFP_labelwise_p\")]\n",
    "mcherry_cols = [c for c in labelwise_df.columns if c.startswith(\"MCHERRY_labelwise_p\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = labelwise_df.loc[\n",
    "    IDX[\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\", 2, :, 1, 50:60], yfp_cols\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.hvplot.scatter(\"t\", \"YFP_labelwise_p0.95\", by=\"trench\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Scatter (size=3)\n",
    "hv.Layout(\n",
    "    [\n",
    "        d.hvplot.scatter(\"t\", c, by=\"trench\", width=500, height=300)\n",
    "        for c in reversed(yfp_cols)\n",
    "    ]\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = labelwise_df.loc[\n",
    "    IDX[\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\", 3, :, :, :], yfp_cols\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Scatter (size=3) [show_legend=False]\n",
    "hv.Layout(\n",
    "    [\n",
    "        d2.hvplot.scatter(\"t\", c, by=\"trench\", width=500, height=300)\n",
    "        for c in reversed(yfp_cols)\n",
    "    ]\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelwise_df.index.get_level_values('position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NYCTaxi(hv.streams.Stream):\n",
    "#     alpha = param.Magnitude(default=0.75, doc=\"Opacity\")\n",
    "#     colormap = param.ObjectSelector(default=\"fire\", objects=\n",
    "#         hpu.list_cmaps(category='Uniform Sequential', bg='dark'))\n",
    "#     location = param.ObjectSelector(default='dropoff', objects=['dropoff', 'pickup'])\n",
    "\n",
    "#     def make_view(self, x_range, y_range, **kwargs):\n",
    "#         pts   = hv.Points(taxi, [self.location+'_x', self.location+'_y'])\n",
    "#         trips = datashade(pts, cmap=hpu.process_cmap(self.colormap),\n",
    "#             x_range=x_range, y_range=y_range, dynamic=False, **dopts)\n",
    "#         return tiles.options(alpha=self.alpha) * trips\n",
    "# explorer = NYCTaxi(name=\"NYC Taxi Trips\")\n",
    "# parambokeh.Widgets(explorer, callback=explorer.event)\n",
    "# hv.DynamicMap(explorer.make_view, streams=[explorer, RangeXY()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Scatter (size=3) [show_legend=False]\n",
    "def get_plot(pos):\n",
    "    c = \"YFP_labelwise_p0.9\"\n",
    "    d = labelwise_df.loc[\n",
    "        IDX[\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\", pos, :, :, :], c\n",
    "    ]\n",
    "    return d.hvplot.scatter(\"t\", c, by=\"trench\", width=500, height=300)\n",
    "\n",
    "\n",
    "hv.HoloMap(\n",
    "    {\n",
    "        pos: get_plot(pos)\n",
    "        for pos in labelwise_df.index._get_level_values(1, unique=True)[:20]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df.head().loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = labelwise_df.loc[\n",
    "    IDX[\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\", 2, :, 1, 50:60], cols\n",
    "]\n",
    "m = pd.melt(d.loc[:, cols])\n",
    "# m.index = d.index\n",
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "# Plot tapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelStream = ui.MultiIndexStream.define(\"LabelStream\", labelwise_df.index)\n",
    "label_stream = LabelStream()\n",
    "box = ui.dataframe_browser(label_stream)\n",
    "label_stream.event()\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = d.hvplot.scatter(\"t\", \"YFP_labelwise_p0.95\").options(tools=[\"tap\", \"hover\"])\n",
    "ui.selection_to_stream(p, label_stream)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb(**kwargs):\n",
    "    dat = labelwise_df.loc[\n",
    "        workflow.stream_slice(\n",
    "            labelwise_df.index.names, kwargs, t=slice(None), label=slice(None)\n",
    "        ),\n",
    "        :,\n",
    "    ]\n",
    "    plot = dat.hvplot.scatter(\"t\", \"YFP_labelwise_p0.95\").options(\n",
    "        tools=[\"tap\", \"hover\"]\n",
    "    )\n",
    "    # ui.selection_to_stream(plot, label_stream)\n",
    "    return plot\n",
    "\n",
    "\n",
    "ui.viewer(cb, label_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129",
   "metadata": {},
   "source": [
    "## Transcription errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cells.index[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_bboxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cells.index[0][2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches = trench_bboxes.xs(\n",
    "    (*selected_cells.index[0][:2], \"MCHERRY\", 0, *selected_cells.index[0][3:-1]),\n",
    "    drop_level=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_trench_stacks(selected_trenches, all_frames, image_limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138",
   "metadata": {},
   "source": [
    "# Trench UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenchwise_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_bboxes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_bboxes[trench_bboxes[(\"info\", \"hough_value\")] > 90].loc[\n",
    "    IDX[:, :, [\"MCHERRY\"], 0, :, :], :\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_bboxes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trenches_segmentation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelStream = ui.MultiIndexStream.define('LabelStream', trench_bboxes.index)\n",
    "LabelStream = ui.MultiIndexStream.define(\"LabelStream\", labelwise_df.index)\n",
    "# LabelStream = ui.MultiIndexStream.define('LabelStream', selected_trenches_segmentation.index)\n",
    "label_stream = LabelStream()\n",
    "\n",
    "box = ui.dataframe_browser(label_stream)\n",
    "label_stream.event()\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stream.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Layout [normalize=False]\n",
    "%%opts Image [width=500 height=300]\n",
    "# image_callback = partial(ui.get_trench_set_overlay, get_frame_func=workflow.get_nd2_frame_cached)\n",
    "# p = ui.trench_set_viewer(trench_bboxes_t0, label_stream, channel='MCHERRY', image_callback=image_callback).options({'Bounds': dict(tools=['tap'])})\n",
    "p = ui.get_trench_set_overlay(\n",
    "    trench_bboxes_t0,\n",
    "    channel=\"MCHERRY\",\n",
    "    **{\n",
    "        k: label_stream.contents[k]\n",
    "        for k in (\"filename\", \"position\", \"t\", \"trench_set\", \"trench\")\n",
    "    },\n",
    ")\n",
    "p = p.options({\"Bounds\": dict(tools=[\"tap\"])})\n",
    "s = Selection1D(source=p)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Layout [normalize=False]\n",
    "%%opts Image [width=800 height=150]\n",
    "image_callback = partial(\n",
    "    ui.get_trench_set_overlay, get_frame_func=workflow.get_nd2_frame_cached\n",
    ")\n",
    "(\n",
    "    ui.trench_set_viewer(\n",
    "        trench_bboxes_t0, label_stream, channel=\"MCHERRY\", image_callback=image_callback\n",
    "    )\n",
    "    + ui.trench_set_viewer(\n",
    "        trench_bboxes_t0, label_stream, channel=\"YFP\", image_callback=image_callback\n",
    "    )\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Layout [normalize=False]\n",
    "%%output size=100\n",
    "hover = HoverTool(\n",
    "    tooltips=[\n",
    "        (\"(x,y)\", \"(@x{0[.]0}, @y{0[.]0})\"),\n",
    "        (\"value\", \"@z\"),\n",
    "    ]\n",
    ")\n",
    "cb = compose(partial(ui.hover_image, hover), ui._trench_img, workflow.get_trench_image)\n",
    "# cb = workflow.get_trench_image\n",
    "(\n",
    "    ui.trench_viewer(trench_bboxes, label_stream, channel=\"MCHERRY\", image_callback=cb)\n",
    "    + ui.trench_viewer(trench_bboxes, label_stream, channel=\"YFP\", image_callback=cb)\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "compose(partial(ui.hover_image, hover), ui._trench_img, workflow.get_trench_image)(\n",
    "    trench_bboxes,\n",
    "    \"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\",\n",
    "    3,\n",
    "    \"MCHERRY\",\n",
    "    0,\n",
    "    1,\n",
    "    56,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp = labelwise_df.loc[\n",
    "    IDX[\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\", 3, 3, 1, 61],\n",
    "    (\"YFP\", \"labelwise\", \"mean\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp2 = labelwise_df.loc[\n",
    "    IDX[\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\", 3],\n",
    "    (\"YFP\", \"labelwise\", \"p0.95\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp2[yfp2 < 300].plot.hist(bins=50, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp2[yfp2 > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp2.loc[IDX[:, 1, 60]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp2.swaplevel(0, 1).swaplevel(1, 2).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp2[yfp2 > 130].groupby([\"trench_set\", \"trench\"]).filter(lambda x: x.count() > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp[yfp > 130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df.xs(\n",
    "    IDX[\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\", 3, 2, 1, 56],\n",
    "    drop_level=False,\n",
    ")[\"YFP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df.loc[\n",
    "    IDX[\"/n/scratch2/jqs1/fidelity/all/180405_txnerr002.nd2\", 0, 2, 1, 56], \"MCHERRY\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    workflow.get_trench_image(\n",
    "        trench_bboxes,\n",
    "        channel=\"MCHERRY\",\n",
    "        **dissoc(label_stream.contents, \"_df\", \"label\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_nd2_frame(\n",
    "    channel=\"MCHERRY\",\n",
    "    **util.get_keys(label_stream.contents, \"filename\", \"position\", \"t\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(util.get_keys, keys=[\"label\"])\n",
    "f(label_stream.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stream.contents.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.image_viewer(frame_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_frame_info(trench_diag, frame_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ui.show_grid(selected, stream=frame_stream)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import tracker\n",
    "\n",
    "memory_tracker = tracker.SummaryTracker()\n",
    "memory_tracker.print_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler.classtracker import ClassTracker\n",
    "\n",
    "tracker = ClassTracker()\n",
    "tracker.track_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import objgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = objgraph.by_type(\"IOStream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "objgraph.show_backrefs(s[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "objgraph.show_most_common_types(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
