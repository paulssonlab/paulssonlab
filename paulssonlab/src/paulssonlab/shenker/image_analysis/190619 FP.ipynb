{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import traceback\n",
    "import warnings\n",
    "from functools import partial\n",
    "from glob import glob\n",
    "from importlib import reload\n",
    "\n",
    "import dask\n",
    "import distributed\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import scipy\n",
    "import zarr\n",
    "from cytoolz import *\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "import nd2reader\n",
    "from matriarch import *\n",
    "\n",
    "# import common, trench_detection, util, data_io, processing\n",
    "# import ui, diagnostics, metadata\n",
    "# import workflow, image, geometry\n",
    "# import trench_detection.hough, trench_detection.core\n",
    "# import trench_segmentation.watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler\n",
    "# %load_ext snakeviz\n",
    "hv.extension(\"bokeh\", \"matplotlib\")\n",
    "%matplotlib inline\n",
    "# tqdm.monitor_interval = 0\n",
    "# asyncio.get_event_loop().set_debug(False)\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd2_filenames = ['/home/jqs1/scratch/190509/190509_YFP_mScarlet_repressilators_fast.nd2']\n",
    "# nd2_filenames = ['/home/jqs1/scratch/190509/190509_YFP_mScarlet_repressilators_faster.nd2']\n",
    "nd2_filenames = [\n",
    "    \"/home/jqs1/scratch/190504/basilisk/190504_YFP_mScarlet_repressilators_fast.nd2\"\n",
    "]\n",
    "# nd2_filenames = ['/home/jqs1/scratch/190504/basilisk/190504_YFP_mScarlet_repressilators002.nd2']\n",
    "# nd2_filenames = ['/home/jqs1/scratch/190411_FP_Ti3/190411_mV_SCFP_repr.nd2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames, metadata, parsed_metadata = workflow.get_nd2_frame_list(nd2_filenames)\n",
    "image_limits = workflow.get_filename_image_limits(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.get(\"distributed.worker.memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.config[\"distributed\"][\"worker\"][\"memory\"] = {\n",
    "    \"target\": 0.9,\n",
    "    \"spill\": None,\n",
    "    \"pause\": None,\n",
    "    \"terminate\": 0.95,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask.config.config['distributed']['worker']['profile'] = {'interval': '10s', 'cycle': '10s'}\n",
    "# {'interval': '10ms', 'cycle': '1000ms'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"04:00:00\",\n",
    "    # job_extra=['-p transfer'],\n",
    "    # job_extra=['--cores-per-socket=8'],\n",
    "    # job_extra=['--exclude=compute-e-16-181,compute-e-16-186'],\n",
    "    # interface='ib0',\n",
    "    memory=\"12GB\",  # TODO!!!\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/projects/matriarch/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")  # ,\n",
    "# diagnostics_port=('127.0.0.1', 8787),\n",
    "# env_extra=['export PYTHONPATH=\"/home/jqs1/projects/matriarch\"',\n",
    "#'export PYTHONTRACEMALLOC=25',\n",
    "#'export MALLOC_CONF=prof:true,prof_leak:true,lg_prof_interval:31,prof_final:true',\n",
    "#           'export LD_PRELOAD=\"/home/jqs1/lib/libjemalloc.so.2\"'])\n",
    "client = Client(cluster)  # , direct_to_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(minimum=0, maximum=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.stop_jobs(cluster.running_jobs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scheduler.stop_services()\n",
    "cluster.scheduler.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_reload():\n",
    "    from importlib import reload\n",
    "\n",
    "    import diagnostics\n",
    "    import image\n",
    "    import trench_detection\n",
    "    import util\n",
    "    import workflow\n",
    "\n",
    "    # reload(util)\n",
    "    # reload(trench_detection.hough)\n",
    "    # reload(diagnostics)\n",
    "    reload(workflow)\n",
    "    # reload(image)\n",
    "\n",
    "\n",
    "client.run(do_reload)\n",
    "do_reload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Trench detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches[pitches > 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameStream = ui.MultiIndexStream.define(\"FrameStream\", all_frames.index)\n",
    "frame_stream = FrameStream()\n",
    "box = ui.dataframe_browser(frame_stream)\n",
    "frame_stream.event()\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%output size=200\n",
    "ui.image_viewer(frame_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "key = tuple(frame_stream.contents[k] for k in (\"filename\", \"position\", \"channel\", \"t\"))\n",
    "# key = ('/home/jqs1/scratch/190509/190509_YFP_mScarlet_repressilators_faster.nd2', 35, 'MCHERRY', 0)\n",
    "frame = workflow.get_nd2_frame(*key)\n",
    "# find_trenches_diag = diagnostics.wrap_diagnostics(trench_detection.find_trenches, ignore_exceptions=False, pandas=False)\n",
    "# trench_points, trench_diag, trench_err = find_trenches_diag(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%output size=150\n",
    "ui.show_plot_browser(trench_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = {}\n",
    "img = frame[500:600, :500]\n",
    "img_labels = trench_segmentation.segment(img, diagnostics=diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"img_k1_frangi\"].redim.range(z=(0, 1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"img_k1_frangi\"].redim.range(z=(0, 1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"img_k1_frangi\"].redim.range(z=(0, 1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"img_k1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_browser(diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# Drift correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(nd2_filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.metadata[\"channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imgs = [nd2.get_frame_2D(v=10, c=0, t=t) for t in range(nd2.sizes[\"t\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import register_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "shift, error, diffphase = register_translation(imgs[0], imgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "shifts = [\n",
    "    register_translation(imgs[t], imgs[t + 1], return_error=False)\n",
    "    for t in range(len(imgs) - 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "shifts_from_0 = [\n",
    "    register_translation(imgs[0], imgs[t + 1], return_error=False)\n",
    "    for t in range(len(imgs) - 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "s = 2\n",
    "shifts3 = [\n",
    "    register_translation(imgs[t], imgs[t + s], return_error=False)\n",
    "    for t in range(len(imgs) - s)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "s = 2\n",
    "shifts_avg = [\n",
    "    register_translation(\n",
    "        np.mean(imgs[t : t + s], axis=0),\n",
    "        np.mean(imgs[t + s : t + 2 * s]),\n",
    "        return_error=False,\n",
    "    )\n",
    "    for chunk in grouper()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(np.array(shifts3)[::s], axis=0))\n",
    "plt.plot(np.arange(len(shifts_from_0)) / s, np.array(shifts_from_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(np.array(shifts3)[::s], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(shifts_from_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(shifts, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(shifts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = np.product(list(util.get_keys(nd2.sizes, \"c\", \"v\").values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(nd2._parser._raw_metadata.x_data)[::period]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(nd2._parser._raw_metadata.x_data)[::period])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(nd2._parser._raw_metadata.y_data)[0::period])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(nd2._parser._raw_metadata.z_data)[0::period])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "# Data reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frames = all_frames.loc[IDX[:, 100:102, :, :], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## Debug trench detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"CFP\"\n",
    "segmentation_t = selected_frames.index.labels[selected_frames.index.names.index(\"t\")][\n",
    "    -1\n",
    "]  # last timepoint\n",
    "\n",
    "find_trenches_diag = diagnostics.wrap_diagnostics(\n",
    "    trench_detection.find_trenches, ignore_exceptions=True, pandas=True\n",
    ")\n",
    "\n",
    "\n",
    "def do_find_trenches(*key):\n",
    "    frame = workflow.get_nd2_frame(*key)\n",
    "    trench_info = find_trenches_diag(frame)\n",
    "    return trench_info\n",
    "\n",
    "\n",
    "trenches = {}\n",
    "for filename, filename_frames in selected_frames.groupby(\"filename\"):\n",
    "    for position, frames in filename_frames.groupby(\"position\"):\n",
    "        key = (filename, position)\n",
    "        frame_to_segment = frames.loc[\n",
    "            IDX[:, :, [segmentation_channel], segmentation_t], :\n",
    "        ]  # TODO: make pluggable\n",
    "        trenches_future = client.submit(do_find_trenches, *frame_to_segment.index[0])\n",
    "        #         trenches_future = do_find_trenches(*frame_to_segment.index[0])\n",
    "        trenches[key] = trenches_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches_res = client.gather(trenches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches_df = pd.DataFrame({k: v[1] for k, v in trenches_res.items()}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(trenches_res.values())[30][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches = trenches_df.loc[:, \"label_1.find_trench_lines.hough_1.peak_func.pitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pitches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches[pitches > 19]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## New trench detection+segmentation+analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trenches(trenches):\n",
    "    return trenches  # TODO!!!!!\n",
    "    pitch = 18\n",
    "    # pitch = 20.9\n",
    "    # pitch = 24\n",
    "    if trenches is None:\n",
    "        return None\n",
    "    #     good_trenches = trenches[((trenches[('diag', 'find_trench_lines.hough_2.peak_func.pitch')] - 24).abs() <= 1)\n",
    "    #                               & (trenches[('info','hough_value')] > 90)]\n",
    "    # TODO: we shouldn't be filtering based on hough_value at all!!\n",
    "    good_trenches = trenches[\n",
    "        (\n",
    "            (\n",
    "                trenches[(\"diag\", \"find_trench_lines.hough_2.peak_func.pitch\")] - pitch\n",
    "            ).abs()\n",
    "            <= 1\n",
    "        )\n",
    "        & (~trenches[(\"upper_left\", \"x\")].isnull())\n",
    "    ]\n",
    "    # TODO: filter based on minimum trench length\n",
    "    # TODO: filter based on trench peak brightness\n",
    "    return good_trenches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelwise_funcs = {\n",
    "    \"mean\": np.mean,\n",
    "    \"min\": np.min,\n",
    "    \"max\": np.max,\n",
    "    (\"p0.3\", \"p0.5\", \"p0.7\", \"p0.9\", \"p0.95\"): partial(\n",
    "        np.percentile, q=(30, 50, 70, 90, 95)\n",
    "    ),\n",
    "}\n",
    "trenchwise_funcs = {\"sharpness\": image.sharpness, **pixelwise_funcs}\n",
    "\n",
    "\n",
    "def _measurement_func(label_image, intensity_image):\n",
    "    if label_image is not None:\n",
    "        eroded_label_image = (\n",
    "            util.repeat_apply(skimage.morphology.binary_erosion, 2)(label_image != 0)\n",
    "            * label_image\n",
    "        )\n",
    "    if intensity_image is None:\n",
    "        if label_image is None:\n",
    "            return None  # can't measure anything\n",
    "        minlength = label_image.max() + 1\n",
    "        mask_labelwise_df = pd.DataFrame(\n",
    "            {\n",
    "                (\"noerode\", \"size\"): np.bincount(label_image.flat, minlength=minlength),\n",
    "                (\"erode2\", \"size\"): np.bincount(\n",
    "                    eroded_label_image.flat, minlength=minlength\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        mask_labelwise_df.index.name = \"label\"\n",
    "        return dict(mask_labelwise=mask_labelwise_df)\n",
    "    trenchwise_df = workflow.map_frame(trenchwise_funcs, intensity_image)\n",
    "    res = dict(trenchwise=trenchwise_df)\n",
    "    if label_image is None:\n",
    "        return res  # only measure trenchwise\n",
    "    labelwise = {\n",
    "        \"noerode\": workflow.map_frame_over_labels(\n",
    "            pixelwise_funcs, label_image, intensity_image\n",
    "        ),\n",
    "        \"erode2\": workflow.map_frame_over_labels(\n",
    "            pixelwise_funcs, eroded_label_image, intensity_image\n",
    "        ),\n",
    "    }\n",
    "    labelwise_df = pd.concat(labelwise, axis=1)\n",
    "    res[\"labelwise\"] = labelwise_df\n",
    "    return res  # measure trenchwise and labelwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_func(\n",
    "    output_name=\"out\",\n",
    "    extension=None,\n",
    "    kind=None,\n",
    "    name=None,\n",
    "    filename=None,\n",
    "    position=None,\n",
    "):\n",
    "    path, basename = os.path.split(filename)\n",
    "    components = [s for s in (\"\", name, extension) if s is not None]\n",
    "    if position is None:\n",
    "        path = [path, output_name, f\"{basename}.{kind}\" + \".\".join(components)]\n",
    "    else:\n",
    "        path = [\n",
    "            path,\n",
    "            output_name,\n",
    "            f\"{basename}.{kind}\",\n",
    "            \"pos{:d}\".format(position) + \".\".join(components),\n",
    "        ]\n",
    "    return os.path.join(*path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.apply_map_futures(\n",
    "    client.gather, all_analysis_futures, predicate=lambda x: x.status == \"error\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
