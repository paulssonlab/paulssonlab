{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import nd2reader\n",
    "import skimage\n",
    "from skimage.transform import SimilarityTransform, warp\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hex2color\n",
    "from cytoolz import partial\n",
    "from itertools import cycle, repeat, chain\n",
    "from numbers import Number\n",
    "import av\n",
    "import dask\n",
    "import distributed\n",
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from IPython.display import Video\n",
    "from paulssonlab.image_analysis import workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2_filename = \"/home/jqs1/scratch/jqs1/microscopy/220704/220704rbs_library_fish.nd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(nd2_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_to_color = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"RFP-PENTA\": \"#e22400\",\n",
    "    \"YFP-DUAL\": \"#f5eb00\",\n",
    "    # \"GFP\": \"#76ba40\",\n",
    "    # \"CY5\": \"#e292fe\",\n",
    "    # \"BFP\": \"#3a87fd\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"02:00:00\",\n",
    "    memory=\"4GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_channels(imgs, hexcolors, scale=True):\n",
    "    colors = [hex2color(hexcolor) for hexcolor in hexcolors]\n",
    "    return _composite_channels(imgs, colors, scale=scale)\n",
    "\n",
    "\n",
    "def _composite_channels(channel_imgs, colors, scale=True):\n",
    "    if len(channel_imgs) != len(colors):\n",
    "        raise ValueError(\"expecting equal numbers of channels and colors\")\n",
    "    num_channels = len(channel_imgs)\n",
    "    if scale:\n",
    "        scaled_imgs = [\n",
    "            channel_imgs[i] / np.percentile(channel_imgs[i], 99.9)\n",
    "            for i in range(num_channels)\n",
    "        ]\n",
    "        for scaled_img in scaled_imgs:\n",
    "            np.clip(scaled_img, 0, 1, scaled_img)  # clip in place\n",
    "    else:\n",
    "        scaled_imgs = channel_imgs\n",
    "    imgs_to_combine = [\n",
    "        scaled_imgs[i][:, :, np.newaxis] * np.array(colors[i])\n",
    "        for i in range(num_channels)\n",
    "    ]\n",
    "    if not len(imgs_to_combine):\n",
    "        imgs_to_combine = [np.ones(colored_imgs[0].shape)]  # white placeholder\n",
    "    img = imgs_to_combine[0]\n",
    "    for img2 in imgs_to_combine[1:]:\n",
    "        img = 1 - (1 - img) * (1 - img2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorized_frame(\n",
    "    nd2, t=0, v=0, channels=(\"YFP-DUAL\", \"RFP-PENTA\"), scaling_funcs=None\n",
    "):\n",
    "    imgs = [\n",
    "        nd2.get_frame_2D(v=v, t=t, c=nd2.metadata[\"channels\"].index(channel))\n",
    "        for channel in channels\n",
    "    ]\n",
    "    if scaling_funcs:\n",
    "        for idx in range(len(channels)):\n",
    "            channel = channels[idx]\n",
    "            if channel not in scaling_funcs:\n",
    "                raise ValueError(f\"missing scaling_func for {channel}\")\n",
    "            imgs[idx] = scaling_funcs[channel](imgs[idx])\n",
    "    img = composite_channels(\n",
    "        imgs,\n",
    "        [channel_to_color[channel] for channel in channels],\n",
    "        scale=(not scaling_funcs),\n",
    "    )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangles_intersect(ul1, lr1, ul2, lr2):\n",
    "    return not (\n",
    "        (ul1[0] > lr2[0]) or (lr1[0] < ul2[0]) or (ul1[1] > lr2[1]) or (lr1[1] < ul2[1])\n",
    "    )\n",
    "\n",
    "\n",
    "def scale_around_center(scale, center):\n",
    "    x, y = center\n",
    "    return (\n",
    "        SimilarityTransform(translation=(-x, -y))\n",
    "        + SimilarityTransform(scale=scale)\n",
    "        + SimilarityTransform(translation=(x, y))\n",
    "    )\n",
    "\n",
    "\n",
    "def output_transformation(input_width, input_height, output_width, output_height):\n",
    "    width_ratio = input_width / output_width\n",
    "    height_ratio = input_height / output_height\n",
    "    scale = max(width_ratio, height_ratio)\n",
    "    x = -(output_width - input_width / scale) / 2\n",
    "    y = -(output_height - input_height / scale) / 2\n",
    "    return SimilarityTransform(translation=(x, y)) + SimilarityTransform(scale=scale)\n",
    "\n",
    "\n",
    "def mosaic_frame(\n",
    "    get_frame_func,\n",
    "    positions,\n",
    "    image_dims,\n",
    "    timepoint,\n",
    "    center=None,\n",
    "    scale=1,\n",
    "    output_dims=(1024, 1024),\n",
    "):\n",
    "    if center is None:\n",
    "        columns = positions[\"x_idx\"].max() - positions[\"x_idx\"].min() + 1\n",
    "        rows = positions[\"y_idx\"].max() - positions[\"y_idx\"].min() + 1\n",
    "        center = (image_dims[0] * columns / 2, image_dims[1] * rows / 2)\n",
    "    viewport_transform = output_transformation(*image_dims, *output_dims)\n",
    "    output_img = np.zeros((output_dims[1], output_dims[0], 3))\n",
    "    viewport_ul = (0, 0)\n",
    "    viewport_lr = (output_dims[0] - 1, output_dims[1] - 1)  # TODO: off-by-one?\n",
    "    for (filename, pos_num), position in positions.iterrows():\n",
    "        frame_corner = (\n",
    "            -image_dims[0] * position[\"x_idx\"],\n",
    "            -image_dims[1] * position[\"y_idx\"],\n",
    "        )\n",
    "        frame_transform = (\n",
    "            output_transformation(*image_dims, *output_dims)\n",
    "            + scale_around_center(1 / scale, (image_dims[0] / 2, image_dims[1] / 2))\n",
    "            + SimilarityTransform(\n",
    "                translation=(\n",
    "                    center[0] - image_dims[0] / 2,\n",
    "                    center[1] - image_dims[1] / 2,\n",
    "                )\n",
    "            )\n",
    "            + SimilarityTransform(translation=frame_corner)\n",
    "        )\n",
    "        frame_ul = frame_transform.inverse((0, 0))[0]\n",
    "        frame_lr = frame_transform.inverse((image_dims[0] - 1, image_dims[1] - 1))[0]\n",
    "        visible = rectangles_intersect(viewport_ul, viewport_lr, frame_ul, frame_lr)\n",
    "        if visible:\n",
    "            img = get_frame_func(t=timepoint, v=pos_num)\n",
    "            output_img += warp(img, frame_transform, output_shape=output_dims[::-1])\n",
    "    return output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_video(ary, filename, fps=30, codec=\"h264\"):\n",
    "    with av.open(filename, mode=\"w\") as container:\n",
    "        stream = container.add_stream(codec, rate=fps)\n",
    "        stream.width = ary[0].shape[0]\n",
    "        stream.height = ary[0].shape[1]\n",
    "        stream.pix_fmt = \"yuv420p\"\n",
    "        for idx in range(len(ary)):\n",
    "            img = np.round(255 * ary[idx]).astype(np.uint8)\n",
    "            img = np.clip(img, 0, 255)\n",
    "            frame = av.VideoFrame.from_ndarray(img, format=\"rgb24\")\n",
    "            for packet in stream.encode(frame):\n",
    "                container.mux(packet)\n",
    "        for packet in stream.encode():\n",
    "            container.mux(packet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_video(a, \"/home/jqs1/scratch/jqs1/microscopy/220704/mosaics/export_test.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"/home/jqs1/scratch/jqs1/microscopy/220704/mosaics/export_test.mp4\", embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intensity_extrema(nd2, channels, v=0, step=10):\n",
    "    extrema = {}\n",
    "    for channel in channels:\n",
    "        min_value = -1\n",
    "        max_value = -1\n",
    "        for t in range(0, nd2.sizes[\"t\"], step):\n",
    "            img = nd2.get_frame_2D(v=v, t=t, c=nd2.metadata[\"channels\"].index(channel))\n",
    "            if min_value == -1:\n",
    "                min_value = img.min()\n",
    "                #max_value = img.max()\n",
    "                max_value = np.percentile(img, 99.9)\n",
    "            else:\n",
    "                min_value = min(min_value, img.min())\n",
    "                #max_value = max(max_value, img.max())\n",
    "                max_value = max(max_value, np.percentile(img, 99.9))\n",
    "        extrema[channel] = (min_value, max_value)\n",
    "    return extrema\n",
    "\n",
    "\n",
    "def get_scaling_funcs(extrema):\n",
    "    scaling_funcs = {}\n",
    "    for channel, (min_value, max_value) in extrema.items():\n",
    "        scaling_funcs[channel] = lambda x: np.clip(\n",
    "            (x - min_value) / (max_value - min_value), 0, 1\n",
    "        )\n",
    "    return scaling_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic_animate_scale(\n",
    "    filename,\n",
    "    scale=1,\n",
    "    timepoints=None,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    # frame_rate=1, #TODO\n",
    "    channels=(\"YFP-DUAL\", \"RFP-PENTA\"),\n",
    "    scaling_funcs=None,\n",
    "    delayed=True,\n",
    "    # ignore_exceptions=True,\n",
    "):\n",
    "    if delayed is True:\n",
    "        delayed = dask.delayed(pure=True)\n",
    "    elif delayed is False:\n",
    "        delayed = lambda func, **kwargs: func\n",
    "    # TODO\n",
    "    # if ignore_exceptions:\n",
    "    #     excepts_get_nd2_frame = excepts(Exception, get_nd2_frame)\n",
    "    #     excepts_segmentation_func = excepts(Exception, segmentation_func)\n",
    "    #     excepts_measure = excepts(Exception, measure)\n",
    "    # else:\n",
    "    #     excepts_get_nd2_frame = get_nd2_frame\n",
    "    #     excepts_segmentation_func = segmentation_func\n",
    "    #     excepts_measure = measure\n",
    "    nd2 = nd2reader.ND2Reader(filename)\n",
    "    nd2s = {filename: nd2 for filename in (filename,)}\n",
    "    metadata = {\n",
    "        nd2_filename: workflow.parse_nd2_metadata(nd2)\n",
    "        for nd2_filename, nd2 in nd2s.items()\n",
    "    }\n",
    "    positions = workflow.get_position_metadata(metadata)\n",
    "    # TODO\n",
    "    small_positions = positions[(positions[\"y_idx\"] < 3) & (positions[\"x_idx\"] < 3)]\n",
    "    image_limits = workflow.get_filename_image_limits(metadata)\n",
    "    get_frame_func = partial(colorized_frame, nd2, scaling_funcs=scaling_funcs)\n",
    "    input_dims = (\n",
    "        image_limits[filename][0][1] + 1,\n",
    "        image_limits[filename][1][1] + 1,\n",
    "    )\n",
    "    if isinstance(scale, Number):\n",
    "        if timepoints is None:\n",
    "            timepoints = range(nd2.sizes[\"t\"])\n",
    "    else:\n",
    "        if timepoints is None:\n",
    "            timepoints = cycle(range(nd2.sizes[\"t\"]))\n",
    "    animation = [\n",
    "        delayed(mosaic_frame)(get_frame_func, small_positions, input_dims, t, scale=s)\n",
    "        for t, s in zip(timepoints, scale)\n",
    "    ]\n",
    "    return animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "extrema = get_intensity_extrema(nd2, (\"YFP-DUAL\", \"RFP-PENTA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_funcs = get_scaling_funcs(extrema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_funcs = get_scaling_funcs({'YFP-DUAL': (262, 8000), 'RFP-PENTA': (278, 5000)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nd2.get_frame_2D(t=0, v=0, c=nd2.metadata[\"channels\"].index(\"YFP-DUAL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_scaled = scaling_funcs[\"YFP-DUAL\"](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scale = repeat(0.3)  # [0.3, 0.3, 0.3, 0.3]\n",
    "#timepoints = range(0, 119, 30)\n",
    "timepoints = [20,40,60]\n",
    "a = mosaic_animate_scale(\n",
    "    nd2_filename,\n",
    "    scale,\n",
    "    timepoints=timepoints,\n",
    "    scaling_funcs=scaling_funcs,\n",
    "    delayed=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a = [\n",
    "    mosaic_frame(\n",
    "        partial(colorized_frame, nd2), small_positions, (5056, 2960), t, scale=0.3\n",
    "    )\n",
    "    for t in (0, 20, 50, 70, 100)  # (0, 10, 20, 30, 50, 70, 100, 115)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
