{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.feather as feather\n",
    "import zarr\n",
    "import dask\n",
    "from dask import delayed\n",
    "import distributed\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import streamz\n",
    "import streamz.dataframe as sdf\n",
    "import holoviews as hv\n",
    "from holoviews.streams import Stream, param, Selection1D\n",
    "from holoviews.operation.datashader import regrid\n",
    "from bokeh.models.tools import HoverTool, TapTool\n",
    "import matplotlib.pyplot as plt\n",
    "import qgrid\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook\n",
    "import warnings\n",
    "from functools import partial\n",
    "from cytoolz import *\n",
    "from operator import getitem\n",
    "import nd2reader\n",
    "from importlib import reload\n",
    "import traceback\n",
    "import hvplot.pandas\n",
    "import cachetools\n",
    "from collections import namedtuple, defaultdict\n",
    "from collections.abc import Mapping, Sequence\n",
    "from numbers import Number\n",
    "import skimage.morphology\n",
    "import scipy\n",
    "from glob import glob\n",
    "import os\n",
    "import asyncio\n",
    "from IPython.display import Video\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd2_filenames = [\"/home/jqs1/scratch/jqs1/microscopy/211117/211117_long_oscillator.nd2\"]\n",
    "# nd2_filenames = [\"/n/standby/hms/sysbio/paulsson/collaborations/Personal_Folders/!!Jacob Quinn Shenker/Standby/180928/CapturedRFP_giant snake.nd2\"]\n",
    "nd2_filenames = [\"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames, metadata = workflow.get_nd2_frame_list(nd2_filenames)\n",
    "image_limits = workflow.get_filename_image_limits(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all_frames` lists each exposure (keyed by filename/position/channel/timepoint). `image_limits` is a dict giving *inclusive* image bounds `((x_min, x_max), (y_min, y_max))` for each input image filename. The reason both of these outputs are keyed by filename (and why `workflow.get_nd2_frame_list` takes a list of images) is that we want to support the use case where image acquisition is stopped and restarted one or more times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"06:00:00\",\n",
    "    memory=\"20GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I run this code block when I make code changes and want my dask workers to reflect these changes. It would be nice if there were a way for this to happen automatically, á là Jupyter autoreload magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_reload():\n",
    "    from importlib import reload\n",
    "    from paulssonlab.image_analysis import util\n",
    "\n",
    "    reload(util)\n",
    "    # reload(trench_detection.hough)\n",
    "    # reload(diagnostics)\n",
    "    # reload(workflow)\n",
    "    # reload(image)\n",
    "\n",
    "\n",
    "client.run(do_reload)\n",
    "do_reload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trench detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells set up a clunky way to browse through an imaging dataset. For example, we can browse to try to find frames that look weird (e.g., a speck of dust); we can then test that trench detection works correctly on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameStream = ui.MultiIndexStream.define(\"FrameStream\", all_frames.index)\n",
    "frame_stream = FrameStream()\n",
    "box = ui.dataframe_browser(frame_stream)\n",
    "frame_stream.event()\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.image_viewer(frame_stream).opts(frame_width=500, frame_height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "key = frame_stream.contents\n",
    "frame = workflow.get_nd2_frame(**key)\n",
    "find_trenches_diag = diagnostics.wrap_diagnostics(\n",
    "    trench_detection.find_trenches, ignore_exceptions=True, pandas=True\n",
    ")\n",
    "trench_points, trench_diag, trench_err = find_trenches_diag(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%output size=150\n",
    "ui.show_plot_browser(trench_diag[\"label_2\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use `pd.IndexSlice` (imported as `IDX`) to select the first three positions and first ten timepoints. This is not the most intuitive syntax (it's easy to forget the order of the keys in the `IDX` expression). Something like `all_frames.select(positions=slice(3), timepoints=slice(10))` might be slightly more intuitive, although that's still a little clunky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames = all_frames.loc[IDX[:, :5, :, [0,50,100]], :]\n",
    "selected_frames = all_frames.loc[IDX[:, :, :, :], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New trench detection+segmentation+analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specify which channel we're using as the input to the segmentation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-Penta\"\n",
    "measure_channels = [\"YFP-DUAL\", \"RFP-Penta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filter_trenches` expects the output (dataframe) from trench detection and returns a filtered dataframe including only the trenches that are suitable for downstream processing. For every FOV, trench detection is run for the first timepoint of every FOV, then passed through `filter_trenches`, and then that list of trenches for that FOV is used to crop each trench for all timepoints. A slightly better way for this to work is to wait until trench cropping is done for all FOVs, send the dataframe of all trenches for **all** FOVs to `filter_trenches`, so that `filter_trenches` can look at parameters like pitch and rotation angle and throw out FOVs where the trench detection produced pitch/angle far away from the median pitch/angle. The reason I initially didn't implement it that way is that this way all downstream processing (e.g., segmentation) is stalled until all FOVs have their trench detection finished. In practice this is probably fine. One way to get the best-of-both-worlds might be to start segmentation for each FOV as soon as trench detection is done, but as soon as trench detection is done for all FOVs, you cancel in-flight and completed segmentation tasks for the trenches that you no longer want because they were filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trenches(trenches):\n",
    "    return trenches\n",
    "    # pitch = 32 # (pixels) here we hard-code the correct pitch\n",
    "    # # so throw out positions with detected pitch more than 1 pixel away from this\n",
    "    # # a better way to do this is to look at the median pitch of all positions and use that\n",
    "    # # as the ground truth instead\n",
    "    # if trenches is None:\n",
    "    #     return None\n",
    "    # good_trenches = trenches[\n",
    "    #     (\n",
    "    #         (\n",
    "    #             trenches[(\"diag\", \"find_trench_lines.hough_2.peak_func.pitch\")] - pitch\n",
    "    #         ).abs()\n",
    "    #         <= 1\n",
    "    #     )\n",
    "    #     & (~trenches[(\"upper_left\", \"x\")].isnull())\n",
    "    # ]\n",
    "    # TODO: filter based on minimum trench length\n",
    "    # return good_trenches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simpler `_measurement_func`. (Either evaluate the above or the below cell.) `_measurement_func` is passed in to `_measure` (below) and provides the user with a way to customize how they want each channel to be measured. `_measurement_func` returns a dict with keys \"framewise,\" \"trenchwise,\" and \"labelwise,\" corresponding to dataframes of measurements made at three levels of granularity. \"Framewise\" measurements represent quantities that are computed from all pixels of an FOV; trenchwise measurements represent quantities (like average fluorescence, or some measure of sharpness/focus) for unsegmented trench crops; labelwise measurements represent quantities that are computed per cell mask. For labelwise measurements, `_measurement_func` is called once with `intensity_image=None`; in this case, it returns a dict with key \"mask_labelwise\"; the corresponding value is a dataframe containing measurements that depend only on the segmentation mask and not on any intensity image (in this case, a measurement called \"size\", which is the number of pixels in each label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\"\n",
    ")\n",
    "img = nd2.get_frame_2D(v=50, t=50, c=1)\n",
    "img_crop = img[:500, :500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_crop_labels = trench_segmentation.segment(img_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_crop_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_measurement_func(img_crop_labels, None)[\"mask_labelwise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_measurement_func(img_crop_labels, None)[\"mask_labelwise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_measurement_func(img_crop_labels, img_crop)[\"labelwise\"]  # [\"mask_labelwise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelwise_funcs = {\"mean\": np.mean, \"sum\": np.sum}\n",
    "# trenchwise_funcs = {\"sharpness\": image.sharpness, **pixelwise_funcs}\n",
    "# trenchwise_funcs = {}\n",
    "\n",
    "\n",
    "def _measurement_func(label_image, intensity_image):\n",
    "    if intensity_image is None:\n",
    "        if label_image is None:\n",
    "            return None  # can't measure anything\n",
    "        mask_labelwise_df = pd.DataFrame(\n",
    "            skimage.measure.regionprops_table(\n",
    "                label_image,\n",
    "                properties=(\n",
    "                    \"label\",\n",
    "                    \"area\",\n",
    "                    \"axis_major_length\",\n",
    "                    \"axis_minor_length\",\n",
    "                    \"orientation\",\n",
    "                    \"centroid\",\n",
    "                ),\n",
    "            ),\n",
    "        ).set_index(\"label\")\n",
    "        return dict(mask_labelwise=mask_labelwise_df)\n",
    "    # trenchwise_df = workflow.map_frame(trenchwise_funcs, intensity_image)\n",
    "    # res = dict(trenchwise=trenchwise_df)\n",
    "    res = {}\n",
    "    if label_image is None:\n",
    "        return res  # only measure trenchwise\n",
    "    labelwise_df = workflow.map_frame_over_labels(\n",
    "        pixelwise_funcs, label_image, intensity_image\n",
    "    )\n",
    "    # labelwise_df = pd.DataFrame(\n",
    "    #     skimage.measure.regionprops_table(\n",
    "    #         label_image,\n",
    "    #         intensity_image,\n",
    "    #         properties=(\"label\", \"intensity_mean\"),\n",
    "    #     ),\n",
    "    # ).set_index(\"label\")\n",
    "    res[\"labelwise\"] = labelwise_df\n",
    "    return res  # measure trenchwise and labelwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modifying the above functions, users can customize how they want to process the images (although 60% of experiments might use the same basic configuration: segment in RFP channel and measure mean fluorescences in RFP/YFP/CFP channels, something that looks like the simple `_measurement_func` directly above). Below is a bunch of boilerplate that probably doesn't need to be customized per-experiment. It should be cleaned up a lot and put in .py files in a package.\n",
    "\n",
    "`processing._get_trench_crops` returns a dict of trench crops keyed by the trench index, plus the additional key `\"_frame\"` which is the full frame (used for \"framewise\" measurements, discussed above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _measure(\n",
    "    trenches,\n",
    "    frames,\n",
    "    measurement_func,\n",
    "    segmentation_channel=segmentation_channel,\n",
    "    measure_channels=None,\n",
    "    segmentation_func=trench_segmentation.watershed.segment,\n",
    "    include_frame=True,\n",
    "    frame_bits=8,\n",
    "    frame_downsample=4,\n",
    "    filename=None,\n",
    "    position=None,\n",
    "):\n",
    "    frame_transformation = compose(\n",
    "        processing.zarrify,\n",
    "        partial(image.quantize, bits=frame_bits),\n",
    "        partial(image.downsample, factor=frame_downsample),\n",
    "    )\n",
    "    trench_crops = processing._get_trench_crops(\n",
    "        trenches,\n",
    "        frames,\n",
    "        include_frame=include_frame,\n",
    "        frame_transformation=frame_transformation,\n",
    "        filename=filename,\n",
    "        position=position,\n",
    "    )\n",
    "    res = {}\n",
    "    segmentation_masks = {}\n",
    "    measurements = {}\n",
    "    # segment\n",
    "    for trench_set, crops_trench_channel_t in trench_crops.items():\n",
    "        if trench_set == \"_frame\":\n",
    "            continue\n",
    "        for trench_idx, crops_channel_t in crops_trench_channel_t.items():\n",
    "            for channel, crops_t in crops_channel_t.items():\n",
    "                for t, crop in crops_t.items():\n",
    "                    if measure_channels is not None and channel not in measure_channels:\n",
    "                        continue\n",
    "                    segmentation_key = (trench_set, trench_idx, segmentation_channel, t)\n",
    "                    segmentation_mask = segmentation_masks.get(segmentation_key, None)\n",
    "                    if segmentation_mask is None and segmentation_func is not None:\n",
    "                        segmentation_mask = segmentation_func(\n",
    "                            trench_crops[trench_set][trench_idx][segmentation_channel][\n",
    "                                t\n",
    "                            ]\n",
    "                        )\n",
    "                        segmentation_masks[segmentation_key] = segmentation_mask\n",
    "                        # measure mask\n",
    "                        if measurement_func is not None:\n",
    "                            measurements[\n",
    "                                (\"mask\", (trench_set, trench_idx, t))\n",
    "                            ] = measurement_func(segmentation_mask, None)\n",
    "                    # measure\n",
    "                    if measurement_func is not None:\n",
    "                        measurements[\n",
    "                            (channel, (trench_set, trench_idx, t))\n",
    "                        ] = measurement_func(segmentation_mask, crop)\n",
    "    if measurement_func is not None:\n",
    "        measurement_dfs = util.map_dict_levels(\n",
    "            lambda k: (k[1], k[0], *k[2:]), measurements\n",
    "        )\n",
    "        for name, dfs in measurement_dfs.items():\n",
    "            dfs = util.unflatten_dict(dfs)\n",
    "            if isinstance(util.get_one(dfs, level=2), pd.Series):\n",
    "                df = pd.concat(\n",
    "                    {\n",
    "                        channel: pd.concat(channel_dfs, axis=1).T\n",
    "                        for channel, channel_dfs in dfs.items()\n",
    "                    },\n",
    "                    axis=1,\n",
    "                )\n",
    "            else:\n",
    "                df = pd.concat(\n",
    "                    {\n",
    "                        channel: pd.concat(channel_dfs, axis=0)\n",
    "                        for channel, channel_dfs in dfs.items()\n",
    "                    },\n",
    "                    axis=1,\n",
    "                )\n",
    "            df.index.names = [\"trench_set\", \"trench\", \"t\", *df.index.names[3:]]\n",
    "            measurement_dfs[name] = df\n",
    "        res[\"measurements\"] = measurement_dfs\n",
    "    images = dict(raw=trench_crops)\n",
    "    if segmentation_func is not None:\n",
    "        images[\"segmentation\"] = util.unflatten_dict(segmentation_masks)\n",
    "    res[\"images\"] = images\n",
    "    return res\n",
    "\n",
    "\n",
    "measure = processing.iterate_over_groupby([\"filename\", \"position\"])(_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to generate filenames for pipeline output files. `kind` is either `\"measurements\"` (tabular output in parquet format) or `\"images\"` (image output in zarr format). By default, these outputs are saved in the same directory as the input ND2 file and have the same basename with additional suffixes. E.g., the input file `211117_long_oscillator.nd2` will have outputs `211117_long_oscillator.nd2.images` (folder of zarrs), `211117_long_oscillator.nd2.measurements` (folder of parquet files), `211117_long_oscillator.nd2.trenches.parquet` (the dataframe of trench bounding boxes), etc. I added the `extra` kwarg just so it's easy to rerun the pipeline multiple times and get different output filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filename_func(\n",
    "    extension=None, kind=None, name=None, filename=None, position=None, extra=\"full\"\n",
    "):\n",
    "    if kind and extra:\n",
    "        kind = f\"{extra}.{kind}\"\n",
    "    components = [s for s in (\"\", name, extension) if s is not None]\n",
    "    if position is None:\n",
    "        path = [f\"{filename}.{kind}\" + \".\".join(components)]\n",
    "    else:\n",
    "        path = [f\"{filename}.{kind}\", \"pos{:d}\".format(position) + \".\".join(components)]\n",
    "    return os.path.join(*path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a morass of boilerplate. Two functions which need a bit more explanation:\n",
    "- `_trench_diag_to_dataframe`: takes a nested dict (a `tree()` object passed to the `diagnostics=` kwarg of `trench_detection.find_trenches`), pulls out the scalar values in the leaves of the nested dict tree (dropping the holoviews plots, etc.), and turns it into a dataframe. The heavy lifting is done by `diagnostics.expand_diagnostics_by_label`, which is a truly ugly function—I owe you some documentation (once I remember myself how it works), but honestly, it should probably just be jettisoned because there has to be a better way of doing all of this. But the basic purpose of `expand_diagnostics_by_label` is to take a dataframe with columns like `label_1.X` and `label_2.X` and turn it into a dataframe with only the column `X` but with an additional level in the multiindex called `label` (and the single row is split into two rows, one for `label=1` and another for `label=2`).\n",
    "- `find_trenches_diag`: this is just `trench_detection.find_trenches` wrapped by `diagnostics.wrap_diagnostics`. `wrap_diagnostics` automatically passes in a `tree()` object to `diagnostics=` and turns the resulting nested dict into a pandas series, which it returns in a tuple `(result, diag, err)`.\n",
    "- `_trench_info_to_dataframe`: this unpacks the tuple returned by `find_trenches_diag`, uses `_trench_diag_to_dataframe` to `pd.concat` the dataframe of trench bounding boxes (`trench_points`, which is the return value of `trench_detection.find_trenches`) together with this additional dataframe of debugging information that was extracted from diagnostics.\n",
    "\n",
    "A quick note: the purpose of the diagnostics kwarg was to enable storing additional information only when a user wanted to manually request it, but never to do so during production operation of the pipeline. Here, just for the trench detection step (not for segmentation), we *are* storing diagnostics for trench finding. The rationale being that if trench detection fails, we can pickle the diagnostics object to disk, and the user can `pickle.load` it and immediately see what's going on. One downside is we're incurring extra processing and memory usage during trench detection, because for positions where trench detection is successful, we store a bunch of holoviews plots only to throw them away as soon as trench detection completes successfully. (Because trench detection is pretty fast compared to segmentation, this maybe isn't a huge problem.) I think a better way to do this would be to run trench detection *without* storing diagnostics, and provide a option to automatically re-run trench detection/segmentation/tracking/etc. steps of the pipeline with diagnostics enabled if any of those steps fail. I think part of the reason I initially implemented it like this is I wasn't sure which of the scalar diagnostics metrics were useful to filter on in `filter_trenches`, which can currently access all of them. Under this new design, any metrics we want to filter on would have to be included with in the dataframe that's returned by `trench_detection.find_trenches`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _trench_diag_to_dataframe(trench_diag, sep=\".\"):\n",
    "    df = trench_diag.to_frame().T\n",
    "    expanded_df = diagnostics.expand_diagnostics_by_label(df)\n",
    "    expanded_df.index = expanded_df.index.droplevel(0)\n",
    "    expanded_df.index.names = [*expanded_df.index.names[:-1], \"trench_set\"]\n",
    "    return expanded_df\n",
    "\n",
    "\n",
    "#     if len(expanded_df):\n",
    "#         expanded_df.index = expanded_df.index.droplevel(0)\n",
    "#         expanded_df.index.names = [*expanded_df.index.names[:-1], 'trench_set']\n",
    "#     else:\n",
    "#         expanded_df = pd.concat([df], keys=[-1], names=['trench_set'])\n",
    "#     return expanded_df\n",
    "\n",
    "\n",
    "def _trench_info_to_dataframe(trench_info):\n",
    "    trench_points, trench_diag, trench_err = trench_info\n",
    "    if trench_err is not None:\n",
    "        # TODO: write trench_err\n",
    "        return None\n",
    "    trench_diag = _trench_diag_to_dataframe(trench_info[1])\n",
    "    # FROM: https://stackoverflow.com/questions/14744068/prepend-a-level-to-a-pandas-multiindex\n",
    "    trench_diag = pd.concat([trench_diag], axis=1, keys=[\"diag\"])\n",
    "    trenches = pd.concat(\n",
    "        [trench_points, util.multi_join(trench_info[0].index, trench_diag)], axis=1\n",
    "    )\n",
    "    return trenches\n",
    "\n",
    "\n",
    "def _trenches_to_bboxes(trenches, image_limits):\n",
    "    trench_bboxes = workflow.get_trench_bboxes(trenches, image_limits)\n",
    "    if trench_bboxes is not None:\n",
    "        trenches = pd.concat([trenches, trench_bboxes], axis=1)\n",
    "    return trenches\n",
    "\n",
    "\n",
    "find_trenches_diag = diagnostics.wrap_diagnostics(\n",
    "    trench_detection.find_trenches, ignore_exceptions=True, pandas=True\n",
    ")\n",
    "\n",
    "\n",
    "def do_find_trenches(*key):\n",
    "    frame = workflow.get_nd2_frame(*key)\n",
    "    trench_info = find_trenches_diag(frame)\n",
    "    return trench_info\n",
    "\n",
    "\n",
    "def do_trenches_to_bboxes(trench_info, key=None, index_names=(\"filename\", \"position\")):\n",
    "    trenches = _trench_info_to_dataframe(trench_info)\n",
    "    if trenches is None:\n",
    "        return None\n",
    "    if key is not None:\n",
    "        trenches = pd.concat([trenches], names=index_names, keys=[key])\n",
    "    trenches = _trenches_to_bboxes(trenches, image_limits=image_limits)\n",
    "    return trenches\n",
    "\n",
    "\n",
    "def do_get_trench_err(trench_info):\n",
    "    trench_points, trench_diag, trench_err = trench_info\n",
    "    if trench_err is None:\n",
    "        return None\n",
    "    if trench_points is not None:\n",
    "        raise ValueError(\"expecting trench_points to be None\")\n",
    "    return trench_info\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def do_serialize_to_disk(\n",
    "    data, filename, overwrite=True, skip_nones=True, format=\"pickle\"\n",
    "):\n",
    "    if skip_nones:\n",
    "        data = {k: v for k, v in data.items() if v is not None}\n",
    "    if not overwrite and os.path.exists(filename):\n",
    "        raise FileExistsError\n",
    "    with open(filename, \"wb\") as f:\n",
    "        if format == \"arrow\":\n",
    "            buf = pa.serialize(data).to_buffer()\n",
    "            f.write(buf)\n",
    "        elif format == \"pickle\":\n",
    "            pickle.dump(data, f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def do_save_trenches(trenches, filename, overwrite=True):\n",
    "    trenches = pd.concat(trenches)\n",
    "    processing.write_dataframe_to_parquet(\n",
    "        filename, trenches, merge=False, overwrite=overwrite\n",
    "    )\n",
    "    return trenches\n",
    "\n",
    "\n",
    "def do_measure_and_write(\n",
    "    trenches,\n",
    "    frames,\n",
    "    return_none=True,\n",
    "    write=True,\n",
    "    filename_func=filename_func,\n",
    "    **kwargs\n",
    "):\n",
    "    if trenches is None:\n",
    "        return None\n",
    "    trenches = filter_trenches(trenches)\n",
    "    res = measure(trenches, frames, **kwargs)\n",
    "    if write:\n",
    "        processing.write_images_and_measurements(\n",
    "            res,\n",
    "            filename_func=filename_func,\n",
    "            dataframe_format=\"parquet\",\n",
    "            write_images=True,\n",
    "            write_measurements=True,\n",
    "        )\n",
    "    if return_none:\n",
    "        return None\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we actually run the pipeline. Tasks are submitted using the dask futures API. Initially I had implemented this so every trench was its own dask task; this resulted in millions of small tasks and the dask scheduler choked on them at the time. I imagine with all the recent improvements in the dask scheduler that approach would work somewhat better now. In the current implementation, tasks are run at the granularity of `(filename, position)` pairs. Each `(filename, position)` pair gets a task (`do_measure_and_write`). `do_measure_and_write` filters the trenches according to `filter_trenches` (specified above), and passes them to `measure` (described above).\n",
    "\n",
    "`do_serialize_to_disk`: this function is designed to take a dask task as input. If the input is non-None, it pickles the input and writes to disk. Here, it is used in combination with `do_get_trench_err` to write a tuple containing the `diagnostics` object and exception to disk for any positions where `do_find_trenches` fails (so the user can pickle.load those files and figure out why that position was failing in the trench detection step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trench_err_futures = {}\n",
    "all_analysis_futures = {}\n",
    "save_trenches_futures = {}\n",
    "save_trench_err_futures = {}\n",
    "\n",
    "all_trench_bboxes_futures = {}  # TODO: just for debugging\n",
    "\n",
    "for filename, filename_frames in selected_frames.groupby(\"filename\"):\n",
    "    # analysis_futures = {}\n",
    "    trench_bboxes_futures = {}\n",
    "    trench_err_futures = {}\n",
    "    for position, frames in filename_frames.groupby(\"position\"):\n",
    "        key = (filename, position)\n",
    "        frame_to_segment = frames.loc[IDX[:, :, [segmentation_channel], 0], :]\n",
    "        trenches_future = client.submit(\n",
    "            do_find_trenches, *frame_to_segment.index[0], priority=10\n",
    "        )\n",
    "        trench_err_futures[key] = client.submit(do_get_trench_err, trenches_future)\n",
    "        trench_bboxes_future = client.submit(\n",
    "            do_trenches_to_bboxes, trenches_future, (filename, position), priority=10\n",
    "        )\n",
    "        trench_bboxes_futures[key] = trench_bboxes_future\n",
    "        all_trench_bboxes_futures[key] = trench_bboxes_future\n",
    "        analysis_future = client.submit(\n",
    "            do_measure_and_write,\n",
    "            trench_bboxes_future,\n",
    "            frames,\n",
    "            measurement_func=_measurement_func,\n",
    "            # measurement_func=None,\n",
    "            # segmentation_func=None,\n",
    "            measure_channels=measure_channels,\n",
    "            segmentation_channel=segmentation_channel,\n",
    "            return_none=True,\n",
    "            write=True,\n",
    "            filename_func=filename_func,\n",
    "        )\n",
    "        all_analysis_futures[key] = analysis_future\n",
    "    # save trenches\n",
    "    trenches_filename = filename_func(\n",
    "        kind=\"trenches\", extension=\"parquet\", filename=filename\n",
    "    )\n",
    "    save_trenches_futures[filename] = client.submit(\n",
    "        do_save_trenches,\n",
    "        list(dict(sorted(trench_bboxes_futures.items())).values()),\n",
    "        trenches_filename,\n",
    "    )\n",
    "    trench_errs_filename = filename_func(\n",
    "        kind=\"trench_errs\", extension=\"pickle\", filename=filename\n",
    "    )\n",
    "    save_trench_err_futures[filename] = client.submit(\n",
    "        do_serialize_to_disk,\n",
    "        trench_err_futures,\n",
    "        trench_errs_filename,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trench_err_futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the utility function `util.apply_map_futures` to filter a (potentially nested) dict of dask futures and pull out only those that have errored, and gather them. This essentially reraises exceptions for failed dask tasks so that you know what went wrong when debugging interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.apply_map_futures(\n",
    "    client.gather, all_analysis_futures, predicate=lambda x: x.status == \"error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`211117_long_oscillator.nd2.trenches.parquet` is the dataframe that is produced by `find_trenches_diag`, listing all the trenches for each position and a bunch of intermediate metrics that `trench_detection.find_trenches` spits out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_data = pa.parquet.read_pandas(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/211117/211117_long_oscillator.nd2.trenches.parquet\"\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trench_data[(\"diag\", \"find_trench_lines.hough_2.peak_func.pitch\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because they have different columns in the index, we store framewise, trenchwise, and labelwise measurements in separate parquet files. Originally I tried having the main node (running the dask scheduler and Jupyter) gather dask tasks and write them to parquet files (one parquet file for all positions); but even trying to be clever and use streamz and asyncio (an amateurish effort on my part, to be sure) having a single node do the parquet writing just couldn't keep up. In the current architecture, each position gets its own set of three parquet files; and a filesystem lockfile is used to ensure that only one dask task is writing to any given position at a time. When the pipeline is running in batch mode (all timepoints are available for processing immediately), all timepoints are measured simultaneously inside `do_measure_and_write`, so there cannot be any lock conflicts. When the pipeline is running in real-time mode, processing each position's timepoint as it comes off the microscope, each position is written to ~7min apart (which is the spacing of the timepoints in a typical experiment), so again the chance of a lock conflict is essentially zero. One notable downside of the current design in real-time mode is that for writing image data timepoint-by-timepoint, for each write, the current zarr chunk is entirely read into memory, the new timepoint is added, the resulting chunk is recompressed and written to disk. Because the trench image cubes are so small, each trench's array is currently stored as single chunks. As such, you're essentially reading and rewriting all cropped image data dozens or hundreds of times over the course of the experiment, which is extremely wasteful. You are amortizing this over the entire 24hr+ length of an experiment, so maybe it's not that bad. I have been trying to come up with a more elegant way to do this and have added some notes to the google doc. (To be clear, I never fully implemented real-time mode but when designing how output was stored and written was trying to anticipate what would work in real-time mode.) When `processing.write_images_and_measurements` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labelwise_df = pa.parquet.read_pandas(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220704/220704rbs_library_fish.nd2.test4.measurements/pos0.labelwise.parquet\"\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df.columns = [\"/\".join(col).strip() for col in labelwise_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelwise_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
