{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import zarr\n",
    "import dask\n",
    "from dask import delayed\n",
    "import distributed\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "import itertools as it\n",
    "from collections import namedtuple\n",
    "import nd2reader\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis import *\n",
    "import paulssonlab.image_analysis.new as new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = send_nd2(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\",\n",
    "    slices=dict(t=slice(None, 3), v=[14, 25]),\n",
    "    delayed=False,\n",
    ")\n",
    "list(x)[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = send_eaton_fish(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/FISH/real_run/\",\n",
    "    r\"fov=(?P<v>\\d+)_config=(?P<c>\\w+)_t=(?P<t>\\d+)\",\n",
    ")\n",
    "list(x)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, output_dir):\n",
    "        self.logger = logging.getLogger(self.__name__)\n",
    "        self.logger.basicConfig(level=logging.DEBUG)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.state = {}\n",
    "\n",
    "    def delayed(self, func, *args, **kwargs):\n",
    "        # TODO:\n",
    "        # log exceptions\n",
    "        # log warnings (deduplicated, count instances)\n",
    "        # optionally retry with diag if func takes \"diagnostics\" argument\n",
    "        # log benchmarking/profiling? or collect stats, only log outliers (+ call arguments)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelwise_funcs = {\"mean\": np.mean, \"sum\": np.sum}\n",
    "# trenchwise_funcs = {\"sharpness\": image.sharpness, **pixelwise_funcs}\n",
    "# trenchwise_funcs = {}\n",
    "\n",
    "\n",
    "def _measurement_func(label_image, intensity_image):\n",
    "    if intensity_image is None:\n",
    "        if label_image is None:\n",
    "            return None  # can't measure anything\n",
    "        mask_labelwise_df = pd.DataFrame(\n",
    "            skimage.measure.regionprops_table(\n",
    "                label_image,\n",
    "                properties=(\n",
    "                    \"label\",\n",
    "                    \"area\",\n",
    "                    \"axis_major_length\",\n",
    "                    \"axis_minor_length\",\n",
    "                    \"orientation\",\n",
    "                    \"centroid\",\n",
    "                ),\n",
    "            ),\n",
    "        ).set_index(\"label\")\n",
    "        return dict(mask_labelwise=mask_labelwise_df)\n",
    "    # trenchwise_df = workflow.map_frame(trenchwise_funcs, intensity_image)\n",
    "    # res = dict(trenchwise=trenchwise_df)\n",
    "    res = {}\n",
    "    if label_image is None:\n",
    "        return res  # only measure trenchwise\n",
    "    labelwise_df = workflow.map_frame_over_labels(\n",
    "        pixelwise_funcs, label_image, intensity_image\n",
    "    )\n",
    "    # labelwise_df = pd.DataFrame(\n",
    "    #     skimage.measure.regionprops_table(\n",
    "    #         label_image,\n",
    "    #         intensity_image,\n",
    "    #         properties=(\"label\", \"intensity_mean\"),\n",
    "    #     ),\n",
    "    # ).set_index(\"label\")\n",
    "    res[\"labelwise\"] = labelwise_df\n",
    "    return res  # measure trenchwise and labelwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _measure(\n",
    "    trenches,\n",
    "    frames,\n",
    "    measurement_func,\n",
    "    segmentation_channel=segmentation_channel,\n",
    "    measure_channels=None,\n",
    "    segmentation_func=trench_segmentation.watershed.segment,\n",
    "    include_frame=True,\n",
    "    frame_bits=8,\n",
    "    frame_downsample=4,\n",
    "    filename=None,\n",
    "    position=None,\n",
    "):\n",
    "    frame_transformation = compose(\n",
    "        processing.zarrify,\n",
    "        partial(image.quantize, bits=frame_bits),\n",
    "        partial(image.downsample, factor=frame_downsample),\n",
    "    )\n",
    "    trench_crops = processing._get_trench_crops(\n",
    "        trenches,\n",
    "        frames,\n",
    "        include_frame=include_frame,\n",
    "        frame_transformation=frame_transformation,\n",
    "        filename=filename,\n",
    "        position=position,\n",
    "    )\n",
    "    res = {}\n",
    "    segmentation_masks = {}\n",
    "    measurements = {}\n",
    "    # segment\n",
    "    for trench_set, crops_trench_channel_t in trench_crops.items():\n",
    "        if trench_set == \"_frame\":\n",
    "            continue\n",
    "        for trench_idx, crops_channel_t in crops_trench_channel_t.items():\n",
    "            for channel, crops_t in crops_channel_t.items():\n",
    "                for t, crop in crops_t.items():\n",
    "                    if measure_channels is not None and channel not in measure_channels:\n",
    "                        continue\n",
    "                    segmentation_key = (trench_set, trench_idx, segmentation_channel, t)\n",
    "                    segmentation_mask = segmentation_masks.get(segmentation_key, None)\n",
    "                    if segmentation_mask is None and segmentation_func is not None:\n",
    "                        segmentation_mask = segmentation_func(\n",
    "                            trench_crops[trench_set][trench_idx][segmentation_channel][\n",
    "                                t\n",
    "                            ]\n",
    "                        )\n",
    "                        segmentation_masks[segmentation_key] = segmentation_mask\n",
    "                        # measure mask\n",
    "                        if measurement_func is not None:\n",
    "                            measurements[\n",
    "                                (\"mask\", (trench_set, trench_idx, t))\n",
    "                            ] = measurement_func(segmentation_mask, None)\n",
    "                    # measure\n",
    "                    if measurement_func is not None:\n",
    "                        measurements[\n",
    "                            (channel, (trench_set, trench_idx, t))\n",
    "                        ] = measurement_func(segmentation_mask, crop)\n",
    "    if measurement_func is not None:\n",
    "        measurement_dfs = util.map_dict_levels(\n",
    "            lambda k: (k[1], k[0], *k[2:]), measurements\n",
    "        )\n",
    "        for name, dfs in measurement_dfs.items():\n",
    "            dfs = util.unflatten_dict(dfs)\n",
    "            if isinstance(util.get_one(dfs, level=2), pd.Series):\n",
    "                df = pd.concat(\n",
    "                    {\n",
    "                        channel: pd.concat(channel_dfs, axis=1).T\n",
    "                        for channel, channel_dfs in dfs.items()\n",
    "                    },\n",
    "                    axis=1,\n",
    "                )\n",
    "            else:\n",
    "                df = pd.concat(\n",
    "                    {\n",
    "                        channel: pd.concat(channel_dfs, axis=0)\n",
    "                        for channel, channel_dfs in dfs.items()\n",
    "                    },\n",
    "                    axis=1,\n",
    "                )\n",
    "            df.index.names = [\"trench_set\", \"trench\", \"t\", *df.index.names[3:]]\n",
    "            measurement_dfs[name] = df\n",
    "        res[\"measurements\"] = measurement_dfs\n",
    "    images = dict(raw=trench_crops)\n",
    "    if segmentation_func is not None:\n",
    "        images[\"segmentation\"] = util.unflatten_dict(segmentation_masks)\n",
    "    res[\"images\"] = images\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(\"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nd2.get_frame_2D(v=100, c=1, t=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trenches = new.image.find_trench_bboxes(img, peak_func=trench_detection.peaks.find_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trenches3 = new.image.find_trench_bboxes(img[:1000,:1000], peak_func=trench_detection.peaks.find_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches3[\"widths\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches3[\"widths\"].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag2 = util.tree()\n",
    "trenches2 = trench_detection.find_trenches(img, peak_func=trench_detection.peaks.find_peaks, diagnostics=diag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag2 = util.tree()\n",
    "trenches2 = new.image.find_trench_bboxes(img, peak_func=trench_detection.peaks.find_peaks, diagnostics=diag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_browser(diag2[\"find_trenches\"][\"label_4\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2[\"find_trenches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2[\"bboxes\"].opts(frame_width=700,frame_height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Rectangles((0,0,1,1)).opts(fill_color=None, line_color=\"red\", line_width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_endpoints = np.vstack((trenches2[\"top_x\"].values, trenches2[\"top_y\"].values)).T\n",
    "bottom_endpoints = np.vstack((trenches2[\"bottom_x\"].values, trenches2[\"bottom_y\"].values)).T\n",
    "top_endpoints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack((top_endpoints, bottom_endpoints)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_browser(diag2[\"label_1\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_browser(diag2[\"labeling\"][\"find_trench_lines\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = diag2[\"labeling\"][\"find_trench_lines\"][\"hough_2\"][\"trimmed_profile\"].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs, spectrum = scipy.signal.periodogram(\n",
    "    data.y.values, window=\"hann\", nfft=2**14, scaling=\"spectrum\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve((freqs,spectrum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Sxx = scipy.signal.spectrogram(data.y.values, nfft=2**12, window=\"hann\", scaling=\"spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Sxx = scipy.signal.spectrogram(data.y.values, nfft=2**12, window=\"hann\", scaling=\"spectrum\", mode=\"complex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(Sxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.QuadMesh((t, f, np.abs(Sxx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.QuadMesh((t, f, np.real(Sxx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(t, f, Sxx, shading='gouraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_browser(diag2[\"labeling\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2#[\"label_1\"][\"find_trench_ends\"][\"image_with_trenches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_browser(diag2[\"label_10\"][\"find_trench_ends\"][\"image_with_trenches\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "trenches = trench_detection.find_trenches(img, diagnostics=diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.show_plot_browser(diag);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "crops = {}\n",
    "for i, crop in it.islice(new.image.iter_crops(img, trenches), 10):\n",
    "    crops[i] = crop\n",
    "    #mask = trench_segmentation.segment(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crops[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crops[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crops[2].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crops[3].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crops[4].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-Penta\"\n",
    "trench_channel = segmentation_channel # channel for trench detection, almost always same as segmentation_channel\n",
    "measure_channels = [\"RFP-Penta\", \"GFP-PENTA\"]\n",
    "fish_channels = [\"RFP-Penta\", \"Cy5-PENTA\", \"Cy7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    pass\n",
    "\n",
    "def handle_image(pipeline, msg):\n",
    "    image = msg[\"image\"]\n",
    "    {\"channel\": channel, \"fov_num\": fov_num, \"t\": t, **other_metadata} = metadata\n",
    "    raw_key = (\"raw\", fov_num, channel)\n",
    "    pipeline.array[raw_key][t] = image\n",
    "    # do we have trenches?\n",
    "    trenches_key = (\"trenches\", fov_num,)\n",
    "    trenches = pipeline.table.get(trenches_key)\n",
    "    need_cropping_key = (\"need_cropping\", fov_num, channel)\n",
    "    # TODO: use a namedtuple (or typing.NamedTuple, or dataclass) as the key so that fields are named\n",
    "    keys_to_crop = pipeline.state.setdefault(need_cropping_key, []).append(raw_key)\n",
    "    if trenches is None and channel == trench_channel:\n",
    "        trenches = pipeline.delayed(new.image.find_trench_bboxes)\n",
    "        pipeline.table[trenches_key] = trenches\n",
    "    if trenches is not None:\n",
    "        for key in keys_to_crop:\n",
    "            # save trench crops\n",
    "            trench_crops = processing._get_trench_crops(\n",
    "                trenches,\n",
    "                frames,\n",
    "                include_frame=include_frame,\n",
    "                frame_transformation=frame_transformation,\n",
    "            )\n",
    "            # add to keys_to_measure\n",
    "            # segment\n",
    "            # measure\n",
    "\n",
    "\n",
    "def handle_fish_barcode(pipeline, msg):\n",
    "    pass\n",
    "\n",
    "\n",
    "# we should pick a name that's better/more intuitive than handle_message\n",
    "def handle_message(pipeline, msg):\n",
    "    match msg:\n",
    "        case {\"type\": \"image\", **_}:\n",
    "            match info:\n",
    "                case {\"image_type\": \"fish_barcode\", **_}:\n",
    "                    handle_fish_barcode(pipeline, msg)\n",
    "                case other:\n",
    "                    handle_image(pipeline, msg)\n",
    "        case {\"type\": \"event\", **info}:\n",
    "            print(\"event\", info)\n",
    "        case {\"type\": \"done\"}:\n",
    "            print(\"DONE\")\n",
    "        case _:\n",
    "            # this exception should be caught, we don't want malformed messages to crash the pipeline\n",
    "            raise ValueError(\"cannot handle message\", msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_message({\"type\": \"img\", \"imgs\": 0, \"metadata\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for msg in arch.send_nd2(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\",\n",
    "    slices=dict(v=slice(10))\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\"/home/jqs1/scratch/jqs1/microscopy/220718/new_architecture/test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for msg in send_nd2(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\"\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for msg in send_eaton_fish(\"/home/jqs1/scratch/jqs1/microscopy/220718/FISH/real_run/\"):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_message(pipeline, {\"type\": \"done\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd2_filenames = [\"/home/jqs1/scratch/jqs1/microscopy/211117/211117_long_oscillator.nd2\"]\n",
    "# nd2_filenames = [\"/n/standby/hms/sysbio/paulsson/collaborations/Personal_Folders/!!Jacob Quinn Shenker/Standby/180928/CapturedRFP_giant snake.nd2\"]\n",
    "nd2_filenames = [\"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames, metadata = workflow.get_nd2_frame_list(nd2_filenames)\n",
    "image_limits = workflow.get_filename_image_limits(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all_frames` lists each exposure (keyed by filename/position/channel/timepoint). `image_limits` is a dict giving *inclusive* image bounds `((x_min, x_max), (y_min, y_max))` for each input image filename. The reason both of these outputs are keyed by filename (and why `workflow.get_nd2_frame_list` takes a list of images) is that we want to support the use case where image acquisition is stopped and restarted one or more times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"06:00:00\",\n",
    "    memory=\"20GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New trench detection+segmentation+analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trenches(trenches):\n",
    "    return trenches\n",
    "    # pitch = 32 # (pixels) here we hard-code the correct pitch\n",
    "    # # so throw out positions with detected pitch more than 1 pixel away from this\n",
    "    # # a better way to do this is to look at the median pitch of all positions and use that\n",
    "    # # as the ground truth instead\n",
    "    # if trenches is None:\n",
    "    #     return None\n",
    "    # good_trenches = trenches[\n",
    "    #     (\n",
    "    #         (\n",
    "    #             trenches[(\"diag\", \"find_trench_lines.hough_2.peak_func.pitch\")] - pitch\n",
    "    #         ).abs()\n",
    "    #         <= 1\n",
    "    #     )\n",
    "    #     & (~trenches[(\"upper_left\", \"x\")].isnull())\n",
    "    # ]\n",
    "    # TODO: filter based on minimum trench length\n",
    "    # return good_trenches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filename_func(\n",
    "    extension=None, kind=None, name=None, filename=None, position=None, extra=\"full\"\n",
    "):\n",
    "    if kind and extra:\n",
    "        kind = f\"{extra}.{kind}\"\n",
    "    components = [s for s in (\"\", name, extension) if s is not None]\n",
    "    if position is None:\n",
    "        path = [f\"{filename}.{kind}\" + \".\".join(components)]\n",
    "    else:\n",
    "        path = [f\"{filename}.{kind}\", \"pos{:d}\".format(position) + \".\".join(components)]\n",
    "    return os.path.join(*path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_trench_err_futures = {}\n",
    "all_analysis_futures = {}\n",
    "save_trenches_futures = {}\n",
    "save_trench_err_futures = {}\n",
    "\n",
    "all_trench_bboxes_futures = {}  # TODO: just for debugging\n",
    "\n",
    "for filename, filename_frames in selected_frames.groupby(\"filename\"):\n",
    "    # analysis_futures = {}\n",
    "    trench_bboxes_futures = {}\n",
    "    trench_err_futures = {}\n",
    "    for position, frames in filename_frames.groupby(\"position\"):\n",
    "        key = (filename, position)\n",
    "        frame_to_segment = frames.loc[IDX[:, :, [segmentation_channel], 0], :]\n",
    "        trenches_future = client.submit(\n",
    "            do_find_trenches, *frame_to_segment.index[0], priority=10\n",
    "        )\n",
    "        trench_err_futures[key] = client.submit(do_get_trench_err, trenches_future)\n",
    "        trench_bboxes_future = client.submit(\n",
    "            do_trenches_to_bboxes, trenches_future, (filename, position), priority=10\n",
    "        )\n",
    "        trench_bboxes_futures[key] = trench_bboxes_future\n",
    "        all_trench_bboxes_futures[key] = trench_bboxes_future\n",
    "        analysis_future = client.submit(\n",
    "            do_measure_and_write,\n",
    "            trench_bboxes_future,\n",
    "            frames,\n",
    "            measurement_func=_measurement_func,\n",
    "            # measurement_func=None,\n",
    "            # segmentation_func=None,\n",
    "            measure_channels=measure_channels,\n",
    "            segmentation_channel=segmentation_channel,\n",
    "            return_none=True,\n",
    "            write=True,\n",
    "            filename_func=filename_func,\n",
    "        )\n",
    "        all_analysis_futures[key] = analysis_future\n",
    "    # save trenches\n",
    "    trenches_filename = filename_func(\n",
    "        kind=\"trenches\", extension=\"parquet\", filename=filename\n",
    "    )\n",
    "    save_trenches_futures[filename] = client.submit(\n",
    "        do_save_trenches,\n",
    "        list(dict(sorted(trench_bboxes_futures.items())).values()),\n",
    "        trenches_filename,\n",
    "    )\n",
    "    trench_errs_filename = filename_func(\n",
    "        kind=\"trench_errs\", extension=\"pickle\", filename=filename\n",
    "    )\n",
    "    save_trench_err_futures[filename] = client.submit(\n",
    "        do_serialize_to_disk,\n",
    "        trench_err_futures,\n",
    "        trench_errs_filename,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
