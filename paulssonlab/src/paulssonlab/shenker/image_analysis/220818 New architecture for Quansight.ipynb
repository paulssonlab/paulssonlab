{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import distributed\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import skimage.measure\n",
    "import zarr\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paulssonlab.image_analysis.new as new\n",
    "from paulssonlab.image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"06:00:00\",\n",
    "    memory=\"2GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-Penta\"\n",
    "trench_detection_channel = segmentation_channel  # channel for trench detection, almost always same as segmentation_channel\n",
    "measure_channels = [\"RFP-Penta\", \"YFP-DUAL\"]\n",
    "fish_channels = [\"RFP-Penta\", \"Cy5-PENTA\", \"Cy7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, output_dir):\n",
    "        self.logger = logging.getLogger(\"Pipeline\")\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.state = {}\n",
    "        self.array = {}\n",
    "        self.table = {}\n",
    "\n",
    "    def delayed(self, func, *args, **kwargs):\n",
    "        # TODO:\n",
    "        # log exceptions\n",
    "        # log warnings (deduplicated, count instances)\n",
    "        # optionally retry with diag if func takes \"diagnostics\" argument\n",
    "        # log benchmarking/profiling? or collect stats, only log outliers (+ call arguments)\n",
    "        return dask.delayed(func, *args, **kwargs)\n",
    "\n",
    "\n",
    "def crop_trenches(img, trenches):\n",
    "    crops = {}\n",
    "    # TODO: the islice is just for testing (we only deal with three trenches for FOV), otherwise every dask task takes a long time\n",
    "    for i, crop in it.islice(new.image.iter_crops(img, trenches), 3):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def segment_trenches(crops):\n",
    "    masks = {}\n",
    "    for i, crop in crops.items():\n",
    "        masks[i] = trench_segmentation.segment(crop)\n",
    "    return masks\n",
    "\n",
    "\n",
    "# TODO: this is really boilerplatey, also we want finer task granularity than doing a whole FOV at once\n",
    "def measure_crops(label_images, intensity_images):\n",
    "    keys = label_images.keys() & intensity_images.keys()\n",
    "    return {k: measure_crop(label_images[k], intensity_images[k]) for k in keys}\n",
    "\n",
    "\n",
    "def measure_crop(label_image, intensity_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            intensity_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"intensity_mean\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")\n",
    "\n",
    "\n",
    "def measure_mask_crops(label_images):\n",
    "    return {k: measure_mask_crop(v) for k, v in label_images.items()}\n",
    "\n",
    "\n",
    "def measure_mask_crop(label_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"area\",\n",
    "                \"axis_major_length\",\n",
    "                \"axis_minor_length\",\n",
    "                \"orientation\",\n",
    "                \"centroid\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")\n",
    "\n",
    "\n",
    "# TODO: use a namedtuple (or typing.NamedTuple, or dataclass) for keys so that fields are named\n",
    "def handle_image(pipeline, msg):\n",
    "    image = msg[\"image\"]\n",
    "    metadata = msg[\"metadata\"]\n",
    "    fov_num = metadata[\"fov_num\"]\n",
    "    t = metadata[\"t\"]\n",
    "    channel = metadata[\"channel\"]\n",
    "    raw_key = (\"raw\", fov_num, t, channel)\n",
    "    # store raw image (in production, we won't do this, we will only store crops as we do below)\n",
    "    pipeline.array[raw_key] = image\n",
    "    # TODO: we need a way to store per-frame metadata and write it to disk\n",
    "    trenches_key = (\n",
    "        \"trenches\",\n",
    "        fov_num,\n",
    "    )\n",
    "    trenches = pipeline.table.get(trenches_key)\n",
    "    # check if we have done trench detection for this FOV\n",
    "    if trenches is None and channel == trench_detection_channel:\n",
    "        # if not, find trenches and save the resulting table\n",
    "        trenches = pipeline.delayed(new.image.find_trench_bboxes)(\n",
    "            image, peak_func=trench_detection.peaks.find_peaks\n",
    "        )\n",
    "        pipeline.table[trenches_key] = trenches\n",
    "    # this list keeps track of all the raw frames that need to be cropped\n",
    "    # frames for multiple channels will accumulate in this list until we get a frame for trench_detection_channel\n",
    "    # if we have already processed such a frame, then keys_to_crop will contain only the current frame (raw_key)\n",
    "    keys_to_crop = pipeline.state.setdefault((\"keys_to_crop\", fov_num), [])\n",
    "    keys_to_crop.append(raw_key)\n",
    "    # we only can do further processing if we have already detected trenches for this FOV\n",
    "    if trenches is not None:\n",
    "        for raw_to_crop in keys_to_crop:\n",
    "            crop_key = (\"crops\", *raw_to_crop[1:])\n",
    "            # save trench crops for every frame in keys_to_crop\n",
    "            pipeline.array[crop_key] = pipeline.delayed(crop_trenches)(\n",
    "                pipeline.array[raw_to_crop], trenches\n",
    "            )\n",
    "            segmentation_key = (\"segmentation\", fov_num, t, segmentation_channel)\n",
    "            segmentation = pipeline.array.get(segmentation_key)\n",
    "            if segmentation is not None:\n",
    "                if crop_key[-1] in measure_channels:\n",
    "                    # if we have segmentation masks for this frame, we can immediately segment only this frame\n",
    "                    keys_to_measure = [crop_key]\n",
    "                else:\n",
    "                    keys_to_measure = []\n",
    "            else:\n",
    "                # we don't have a segmentation mask yet, so we need to add to the keys_to_measure list\n",
    "                keys_to_measure = pipeline.state.setdefault(\n",
    "                    (\"keys_to_measure\", fov_num, t), []\n",
    "                )\n",
    "                if crop_key[-1] in measure_channels:\n",
    "                    # we want to measure this frame\n",
    "                    keys_to_measure.append(crop_key)\n",
    "                if crop_key[-1] == segmentation_channel:\n",
    "                    # if this frame's channel is the segmentation channel, run segmentation\n",
    "                    segmentation = pipeline.delayed(segment_trenches)(\n",
    "                        pipeline.array[crop_key]\n",
    "                    )\n",
    "                    pipeline.array[segmentation_key] = segmentation\n",
    "                    # once we have the segmentation mask, get measurements for the mask\n",
    "                    pipeline.table[\n",
    "                        (\n",
    "                            \"mask_measurements\",\n",
    "                            *crop_key[1:],\n",
    "                        )\n",
    "                    ] = pipeline.delayed(measure_mask_crops)(segmentation)\n",
    "            segmentation = pipeline.array.get(segmentation_key)\n",
    "            # if we now have the segmentation mask, try measuring all frames in the keys_to_measure list\n",
    "            if segmentation is not None:\n",
    "                for crop_to_measure in keys_to_measure:\n",
    "                    measurements_key = (\"measurements\", *crop_to_measure[1:])\n",
    "                    pipeline.table[measurements_key] = pipeline.delayed(measure_crops)(\n",
    "                        segmentation, pipeline.array[crop_to_measure]\n",
    "                    )\n",
    "                pipeline.state.pop((\"keys_to_measure\", fov_num, t), None)\n",
    "        pipeline.state.pop((\"keys_to_crop\", fov_num), None)\n",
    "\n",
    "\n",
    "def handle_fish_barcode(pipeline, msg):\n",
    "    pass  # TODO\n",
    "\n",
    "\n",
    "# we should pick a name that's better/more intuitive than handle_message\n",
    "def handle_message(pipeline, msg):\n",
    "    match msg:\n",
    "        case {\"type\": \"image\", **info}:\n",
    "            match info:\n",
    "                case {\"image_type\": \"fish_barcode\"}:\n",
    "                    handle_fish_barcode(pipeline, msg)\n",
    "                case other:\n",
    "                    handle_image(pipeline, msg)\n",
    "        case {\"type\": \"nd2_metadata\"}:\n",
    "            print(\"got metadata\")  # TODO\n",
    "        case {\"type\": \"event\", **info}:\n",
    "            print(\"event\", info)\n",
    "        case {\"type\": \"done\"}:\n",
    "            print(\"DONE\")\n",
    "        case _:\n",
    "            # this exception should be caught, we don't want malformed messages to crash the pipeline\n",
    "            raise ValueError(\"cannot handle message\", msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\"\n",
    "filename = \"/home/jqs1/scratch/jqs1/microscopy/220523/220523_library_test_smallfile.nd2\"\n",
    "pipeline = Pipeline(\"/home/jqs1/scratch/jqs1/microscopy/220718/new_architecture/test1\")\n",
    "for msg in new.readers.send_nd2(\n",
    "    filename,\n",
    "    slices=dict(v=slice(1), t=slice(1)),\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline = Pipeline(\"/home/jqs1/scratch/jqs1/microscopy/220718/new_architecture/test1\")\n",
    "for msg in new.readers.send_nd2(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\",\n",
    "    slices=dict(v=slice(1), t=slice(1)),\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_graph = pipeline.array[(\"crops\", 0, 0, \"RFP-Penta\")]\n",
    "masks_graph = pipeline.array[(\"segmentation\", 0, 0, \"RFP-Penta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# crops = crops_graph.compute(scheduler=\"synchronous\")\n",
    "crops = client.compute(crops_graph, sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crops[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# masks = masks_graph.compute(scheduler=\"synchronous\")\n",
    "masks = client.compute(masks_graph, sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trenches = client.compute(pipeline.table[(\"trenches\", 0)], sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.table.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "measurements = client.compute(\n",
    "    pipeline.table[(\"measurements\", 0, 0, \"RFP-Penta\")], sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mask_measurements = client.compute(\n",
    "    pipeline.table[(\"mask_measurements\", 0, 0, \"RFP-Penta\")], sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_measurements[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "This is how the full pipeline could be run for an experiment which has a first phase (stored in ND2) and a second FISH phase (stored in HDF5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\"/home/jqs1/scratch/jqs1/microscopy/220718/new_architecture/test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for msg in send_nd2(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\"\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for msg in send_eaton_fish(\"/home/jqs1/scratch/jqs1/microscopy/220718/FISH/real_run/\"):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_message(pipeline, {\"type\": \"done\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
