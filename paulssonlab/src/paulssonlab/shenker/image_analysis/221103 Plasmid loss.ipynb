{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import zarr\n",
    "import dask\n",
    "from dask import delayed\n",
    "import distributed\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial, reduce\n",
    "import operator\n",
    "import itertools as it\n",
    "from collections import namedtuple\n",
    "import nd2reader\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import skimage.measure\n",
    "import pickle\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis import *\n",
    "import paulssonlab.image_analysis.new as new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"06:00:00\",\n",
    "    memory=\"4GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_correction_channel = \"Phase-Fluor\"\n",
    "segmentation_channel = \"RFP-PENTA\"\n",
    "trench_detection_channel = segmentation_channel  # channel for trench detection, almost always same as segmentation_channel\n",
    "measure_channels = [\"RFP-PENTA\", \"GFP-PENTA\"]\n",
    "fish_channels = [\"RFP-Penta\", \"Cy5-PENTA\", \"Cy7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, output_dir):\n",
    "        self.logger = logging.getLogger(\"Pipeline\")\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.state = {}\n",
    "        self.array = {}\n",
    "        self.table = {}\n",
    "\n",
    "    def delayed(self, func, *args, **kwargs):\n",
    "        # TODO:\n",
    "        # log exceptions\n",
    "        # log warnings (deduplicated, count instances)\n",
    "        # optionally retry with diag if func takes \"diagnostics\" argument\n",
    "        # log benchmarking/profiling? or collect stats, only log outliers (+ call arguments)\n",
    "        return dask.delayed(func, *args, **kwargs)\n",
    "\n",
    "def crop_trenches(img, trenches):\n",
    "    crops = {}\n",
    "    # TODO: the islice is just for testing (we only deal with three trenches for FOV), otherwise every dask task takes a long time\n",
    "    #for i, crop in it.islice(new.image.iter_crops(img, trenches), 3):\n",
    "    for i, crop in new.image.iter_crops(img, trenches):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def segment_trenches(crops):\n",
    "    masks = {}\n",
    "    for i, crop in crops.items():\n",
    "        try:\n",
    "            masks[i] = trench_segmentation.segment(crop)\n",
    "        except:\n",
    "            pass\n",
    "    return masks\n",
    "\n",
    "# TODO: this is really boilerplatey, also we want finer task granularity than doing a whole FOV at once\n",
    "def measure_crops(label_images, intensity_images):\n",
    "    keys = label_images.keys() & intensity_images.keys()\n",
    "    return {k: measure_crop(label_images[k], intensity_images[k]) for k in keys}\n",
    "\n",
    "def measure_crop(label_image, intensity_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            intensity_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"intensity_mean\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")\n",
    "\n",
    "def measure_mask_crops(label_images):\n",
    "    return {k: measure_mask_crop(v) for k, v in label_images.items()}\n",
    "\n",
    "def measure_mask_crop(label_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"area\",\n",
    "                \"axis_major_length\",\n",
    "                \"axis_minor_length\",\n",
    "                \"orientation\",\n",
    "                \"centroid\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")\n",
    "\n",
    "\n",
    "# TODO: use a namedtuple (or typing.NamedTuple, or dataclass) for keys so that fields are named\n",
    "def handle_image(pipeline, msg):\n",
    "    image = msg[\"image\"]\n",
    "    metadata = msg[\"metadata\"]\n",
    "    fov_num = metadata[\"fov_num\"]\n",
    "    t = metadata[\"t\"]\n",
    "    channel = metadata[\"channel\"]\n",
    "    raw_key = (\"raw\", fov_num, t, channel)\n",
    "    # store raw image (in production, we won't do this, we will only store crops as we do below)\n",
    "    pipeline.array[raw_key] = image\n",
    "    # TODO: we need a way to store per-frame metadata and write it to disk\n",
    "    trenches_key = (\n",
    "        \"trenches\",\n",
    "        fov_num,\n",
    "    )\n",
    "    trenches = pipeline.table.get(trenches_key)\n",
    "    # check if we have done trench detection for this FOV\n",
    "    if trenches is None and channel == trench_detection_channel:\n",
    "        # if not, find trenches and save the resulting table\n",
    "        trenches = pipeline.delayed(new.image.find_trench_bboxes)(image, peak_func=trench_detection.peaks.find_peaks)\n",
    "        pipeline.table[trenches_key] = trenches\n",
    "    # this list keeps track of all the raw frames that need to be cropped\n",
    "    # frames for multiple channels will accumulate in this list until we get a frame for trench_detection_channel\n",
    "    # if we have already processed such a frame, then keys_to_crop will contain only the current frame (raw_key)\n",
    "    keys_to_crop = pipeline.state.setdefault((\"keys_to_crop\", fov_num), [])\n",
    "    keys_to_crop.append(raw_key)\n",
    "    # we only can do further processing if we have already detected trenches for this FOV\n",
    "    if trenches is not None:\n",
    "        for raw_to_crop in keys_to_crop:\n",
    "            crop_key = (\"crops\", *raw_to_crop[1:])\n",
    "            # save trench crops for every frame in keys_to_crop\n",
    "            pipeline.array[crop_key] = pipeline.delayed(crop_trenches)(\n",
    "                pipeline.array[raw_to_crop], trenches\n",
    "            )\n",
    "            segmentation_key = (\"segmentation\", fov_num, t, segmentation_channel)\n",
    "            segmentation = pipeline.array.get(segmentation_key)\n",
    "            if segmentation is not None:\n",
    "                if crop_key[-1] in measure_channels:\n",
    "                    # if we have segmentation masks for this frame, we can immediately segment only this frame\n",
    "                    keys_to_measure = [crop_key]\n",
    "                else:\n",
    "                    keys_to_measure = []\n",
    "            else:\n",
    "                # we don't have a segmentation mask yet, so we need to add to the keys_to_measure list\n",
    "                keys_to_measure = pipeline.state.setdefault((\"keys_to_measure\", fov_num, t), [])\n",
    "                if crop_key[-1] in measure_channels:\n",
    "                    # we want to measure this frame\n",
    "                    keys_to_measure.append(crop_key)\n",
    "                if crop_key[-1] == segmentation_channel:\n",
    "                    # if this frame's channel is the segmentation channel, run segmentation\n",
    "                    segmentation = pipeline.delayed(segment_trenches)(\n",
    "                        pipeline.array[crop_key]\n",
    "                    )\n",
    "                    pipeline.array[segmentation_key] = segmentation\n",
    "                    # once we have the segmentation mask, get measurements for the mask\n",
    "                    pipeline.table[(\"mask_measurements\", *crop_key[1:],)] = pipeline.delayed(\n",
    "                        measure_mask_crops\n",
    "                    )(segmentation)\n",
    "            segmentation = pipeline.array.get(segmentation_key)\n",
    "            # if we now have the segmentation mask, try measuring all frames in the keys_to_measure list\n",
    "            if segmentation is not None:\n",
    "                for crop_to_measure in keys_to_measure:\n",
    "                    measurements_key = (\"measurements\", *crop_to_measure[1:])\n",
    "                    pipeline.table[measurements_key] = pipeline.delayed(measure_crops)(\n",
    "                        segmentation, pipeline.array[crop_to_measure]\n",
    "                    )\n",
    "                pipeline.state.pop((\"keys_to_measure\", fov_num, t), None)\n",
    "        pipeline.state.pop((\"keys_to_crop\", fov_num), None)\n",
    "\n",
    "\n",
    "def handle_fish_barcode(pipeline, msg):\n",
    "    pass # TODO\n",
    "\n",
    "\n",
    "# we should pick a name that's better/more intuitive than handle_message\n",
    "def handle_message(pipeline, msg):\n",
    "    match msg:\n",
    "        case {\"type\": \"image\", **info}:\n",
    "            match info:\n",
    "                case {\"image_type\": \"fish_barcode\"}:\n",
    "                    handle_fish_barcode(pipeline, msg)\n",
    "                case other:\n",
    "                    handle_image(pipeline, msg)\n",
    "        case {\"type\": \"nd2_metadata\"}:\n",
    "            print(\"got metadata\") # TODO\n",
    "        case {\"type\": \"event\", **info}:\n",
    "            print(\"event\", info)\n",
    "        case {\"type\": \"done\"}:\n",
    "            print(\"DONE\")\n",
    "        case _:\n",
    "            # this exception should be caught, we don't want malformed messages to crash the pipeline\n",
    "            raise ValueError(\"cannot handle message\", msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filename = \"/home/jqs1/scratch/jqs1/microscopy/210511/RBS_ramp.nd2\"\n",
    "pipeline = Pipeline(\"/home/jqs1/scratch/jqs1/microscopy/220718/new_architecture/test1\")\n",
    "for msg in new.readers.send_nd2(\n",
    "    filename,\n",
    "    slices=dict(v=[30], t=slice(40,None)),\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures = util.apply_map_futures(client.compute, (pipeline.table, pipeline.array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "table, array = client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_filename = \"/home/jqs1/group/221102plasmidloss_1.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open(pickle_filename, \"wb\") as f:\n",
    "    pickle.dump((table, array), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "table2, array2 = pickle.load(pickle_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reformat outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_tables(table, prefix):\n",
    "    if not isinstance(prefix, tuple):\n",
    "        prefix = (prefix,)\n",
    "    keys = sorted([k for k in tables.keys() if k[:len(prefix)] == prefix])\n",
    "    df = pd.concat({k[len(prefix):]: pd.concat(tables[k], names=[\"trench\"]) for k in keys}, names=[\"fov\", \"t\", \"channel\"])\n",
    "    df = df.unstack(\"channel\")\n",
    "    # replace MultiIndex with Index of slash-separated names like \"GFP-PENTA/mean_intensity\"\n",
    "    df.columns = [\"/\".join(col[::-1]) for col in df.columns.values]\n",
    "    return df\n",
    "\n",
    "d = reformat_table(table, \"measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_crops(array, prefix, fov, channel):\n",
    "    keys = sorted([k for k in array.keys() if len(k) == 4 and k[:2] == (prefix, fov) and k[3] == channel])\n",
    "    trenches = reduce(operator.and_, [array[k].keys() for k in keys])\n",
    "    crops = {}\n",
    "    for trench in list(trenches):\n",
    "        crops[trench] = np.stack([array[k][trench] for k in keys])\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d = stack_crops(array, \"crops\", 30, \"RFP-PENTA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = d[33]\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(np.swapaxes(a, 0, 1).reshape(a.shape[1], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(a.shape[1], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a.reshape(a.shape[0] * a.shape[1], a.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(array[('crops', 30, 48, 'RFP-PENTA')][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[IDX[:,:,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[IDX[:,:,0,:]].hvplot.scatter(\"t\", \"GFP-PENTA/intensity_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reset_index().hvplot(\"GFP-PENTA/intensity_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reset_index(\"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = d.unstack(\"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.columns = [\"/\".join(col[::-1]) for col in dd.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(d.reset_index(\"channel\"), id_vars=[\"channel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift correction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(\"/home/jqs1/scratch/jqs1/microscopy/210511/RBS_ramp.nd2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = nd2.get_frame_2D(v=30,t=0, c=0)\n",
    "f2 = nd2.get_frame_2D(v=30,t=150, c=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.registration import optical_flow_ilk, optical_flow_tvl1, phase_cross_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_cross_correlation(f1, f2, return_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(f1-f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
