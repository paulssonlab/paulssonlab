{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import dask\n",
    "import distributed\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import skimage.measure\n",
    "import zarr\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "IDX = pd.IndexSlice\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paulssonlab.image_analysis.new as new\n",
    "from paulssonlab.image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"06:00:00\",\n",
    "    memory=\"2GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-Penta\"\n",
    "trench_detection_channel = segmentation_channel  # channel for trench detection, almost always same as segmentation_channel\n",
    "measure_channels = [\"RFP-Penta\", \"YFP-DUAL\"]\n",
    "fish_channels = [\"RFP-Penta\", \"Cy5-PENTA\", \"Cy7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load outputs from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_filename = \"/home/jqs1/group/221108rbsdeglibrary_1.pickle\"\n",
    "pickle_filename = \"/home/jqs1/group/221108rbsdeglibrary_1_table.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open(pickle_filename, \"rb\") as f:\n",
    "    table, array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rename_column(col):\n",
    "    if col[0] == \"mask_measurements\":\n",
    "        return col[1]\n",
    "    elif col[0] == \"measurements\":\n",
    "        return \"/\".join(col[1:])\n",
    "    else:\n",
    "        return \"/\".join(col)\n",
    "\n",
    "\n",
    "def reformat_table(table, flatten_column_names=False):\n",
    "    prefixes = sorted(set(k[0] for k in table.keys()))\n",
    "    df = pd.concat(\n",
    "        {\n",
    "            prefix: pd.concat(\n",
    "                {\n",
    "                    k[1:]: pd.concat(table[k], names=[\"roi\"])\n",
    "                    for k in table.keys()\n",
    "                    if k[0] == prefix\n",
    "                },\n",
    "                names=[\"fov\", \"t\", \"channel\"],\n",
    "            ).unstack(\"channel\")\n",
    "            for prefix in prefixes\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    "    if flatten_column_names:\n",
    "        # replace MultiIndex with Index of slash-separated names like \"GFP-PENTA/mean_intensity\"\n",
    "        df.columns = [_rename_column(col) for col in df.columns.values]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pyinstrument\n",
    "reformat_table(\n",
    "    {\n",
    "        k: v\n",
    "        for k, v in table.items()\n",
    "        if k[0] in (\"measurements\", \"mask_measurements\") and k[2] < 3\n",
    "    },\n",
    "    flatten_column_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_crops(array, prefix, fov, channel):\n",
    "    keys = sorted(\n",
    "        [\n",
    "            k\n",
    "            for k in array.keys()\n",
    "            if len(k) == 4 and k[:2] == (prefix, fov) and k[3] == channel\n",
    "        ]\n",
    "    )\n",
    "    trenches = reduce(operator.and_, [array[k].keys() for k in keys])\n",
    "    crops = {}\n",
    "    for trench in list(trenches):\n",
    "        crops[trench] = np.stack([array[k][trench] for k in keys])\n",
    "    return crops\n",
    "\n",
    "\n",
    "def unstack(ary):\n",
    "    return np.swapaxes(ary, 0, 1).reshape(ary.shape[1], -1)\n",
    "\n",
    "\n",
    "def pad_and_stack(arys, fill_value=0):\n",
    "    shape = np.max([ary.shape for ary in arys], axis=0)\n",
    "    return np.stack(\n",
    "        [\n",
    "            np.pad(\n",
    "                ary,\n",
    "                ((shape[0] - ary.shape[0], 0), (shape[1] - ary.shape[1], 0)),\n",
    "                constant_values=fill_value,\n",
    "            )\n",
    "            for ary in arys\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def pad_unstack(arys):\n",
    "    return unstack(pad_and_stack(arys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_measurements = reformat_table(\n",
    "    {\n",
    "        k: v\n",
    "        for k, v in table.items()\n",
    "        if k[0] in (\"measurements\", \"mask_measurements\")  # and k[2] < 3\n",
    "    },\n",
    "    flatten_column_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches = pd.concat(\n",
    "    {k[1]: v for k, v in table.items() if k[0] == \"trenches\"}, names=[\"fov\", \"roi\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix ROI orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# labeling for odd trench_sets need to be inverted\n",
    "def fix_label_order(df):\n",
    "    if trenches[\"trench_set\"].loc[df.index[0][:2]] % 2 == 0:\n",
    "        return df\n",
    "    else:\n",
    "        df[\"label\"] = df[\"label\"].max() - df[\"label\"] + df[\"label\"].min()\n",
    "        return df.sort_values(\"label\")\n",
    "\n",
    "\n",
    "all_measurements2 = (\n",
    "    all_measurements.reset_index([\"label\"])\n",
    "    .groupby([\"fov\", \"roi\", \"t\"], group_keys=False)\n",
    "    .progress_transform(fix_label_order)\n",
    ").set_index(\"label\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_measurements2.loc[IDX[:, :, 1, 1]].hvplot.scatter(\"t\", \"centroid-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_measurements2.loc[IDX[:, :, 1, 1]].hvplot.scatter(\"t\", \"axis_major_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trenches[trenches[\"trench_set\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_measurements.loc[IDX[:, :, 300, 1]].hvplot.scatter(\"t\", \"axis_major_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_measurements2.loc[IDX[:, :, 300, 1]].hvplot.scatter(\"t\", \"axis_major_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_measurements2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle_filename = \"/home/jqs1/group/221108rbsdeglibrary_1_table_reformatted2.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with open(pickle_filename, \"wb\") as f:\n",
    "    pickle.dump((all_measurements, trenches), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open(pickle_filename, \"rb\") as f:\n",
    "    all_measurements, trenches = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Growth rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "one_trench = all_measurements.xs(IDX[:, :, 1000, :], drop_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mothers = one_trench.xs(IDX[:, :, :, 1], drop_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def track_mother_cell(df):\n",
    "    # groupby rois\n",
    "    mothers = df.xs(IDX[:, :, :, 1], drop_level=False)\n",
    "    lengths = mothers[\"axis_major_length\"].values\n",
    "    # first cell ID is 1, (0 is used as marker of non-tracked cell segment)\n",
    "    mother_cell_ids = np.concatenate(([1], 1 + np.cumsum(lengths[1:] < lengths[:-1])))\n",
    "    cell_ids = np.zeros(len(df), dtype=np.uint64)\n",
    "    cell_ids[df.index.get_locs(IDX[:, :, :, 1])] = mother_cell_ids\n",
    "    return df.assign(cell_id=cell_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_trench_tracked = track_mother_cell(one_trench)\n",
    "one_trench_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_trench_tracked[one_trench_tracked[\"cell_id\"] != 0].hvplot.scatter(\n",
    "    \"t\", \"axis_major_length\", by=\"cell_id\", cmap=\"Category20\", legend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_tracked = all_measurements.groupby([\"fov\", \"roi\"], group_keys=False).progress_apply(\n",
    "    track_mother_cell\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_tracked.xs(IDX[:, :, 3001, 1]).hvplot.scatter(\n",
    "    \"t\", \"axis_major_length\", by=\"cell_id\", cmap=\"Category20\", legend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_growth_rates.loc[IDX[:,:,3001,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_trench_onlytracked = one_trench_tracked[one_trench_tracked[\"cell_id\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_cellid = one_trench_onlytracked[one_trench_onlytracked[\"cell_id\"] == 4]\n",
    "one_cellid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lineage_growth_rate(one_cellid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ols(x, y):\n",
    "    num_obs = len(x)\n",
    "    x_bar = x.sum() / num_obs\n",
    "    y_bar = y.sum() / num_obs\n",
    "    beta = (num_obs * (x * y).sum() - x.sum() * y.sum()) / (\n",
    "        num_obs * (x**2).sum() - x.sum()**2\n",
    "    )\n",
    "    alpha = y_bar - beta * x_bar\n",
    "    y_hat = alpha + beta * x\n",
    "    r2 = np.sum((y_hat - y_bar) ** 2) / np.sum((y - y_bar) ** 2)\n",
    "    return alpha, beta, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineage_growth_rate_interval(df, min_obs=3):\n",
    "    if len(df) < min_obs:\n",
    "        return\n",
    "    ts = df.index.get_level_values(\"t\").values\n",
    "    log_length = np.log(df[\"axis_major_length\"].values)\n",
    "    # return pd.Series(ols(ts, log_length), index=[\"alpha\", \"beta\", \"r2\"])\n",
    "    interval = pd.Interval(ts[0], ts[-1], closed=\"both\")\n",
    "    k = df.index[0]\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        [(k[0], interval, k[2], df[\"cell_id\"].iloc[0])],\n",
    "        names=[\"fov\", \"t\", \"roi\", \"cell_id\"],\n",
    "    )\n",
    "    return pd.DataFrame(\n",
    "        [ols(ts, log_length)], columns=[\"alpha\", \"beta\", \"r2\"], index=index\n",
    "    )\n",
    "\n",
    "\n",
    "def lineage_growth_rate(df, min_obs=3):\n",
    "    if len(df) < min_obs:\n",
    "        return\n",
    "    ts = df.index.get_level_values(\"t\").values\n",
    "    # TODO: not necessary, but makes alpha (y-intercept) comparable between lineages\n",
    "    ts -= ts.min()\n",
    "    log_length = np.log(df[\"axis_major_length\"].values)\n",
    "    new_df = pd.DataFrame(\n",
    "        np.repeat([ols(ts, log_length)], len(df), axis=0),\n",
    "        columns=[\"alpha\", \"beta\", \"r2\"],\n",
    "        index=df.index,\n",
    "    )\n",
    "    return new_df.assign(cell_id=df[\"cell_id\"]).set_index(\"cell_id\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "one_trench_onlytracked.groupby(\n",
    "    [\"fov\", \"roi\", \"cell_id\"], group_keys=False\n",
    ").progress_apply(lineage_growth_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_growth_rates = all_tracked[all_tracked[\"cell_id\"] != 0].groupby(\n",
    "    [\"fov\", \"roi\", \"cell_id\"], group_keys=False\n",
    ").progress_apply(lineage_growth_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_growth_rates[\"r2\"].hvplot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW: low-time-resolution growth rate for each trench (so can make 2d heatmaps)\n",
    "# - dumb linear regression, batch per FOV (?) so only one LAPACK call?\n",
    "# LATER: high-time-resolution growth rates grouped by genetic identity (e.g., barcode)\n",
    "# - slightly (?) slower but better if we do this as an average of per-cellid growth rates\n",
    "#   (that way we can filter out junk on per-cellid characteristics, r^2, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "observable = \"beta\"\n",
    "num_bins = 100\n",
    "#measurements_subset = all_growth_rates[all_growth_rates[\"r2\"] > 0.9]\n",
    "measurements_subset = measurements_subset.reset_index()[[\"t\", \"alpha\", \"beta\", \"r2\"]]\n",
    "bins = np.linspace(\n",
    "    measurements_subset[observable].min(),\n",
    "    measurements_subset[observable].max(),\n",
    "    num_bins,\n",
    ")\n",
    "heatmap = measurements_subset.groupby([\"t\"]).apply(\n",
    "    lambda x: pd.Series(np.histogram(x[observable], bins=bins)[0], index=bins[:-1])\n",
    ")\n",
    "heatmap.columns.name = observable\n",
    "heatmap = xr.DataArray(heatmap.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heatmap.hvplot.quadmesh(\n",
    "    cmap=\"blues\",\n",
    "    # logy=True,\n",
    "    logz=True,\n",
    "    # clim=(1, 1e4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
