{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import distributed\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import skimage.measure\n",
    "import zarr\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from holoviews.operation.datashader import regrid\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis import *\n",
    "from paulssonlab.util.ui import display_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"GFP\": \"#f44336\",\n",
    "    \"Cy5\": \"#03a9f4\",\n",
    "    # \"Cy7\": \"#ffeb3b\"\n",
    "    \"Cy7\": \"#8bc34a\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"06:00:00\",\n",
    "    memory=\"2GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-PENTA\"\n",
    "trench_detection_channel = segmentation_channel  # channel for trench detection, almost always same as segmentation_channel\n",
    "measure_channels = [\"RFP-PENTA\", \"YFP-DUAL\"]\n",
    "fish_channels = [\"RFP-PENTA\", \"Cy5-PENTA\", \"Cy7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, output_dir):\n",
    "        self.logger = logging.getLogger(\"Pipeline\")\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.state = {}\n",
    "        self.array = {}\n",
    "        self.table = {}\n",
    "\n",
    "    def delayed(self, func, *args, **kwargs):\n",
    "        # TODO:\n",
    "        # log exceptions\n",
    "        # log warnings (deduplicated, count instances)\n",
    "        # optionally retry with diag if func takes \"diagnostics\" argument\n",
    "        # log benchmarking/profiling? or collect stats, only log outliers (+ call arguments)\n",
    "        return dask.delayed(func, *args, **kwargs)\n",
    "\n",
    "\n",
    "def crop_trenches(img, trenches):\n",
    "    crops = {}\n",
    "    # TODO: the islice is just for testing (we only deal with three trenches for FOV), otherwise every dask task takes a long time\n",
    "    for i, crop in it.islice(new.image.iter_crops(img, trenches), 3):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def segment_trenches(crops):\n",
    "    masks = {}\n",
    "    for i, crop in crops.items():\n",
    "        masks[i] = trench_segmentation.segment(crop)\n",
    "    return masks\n",
    "\n",
    "\n",
    "# TODO: this is really boilerplatey, also we want finer task granularity than doing a whole FOV at once\n",
    "def measure_crops(label_images, intensity_images):\n",
    "    keys = label_images.keys() & intensity_images.keys()\n",
    "    return {k: measure_crop(label_images[k], intensity_images[k]) for k in keys}\n",
    "\n",
    "\n",
    "def measure_crop(label_image, intensity_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            intensity_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"intensity_mean\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")\n",
    "\n",
    "\n",
    "def measure_mask_crops(label_images):\n",
    "    return {k: measure_mask_crop(v) for k, v in label_images.items()}\n",
    "\n",
    "\n",
    "def measure_mask_crop(label_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"area\",\n",
    "                \"axis_major_length\",\n",
    "                \"axis_minor_length\",\n",
    "                \"orientation\",\n",
    "                \"centroid\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")\n",
    "\n",
    "\n",
    "# TODO: use a namedtuple (or typing.NamedTuple, or dataclass) for keys so that fields are named\n",
    "def handle_image(pipeline, msg):\n",
    "    image = msg[\"image\"]\n",
    "    metadata = msg[\"metadata\"]\n",
    "    fov_num = metadata[\"fov_num\"]\n",
    "    t = metadata[\"t\"]\n",
    "    channel = metadata[\"channel\"]\n",
    "    raw_key = (\"raw\", fov_num, t, channel)\n",
    "    # store raw image (in production, we won't do this, we will only store crops as we do below)\n",
    "    pipeline.array[raw_key] = image\n",
    "    # TODO: we need a way to store per-frame metadata and write it to disk\n",
    "    trenches_key = (\n",
    "        \"trenches\",\n",
    "        fov_num,\n",
    "    )\n",
    "    trenches = pipeline.table.get(trenches_key)\n",
    "    # check if we have done trench detection for this FOV\n",
    "    if trenches is None and channel == trench_detection_channel:\n",
    "        # if not, find trenches and save the resulting table\n",
    "        trenches = pipeline.delayed(new.image.find_trench_bboxes)(\n",
    "            image, peak_func=trench_detection.peaks.find_peaks\n",
    "        )\n",
    "        pipeline.table[trenches_key] = trenches\n",
    "    # this list keeps track of all the raw frames that need to be cropped\n",
    "    # frames for multiple channels will accumulate in this list until we get a frame for trench_detection_channel\n",
    "    # if we have already processed such a frame, then keys_to_crop will contain only the current frame (raw_key)\n",
    "    keys_to_crop = pipeline.state.setdefault((\"keys_to_crop\", fov_num), [])\n",
    "    keys_to_crop.append(raw_key)\n",
    "    # we only can do further processing if we have already detected trenches for this FOV\n",
    "    if trenches is not None:\n",
    "        for raw_to_crop in keys_to_crop:\n",
    "            crop_key = (\"crops\", *raw_to_crop[1:])\n",
    "            # save trench crops for every frame in keys_to_crop\n",
    "            pipeline.array[crop_key] = pipeline.delayed(crop_trenches)(\n",
    "                pipeline.array[raw_to_crop], trenches\n",
    "            )\n",
    "            segmentation_key = (\"segmentation\", fov_num, t, segmentation_channel)\n",
    "            segmentation = pipeline.array.get(segmentation_key)\n",
    "            if segmentation is not None:\n",
    "                if crop_key[-1] in measure_channels:\n",
    "                    # if we have segmentation masks for this frame, we can immediately segment only this frame\n",
    "                    keys_to_measure = [crop_key]\n",
    "                else:\n",
    "                    keys_to_measure = []\n",
    "            else:\n",
    "                # we don't have a segmentation mask yet, so we need to add to the keys_to_measure list\n",
    "                keys_to_measure = pipeline.state.setdefault(\n",
    "                    (\"keys_to_measure\", fov_num, t), []\n",
    "                )\n",
    "                if crop_key[-1] in measure_channels:\n",
    "                    # we want to measure this frame\n",
    "                    keys_to_measure.append(crop_key)\n",
    "                if crop_key[-1] == segmentation_channel:\n",
    "                    # if this frame's channel is the segmentation channel, run segmentation\n",
    "                    segmentation = pipeline.delayed(segment_trenches)(\n",
    "                        pipeline.array[crop_key]\n",
    "                    )\n",
    "                    pipeline.array[segmentation_key] = segmentation\n",
    "                    # once we have the segmentation mask, get measurements for the mask\n",
    "                    pipeline.table[\n",
    "                        (\n",
    "                            \"mask_measurements\",\n",
    "                            *crop_key[1:],\n",
    "                        )\n",
    "                    ] = pipeline.delayed(measure_mask_crops)(segmentation)\n",
    "            segmentation = pipeline.array.get(segmentation_key)\n",
    "            # if we now have the segmentation mask, try measuring all frames in the keys_to_measure list\n",
    "            if segmentation is not None:\n",
    "                for crop_to_measure in keys_to_measure:\n",
    "                    measurements_key = (\"measurements\", *crop_to_measure[1:])\n",
    "                    pipeline.table[measurements_key] = pipeline.delayed(measure_crops)(\n",
    "                        segmentation, pipeline.array[crop_to_measure]\n",
    "                    )\n",
    "                pipeline.state.pop((\"keys_to_measure\", fov_num, t), None)\n",
    "        pipeline.state.pop((\"keys_to_crop\", fov_num), None)\n",
    "\n",
    "\n",
    "def handle_fish_barcode(pipeline, msg):\n",
    "    pass  # TODO\n",
    "\n",
    "\n",
    "# we should pick a name that's better/more intuitive than handle_message\n",
    "def handle_message(pipeline, msg):\n",
    "    match msg:\n",
    "        case {\"type\": \"image\", **info}:\n",
    "            match info:\n",
    "                case {\"image_type\": \"fish_barcode\"}:\n",
    "                    handle_fish_barcode(pipeline, msg)\n",
    "                case other:\n",
    "                    handle_image(pipeline, msg)\n",
    "        case {\"type\": \"nd2_metadata\"}:\n",
    "            print(\"got metadata\")  # TODO\n",
    "        case {\"type\": \"event\", **info}:\n",
    "            print(\"event\", info)\n",
    "        case {\"type\": \"done\"}:\n",
    "            print(\"DONE\")\n",
    "        case _:\n",
    "            # this exception should be caught, we don't want malformed messages to crash the pipeline\n",
    "            raise ValueError(\"cannot handle message\", msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/220523/220523_library_test_smallfile.nd2\"\n",
    "pipeline = Pipeline(\"/home/jqs1/scratch/jqs1/microscopy/220718/new_architecture/test1\")\n",
    "for msg in new.readers.send_nd2(\n",
    "    filename,\n",
    "    slices=dict(v=slice(1), t=slice(1)),\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline = Pipeline(\"/home/jqs1/scratch/jqs1/microscopy/220718/new_architecture/test1\")\n",
    "for msg in new.readers.send_nd2(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\",\n",
    "    slices=dict(v=slice(1), t=slice(1)),\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_graph = pipeline.array[(\"crops\", 0, 0, \"RFP-Penta\")]\n",
    "masks_graph = pipeline.array[(\"segmentation\", 0, 0, \"RFP-Penta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# crops = crops_graph.compute(scheduler=\"synchronous\")\n",
    "crops = client.compute(crops_graph, sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crops[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# masks = masks_graph.compute(scheduler=\"synchronous\")\n",
    "masks = client.compute(masks_graph, sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trenches = client.compute(pipeline.table[(\"trenches\", 0)], sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.table.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "measurements = client.compute(\n",
    "    pipeline.table[(\"measurements\", 0, 0, \"RFP-Penta\")], sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mask_measurements = client.compute(\n",
    "    pipeline.table[(\"mask_measurements\", 0, 0, \"RFP-Penta\")], sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_measurements[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "This is how the full pipeline could be run for an experiment which has a first phase (stored in ND2) and a second FISH phase (stored in HDF5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\"/home/jqs1/scratch/jqs1/microscopy/220718/new_architecture/test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for msg in send_nd2(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/RBS_DEG_library_20x.nd2\"\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for msg in send_eaton_fish(\n",
    "    \"/home/jqs1/scratch/jqs1/microscopy/220718/FISH/real_run/\",\n",
    "    r\"fov=(?P<v>\\d+)_config=(?P<c>\\w+)_t=(?P<t>\\d+)\",\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_message(pipeline, {\"type\": \"done\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230215/230215induction.nd2\" #v=7\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230326/230326promrbs.nd2\" #v=8,t=10\n",
    "filename = \"/home/jqs1/scratch/jqs1/microscopy/230404/230404_rbsprom.nd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.metadata[\"channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nd2.get_frame_2D(v=8, c=0, t=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img / img.max() * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "trenches = trench_detection.find_trenches(img, diagnostics=diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag2 = util.tree()\n",
    "trenches2 = trench_detection.find_trenches(\n",
    "    img, peak_func=trench_detection.peaks.find_peaks, diagnostics=diag2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"label_1\"][\"find_trench_ends\"][\"image_with_trenches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2[\"label_1\"][\"find_trench_ends\"][\"image_with_trenches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"label_1\"][\"find_trench_lines\"][\"hough_0\"][\"peak_func\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"label_1\"][\"find_trench_lines\"][\"hough_0\"][\"peak_func\"][\"spectrum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag3 = util.tree()\n",
    "img_bin = trench_detection.set_finding.binarize_trench_image(img, diagnostics=diag3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(img.flat, bins=300, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis.image import (\n",
    "    gaussian_box_approximation,\n",
    "    normalize_componentwise,\n",
    "    remove_large_objects,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowpass_radius = 500\n",
    "img_lowpass = gaussian_box_approximation(img, lowpass_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rb = skimage.restoration.rolling_ball(img, radius=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(rb, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image((img - rb) / img.max() * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "?skimage.filters.threshold_sauvola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img > skimage.filters.threshold_sauvola(img, window_size=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img > skimage.filters.threshold_otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img / img.max() * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img - img_lowpass, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img - img_lowpass, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img_bin[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"][\"thresholded_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"label_1\"][\"find_trench_lines\"][\"hough_0\"][\"peak_func\"][\"refined_points\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"label_2\"][\"find_trench_ends\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "?trench_detection.hough.find_periodic_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "h = trench_detection.hough.hough_line_intensity(\n",
    "    img, theta=np.linspace(-np.pi / 5, np.pi / 5, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(h[0].T, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "h[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.deg2rad(5) / np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "# Manual FISH trench crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230215/230215induction.nd2\" #v=7\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230326/230326promrbs.nd2\" #v=8,t=10\n",
    "filename = \"/home/jqs1/scratch/jqs1/microscopy/230404/230404_rbsprom.nd2\"\n",
    "fish_filename = Path(filename).parent / \"FISH/real_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nd2.get_frame_2D(v=8, c=0, t=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 8.947368421052635e-10\n",
    "img_t = image.correct_radial_distortion(img, k1=k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# diag = util.tree()\n",
    "diag = None\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    img_t,\n",
    "    # angle=np.deg2rad(0.001),\n",
    "    join_info=False,\n",
    "    width=12,\n",
    "    # width_to_line_width_ratio=2,\n",
    "    # width_to_pitch_ratio=None,\n",
    "    # peak_func=trench_detection.peaks.find_peaks,\n",
    "    diagnostics=diag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_trenches(img, trenches):\n",
    "    crops = {}\n",
    "    # for i, crop in it.islice(geometry.iter_crops(img, trenches), 10, 13):\n",
    "    for i, crop in geometry.iter_crops(img, trenches):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def stack_crops(crops, channels, timepoints):\n",
    "    stacks = {}\n",
    "    for (t, channel), frame_crops in crops.items():\n",
    "        channel_idx = channels.index(channel)\n",
    "        timepoint_idx = timepoints.index(t)\n",
    "        for trench_idx, trench_slice in frame_crops.items():\n",
    "            if trench_idx not in stacks:\n",
    "                stacks[trench_idx] = zarr.create(\n",
    "                    (len(channels), len(timepoints), *trench_slice.shape),\n",
    "                    dtype=trench_slice.dtype,\n",
    "                    fill_value=np.nan,\n",
    "                )\n",
    "            stacks[trench_idx][channel_idx, timepoint_idx, :, :] = trench_slice\n",
    "    return stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calibrate_image(img, k1=0):\n",
    "    img = skimage.img_as_float32(img)\n",
    "    img = image.correct_radial_distortion(img, k1=k1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed = util.get_delayed(True)\n",
    "fish_frames = {}\n",
    "fish_crops = {}\n",
    "fish_channels = set()\n",
    "fish_timepoints = set()\n",
    "for msg in readers.send_eaton_fish(\n",
    "    fish_filename,\n",
    "    r\"fov=(?P<v>\\d+)_config=(?P<c>\\w+)_t=(?P<t>\\d+)\",\n",
    "    slices=dict(t=None, v=[8]),\n",
    "    delayed=delayed,\n",
    "):\n",
    "    # print(msg[\"metadata\"],msg[\"image\"].shape)\n",
    "    fish_img = msg[\"image\"]\n",
    "    fish_img_corrected = delayed(calibrate_image)(fish_img, k1=k1)\n",
    "    t = msg[\"metadata\"][\"t\"]\n",
    "    channel = msg[\"metadata\"][\"channel\"]\n",
    "    fish_channels.add(channel)\n",
    "    fish_timepoints.add(t)\n",
    "    fish_frames[(t, channel)] = fish_img_corrected\n",
    "    fish_crops[(t, channel)] = delayed(crop_trenches)(fish_img_corrected, trenches)\n",
    "fish_channels = list(sorted(fish_channels))\n",
    "fish_timepoints = list(sorted(fish_timepoints))\n",
    "fish_stacks = delayed(stack_crops)(fish_crops, fish_channels, fish_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_channel_colors = [fish_colors[ch] for ch in fish_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_frames0, fish_stacks0 = dask.compute(fish_frames, fish_stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_stacks0[10].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in new.readers.send_nd2(\n",
    "    filename,\n",
    "    slices=dict(v=slice(1), t=slice(1)),\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = fish_stacks0[13][1:, :9]\n",
    "# x = x - x.min(axis=1)[:,np.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mean(ary):\n",
    "    ary = ary - ary.min(axis=1)[:, np.newaxis, :, :]\n",
    "    # lmbda = (ary.max(axis=1) - ary.min(axis=1))[:,np.newaxis,:,:]\n",
    "    lmbda = ary.max(axis=1)[:, np.newaxis, :, :]\n",
    "    w = (\n",
    "        1\n",
    "        / 3\n",
    "        * (lmbda / lmbda.sum(axis=(2, 3))[:, :, np.newaxis, np.newaxis]).sum(axis=0)[\n",
    "            np.newaxis, :, :, :\n",
    "        ]\n",
    "    )\n",
    "    if w.sum() == 0:\n",
    "        return None\n",
    "    return np.average(ary, axis=(2, 3), weights=np.broadcast_to(w, ary.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics = {\n",
    "    idx: weighted_mean(np.asarray(stack[1:, :9]))\n",
    "    for idx, stack in tqdm(fish_stacks0.items())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(1 for x in fish_metrics.values() if x is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bit_names = [(ch, str(t)) for ch in fish_channels[1:] for t in fish_timepoints[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        trench_idx: ary.flatten()\n",
    "        for trench_idx, ary in fish_metrics.items()\n",
    "        if ary is not None\n",
    "    },\n",
    "    columns=pd.MultiIndex.from_tuples(bit_names, names=[\"channel\", \"timepoint\"]),\n",
    "    orient=\"index\",\n",
    ").rename_axis(index=\"trench_idx\")\n",
    "fish_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2 = fish_metrics_df.melt(ignore_index=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_thresholds = {\"GFP\": 0.007, \"Cy5\": 0.005, \"Cy7\": 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2[\"ground_truth\"] = fish_metrics_df2[\"value\"] > fish_metrics_df2[\n",
    "    \"channel\"\n",
    "].map(fish_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(fish_metrics_df2.groupby(\"trench_idx\").sum(\"ground_truth\") == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2.groupby(\"channel\").apply(lambda x: x[\"ground_truth\"].sum() / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(fish_metrics_df2.groupby(\"channel\").sum(\"ground_truth\") == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx = 1901\n",
    "idx = 2350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = fish_stacks0[idx][1:, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2[fish_metrics_df2[\"trench_idx\"] == idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(image.unstack_multichannel(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = x - x.min(axis=1)[:, np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(image.unstack_multichannel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(weighted_mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Violin(fish_metrics_df2, [\"channel\", \"timepoint\"], \"value\").opts(\n",
    "    hv.opts(\n",
    "        width=700,\n",
    "        show_legend=True,\n",
    "        violin_color=hv.dim(\"channel\").str(),\n",
    "        inner=None,\n",
    "        # violin_width=1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Violin(fish_metrics_df2, [\"channel\", \"timepoint\", \"ground_truth\"], \"value\").opts(\n",
    "    hv.opts(\n",
    "        width=700,\n",
    "        show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        split=hv.dim(\"ground_truth\"),\n",
    "        violin_width=3,\n",
    "        inner=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = hv.Dataset(fish_metrics_df2, [\"channel\", \"timepoint\", \"ground_truth\"], \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.to(hv.Violin, [\"timepoint\", \"ground_truth\"]).layout(\"channel\").opts(\n",
    "    hv.opts.Violin(\n",
    "        width=700,\n",
    "        # show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        split=hv.dim(\"ground_truth\"),\n",
    "        violin_width=3,\n",
    "        inner=None,\n",
    "        axiswise=True,\n",
    "    )\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = ds.to(hv.Violin, [\"timepoint\"]).overlay(\"ground_truth\").layout(\"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_stacked_violins = (\n",
    "    ds.to(hv.Violin, [\"timepoint\"]).overlay(\"ground_truth\").layout(\"channel\")\n",
    ")\n",
    "\n",
    "hv.Layout([v.redim(value=k) for k, v in _stacked_violins.items()]).opts(\n",
    "    hv.opts.Violin(\n",
    "        width=700,\n",
    "        # show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        # violin_width=3,\n",
    "        inner=None,\n",
    "        bandwidth=0.2,\n",
    "        cut=0.05,\n",
    "    )\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fish_metrics_df2.groupby(\"channel\").apply(lambda x: hv.Violin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): hv.Distribution(df, \"value\").redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ")  # .opts(hv.opts.Distribution(logy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): hv.Dataset(df, [\"ground_truth\"], \"value\").to(\n",
    "            hv.Distribution\n",
    "        )\n",
    "        # .overlay(\"ground_truth\")\n",
    "        # hv.Distribution(df, \"value\").redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ")  # .opts(hv.opts.Distribution(show_legend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): (\n",
    "            hv.Distribution(df[df[\"ground_truth\"]], \"value\", label=\"On\")\n",
    "            * hv.Distribution(df[~df[\"ground_truth\"]], \"value\", label=\"Off\")\n",
    "        ).redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ").opts(hv.opts.Distribution(show_legend=True, bandwidth=0.3, cut=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.sampledata.iris import flowers\n",
    "from holoviews.operation import gridmatrix\n",
    "\n",
    "iris_ds = hv.Dataset(flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df3 = fish_metrics_df.set_axis(\n",
    "    [\"_\".join(c) for c in fish_metrics_df.columns], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df3 = fish_metrics_df3.loc[\n",
    "    :, [*fish_metrics_df3.columns[3:6], *fish_metrics_df3.columns[13:16]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "density_grid = gridmatrix(\n",
    "    hv.Dataset(fish_metrics_df3), diagonal_type=hv.Distribution, chart_type=hv.Bivariate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "density_grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
