{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import distributed\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import scipy\n",
    "import skimage.measure\n",
    "import zarr\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis import *\n",
    "from paulssonlab.util.ui import display_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"06:00:00\",\n",
    "    memory=\"2GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Trench detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230215/230215induction.nd2\" #v=7\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230326/230326promrbs.nd2\" #v=8,t=10\n",
    "filename = \"/home/jqs1/scratch/jqs1/microscopy/230404/230404_rbsprom.nd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.metadata[\"channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nd2.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nd2.get_frame_2D(v=8, c=0, t=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(img, scale=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(img, scale=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Radial distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 8.947368421052635e-10\n",
    "# k1 = 2e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img_t = image.correct_radial_distortion(img, k1=k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    img_t, width_to_pitch_ratio=1.4 / 3.5, join_info=False, diagnostics=diag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Radial distortion optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1s = np.linspace(-1e-9, 2e-9, 20)\n",
    "res = []\n",
    "for k1 in tqdm(k1s):\n",
    "    img_corrected = image.correct_radial_distortion(img, k1=k1)\n",
    "    h, theta, rho = trench_detection.hough.hough_line_intensity(\n",
    "        img_corrected, theta=np.linspace(-np.pi / 50, np.pi / 50, 400)\n",
    "    )\n",
    "    smooth = 4\n",
    "    diff_h = np.diff(h.astype(np.int_), axis=1)  # TODO: is diff necessary??\n",
    "    diff_h_std = diff_h.std(axis=0)  # / diff_h.max(axis=0)\n",
    "    if smooth:\n",
    "        diff_h_std_smoothed = scipy.ndimage.gaussian_filter1d(diff_h_std, smooth)\n",
    "    else:\n",
    "        diff_h_std_smoothed = diff_h_std\n",
    "    theta_idx = diff_h_std_smoothed.argmax()\n",
    "    diff_h_std_max = diff_h_std_smoothed[theta_idx]\n",
    "    angle = theta[theta_idx]\n",
    "    res.append(\n",
    "        dict(\n",
    "            k1=k1,\n",
    "            h=h,\n",
    "            diff_h=diff_h,\n",
    "            diff_h_std=diff_h_std,\n",
    "            diff_h_std_smoothed=diff_h_std_smoothed,\n",
    "            angle=angle,\n",
    "            theta_idx=theta_idx,\n",
    "            img_corrected=img_corrected,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for idx in range(len(res)):\n",
    "    plt.plot(res[idx][\"diff_h_std\"][120:200], label=idx)\n",
    "plt.legend()\n",
    "plt.plot(res[12][\"diff_h_std\"][120:200], lw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "idx = 12\n",
    "plt.plot(res[idx - 2][\"diff_h_std\"][120:200])\n",
    "plt.plot(res[idx][\"diff_h_std\"][120:200], lw=4)\n",
    "plt.plot(res[idx + 2][\"diff_h_std\"][120:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[12][\"k1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(res[-3][\"img_corrected\"], scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# FISH correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230215/230215induction.nd2\" #v=7\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230326/230326promrbs.nd2\" #v=8,t=10\n",
    "filename = \"/home/jqs1/scratch/jqs1/microscopy/230404/230404_rbsprom.nd2\"\n",
    "fish_filename = Path(filename).parent / \"FISH/real_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k1 = 8.947368421052635e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calibrate_image(img, k1=0):\n",
    "    img = skimage.img_as_float32(img)\n",
    "    img = image.correct_radial_distortion(img, k1=k1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed = util.get_delayed(True)\n",
    "fish_frames = {}\n",
    "fish_crops = {}\n",
    "fish_channels = set()\n",
    "fish_timepoints = set()\n",
    "for msg in readers.send_eaton_fish(\n",
    "    fish_filename,\n",
    "    r\"fov=(?P<v>\\d+)_config=(?P<c>\\w+)_t=(?P<t>\\d+)\",\n",
    "    slices=dict(t=None, v=[8]),\n",
    "    delayed=delayed,\n",
    "):\n",
    "    # print(msg[\"metadata\"],msg[\"image\"].shape)\n",
    "    fish_img = msg[\"image\"]\n",
    "    # fish_img_corrected = delayed(calibrate_image)(fish_img, k1=k1)\n",
    "    fish_img_corrected = delayed(skimage.img_as_float32)(fish_img)\n",
    "    t = msg[\"metadata\"][\"t\"]\n",
    "    channel = msg[\"metadata\"][\"channel\"]\n",
    "    fish_channels.add(channel)\n",
    "    fish_timepoints.add(t)\n",
    "    fish_frames[(t, channel)] = fish_img_corrected\n",
    "fish_channels = list(sorted(fish_channels))\n",
    "fish_timepoints = list(sorted(fish_timepoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_frames0 = dask.compute(fish_frames)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stacks = {}\n",
    "for channel in fish_channels:\n",
    "    for timepoint_idx, timepoint in enumerate(fish_timepoints):\n",
    "        img = fish_frames0[(timepoint, channel)]\n",
    "        if channel not in stacks:\n",
    "            stacks[channel] = np.full((len(fish_timepoints), *img.shape), np.nan)\n",
    "        stacks[channel][timepoint_idx, :, :] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacks[\"GFP\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacks[\"GFP\"][3:9].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacks[\"GFP\"][3:9].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(stacks[\"GFP\"][3:9].max(axis=0), scale=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(stacks[\"GFP\"][3:9].min(axis=0), scale=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(\n",
    "    stacks[\"GFP\"][3:9].max(axis=0) - stacks[\"GFP\"][3:9].min(axis=0), scale=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(stacks[\"GFP\"][:9].max(axis=0) - stacks[\"GFP\"][:9].min(axis=0), scale=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "# Drift correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = {t: nd2.get_frame_2D(v=8, c=0, t=t)[:500, :500] for t in trange(225)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.HoloMap({k: ui.RevImage(v) for k, v in imgs.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    imgs[0], width_to_pitch_ratio=1.4 / 3.5, join_info=False, diagnostics=diag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "diag2 = util.tree()\n",
    "trenches2, info2 = trench_detection.find_trenches(\n",
    "    imgs[20], width_to_pitch_ratio=2 / 3.5, join_info=False, diagnostics=diag2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag2[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "diag3 = util.tree()\n",
    "trenches3, info3 = trench_detection.find_trenches(\n",
    "    imgs[210], width_to_pitch_ratio=1.4 / 3.5, join_info=False, diagnostics=diag3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag3[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ui.RevImage(imgs[210]) * trench_detection.plot_trenches(trenches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ui.RevImage(imgs[210]) * trench_detection.plot_trenches(trenches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trench_detection.plot_trenches(trenches2).opts(\n",
    "    hv.opts.Rectangles(line_color=\"blue\")\n",
    ") * trench_detection.plot_trenches(trenches3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx=59\n",
    "idx = 80\n",
    "crop = get_crop(imgs[idx], trenches2, 10)\n",
    "pts = trench_cell_endpoints(crop)\n",
    "ui.RevImage(crop).opts(frame_width=40) * hv.Points(pts + 0.5).opts(color=\"red\", size=4)\n",
    "# hv.Points(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plots = {}\n",
    "for t in trange(60, 90, 1):\n",
    "    crop = get_crop(imgs[t], trenches2, 11)\n",
    "    pts = trench_cell_endpoints(crop)\n",
    "    plots[t] = ui.RevImage(crop).opts(frame_width=40) * hv.Points(pts + 0.5).opts(\n",
    "        color=\"red\", size=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.HoloMap(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "TRENCH_COORDINATE_COLUMNS = set([\"top\", \"bottom\", \"ul\", \"lr\"])\n",
    "\n",
    "\n",
    "def trench_cell_endpoints(img, sigma=2, k=2, min_height=0.3, margin_factor=1):\n",
    "    img = skimage.img_as_float(img)\n",
    "    profile = img.mean(axis=1)\n",
    "    grad = misc.holoborodko_diff.holo_diff(\n",
    "        1, scipy.ndimage.gaussian_filter1d(profile, sigma)\n",
    "    )\n",
    "    with warnings.catch_warnings(\n",
    "        action=\"ignore\", category=scipy.signal._peak_finding_utils.PeakPropertyWarning\n",
    "    ):\n",
    "        pos_peaks, pos_peak_props = scipy.signal.find_peaks(\n",
    "            grad, height=min_height * grad.max(), width=(None, None)\n",
    "        )\n",
    "        neg_peaks, neg_peak_props = scipy.signal.find_peaks(\n",
    "            -grad, height=-min_height * grad.min(), width=(None, None)\n",
    "        )\n",
    "    y1 = pos_peaks[0]\n",
    "    y2 = neg_peaks[-1]\n",
    "    margin = int(\n",
    "        np.ceil(\n",
    "            margin_factor\n",
    "            * (pos_peak_props[\"widths\"][0] + neg_peak_props[\"widths\"][-1])\n",
    "            / 2\n",
    "        )\n",
    "    )\n",
    "    cutoff1 = min(y1 + 1 + margin, img.shape[0])\n",
    "    cutoff2 = max(y2 - margin, 0)\n",
    "    weights1 = profile[:cutoff1, np.newaxis]\n",
    "    weights2 = profile[cutoff2:, np.newaxis]\n",
    "    x1 = (\n",
    "        np.arange(img.shape[1])[np.newaxis, :] * (img[:cutoff1, :] * weights1) ** k\n",
    "    ).sum() / ((img[:cutoff1, :] * weights1) ** k).sum()\n",
    "    x2 = (\n",
    "        np.arange(img.shape[1])[np.newaxis, :] * (img[cutoff2:, :] * weights2) ** k\n",
    "    ).sum() / ((img[cutoff2:, :] * weights2) ** k).sum()\n",
    "    return np.array([[x1, y1], [x2, y2]])\n",
    "\n",
    "\n",
    "def get_crop(img, trenches, trench_idx):\n",
    "    ul_x = trenches[\"ul_x\"].values\n",
    "    ul_y = trenches[\"ul_y\"].values\n",
    "    lr_x = trenches[\"lr_x\"].values\n",
    "    lr_y = trenches[\"lr_y\"].values\n",
    "    return img[\n",
    "        ul_y[trench_idx] : lr_y[trench_idx] + 1, ul_x[trench_idx] : lr_x[trench_idx] + 1\n",
    "    ]\n",
    "\n",
    "\n",
    "def _coordinate_columns(columns):\n",
    "    cols_x = set([f\"{col}_x\" for col in TRENCH_COORDINATE_COLUMNS]) & set(columns)\n",
    "    cols_y = set([f\"{col}_y\" for col in TRENCH_COORDINATE_COLUMNS]) & set(columns)\n",
    "    return cols_x, cols_y\n",
    "\n",
    "\n",
    "def filter_trenches(trenches, image_limits):\n",
    "    x_lim = image_limits[0]\n",
    "    y_lim = image_limits[1]\n",
    "    cols_x, cols_y = _coordinate_columns(trenches.columns)\n",
    "    return trenches[\n",
    "        np.logical_and.reduce([trenches[col].between(*x_lim) for col in cols_x])\n",
    "        & np.logical_and.reduce([trenches[col].between(*y_lim) for col in cols_y])\n",
    "    ]\n",
    "\n",
    "\n",
    "def shift_trenches(trenches, shift):\n",
    "    cols_x, cols_y = _coordinate_columns(trenches.columns)\n",
    "    coords_x = {col: trenches[col].values + shift[0] for col in cols_x}\n",
    "    coords_y = {col: trenches[col].values + shift[1] for col in cols_y}\n",
    "    return trenches.assign(**coords_x, **coords_y)\n",
    "\n",
    "\n",
    "def find_trench_drift(\n",
    "    img1,\n",
    "    img2,\n",
    "    trenches,\n",
    "    tolerance=1,\n",
    "    feature_func=trench_cell_endpoints,\n",
    "    diagnostics=None,\n",
    "):\n",
    "    image_limits = geometry.get_image_limits(img1.shape)\n",
    "    features1 = {}\n",
    "    shifted_trenches = filter_trenches(trenches, image_limits)\n",
    "    for roi_idx, crop, ul in geometry.iter_crops(img1, shifted_trenches, corner=True):\n",
    "        features1[roi_idx] = feature_func(crop) + ul[np.newaxis, ...]\n",
    "    shift = np.array([0, 0], dtype=np.int64)\n",
    "    plot_lines = []\n",
    "    features2 = {}\n",
    "    while True:\n",
    "        shifted_trenches = filter_trenches(\n",
    "            shift_trenches(trenches, shift), image_limits\n",
    "        )\n",
    "        for roi_idx, crop, ul in geometry.iter_crops(\n",
    "            img2, shifted_trenches, corner=True\n",
    "        ):\n",
    "            features2[roi_idx] = feature_func(crop) + ul[np.newaxis, ...]\n",
    "        for roi_idx in features1.keys() & features2.keys():\n",
    "            roi_features1 = features1[roi_idx]\n",
    "            roi_features2 = features2[roi_idx]\n",
    "            if roi_features1 is None or roi_features2 is None:\n",
    "                continue\n",
    "            for feature_idx in range(min(len(roi_features1), len(roi_features2))):\n",
    "                plot_lines.append(\n",
    "                    [roi_features1[feature_idx], roi_features2[feature_idx]]\n",
    "                )\n",
    "        break\n",
    "    return plot_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x = find_trench_drift(imgs[20], imgs[40], trenches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_robust, inliers = skimage.measure.ransac(\n",
    "    (*np.array(x).swapaxes(0, 1),),\n",
    "    skimage.transform.EuclideanTransform,\n",
    "    min_samples=3,\n",
    "    residual_threshold=2,\n",
    "    max_trials=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = [\n",
    "    [(*c[0], \"red\" if inlier else \"gray\"), (*c[1], \"red\" if inlier else \"gray\")]\n",
    "    for c, inlier in zip(x, inliers)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Path(y, vdims=[\"color\"]).opts(color=\"color\", line_width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_robust.translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Path(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TranslationTransform(skimage.transform.EuclideanTransform):\n",
    "    def estimate(self, src, dst):\n",
    "        translation = (dst - src).mean(axis=1)\n",
    "        self.params[0 : self.dimensionality, self.dimensionality] = translation\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plots = {}\n",
    "for t in trange(225):\n",
    "    crop = get_crop(imgs[t], trenches2, 5)\n",
    "    pts = trench_cell_endpoints(crop)\n",
    "    # plots[t] = ui.RevImage(crop).opts(frame_width=40) * hv.Points(pts + 0.5).opts(\n",
    "    #     color=\"red\", size=4\n",
    "    # )\n",
    "    plots[t] = hv.Curve([(0, t), (2, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plots = {}\n",
    "for t in trange(225):\n",
    "    crop = get_crop(imgs[t], trenches2, 5)\n",
    "    pts = trench_cell_endpoints(crop)\n",
    "    plots[t] = ui.RevImage(crop).opts(frame_width=40) * hv.Points(pts + 0.5).opts(\n",
    "        color=\"red\", size=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.HoloMap(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.HoloMap(plots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
