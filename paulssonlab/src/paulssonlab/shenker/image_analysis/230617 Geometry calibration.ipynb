{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import distributed\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import scipy\n",
    "import skimage.measure\n",
    "import zarr\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from holoviews.operation.datashader import regrid\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis import *\n",
    "from paulssonlab.util.ui import display_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"06:00:00\",\n",
    "    memory=\"2GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Trench detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230215/230215induction.nd2\" #v=7\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230326/230326promrbs.nd2\" #v=8,t=10\n",
    "filename = \"/home/jqs1/scratch/jqs1/microscopy/230404/230404_rbsprom.nd2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.metadata[\"channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nd2.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nd2.get_frame_2D(v=8, c=0, t=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(img, scale=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(img, scale=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Radial distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 8.947368421052635e-10\n",
    "# k1 = 2e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img_t = image.correct_radial_distortion(img, k1=k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    img_t, width_to_pitch_ratio=1.4 / 3.5, join_info=False, diagnostics=diag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Radial distortion optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1s = np.linspace(-1e-9, 2e-9, 20)\n",
    "res = []\n",
    "for k1 in tqdm(k1s):\n",
    "    img_corrected = image.correct_radial_distortion(img, k1=k1)\n",
    "    h, theta, rho = trench_detection.hough.hough_line_intensity(\n",
    "        img_corrected, theta=np.linspace(-np.pi / 50, np.pi / 50, 400)\n",
    "    )\n",
    "    smooth = 4\n",
    "    diff_h = np.diff(h.astype(np.int_), axis=1)  # TODO: is diff necessary??\n",
    "    diff_h_std = diff_h.std(axis=0)  # / diff_h.max(axis=0)\n",
    "    if smooth:\n",
    "        diff_h_std_smoothed = scipy.ndimage.gaussian_filter1d(diff_h_std, smooth)\n",
    "    else:\n",
    "        diff_h_std_smoothed = diff_h_std\n",
    "    theta_idx = diff_h_std_smoothed.argmax()\n",
    "    diff_h_std_max = diff_h_std_smoothed[theta_idx]\n",
    "    angle = theta[theta_idx]\n",
    "    res.append(\n",
    "        dict(\n",
    "            k1=k1,\n",
    "            h=h,\n",
    "            diff_h=diff_h,\n",
    "            diff_h_std=diff_h_std,\n",
    "            diff_h_std_smoothed=diff_h_std_smoothed,\n",
    "            angle=angle,\n",
    "            theta_idx=theta_idx,\n",
    "            img_corrected=img_corrected,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for idx in range(len(res)):\n",
    "    plt.plot(res[idx][\"diff_h_std\"][120:200], label=idx)\n",
    "plt.legend()\n",
    "plt.plot(res[12][\"diff_h_std\"][120:200], lw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "idx = 12\n",
    "plt.plot(res[idx - 2][\"diff_h_std\"][120:200])\n",
    "plt.plot(res[idx][\"diff_h_std\"][120:200], lw=4)\n",
    "plt.plot(res[idx + 2][\"diff_h_std\"][120:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[12][\"k1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(res[-3][\"img_corrected\"], scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# FISH correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230215/230215induction.nd2\" #v=7\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230326/230326promrbs.nd2\" #v=8,t=10\n",
    "filename = \"/home/jqs1/scratch/jqs1/microscopy/230404/230404_rbsprom.nd2\"\n",
    "fish_filename = Path(filename).parent / \"FISH/real_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k1 = 8.947368421052635e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calibrate_image(img, k1=0):\n",
    "    img = skimage.img_as_float32(img)\n",
    "    img = image.correct_radial_distortion(img, k1=k1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed = util.get_delayed(True)\n",
    "fish_frames = {}\n",
    "fish_crops = {}\n",
    "fish_channels = set()\n",
    "fish_timepoints = set()\n",
    "for msg in readers.send_eaton_fish(\n",
    "    fish_filename,\n",
    "    r\"fov=(?P<v>\\d+)_config=(?P<c>\\w+)_t=(?P<t>\\d+)\",\n",
    "    slices=dict(t=None, v=[8]),\n",
    "    delayed=delayed,\n",
    "):\n",
    "    # print(msg[\"metadata\"],msg[\"image\"].shape)\n",
    "    fish_img = msg[\"image\"]\n",
    "    # fish_img_corrected = delayed(calibrate_image)(fish_img, k1=k1)\n",
    "    fish_img_corrected = delayed(skimage.img_as_float32)(fish_img)\n",
    "    t = msg[\"metadata\"][\"t\"]\n",
    "    channel = msg[\"metadata\"][\"channel\"]\n",
    "    fish_channels.add(channel)\n",
    "    fish_timepoints.add(t)\n",
    "    fish_frames[(t, channel)] = fish_img_corrected\n",
    "fish_channels = list(sorted(fish_channels))\n",
    "fish_timepoints = list(sorted(fish_timepoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_frames0 = dask.compute(fish_frames)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stacks = {}\n",
    "for channel in fish_channels:\n",
    "    for timepoint_idx, timepoint in enumerate(fish_timepoints):\n",
    "        img = fish_frames0[(timepoint, channel)]\n",
    "        if channel not in stacks:\n",
    "            stacks[channel] = np.full((len(fish_timepoints), *img.shape), np.nan)\n",
    "        stacks[channel][timepoint_idx, :, :] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacks[\"GFP\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacks[\"GFP\"][3:9].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacks[\"GFP\"][3:9].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(stacks[\"GFP\"][3:9].max(axis=0), scale=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(stacks[\"GFP\"][3:9].min(axis=0), scale=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(\n",
    "    stacks[\"GFP\"][3:9].max(axis=0) - stacks[\"GFP\"][3:9].min(axis=0), scale=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(stacks[\"GFP\"][:9].max(axis=0) - stacks[\"GFP\"][:9].min(axis=0), scale=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "# Drift correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = {t: nd2.get_frame_2D(v=8, c=0, t=t)[:500, :500] for t in trange(225)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.HoloMap({k: ui.RevImage(v) for k, v in imgs.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    imgs[0], width_to_pitch_ratio=1.4 / 3.5, join_info=False, diagnostics=diag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "diag2 = util.tree()\n",
    "trenches2, info2 = trench_detection.find_trenches(\n",
    "    imgs[20], width_to_pitch_ratio=1.4 / 3.5, join_info=False, diagnostics=diag2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag2[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "diag3 = util.tree()\n",
    "trenches3, info3 = trench_detection.find_trenches(\n",
    "    imgs[210], width_to_pitch_ratio=1.4 / 3.5, join_info=False, diagnostics=diag3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag3[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ui.RevImage(imgs[210]) * trench_detection.plot_trenches(trenches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ui.RevImage(imgs[210]) * trench_detection.plot_trenches(trenches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trench_detection.plot_trenches(trenches2).opts(\n",
    "    hv.opts.Rectangles(line_color=\"blue\")\n",
    ") * trench_detection.plot_trenches(trenches3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plots = {}\n",
    "t_min = 70\n",
    "t_delta = 50\n",
    "for t in range(t_min, t_min + t_delta + 1, 3):\n",
    "    # for t in [t_min, t_min+t_delta+1]:\n",
    "    crop = get_crop(imgs[t], trenches2, 12)\n",
    "    pts = trench_cell_endpoints(crop)\n",
    "    plots[t] = ui.RevImage(crop).opts(frame_width=40) * hv.Points(pts + 0.5).opts(\n",
    "        color=\"red\", size=4\n",
    "    )\n",
    "hv.HoloMap(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx=59\n",
    "idx = 100\n",
    "crop = get_crop(imgs[idx], trenches2, 12)\n",
    "pts = trench_cell_endpoints(crop)\n",
    "ui.RevImage(crop).opts(frame_width=40) * hv.Points(pts + 0.5).opts(color=\"red\", size=4)\n",
    "# hv.Points(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "TRENCH_COORDINATE_COLUMNS = set([\"top\", \"bottom\", \"ul\", \"lr\"])\n",
    "\n",
    "\n",
    "def trench_cell_endpoints(img, sigma=2, k=2, min_height=0.3, margin_factor=1):\n",
    "    img = skimage.img_as_float(img)\n",
    "    profile = img.mean(axis=1)\n",
    "    grad = misc.holoborodko_diff.holo_diff(\n",
    "        1, scipy.ndimage.gaussian_filter1d(profile, sigma)\n",
    "    )\n",
    "    with warnings.catch_warnings(\n",
    "        action=\"ignore\", category=scipy.signal._peak_finding_utils.PeakPropertyWarning\n",
    "    ):\n",
    "        pos_peaks, pos_peak_props = scipy.signal.find_peaks(\n",
    "            grad, height=min_height * grad.max(), width=(None, None)\n",
    "        )\n",
    "        neg_peaks, neg_peak_props = scipy.signal.find_peaks(\n",
    "            -grad, height=-min_height * grad.min(), width=(None, None)\n",
    "        )\n",
    "    if len(pos_peaks) < 2:\n",
    "        return None\n",
    "    y1 = pos_peaks[0]\n",
    "    y2 = neg_peaks[-1]\n",
    "    margin = int(\n",
    "        np.ceil(\n",
    "            margin_factor\n",
    "            * (pos_peak_props[\"widths\"][0] + neg_peak_props[\"widths\"][-1])\n",
    "            / 2\n",
    "        )\n",
    "    )\n",
    "    cutoff1 = min(y1 + 1 + margin, img.shape[0])\n",
    "    cutoff2 = max(y2 - margin, 0)\n",
    "    x1 = img[:cutoff1, :].mean(axis=0).argmax()\n",
    "    x2 = img[cutoff2:, :].mean(axis=0).argmax()\n",
    "    return np.array([[x1, y1], [x2, y2]])\n",
    "\n",
    "\n",
    "def get_crop(img, trenches, trench_idx):\n",
    "    ul_x = trenches[\"ul_x\"].values\n",
    "    ul_y = trenches[\"ul_y\"].values\n",
    "    lr_x = trenches[\"lr_x\"].values\n",
    "    lr_y = trenches[\"lr_y\"].values\n",
    "    return img[\n",
    "        ul_y[trench_idx] : lr_y[trench_idx] + 1, ul_x[trench_idx] : lr_x[trench_idx] + 1\n",
    "    ]\n",
    "\n",
    "\n",
    "def _coordinate_columns(columns):\n",
    "    cols_x = set([f\"{col}_x\" for col in TRENCH_COORDINATE_COLUMNS]) & set(columns)\n",
    "    cols_y = set([f\"{col}_y\" for col in TRENCH_COORDINATE_COLUMNS]) & set(columns)\n",
    "    return cols_x, cols_y\n",
    "\n",
    "\n",
    "def filter_trenches(trenches, image_limits):\n",
    "    x_lim = image_limits[0]\n",
    "    y_lim = image_limits[1]\n",
    "    cols_x, cols_y = _coordinate_columns(trenches.columns)\n",
    "    return trenches[\n",
    "        np.logical_and.reduce([trenches[col].between(*x_lim) for col in cols_x])\n",
    "        & np.logical_and.reduce([trenches[col].between(*y_lim) for col in cols_y])\n",
    "    ]\n",
    "\n",
    "\n",
    "def shift_trenches(trenches, shift):\n",
    "    cols_x, cols_y = _coordinate_columns(trenches.columns)\n",
    "    coords_x = {col: trenches[col].values + shift[0] for col in cols_x}\n",
    "    coords_y = {col: trenches[col].values + shift[1] for col in cols_y}\n",
    "    return trenches.assign(**coords_x, **coords_y)\n",
    "\n",
    "\n",
    "class TranslationTransform(skimage.transform.EuclideanTransform):\n",
    "    def estimate(self, src, dst):\n",
    "        translation = (dst - src).mean(axis=0)\n",
    "        self.params[0 : self.dimensionality, self.dimensionality] = translation\n",
    "        return True\n",
    "\n",
    "\n",
    "def ransac_translation(\n",
    "    data, residual_threshold=3, min_samples=10, diagnostics=None, **kwargs\n",
    "):\n",
    "    data = (*np.array(data).swapaxes(0, 1),)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", \"divide by zero encountered in scalar divide\")\n",
    "        model_robust, inliers = skimage.measure.ransac(\n",
    "            data,\n",
    "            TranslationTransform,\n",
    "            min_samples=min_samples,\n",
    "            residual_threshold=residual_threshold,\n",
    "            **kwargs,\n",
    "        )\n",
    "    if diagnostics is not None:\n",
    "        feature_points = [\n",
    "            [(*d1, \"red\" if inlier else \"gray\"), (*d2, \"red\" if inlier else \"gray\")]\n",
    "            for d1, d2, inlier in zip(data[0], data[1], inliers)\n",
    "        ]\n",
    "        diagnostics[\"correspondences\"] = hv.Path(feature_points, vdims=[\"color\"]).opts(\n",
    "            color=\"color\", line_width=2\n",
    "        )\n",
    "    return model_robust.translation\n",
    "\n",
    "\n",
    "def find_trench_drift(\n",
    "    img1,\n",
    "    img2,\n",
    "    trenches,\n",
    "    initial_shift=None,\n",
    "    tolerance=1,\n",
    "    feature_func=trench_cell_endpoints,\n",
    "    estimation_func=ransac_translation,\n",
    "    max_iterations=1,\n",
    "    diagnostics=None,\n",
    "):\n",
    "    image_limits = geometry.get_image_limits(img1.shape)\n",
    "    features1 = {}\n",
    "    if initial_shift is None:\n",
    "        initial_shift = np.array([0, 0])\n",
    "    shifted_trenches = filter_trenches(\n",
    "        shift_trenches(trenches, initial_shift), image_limits\n",
    "    )\n",
    "    for roi_idx, crop, ul in geometry.iter_crops(img1, shifted_trenches, corner=True):\n",
    "        if (feature := feature_func(crop)) is not None:\n",
    "            features1[roi_idx] = feature + ul[np.newaxis, ...]\n",
    "    shift = initial_shift\n",
    "    for i in range(max_iterations):\n",
    "        features_list = []\n",
    "        features2 = {}\n",
    "        shifted_trenches = filter_trenches(\n",
    "            shift_trenches(trenches, shift), image_limits\n",
    "        )\n",
    "        for roi_idx, crop, ul in geometry.iter_crops(\n",
    "            img2, shifted_trenches, corner=True\n",
    "        ):\n",
    "            if (feature := feature_func(crop)) is not None:\n",
    "                features2[roi_idx] = feature + ul[np.newaxis, ...]\n",
    "        for roi_idx in features1.keys() & features2.keys():\n",
    "            roi_features1 = features1[roi_idx]\n",
    "            roi_features2 = features2[roi_idx]\n",
    "            if roi_features1 is None or roi_features2 is None:\n",
    "                continue\n",
    "            for feature_idx in range(min(len(roi_features1), len(roi_features2))):\n",
    "                features_list.append(\n",
    "                    [roi_features1[feature_idx], roi_features2[feature_idx]]\n",
    "                )\n",
    "        features_list = np.array(features_list)\n",
    "        new_shift = estimation_func(features_list, diagnostics=diagnostics)\n",
    "        new_shift = np.round(new_shift).astype(np.int64)\n",
    "        # if np.linalg.norm(new_shift, shift) <= tolerance:\n",
    "        #     break\n",
    "        shift = new_shift\n",
    "    diagnostics[\"features1\"] = hv.Points(features_list.swapaxes(0, 1)[0])\n",
    "    diagnostics[\"features2\"] = hv.Points(features_list.swapaxes(0, 1)[1])\n",
    "    return shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "diag_d = util.tree()\n",
    "shift = find_trench_drift(imgs[20], imgs[101], trenches, diagnostics=diag_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag_d[\"features1\"] * diag_d[\"features2\"].opts(color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_d[\"correspondences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plots = {}\n",
    "for t in trange(225):\n",
    "    crop = get_crop(imgs[t], trenches2, 5)\n",
    "    pts = trench_cell_endpoints(crop)\n",
    "    # plots[t] = ui.RevImage(crop).opts(frame_width=40) * hv.Points(pts + 0.5).opts(\n",
    "    #     color=\"red\", size=4\n",
    "    # )\n",
    "    plots[t] = hv.Curve([(0, t), (2, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plots = {}\n",
    "for t in trange(225):\n",
    "    crop = get_crop(imgs[t], trenches2, 5)\n",
    "    pts = trench_cell_endpoints(crop)\n",
    "    plots[t] = ui.RevImage(crop).opts(frame_width=40) * hv.Points(pts + 0.5).opts(\n",
    "        color=\"red\", size=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "k1 = 8.947368421052635e-10\n",
    "img1 = image.correct_radial_distortion(nd2.get_frame_2D(v=8, t=70, c=0), k1=k1)\n",
    "img2 = image.correct_radial_distortion(nd2.get_frame_2D(v=8, t=110, c=0), k1=k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trenches = trench_detection.find_trenches(img1, width_to_pitch_ratio=2 / 3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "regrid(\n",
    "    hv.HoloMap({t: ui.RevImage(x) for t, x in enumerate([img1, img2])})\n",
    ") * hv.HoloMap({t: trench_detection.plot_trenches(trenches) for t in range(2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag_d = util.tree()\n",
    "shift = find_trench_drift(img1, img2, trenches, diagnostics=diag_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(trenches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag_d[\"features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "# Drift correction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = {t: nd2.get_frame_2D(v=8, c=0, t=t)[:500, :500] for t in trange(225)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trenches, info = trench_detection.find_trenches(\n",
    "    imgs[20],\n",
    "    width_to_pitch_ratio=1.4 / 3.5,\n",
    "    join_info=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?filter_trenches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_limits = geometry.get_image_limits(imgs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t0 = 20\n",
    "t1 = 225\n",
    "ts = np.arange(t0 + 1, t1)\n",
    "shifts = {}\n",
    "shifts[t0] = np.array([0, 0])\n",
    "correspondences = {}\n",
    "features = {}\n",
    "for t in tqdm(ts):\n",
    "    diag = {}\n",
    "    # shift = find_trench_drift(\n",
    "    #     imgs[t - 1], imgs[t], trenches, initial_shift=shifts[t - 1], diagnostics=diag\n",
    "    # )\n",
    "    shift = find_trench_drift(\n",
    "        imgs[t0], imgs[t], trenches, initial_shift=shifts[t0], diagnostics=diag\n",
    "    )\n",
    "    shifts[t] = shift\n",
    "    correspondences[t] = diag[\"correspondences\"]\n",
    "    features[t] = diag[\"features2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regrid(hv.HoloMap({t: ui.RevImage(imgs[t]) for t in ts})) * hv.HoloMap(\n",
    "    {\n",
    "        t: trench_detection.plot_trenches(\n",
    "            filter_trenches(shift_trenches(trenches, shifts[t]), image_limits)\n",
    "        )\n",
    "        for t in ts\n",
    "    }\n",
    ") * hv.HoloMap({t: features[t] for t in ts}).opts(color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regrid(hv.HoloMap({t: ui.RevImage(imgs[t]) for t in ts})) * hv.HoloMap(\n",
    "    {\n",
    "        t: trench_detection.plot_trenches(\n",
    "            filter_trenches(shift_trenches(trenches, shifts[t]), image_limits)\n",
    "        )\n",
    "        for t in ts\n",
    "    }\n",
    ") * hv.HoloMap({t: features[t] for t in ts}).opts(color=\"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
