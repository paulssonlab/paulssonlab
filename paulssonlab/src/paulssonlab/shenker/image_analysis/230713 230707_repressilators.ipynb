{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools as it\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import distributed\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import skimage.measure\n",
    "import zarr\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from holoviews.operation.datashader import regrid\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis import *\n",
    "from paulssonlab.image_analysis.ui import display_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230215/230215induction.nd2\" #v=7\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230326/230326promrbs.nd2\" #v=8,t=10\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230404/230404_rbsprom.nd2\"\n",
    "# filename = workflow.SplitFilename(\n",
    "#     sorted(\n",
    "#         glob.glob(\n",
    "#             \"/home/jqs1/scratch/jqs1/microscopy/230619/230619_NAO745_repressilators_split.nd2*\"\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "filename = workflow.SplitFilename(\n",
    "    sorted(\n",
    "        glob.glob(\n",
    "            \"/home/jqs1/scratch/jqs1/microscopy/230707/230707_repressilators_restart.nd2.split.a*\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fish_filename = Path(filename).parent / \"FISH/real_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = workflow.get_nd2_reader(filename)\n",
    "t_max = nd2.sizes[\"t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"CFP-EM\": \"#f44336\",  # TODO\n",
    "    \"YFP-EM\": \"#03a9f4\",\n",
    "    \"RFP-EM\": \"#8bc34a\",\n",
    "}\n",
    "\n",
    "fish_colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"GFP\": \"#f44336\",\n",
    "    \"Cy5\": \"#03a9f4\",\n",
    "    # \"Cy7\": \"#ffeb3b\"\n",
    "    \"Cy7\": \"#8bc34a\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"02:00:00\",\n",
    "    memory=\"16GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-PENTA\"\n",
    "trench_detection_channel = segmentation_channel  # channel for trench detection, almost always same as segmentation_channel\n",
    "measure_channels = [\"RFP-PENTA\", \"YFP-DUAL\"]\n",
    "fish_channels = [\"RFP-PENTA\", \"Cy5-PENTA\", \"Cy7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_rois(img, rois):\n",
    "    crops = {}\n",
    "    # TODO: the islice is just for testing (we only deal with three trenches for FOV), otherwise every dask task takes a long time\n",
    "    # for i, crop in it.islice(geometry.iter_roi_crops(img, rois), 100):\n",
    "    for i, crop in geometry.iter_roi_crops(img, rois):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def segment_crops(crops):\n",
    "    masks = {}\n",
    "    for i, crop in crops.items():\n",
    "        masks[i] = segmentation.watershed.segment(crop)\n",
    "    return masks\n",
    "\n",
    "\n",
    "# TODO: this is really boilerplatey, also we want finer task granularity than doing a whole FOV at once\n",
    "# def measure_crops(label_images, intensity_images):\n",
    "#     keys = label_images.keys() & intensity_images.keys()\n",
    "#     return {k: measure_crop(label_images[k], intensity_images[k]) for k in keys}\n",
    "def measure_crops(intensity_images):\n",
    "    keys = intensity_images.keys()\n",
    "    return {k: measure_crop(intensity_images[k]) for k in keys}\n",
    "\n",
    "\n",
    "# def measure_crop(label_image, intensity_image):\n",
    "# return pd.DataFrame(\n",
    "#     skimage.measure.regionprops_table(\n",
    "#         label_image,\n",
    "#         intensity_image,\n",
    "#         properties=(\n",
    "#             \"label\",\n",
    "#             \"intensity_mean\",\n",
    "#         ),\n",
    "#     )\n",
    "# ).set_index(\"label\")\n",
    "def measure_crop(intensity_image):\n",
    "    centerline = intensity_image[:, intensity_image.shape[1] // 2]\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"p1\": np.percentile(intensity_image, 1),\n",
    "            \"p50\": np.median(intensity_image),\n",
    "            \"p90\": np.percentile(intensity_image, 90),\n",
    "            \"p99\": np.percentile(intensity_image, 99),\n",
    "            \"mean\": np.mean(intensity_image),\n",
    "            \"centerline_mean\": np.mean(centerline),\n",
    "            \"centerline_median\": np.median(centerline),\n",
    "        },\n",
    "        name=\"value\",\n",
    "    ).rename_axis(index=\"observable\")\n",
    "\n",
    "\n",
    "def measure_mask_crops(label_images):\n",
    "    return {k: measure_mask_crop(v) for k, v in label_images.items()}\n",
    "\n",
    "\n",
    "def measure_mask_crop(label_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"area\",\n",
    "                \"axis_major_length\",\n",
    "                \"axis_minor_length\",\n",
    "                \"orientation\",\n",
    "                \"centroid\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")\n",
    "\n",
    "\n",
    "def write_parquet(output_dir, measurements, position, t):\n",
    "    df = pd.concat(\n",
    "        {\n",
    "            channel: pd.concat(channel_df, names=[\"roi_idx\"])\n",
    "            for channel, channel_df in measurements.items()\n",
    "        },\n",
    "        names=[\"channel\"],\n",
    "    ).reset_index()\n",
    "    df[\"position\"] = np.array(position).astype(np.uint16)\n",
    "    df[\"t\"] = np.array(t).astype(np.uint16)\n",
    "    pq.write_to_dataset(\n",
    "        pa.Table.from_pandas(df, preserve_index=False),\n",
    "        Path(output_dir) / \"measurements\",\n",
    "        partition_cols=[\"position\", \"t\"],\n",
    "        existing_data_behavior=\"delete_matching\",\n",
    "    )\n",
    "\n",
    "\n",
    "def stack_dict(d):\n",
    "    shape = next(iter(d.values())).shape\n",
    "    null = np.full(shape, np.nan)\n",
    "    return [d.get(idx, null) for idx in range(max(d.keys()) + 1)]\n",
    "\n",
    "\n",
    "def _pad(ary, shape):\n",
    "    return np.pad(\n",
    "        ary, [(0, max(goal - current, 0)) for goal, current in zip(shape, ary.shape)]\n",
    "    )\n",
    "\n",
    "\n",
    "def write_zarr(filename, crops, t, max_t, channels):\n",
    "    store = zarr.DirectoryStore(filename)  # DirectoryStoreV3(filename)\n",
    "    if not filename.exists():\n",
    "        num_rois = max(crops[channels[0]].keys()) + 1\n",
    "        num_channels = len(channels)\n",
    "        max_shape = np.max([crop.shape for crop in crops[channels[0]].values()], axis=0)\n",
    "        shape = (num_rois, max_t, num_channels, *max_shape)\n",
    "        chunks = (5, 1, num_channels, None, None)\n",
    "        ary = zarr.open_array(\n",
    "            store,\n",
    "            mode=\"a\",\n",
    "            zarr_version=2,\n",
    "            shape=shape,\n",
    "            chunks=chunks,\n",
    "            fill_value=np.nan,\n",
    "        )\n",
    "    else:\n",
    "        ary = zarr.open_array(store, mode=\"a\", zarr_version=2)\n",
    "        max_shape = ary.shape[-2:]\n",
    "    stack = np.array(\n",
    "        [\n",
    "            stack_dict(\n",
    "                {\n",
    "                    idx: _pad(crop.astype(np.float32), max_shape)\n",
    "                    for idx, crop in crops[channel].items()\n",
    "                }\n",
    "            )\n",
    "            for channel in channels\n",
    "        ]\n",
    "    ).swapaxes(0, 1)\n",
    "    ary[:, t, ...] = stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(filename).parent / \"test_output\"\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-EM\"\n",
    "measurement_channels = [\"CFP-EM\", \"YFP-EM\", \"RFP-EM\"]\n",
    "width_to_pitch_ratio = 1.4 / 3.5\n",
    "k1 = 8.947368421052635e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_func(filename, position, channel, t, k1=k1, dark=None, flat=None):\n",
    "    return image.correct_radial_distortion(\n",
    "        np.asarray(\n",
    "            workflow.get_nd2_frame(\n",
    "                filename, position=position, channel=channel, t=t, dark=dark, flat=flat\n",
    "            )\n",
    "        ),\n",
    "        k1=k1,\n",
    "    )[550:2350, 1500:3500]\n",
    "    # return np.asarray(\n",
    "    #     workflow.get_nd2_frame(filename, position, channel, t, dark=dark, flat=flat)\n",
    "    # )[550:2350, 1500:3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img0 = get_frame_func(filename, 11, segmentation_channel, 0)\n",
    "image_limits = geometry.get_image_limits(img0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img0, scale=0.9, downsample=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "rois, info = trench_detection.find_trenches(\n",
    "    img0,\n",
    "    width_to_pitch_ratio=width_to_pitch_ratio,\n",
    "    join_info=False,\n",
    "    diagnostics=diag,\n",
    ")\n",
    "angle = info[\"angle\"]\n",
    "pitch = info[\"pitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"][\"num_components\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"][\"normalized_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fov(\n",
    "    get_frame_func,\n",
    "    position,\n",
    "    ts,\n",
    "    output_dir,\n",
    "    segmentation_channel,\n",
    "    measurement_channels,\n",
    "    image_limits,\n",
    "    find_trenches_kwargs={},\n",
    "    dark=None,\n",
    "    flats=None,\n",
    "    delayed=True,\n",
    "):\n",
    "    delayed = util.get_delayed(delayed)\n",
    "    channels = [\n",
    "        segmentation_channel,\n",
    "        *(set(measurement_channels) - set([segmentation_channel])),\n",
    "    ]\n",
    "    measurement_channels = measurement_channels\n",
    "    rois = None\n",
    "    shifts = {}\n",
    "    write_tasks = []\n",
    "    for prev_t, t in tqdm(list(zip(it.chain([None], ts[:-1]), ts))):\n",
    "        segmentation_img = delayed(get_frame_func)(position, segmentation_channel, t)\n",
    "        if rois is None:\n",
    "            rois = delayed(trench_detection.find_trenches)(\n",
    "                segmentation_img, **{**dict(join_info=True), **find_trenches_kwargs}\n",
    "            )\n",
    "            shifts[t] = np.array([0, 0])\n",
    "            initial_drift_features = delayed(drift.get_drift_features)(\n",
    "                segmentation_img, rois, shifts[t]\n",
    "            )\n",
    "        else:\n",
    "            shifts[t] = delayed(drift.find_feature_drift)(\n",
    "                initial_drift_features,\n",
    "                segmentation_img,\n",
    "                rois,\n",
    "                initial_shift2=shifts[prev_t],\n",
    "            )\n",
    "        shifted_rois = delayed(geometry.filter_rois)(\n",
    "            delayed(geometry.shift_rois)(rois, shifts[t]), image_limits\n",
    "        )\n",
    "        crops = {}\n",
    "        measurements = {}\n",
    "        for channel in channels:\n",
    "            if channel == segmentation_channel:\n",
    "                crops[channel] = delayed(crop_rois)(segmentation_img, shifted_rois)\n",
    "                # mask_crops = delayed(segment_crops)(crops[channel])\n",
    "                # mask_measurements = delayed(measure_mask_crops)(mask_crops)\n",
    "            else:\n",
    "                img = delayed(get_frame_func)(position, channel, t)\n",
    "                crops[channel] = delayed(crop_rois)(img, shifted_rois)\n",
    "            if channel in measurement_channels:\n",
    "                # measurements[channel] = delayed(measure_crops)(mask_crops, crops[channel])\n",
    "                measurements[channel] = delayed(measure_crops)(crops[channel])\n",
    "        metadata = dict(shifts=shifts)\n",
    "        write_tasks.append(\n",
    "            delayed(write_parquet)(output_dir, measurements, position, t)\n",
    "        )\n",
    "        # TODO\n",
    "        max_t = 300\n",
    "        write_tasks.append(\n",
    "            delayed(write_zarr)(\n",
    "                output_dir / f\"crops_v={position}.zarr\",\n",
    "                crops,\n",
    "                t,\n",
    "                max_t,\n",
    "                measurement_channels,\n",
    "            )\n",
    "        )\n",
    "        # TODO: rois, metadata\n",
    "    return write_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%pyinstrument\n",
    "ts = np.arange(t_max)\n",
    "# ts = np.arange(2)\n",
    "res = []\n",
    "for position in np.arange(13, 40):\n",
    "    res.append(\n",
    "        process_fov(\n",
    "            partial(get_frame_func, filename),\n",
    "            position,\n",
    "            ts,\n",
    "            output_dir / \"test2\",\n",
    "            segmentation_channel,\n",
    "            measurement_channels,\n",
    "            image_limits,\n",
    "            find_trenches_kwargs=dict(\n",
    "                angle=angle, pitch=pitch, width_to_pitch_ratio=2.2 / 3.5\n",
    "            ),\n",
    "            delayed=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures = [client.compute(x) for x in tqdm(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "del futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $output_dir/test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $output_dir/test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.dataset(\n",
    "    output_dir / \"test2/measurements\", format=\"parquet\", partitioning=\"hive\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = dataset.to_table(filter=ds.field(\"position\") == 11).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = (\n",
    "    df[df[\"observable\"] == \"p90\"]\n",
    "    .pivot_table(\n",
    "        columns=[\"channel\"], values=[\"value\"], index=[\"position\", \"roi_idx\", \"t\"]\n",
    "    )\n",
    "    .droplevel(0, axis=1)\n",
    "    # .droplevel([\"position\"])\n",
    "    # .reset_index(\"roi_idx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info(verbose=True, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df2.groupby([\"position\", \"roi_idx\"]))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, quantile=0.9):\n",
    "    if quantile is None or quantile == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return x / x.quantile(quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = norm(df2.loc[(11, 21)].loc[IDX[40:], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(x[\"CFP-EM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index()[df2.reset_index()[\"roi_idx\"] == 244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(df2.loc[(11, 244)].loc[IDX[40:], :]).hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df2.index.get_level_values(\"roi_idx\") == 244).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_idxs = np.unique(\n",
    "    df2.index.get_level_values(\"roi_idx\")\n",
    ")  # df2.index.levels[df2.index.names.index(\"roi_idx\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = list(df2.groupby([\"position\", \"roi_idx\"], as_index=False, group_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(groups[5][1].droplevel([\"position\", \"roi_idx\"])).hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.HoloMap(\n",
    "    {\n",
    "        t: norm(\n",
    "            groups[t][1].droplevel([\"position\", \"roi_idx\"]).loc[IDX[40:], :]\n",
    "        ).hvplot()\n",
    "        for t in range(2)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21, 57, 67, 103, 105, 107, 116, 149, 162, 170, 185, 191, 215, 237, 246, 252, 268, 285, 302, 319, 321, 342, 346, 375, 417, 432, 453, 454, 457, 462, 463\n",
    "# 535, 567, 588, 600, 638, 644, 650, 677, 680, 690, 707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.HoloMap(\n",
    "    {\n",
    "        idx[1]: norm(group.droplevel([\"position\", \"roi_idx\"]).loc[IDX[40:], :]).hvplot()\n",
    "        for idx, group in groups[400:]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zarr.open_array(output_dir / \"test2/crops_v=11.zarr\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(z[1][0][1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max0 = 20\n",
    "(\n",
    "    hv.HoloMap({t: ui.RevImage(z[21][t][0].T) for t in range(t_max0)}).options(\n",
    "        frame_width=400\n",
    "    )\n",
    "    + hv.HoloMap({t: ui.RevImage(z[21][t][1].T) for t in range(t_max0)}).options(\n",
    "        frame_width=400\n",
    "    )\n",
    "    + hv.HoloMap({t: ui.RevImage(z[21][t][2].T) for t in range(t_max0)}).options(\n",
    "        frame_width=400\n",
    "    )\n",
    ").cols(1).opts(hv.opts.Image(axiswise=True), hv.opts.Layout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output backend='matplotlib'\n",
    "# %%opts Layout [normalize=False fig_inches=2 vspace=0 aspect_weight=1 sublabel_format='' tight=True title_format=\"{filename:}\\npos: {position:} trench: {trench_set:}.{trench:} t: {t:}\".format(**label_stream.contents) fontsize=20]\n",
    "# %%opts Scatter [aspect=6]\n",
    "key = tuple(getattr(label_stream, attr) for attr in trench_key)\n",
    "index = detected_bursts.groupby(trench_key).get_group(key).index\n",
    "ts = index._get_level_values(index._get_level_number(\"t\"), unique=True)\n",
    "# ts = list(range(3))\n",
    "\n",
    "movie = (\n",
    "    trench_movie(trench_bboxes, key, \"MCHERRY\", ts)\n",
    "    + trench_movie(trench_bboxes, key, \"YFP\", ts)\n",
    "    + scatter_movie(labelwise_df, label_stream.contents, ts)\n",
    "    * hv.HoloMap(\n",
    "        {t: hv.VLine(t).options(color=\"red\", backend=\"matplotlib\") for t in ts}\n",
    "    )\n",
    ").cols(1)\n",
    "movie2 = movie.options(\n",
    "    {\n",
    "        \"Layout\": dict(\n",
    "            normalize=False,\n",
    "            framewise=True,\n",
    "            fig_inches=7,\n",
    "            vspace=0,\n",
    "            aspect_weight=1,\n",
    "            sublabel_format=\"\",\n",
    "            tight=False,\n",
    "            fontsize=15,\n",
    "            title_format=\"{filename:}\\npos: {position:} trench: {trench_set:}.{trench:} t: {t:}\".format(\n",
    "                **label_stream.contents\n",
    "            ),\n",
    "        ),\n",
    "        \"Scatter\": dict(aspect=6, s=20),\n",
    "    },\n",
    "    backend=\"matplotlib\",\n",
    ")\n",
    "m = holomap_to_video(movie2, out=\"/tmp/jqsmovie.mp4\", size=100, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ZARR_V3_EXPERIMENTAL_API\"] = \"1\"\n",
    "os.environ[\"ZARR_V3_SHARDING\"] = \"1\"\n",
    "\n",
    "from zarr._storage.v3 import DirectoryStoreV3\n",
    "from zarr._storage.v3_storage_transformers import ShardingStorageTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Manual FISH trench crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nd2.get_frame_2D(v=8, c=0, t=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 8.947368421052635e-10\n",
    "img_t = image.correct_radial_distortion(img, k1=k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# diag = util.tree()\n",
    "diag = None\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    img_t,\n",
    "    # angle=np.deg2rad(0.001),\n",
    "    join_info=False,\n",
    "    width=12,\n",
    "    # width_to_line_width_ratio=2,\n",
    "    # width_to_pitch_ratio=None,\n",
    "    # peak_func=trench_detection.peaks.find_peaks,\n",
    "    diagnostics=diag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_trenches(img, trenches):\n",
    "    crops = {}\n",
    "    # for i, crop in it.islice(geometry.iter_crops(img, trenches), 10, 13):\n",
    "    for i, crop in geometry.iter_crops(img, trenches):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def stack_crops(crops, channels, timepoints):\n",
    "    stacks = {}\n",
    "    for (t, channel), frame_crops in crops.items():\n",
    "        channel_idx = channels.index(channel)\n",
    "        timepoint_idx = timepoints.index(t)\n",
    "        for trench_idx, trench_slice in frame_crops.items():\n",
    "            if trench_idx not in stacks:\n",
    "                stacks[trench_idx] = zarr.create(\n",
    "                    (len(channels), len(timepoints), *trench_slice.shape),\n",
    "                    dtype=trench_slice.dtype,\n",
    "                    fill_value=np.nan,\n",
    "                )\n",
    "            stacks[trench_idx][channel_idx, timepoint_idx, :, :] = trench_slice\n",
    "    return stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calibrate_image(img, k1=0):\n",
    "    img = skimage.img_as_float32(img)\n",
    "    img = image.correct_radial_distortion(img, k1=k1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed = util.get_delayed(True)\n",
    "fish_frames = {}\n",
    "fish_crops = {}\n",
    "fish_channels = set()\n",
    "fish_timepoints = set()\n",
    "for msg in readers.send_eaton_fish(\n",
    "    fish_filename,\n",
    "    r\"fov=(?P<v>\\d+)_config=(?P<c>\\w+)_t=(?P<t>\\d+)\",\n",
    "    slices=dict(t=None, v=[8]),\n",
    "    delayed=delayed,\n",
    "):\n",
    "    # print(msg[\"metadata\"],msg[\"image\"].shape)\n",
    "    fish_img = msg[\"image\"]\n",
    "    fish_img_corrected = delayed(calibrate_image)(fish_img, k1=k1)\n",
    "    fov = msg[\"metadata\"][\"fov\"]\n",
    "    t = msg[\"metadata\"][\"t\"]\n",
    "    channel = msg[\"metadata\"][\"channel\"]\n",
    "    fish_channels.add(channel)\n",
    "    fish_timepoints.add(t)\n",
    "    fish_frames[(t, channel)] = fish_img_corrected\n",
    "    fish_crops[(t, channel)] = delayed(crop_trenches)(fish_img_corrected, trenches)\n",
    "fish_channels = list(sorted(fish_channels))\n",
    "fish_timepoints = list(sorted(fish_timepoints))\n",
    "fish_stacks = delayed(stack_crops)(fish_crops, fish_channels, fish_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_channel_colors = [fish_colors[ch] for ch in fish_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_frames0, fish_stacks0 = dask.compute(fish_frames, fish_stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_stacks0[10].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in new.readers.send_nd2(\n",
    "    filename,\n",
    "    slices=dict(v=slice(1), t=slice(1)),\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = fish_stacks0[13][1:, :9]\n",
    "# x = x - x.min(axis=1)[:,np.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mean(ary):\n",
    "    ary = ary - ary.min(axis=1)[:, np.newaxis, :, :]\n",
    "    # lmbda = (ary.max(axis=1) - ary.min(axis=1))[:,np.newaxis,:,:]\n",
    "    lmbda = ary.max(axis=1)[:, np.newaxis, :, :]\n",
    "    w = (\n",
    "        1\n",
    "        / 3\n",
    "        * (lmbda / lmbda.sum(axis=(2, 3))[:, :, np.newaxis, np.newaxis]).sum(axis=0)[\n",
    "            np.newaxis, :, :, :\n",
    "        ]\n",
    "    )\n",
    "    if w.sum() == 0:\n",
    "        return None\n",
    "    return np.average(ary, axis=(2, 3), weights=np.broadcast_to(w, ary.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics = {\n",
    "    idx: weighted_mean(np.asarray(stack[1:, :9]))\n",
    "    for idx, stack in tqdm(fish_stacks0.items())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(1 for x in fish_metrics.values() if x is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bit_names = [(ch, str(t)) for ch in fish_channels[1:] for t in fish_timepoints[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        trench_idx: ary.flatten()\n",
    "        for trench_idx, ary in fish_metrics.items()\n",
    "        if ary is not None\n",
    "    },\n",
    "    columns=pd.MultiIndex.from_tuples(bit_names, names=[\"channel\", \"timepoint\"]),\n",
    "    orient=\"index\",\n",
    ").rename_axis(index=\"trench_idx\")\n",
    "fish_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2 = fish_metrics_df.melt(ignore_index=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_thresholds = {\"GFP\": 0.007, \"Cy5\": 0.005, \"Cy7\": 0.002}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2[\"ground_truth\"] = fish_metrics_df2[\"value\"] > fish_metrics_df2[\n",
    "    \"channel\"\n",
    "].map(fish_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(fish_metrics_df2.groupby(\"trench_idx\").sum(\"ground_truth\") == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2.groupby(\"channel\").apply(lambda x: x[\"ground_truth\"].sum() / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(fish_metrics_df2.groupby(\"channel\").sum(\"ground_truth\") == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx = 1901\n",
    "idx = 3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = fish_stacks0[idx][1:, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2[fish_metrics_df2[\"trench_idx\"] == idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(image.unstack_multichannel(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = x - x.min(axis=1)[:, np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(image.unstack_multichannel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(weighted_mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Violin(fish_metrics_df2, [\"channel\", \"timepoint\"], \"value\").opts(\n",
    "    hv.opts(\n",
    "        width=700,\n",
    "        show_legend=True,\n",
    "        violin_color=hv.dim(\"channel\").str(),\n",
    "        inner=None,\n",
    "        # violin_width=1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Violin(fish_metrics_df2, [\"channel\", \"timepoint\", \"ground_truth\"], \"value\").opts(\n",
    "    hv.opts(\n",
    "        width=700,\n",
    "        show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        split=hv.dim(\"ground_truth\"),\n",
    "        violin_width=3,\n",
    "        inner=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = hv.Dataset(fish_metrics_df2, [\"channel\", \"timepoint\", \"ground_truth\"], \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.to(hv.Violin, [\"timepoint\", \"ground_truth\"]).layout(\"channel\").opts(\n",
    "    hv.opts.Violin(\n",
    "        width=700,\n",
    "        # show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        split=hv.dim(\"ground_truth\"),\n",
    "        violin_width=3,\n",
    "        inner=None,\n",
    "        axiswise=True,\n",
    "    )\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = ds.to(hv.Violin, [\"timepoint\"]).overlay(\"ground_truth\").layout(\"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_stacked_violins = (\n",
    "    ds.to(hv.Violin, [\"timepoint\"]).overlay(\"ground_truth\").layout(\"channel\")\n",
    ")\n",
    "\n",
    "hv.Layout([v.redim(value=k) for k, v in _stacked_violins.items()]).opts(\n",
    "    hv.opts.Violin(\n",
    "        width=700,\n",
    "        # show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        # violin_width=3,\n",
    "        inner=None,\n",
    "        bandwidth=0.2,\n",
    "        cut=0.05,\n",
    "    )\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fish_metrics_df2.groupby(\"channel\").apply(lambda x: hv.Violin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): hv.Distribution(df, \"value\").redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ")  # .opts(hv.opts.Distribution(logy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): hv.Dataset(df, [\"ground_truth\"], \"value\").to(\n",
    "            hv.Distribution\n",
    "        )\n",
    "        # .overlay(\"ground_truth\")\n",
    "        # hv.Distribution(df, \"value\").redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ")  # .opts(hv.opts.Distribution(show_legend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): (\n",
    "            hv.Distribution(df[df[\"ground_truth\"]], \"value\", label=\"On\")\n",
    "            * hv.Distribution(df[~df[\"ground_truth\"]], \"value\", label=\"Off\")\n",
    "        ).redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ").opts(hv.opts.Distribution(show_legend=True, bandwidth=0.3, cut=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.sampledata.iris import flowers\n",
    "from holoviews.operation import gridmatrix\n",
    "\n",
    "iris_ds = hv.Dataset(flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df3 = fish_metrics_df.set_axis(\n",
    "    [\"_\".join(c) for c in fish_metrics_df.columns], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df3 = fish_metrics_df3.loc[\n",
    "    :, [*fish_metrics_df3.columns[3:6], *fish_metrics_df3.columns[13:16]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "density_grid = gridmatrix(\n",
    "    hv.Dataset(fish_metrics_df3), diagonal_type=hv.Distribution, chart_type=hv.Bivariate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "density_grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
