{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools as it\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import distributed\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import skimage.measure\n",
    "import zarr\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from holoviews.operation.datashader import regrid\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis import *\n",
    "from paulssonlab.image_analysis.ui import display_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230215/230215induction.nd2\" #v=7\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230326/230326promrbs.nd2\" #v=8,t=10\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230404/230404_rbsprom.nd2\"\n",
    "# filename = workflow.SplitFilename(\n",
    "#     sorted(\n",
    "#         glob.glob(\n",
    "#             \"/home/jqs1/scratch/jqs1/microscopy/230619/230619_NAO745_repressilators_split.nd2*\"\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "filename = workflow.SplitFilename(\n",
    "    sorted(\n",
    "        glob.glob(\n",
    "            \"/home/jqs1/scratch/jqs1/microscopy/230707/230707_repressilators_restart.nd2.split.a*\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fish_filename = Path(filename).parent / \"FISH/real_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = workflow.get_nd2_reader(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"CFP-EM\": \"#f44336\",  # TODO\n",
    "    \"YFP-EM\": \"#03a9f4\",\n",
    "    \"RFP-EM\": \"#8bc34a\",\n",
    "}\n",
    "\n",
    "fish_colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"GFP\": \"#f44336\",\n",
    "    \"Cy5\": \"#03a9f4\",\n",
    "    # \"Cy7\": \"#ffeb3b\"\n",
    "    \"Cy7\": \"#8bc34a\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"06:00:00\",\n",
    "    memory=\"2GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-PENTA\"\n",
    "trench_detection_channel = segmentation_channel  # channel for trench detection, almost always same as segmentation_channel\n",
    "measure_channels = [\"RFP-PENTA\", \"YFP-DUAL\"]\n",
    "fish_channels = [\"RFP-PENTA\", \"Cy5-PENTA\", \"Cy7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_rois(img, rois):\n",
    "    crops = {}\n",
    "    # TODO: the islice is just for testing (we only deal with three trenches for FOV), otherwise every dask task takes a long time\n",
    "    for i, crop in it.islice(geometry.iter_roi_crops(img, trenches), 100):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def segment_crops(crops):\n",
    "    masks = {}\n",
    "    for i, crop in crops.items():\n",
    "        masks[i] = segmentation.watershed.segment(crop)\n",
    "    return masks\n",
    "\n",
    "\n",
    "# TODO: this is really boilerplatey, also we want finer task granularity than doing a whole FOV at once\n",
    "def measure_crops(label_images, intensity_images):\n",
    "    keys = label_images.keys() & intensity_images.keys()\n",
    "    return {k: measure_crop(label_images[k], intensity_images[k]) for k in keys}\n",
    "\n",
    "\n",
    "def measure_crop(label_image, intensity_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            intensity_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"intensity_mean\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")\n",
    "\n",
    "\n",
    "def measure_mask_crops(label_images):\n",
    "    return {k: measure_mask_crop(v) for k, v in label_images.items()}\n",
    "\n",
    "\n",
    "def measure_mask_crop(label_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"area\",\n",
    "                \"axis_major_length\",\n",
    "                \"axis_minor_length\",\n",
    "                \"orientation\",\n",
    "                \"centroid\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(filename).parent / \"test_output\"\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-EM\"\n",
    "measurement_channels = [\"CFP-EM\", \"YFP-EM\", \"RFP-EM\"]\n",
    "width_to_pitch_ratio = 1.4 / 3.5\n",
    "k1 = 8.947368421052635e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_func(filename, position, channel, t, k1=k1, dark=None, flat=None):\n",
    "    return image.correct_radial_distortion(\n",
    "        np.asarray(\n",
    "            workflow.get_nd2_frame(\n",
    "                filename, position=position, channel=channel, t=t, dark=dark, flat=flat\n",
    "            )\n",
    "        ),\n",
    "        k1=k1,\n",
    "    )[550:2350, 1500:3500]\n",
    "    # return np.asarray(\n",
    "    #     workflow.get_nd2_frame(filename, position, channel, t, dark=dark, flat=flat)\n",
    "    # )[550:2350, 1500:3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img0 = get_frame_func(filename, 11, segmentation_channel, 0)\n",
    "image_limits = geometry.get_image_limits(img0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img0, scale=0.9, downsample=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    img0,\n",
    "    width_to_pitch_ratio=width_to_pitch_ratio,\n",
    "    join_info=False,\n",
    "    diagnostics=diag,\n",
    ")\n",
    "angle = info[\"angle\"]\n",
    "pitch = info[\"pitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"][\"num_components\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"][\"normalized_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fov(\n",
    "    get_frame_func,\n",
    "    ts,\n",
    "    output_filename,\n",
    "    segmentation_channel,\n",
    "    measurement_channels,\n",
    "    image_limits,\n",
    "    find_trenches_kwargs={},\n",
    "    dark=None,\n",
    "    flats=None,\n",
    "    delayed=True,\n",
    "):\n",
    "    delayed = util.get_delayed(delayed)\n",
    "    channels = [\n",
    "        segmentation_channel,\n",
    "        *(set(measurement_channels) - set([segmentation_channel])),\n",
    "    ]\n",
    "    measurement_channels = set(measurement_channels)\n",
    "    rois = None\n",
    "    shifts = {}\n",
    "    for prev_t, t in tqdm(list(zip(it.chain([None], ts[:-1]), ts))):\n",
    "        segmentation_img = delayed(get_frame_func)(segmentation_channel, t)\n",
    "        if rois is None:\n",
    "            rois = delayed(trench_detection.find_trenches)(\n",
    "                segmentation_img, **{**dict(join_info=True), **find_trenches_kwargs}\n",
    "            )\n",
    "            shifts[t] = np.array([0, 0])\n",
    "            initial_drift_features = delayed(drift.get_drift_features)(\n",
    "                segmentation_img, rois, shifts[t]\n",
    "            )\n",
    "        else:\n",
    "            shifts[t] = delayed(drift.find_feature_drift)(\n",
    "                initial_drift_features,\n",
    "                segmentation_img,\n",
    "                rois,\n",
    "                initial_shift2=shifts[prev_t],\n",
    "            )\n",
    "        shifted_rois = delayed(geometry.filter_rois)(\n",
    "            delayed(geometry.shift_rois)(rois, shifts[t]), image_limits\n",
    "        )\n",
    "        crops = {}\n",
    "        measurements = {}\n",
    "        for channel in channels:\n",
    "            if channel == segmentation_channel:\n",
    "                crops[channel] = delayed(crop_rois)(segmentation_img, shifted_rois)\n",
    "                mask_crops = delayed(segment_crops)(crops[channel])\n",
    "                mask_measurements = delayed(measure_mask_crops)(mask_crops)\n",
    "            else:\n",
    "                img = delayed(get_frame_func)(channel, t)\n",
    "                crops[channel] = delayed(crop_rois)(img, shifted_rois)\n",
    "            if channel in measurement_channels:\n",
    "                measurements[channel] = delayed(measure_crops)(\n",
    "                    crops[channel], mask_crops\n",
    "                )\n",
    "        metadata = dict(shifts=shifts)\n",
    "        return crops, mask_crops, measurements, rois, metadata\n",
    "        # merge measurements into a single DF, save\n",
    "        # save zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pyinstrument\n",
    "#%%time\n",
    "ts = np.arange(5)\n",
    "position = 11\n",
    "output_filename = output_dir / f\"v={position}\"\n",
    "res = process_fov(\n",
    "    partial(get_frame_func, filename, position),\n",
    "    ts,\n",
    "    output_filename,\n",
    "    segmentation_channel,\n",
    "    measurement_channels,\n",
    "    image_limits,\n",
    "    find_trenches_kwargs=dict(angle=angle, pitch=pitch, width_to_pitch_ratio=2.2 / 3.5),\n",
    "    delayed=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    {channel: pd.concat(df, names=[\"roi_idx\"]) for channel, df in res[2].items()},\n",
    "    names=[\"channel\"],\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat(\n",
    "    {\n",
    "        \"YFP-EM\": pd.concat(\n",
    "            {\n",
    "                channel: pd.concat(df, names=[\"roi_idx\"])\n",
    "                for channel, df in res[2].items()\n",
    "            },\n",
    "            names=[\"channel\"],\n",
    "        )\n",
    "    }\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1][80].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[1][80].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[0][\"RFP-EM\"][51].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[0][\"YFP-EM\"][51].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[0][\"CFP-EM\"][51].T);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Manual FISH trench crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = nd2reader.ND2Reader(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nd2.get_frame_2D(v=8, c=0, t=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 8.947368421052635e-10\n",
    "img_t = image.correct_radial_distortion(img, k1=k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# diag = util.tree()\n",
    "diag = None\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    img_t,\n",
    "    # angle=np.deg2rad(0.001),\n",
    "    join_info=False,\n",
    "    width=12,\n",
    "    # width_to_line_width_ratio=2,\n",
    "    # width_to_pitch_ratio=None,\n",
    "    # peak_func=trench_detection.peaks.find_peaks,\n",
    "    diagnostics=diag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_trenches(img, trenches):\n",
    "    crops = {}\n",
    "    # for i, crop in it.islice(geometry.iter_crops(img, trenches), 10, 13):\n",
    "    for i, crop in geometry.iter_crops(img, trenches):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def stack_crops(crops, channels, timepoints):\n",
    "    stacks = {}\n",
    "    for (t, channel), frame_crops in crops.items():\n",
    "        channel_idx = channels.index(channel)\n",
    "        timepoint_idx = timepoints.index(t)\n",
    "        for trench_idx, trench_slice in frame_crops.items():\n",
    "            if trench_idx not in stacks:\n",
    "                stacks[trench_idx] = zarr.create(\n",
    "                    (len(channels), len(timepoints), *trench_slice.shape),\n",
    "                    dtype=trench_slice.dtype,\n",
    "                    fill_value=np.nan,\n",
    "                )\n",
    "            stacks[trench_idx][channel_idx, timepoint_idx, :, :] = trench_slice\n",
    "    return stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calibrate_image(img, k1=0):\n",
    "    img = skimage.img_as_float32(img)\n",
    "    img = image.correct_radial_distortion(img, k1=k1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed = util.get_delayed(True)\n",
    "fish_frames = {}\n",
    "fish_crops = {}\n",
    "fish_channels = set()\n",
    "fish_timepoints = set()\n",
    "for msg in readers.send_eaton_fish(\n",
    "    fish_filename,\n",
    "    r\"fov=(?P<v>\\d+)_config=(?P<c>\\w+)_t=(?P<t>\\d+)\",\n",
    "    slices=dict(t=None, v=[8]),\n",
    "    delayed=delayed,\n",
    "):\n",
    "    # print(msg[\"metadata\"],msg[\"image\"].shape)\n",
    "    fish_img = msg[\"image\"]\n",
    "    fish_img_corrected = delayed(calibrate_image)(fish_img, k1=k1)\n",
    "    fov = msg[\"metadata\"][\"fov\"]\n",
    "    t = msg[\"metadata\"][\"t\"]\n",
    "    channel = msg[\"metadata\"][\"channel\"]\n",
    "    fish_channels.add(channel)\n",
    "    fish_timepoints.add(t)\n",
    "    fish_frames[(t, channel)] = fish_img_corrected\n",
    "    fish_crops[(t, channel)] = delayed(crop_trenches)(fish_img_corrected, trenches)\n",
    "fish_channels = list(sorted(fish_channels))\n",
    "fish_timepoints = list(sorted(fish_timepoints))\n",
    "fish_stacks = delayed(stack_crops)(fish_crops, fish_channels, fish_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_channel_colors = [fish_colors[ch] for ch in fish_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_frames0, fish_stacks0 = dask.compute(fish_frames, fish_stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_stacks0[10].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in new.readers.send_nd2(\n",
    "    filename,\n",
    "    slices=dict(v=slice(1), t=slice(1)),\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = fish_stacks0[13][1:, :9]\n",
    "# x = x - x.min(axis=1)[:,np.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mean(ary):\n",
    "    ary = ary - ary.min(axis=1)[:, np.newaxis, :, :]\n",
    "    # lmbda = (ary.max(axis=1) - ary.min(axis=1))[:,np.newaxis,:,:]\n",
    "    lmbda = ary.max(axis=1)[:, np.newaxis, :, :]\n",
    "    w = (\n",
    "        1\n",
    "        / 3\n",
    "        * (lmbda / lmbda.sum(axis=(2, 3))[:, :, np.newaxis, np.newaxis]).sum(axis=0)[\n",
    "            np.newaxis, :, :, :\n",
    "        ]\n",
    "    )\n",
    "    if w.sum() == 0:\n",
    "        return None\n",
    "    return np.average(ary, axis=(2, 3), weights=np.broadcast_to(w, ary.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics = {\n",
    "    idx: weighted_mean(np.asarray(stack[1:, :9]))\n",
    "    for idx, stack in tqdm(fish_stacks0.items())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(1 for x in fish_metrics.values() if x is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bit_names = [(ch, str(t)) for ch in fish_channels[1:] for t in fish_timepoints[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        trench_idx: ary.flatten()\n",
    "        for trench_idx, ary in fish_metrics.items()\n",
    "        if ary is not None\n",
    "    },\n",
    "    columns=pd.MultiIndex.from_tuples(bit_names, names=[\"channel\", \"timepoint\"]),\n",
    "    orient=\"index\",\n",
    ").rename_axis(index=\"trench_idx\")\n",
    "fish_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2 = fish_metrics_df.melt(ignore_index=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_thresholds = {\"GFP\": 0.007, \"Cy5\": 0.005, \"Cy7\": 0.002}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2[\"ground_truth\"] = fish_metrics_df2[\"value\"] > fish_metrics_df2[\n",
    "    \"channel\"\n",
    "].map(fish_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(fish_metrics_df2.groupby(\"trench_idx\").sum(\"ground_truth\") == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2.groupby(\"channel\").apply(lambda x: x[\"ground_truth\"].sum() / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(fish_metrics_df2.groupby(\"channel\").sum(\"ground_truth\") == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx = 1901\n",
    "idx = 3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = fish_stacks0[idx][1:, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2[fish_metrics_df2[\"trench_idx\"] == idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(image.unstack_multichannel(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = x - x.min(axis=1)[:, np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(image.unstack_multichannel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(weighted_mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Violin(fish_metrics_df2, [\"channel\", \"timepoint\"], \"value\").opts(\n",
    "    hv.opts(\n",
    "        width=700,\n",
    "        show_legend=True,\n",
    "        violin_color=hv.dim(\"channel\").str(),\n",
    "        inner=None,\n",
    "        # violin_width=1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Violin(fish_metrics_df2, [\"channel\", \"timepoint\", \"ground_truth\"], \"value\").opts(\n",
    "    hv.opts(\n",
    "        width=700,\n",
    "        show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        split=hv.dim(\"ground_truth\"),\n",
    "        violin_width=3,\n",
    "        inner=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = hv.Dataset(fish_metrics_df2, [\"channel\", \"timepoint\", \"ground_truth\"], \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.to(hv.Violin, [\"timepoint\", \"ground_truth\"]).layout(\"channel\").opts(\n",
    "    hv.opts.Violin(\n",
    "        width=700,\n",
    "        # show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        split=hv.dim(\"ground_truth\"),\n",
    "        violin_width=3,\n",
    "        inner=None,\n",
    "        axiswise=True,\n",
    "    )\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = ds.to(hv.Violin, [\"timepoint\"]).overlay(\"ground_truth\").layout(\"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_stacked_violins = (\n",
    "    ds.to(hv.Violin, [\"timepoint\"]).overlay(\"ground_truth\").layout(\"channel\")\n",
    ")\n",
    "\n",
    "hv.Layout([v.redim(value=k) for k, v in _stacked_violins.items()]).opts(\n",
    "    hv.opts.Violin(\n",
    "        width=700,\n",
    "        # show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        # violin_width=3,\n",
    "        inner=None,\n",
    "        bandwidth=0.2,\n",
    "        cut=0.05,\n",
    "    )\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fish_metrics_df2.groupby(\"channel\").apply(lambda x: hv.Violin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): hv.Distribution(df, \"value\").redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ")  # .opts(hv.opts.Distribution(logy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): hv.Dataset(df, [\"ground_truth\"], \"value\").to(\n",
    "            hv.Distribution\n",
    "        )\n",
    "        # .overlay(\"ground_truth\")\n",
    "        # hv.Distribution(df, \"value\").redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ")  # .opts(hv.opts.Distribution(show_legend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): (\n",
    "            hv.Distribution(df[df[\"ground_truth\"]], \"value\", label=\"On\")\n",
    "            * hv.Distribution(df[~df[\"ground_truth\"]], \"value\", label=\"Off\")\n",
    "        ).redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ").opts(hv.opts.Distribution(show_legend=True, bandwidth=0.3, cut=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.sampledata.iris import flowers\n",
    "from holoviews.operation import gridmatrix\n",
    "\n",
    "iris_ds = hv.Dataset(flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df3 = fish_metrics_df.set_axis(\n",
    "    [\"_\".join(c) for c in fish_metrics_df.columns], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df3 = fish_metrics_df3.loc[\n",
    "    :, [*fish_metrics_df3.columns[3:6], *fish_metrics_df3.columns[13:16]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "density_grid = gridmatrix(\n",
    "    hv.Dataset(fish_metrics_df3), diagonal_type=hv.Distribution, chart_type=hv.Bivariate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "density_grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
