{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools as it\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import distributed\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import scipy.signal\n",
    "import skimage.measure\n",
    "import zarr\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from holoviews.operation.datashader import regrid\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paulssonlab.image_analysis.mosaic as mosaic\n",
    "from paulssonlab.image_analysis import *\n",
    "from paulssonlab.image_analysis.ui import display_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")\n",
    "# hv.extension(\"matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230213/230213induction.nd2\"\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230215/230215induction.nd2\" #v=7\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230326/230326promrbs.nd2\" #v=8,t=10\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/230404/230404_rbsprom.nd2\"\n",
    "# filename = workflow.SplitFilename(\n",
    "#     sorted(\n",
    "#         glob.glob(\n",
    "#             \"/home/jqs1/scratch/jqs1/microscopy/230619/230619_NAO745_repressilators_split.nd2*\"\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "filename = workflow.SplitFilename(\n",
    "    sorted(\n",
    "        glob.glob(\n",
    "            # \"/home/jqs1/scratch/jqs1/microscopy/230707/230707_repressilators_restart.nd2.split.a*\"\n",
    "            \"/home/jqs1/scratch/jqs1/microscopy/230830/230830_repressilators.nd2.split.*\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# filename = \"/home/jqs1/scratch/jqs1/microscopy/231101/231101_FP_calibration.nd2\"\n",
    "fish_filename = Path(filename).parent / \"FISH/real_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = workflow.get_nd2_reader(filename)\n",
    "max_t = nd2.sizes[\"t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.metadata[\"channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    # \"CFP-EM\": \"#6fb2e4\",\n",
    "    # \"YFP-EM\": \"#eee461\",\n",
    "    # \"RFP-EM\": \"#c66526\",\n",
    "    \"CFP-EM\": \"#648FFF\",\n",
    "    \"YFP-EM\": \"#FFB000\",\n",
    "    \"RFP-EM\": \"#DC267F\",\n",
    "}\n",
    "\n",
    "fish_colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"GFP\": \"#f44336\",\n",
    "    \"Cy5\": \"#03a9f4\",\n",
    "    # \"Cy7\": \"#ffeb3b\"\n",
    "    \"Cy7\": \"#8bc34a\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"02:00:00\",\n",
    "    memory=\"16GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_rois(img, rois):\n",
    "    crops = {}\n",
    "    # TODO: the islice is just for testing (we only deal with three trenches for FOV), otherwise every dask task takes a long time\n",
    "    # for i, crop in it.islice(geometry.iter_roi_crops(img, rois), 100):\n",
    "    for i, crop in geometry.iter_roi_crops(img, rois):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def segment_crops(crops):\n",
    "    masks = {}\n",
    "    for i, crop in crops.items():\n",
    "        masks[i] = segmentation.watershed.segment(crop)\n",
    "    return masks\n",
    "\n",
    "\n",
    "# TODO: this is really boilerplatey, also we want finer task granularity than doing a whole FOV at once\n",
    "# def measure_crops(label_images, intensity_images):\n",
    "#     keys = label_images.keys() & intensity_images.keys()\n",
    "#     return {k: measure_crop(label_images[k], intensity_images[k]) for k in keys}\n",
    "def measure_crops(intensity_images):\n",
    "    keys = intensity_images.keys()\n",
    "    return {k: measure_crop(intensity_images[k]) for k in keys}\n",
    "\n",
    "\n",
    "# def measure_crop(label_image, intensity_image):\n",
    "# return pd.DataFrame(\n",
    "#     skimage.measure.regionprops_table(\n",
    "#         label_image,\n",
    "#         intensity_image,\n",
    "#         properties=(\n",
    "#             \"label\",\n",
    "#             \"intensity_mean\",\n",
    "#         ),\n",
    "#     )\n",
    "# ).set_index(\"label\")\n",
    "def measure_crop(intensity_image):\n",
    "    centerline = intensity_image[:, intensity_image.shape[1] // 2]\n",
    "    return pd.Series(\n",
    "        {\n",
    "            # \"p1\": np.percentile(intensity_image, 1),\n",
    "            # \"p50\": np.median(intensity_image),\n",
    "            \"p90\": np.percentile(intensity_image, 90),\n",
    "            # \"p99\": np.percentile(intensity_image, 99),\n",
    "            # \"mean\": np.mean(intensity_image),\n",
    "            # \"centerline_mean\": np.mean(centerline),\n",
    "            # \"centerline_median\": np.median(centerline),\n",
    "        },\n",
    "        name=\"value\",\n",
    "    ).rename_axis(index=\"observable\")\n",
    "\n",
    "\n",
    "def measure_mask_crops(label_images):\n",
    "    return {k: measure_mask_crop(v) for k, v in label_images.items()}\n",
    "\n",
    "\n",
    "def measure_mask_crop(label_image):\n",
    "    return pd.DataFrame(\n",
    "        skimage.measure.regionprops_table(\n",
    "            label_image,\n",
    "            properties=(\n",
    "                \"label\",\n",
    "                \"area\",\n",
    "                \"axis_major_length\",\n",
    "                \"axis_minor_length\",\n",
    "                \"orientation\",\n",
    "                \"centroid\",\n",
    "            ),\n",
    "        )\n",
    "    ).set_index(\"label\")\n",
    "\n",
    "\n",
    "def write_parquet(output_dir, measurements, position, t):\n",
    "    df = pd.concat(\n",
    "        {\n",
    "            channel: pd.concat(channel_df, names=[\"roi_idx\"])\n",
    "            for channel, channel_df in measurements.items()\n",
    "        },\n",
    "        names=[\"channel\"],\n",
    "    ).reset_index()\n",
    "    df[\"position\"] = np.array(position).astype(np.uint16)\n",
    "    df[\"t\"] = np.array(t).astype(np.uint16)\n",
    "    pq.write_to_dataset(\n",
    "        pa.Table.from_pandas(df, preserve_index=False),\n",
    "        Path(output_dir) / \"measurements\",\n",
    "        partition_cols=[\"position\", \"t\"],\n",
    "        existing_data_behavior=\"delete_matching\",\n",
    "    )\n",
    "\n",
    "\n",
    "def stack_dict(d, size=None, cval=0):\n",
    "    if size is None:\n",
    "        size = max(d.keys()) + 1\n",
    "    shape = next(iter(d.values())).shape\n",
    "    null = np.full(shape, cval)\n",
    "    return [d.get(idx, null) for idx in range(size)]\n",
    "\n",
    "\n",
    "def _pad(ary, shape, cval=0):\n",
    "    return np.pad(\n",
    "        ary,\n",
    "        [(0, max(goal - current, 0)) for goal, current in zip(shape, ary.shape)],\n",
    "        constant_values=cval,\n",
    "    )\n",
    "\n",
    "\n",
    "def write_zarr(filename, crops, t, max_t, channels, cval=0, dtype=np.uint16):\n",
    "    store = zarr.DirectoryStore(filename)  # DirectoryStoreV3(filename)\n",
    "    if not filename.exists():\n",
    "        num_rois = max(crops[channels[0]].keys()) + 1\n",
    "        num_channels = len(channels)\n",
    "        max_shape = np.max([crop.shape for crop in crops[channels[0]].values()], axis=0)\n",
    "        shape = (num_rois, max_t, num_channels, *max_shape)\n",
    "        # chunks = (5, 1, num_channels, None, None)\n",
    "        chunks = (20, 1, num_channels, None, None)\n",
    "        ary = zarr.open_array(\n",
    "            store,\n",
    "            mode=\"a\",\n",
    "            zarr_version=2,\n",
    "            shape=shape,\n",
    "            chunks=chunks,\n",
    "            fill_value=cval,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "    else:\n",
    "        ary = zarr.open_array(store, mode=\"a\", zarr_version=2)\n",
    "        max_shape = ary.shape[-2:]\n",
    "    stack = np.array(\n",
    "        [\n",
    "            stack_dict(\n",
    "                {\n",
    "                    idx: _pad(crop.astype(dtype), max_shape)\n",
    "                    for idx, crop in crops[channel].items()\n",
    "                },\n",
    "                size=ary.shape[0],\n",
    "            )\n",
    "            for channel in channels\n",
    "        ]\n",
    "    ).swapaxes(0, 1)\n",
    "    ary[:, t, ...] = stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = Path(filename).parent / \"for_ranit_3fovs_uint16_v2\"\n",
    "# output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #segmentation_channels = [\"RFP-PENTA\"]\n",
    "# segmentation_channels = [\"RFP-EM\", \"GFP-EM\", \"YFP-EM\", \"CFP-EM\"]\n",
    "# trench_detection_channels = segmentation_channels # channel for trench detection, almost always same as segmentation_channel\n",
    "# # measure_channels = [\"RFP-PENTA\", \"YFP-DUAL\"]\n",
    "# measure_channels = [\"Phase-Fluor\", \"RFP-EM\", \"GFP-EM\", \"YFP-EM\", \"CFP-EM\"]\n",
    "# fish_channels = [\"RFP-PENTA\", \"Cy5-PENTA\", \"Cy7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channels = [\"RFP-EM\"]\n",
    "# measurement_channels = [\"CFP-EM\", \"YFP-EM\", \"RFP-EM\"]\n",
    "measurement_channels = []\n",
    "crop_channels = nd2.metadata[\"channels\"]\n",
    "# channel_colors = [colors[channel] for channel in measurement_channels]\n",
    "width_to_pitch_ratio = 1.4 / 3.5  # for debugging: 2.2 / 3.5\n",
    "k1 = 8.5e-10\n",
    "center_y = -800\n",
    "center_x = 0\n",
    "center = image.center_from_shape((nd2.sizes[\"y\"], nd2.sizes[\"x\"])) - np.array(\n",
    "    [center_x, center_y]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_func(\n",
    "    filename, position, channel, t, k1=k1, center=center, dark=None, flat=None\n",
    "):\n",
    "    return image.correct_radial_distortion(\n",
    "        np.asarray(\n",
    "            workflow.get_nd2_frame(\n",
    "                filename, position=position, channel=channel, t=t, dark=dark, flat=flat\n",
    "            )\n",
    "        ),\n",
    "        k1=k1,\n",
    "        input_center=center,\n",
    "    ).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img0 = get_frame_func(filename, 11, segmentation_channels[0], 0)\n",
    "# TODO: replace with calculation that doesn't require processing an image\n",
    "image_limits = geometry.get_image_limits(img0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img0, scale=0.99, downsample=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"Phase-Fluor\", \"RFP-EM\", \"GFP-EM\", \"YFP-EM\", \"CFP-EM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(get_frame_func(filename, 11, \"GFP-EM\", 0), scale=0.99, downsample=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(get_frame_func(filename, 11, \"YFP-EM\", 0), scale=0.99, downsample=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(get_frame_func(filename, 11, \"CFP-EM\", 20), scale=0.99, downsample=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imgs = [\n",
    "    get_frame_func(filename, 50, channel, 0)\n",
    "    for channel in tqdm(nd2.metadata[\"channels\"][1:])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def combine_channels_for_segmentation(imgs, same_dtype=True):\n",
    "    dtype = imgs[0].dtype\n",
    "    imgs = [\n",
    "        imgs[0],\n",
    "        *(skimage.exposure.match_histograms(img, imgs[0]) for img in imgs[1:]),\n",
    "    ]\n",
    "    combined = np.sum(np.stack(imgs) / len(imgs), axis=0)\n",
    "    if same_dtype:\n",
    "        combined = combined.astype(dtype)\n",
    "    return combined\n",
    "\n",
    "\n",
    "combined = combine_channels_for_segmentation(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(combined, scale=0.99, downsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "rois, info = trench_detection.find_trenches(\n",
    "    img0,\n",
    "    width_to_pitch_ratio=width_to_pitch_ratio,\n",
    "    join_info=False,\n",
    "    diagnostics=diag,\n",
    "    # pitch=16.173741362290226\n",
    ")\n",
    "angle = info[\"angle\"]\n",
    "pitch = info[\"pitch\"]\n",
    "(angle, pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"set_finding\"][\"image_with_lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fov(\n",
    "    get_frame_func,\n",
    "    position,\n",
    "    ts,\n",
    "    output_dir,\n",
    "    segmentation_channels,\n",
    "    measurement_channels,\n",
    "    crop_channels,\n",
    "    image_limits,\n",
    "    write_full_frames=True,\n",
    "    find_trenches_kwargs={},\n",
    "    dark=None,\n",
    "    flats=None,\n",
    "    delayed=True,\n",
    "):\n",
    "    delayed = util.get_delayed(delayed)\n",
    "    channels = [\n",
    "        segmentation_channels[0],\n",
    "        *(\n",
    "            set(measurement_channels).union(crop_channels)\n",
    "            - set([segmentation_channels[0]])\n",
    "        ),\n",
    "    ]\n",
    "    measurement_channels = measurement_channels\n",
    "    rois = None\n",
    "    shifts = {}\n",
    "    write_tasks = []\n",
    "    for prev_t, t in tqdm(list(zip(it.chain([None], ts[:-1]), ts))):\n",
    "        segmentation_img = delayed(get_frame_func)(\n",
    "            position, segmentation_channels[0], t\n",
    "        )\n",
    "        full_frames = {segmentation_channels[0]: segmentation_img}\n",
    "        if rois is None:\n",
    "            rois = delayed(trench_detection.find_trenches)(\n",
    "                segmentation_img, **{**dict(join_info=True), **find_trenches_kwargs}\n",
    "            )\n",
    "            shifts[t] = np.array([0, 0])\n",
    "            initial_drift_features = delayed(drift.get_drift_features)(\n",
    "                segmentation_img, rois, shifts[t]\n",
    "            )\n",
    "        else:\n",
    "            shifts[t] = delayed(drift.find_feature_drift)(\n",
    "                initial_drift_features,\n",
    "                segmentation_img,\n",
    "                rois,\n",
    "                initial_shift2=shifts[prev_t],\n",
    "            )\n",
    "        shifted_rois = delayed(geometry.filter_rois)(\n",
    "            delayed(geometry.shift_rois)(rois, shifts[t]), image_limits\n",
    "        )\n",
    "        crops = {}\n",
    "        measurements = {}\n",
    "        for channel in channels:\n",
    "            if channel == segmentation_channels[0]:\n",
    "                crops[channel] = delayed(crop_rois)(segmentation_img, shifted_rois)\n",
    "                # mask_crops = delayed(segment_crops)(crops[channel])\n",
    "                # mask_measurements = delayed(measure_mask_crops)(mask_crops)\n",
    "            else:\n",
    "                img = delayed(get_frame_func)(position, channel, t)\n",
    "                full_frames[channel] = img\n",
    "                crops[channel] = delayed(crop_rois)(img, shifted_rois)\n",
    "            if channel in measurement_channels:\n",
    "                # measurements[channel] = delayed(measure_crops)(mask_crops, crops[channel])\n",
    "                measurements[channel] = delayed(measure_crops)(crops[channel])\n",
    "        metadata = dict(shifts=shifts)\n",
    "        if measurements:\n",
    "            write_tasks.append(\n",
    "                delayed(write_parquet)(output_dir, measurements, position, t)\n",
    "            )\n",
    "        crops_to_write = {\n",
    "            channel: channel_crops\n",
    "            for channel, channel_crops in crops.items()\n",
    "            if channel in crop_channels\n",
    "        }\n",
    "        write_tasks.append(\n",
    "            delayed(write_zarr)(\n",
    "                output_dir / f\"crops_v={position}.zarr\",\n",
    "                crops_to_write,\n",
    "                t,\n",
    "                max_t,\n",
    "                crop_channels,\n",
    "            )\n",
    "        )\n",
    "        full_frames_to_write = {\n",
    "            channel: {0: frame} for channel, frame in full_frames.items()\n",
    "        }\n",
    "        write_tasks.append(\n",
    "            delayed(write_zarr)(\n",
    "                output_dir / f\"full_frames_v={position}.zarr\",\n",
    "                full_frames_to_write,\n",
    "                t,\n",
    "                max_t,\n",
    "                crop_channels,\n",
    "            )\n",
    "        )\n",
    "        # TODO: rois, metadata\n",
    "    return write_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%pyinstrument\n",
    "ts = np.arange(max_t)\n",
    "# ts = np.arange(2)\n",
    "res = []\n",
    "for position in trange(11, 14):\n",
    "    res.append(\n",
    "        process_fov(\n",
    "            partial(get_frame_func, filename),\n",
    "            position,\n",
    "            ts,\n",
    "            output_dir,\n",
    "            segmentation_channels,\n",
    "            measurement_channels,\n",
    "            crop_channels,\n",
    "            image_limits,\n",
    "            find_trenches_kwargs=dict(\n",
    "                angle=angle, pitch=pitch, width_to_pitch_ratio=width_to_pitch_ratio\n",
    "            ),\n",
    "            delayed=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures = [client.compute(x) for x in tqdm(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "del futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "errored = [e for fov in futures if (e := [f for f in fov if f.status == \"error\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "# Trench detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_channel = \"RFP-EM\"\n",
    "# measurement_channels = [\"CFP-EM\", \"YFP-EM\", \"RFP-EM\"]\n",
    "measurement_channels = []\n",
    "crop_channels = nd2.metadata[\"channels\"]\n",
    "# channel_colors = [colors[channel] for channel in measurement_channels]\n",
    "width_to_pitch_ratio = 1.4 / 3.5\n",
    "k1 = 8.5e-10\n",
    "center_y = -800\n",
    "center_x = 0\n",
    "center = image.center_from_shape((nd2.sizes[\"y\"], nd2.sizes[\"x\"])) - np.array(\n",
    "    [center_x, center_y]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_frame(img, k1=k1, center=center, dark=None, flat=None):\n",
    "    return image.correct_radial_distortion(\n",
    "        img,\n",
    "        k1=k1,\n",
    "        input_center=center,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_frame_func(\n",
    "    filename, position, channel, t, k1=k1, center=center, dark=None, flat=None\n",
    "):\n",
    "    return correct_frame(\n",
    "        np.asarray(\n",
    "            workflow.get_nd2_frame(\n",
    "                filename, position=position, channel=channel, t=t, dark=dark, flat=flat\n",
    "            )\n",
    "        ),\n",
    "        k1=k1,\n",
    "        center=center,\n",
    "        dark=dark,\n",
    "        flat=flat,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img0 = get_frame_func(filename, 11, segmentation_channel, 0)\n",
    "# TODO: replace with calculation that doesn't require processing an image\n",
    "image_limits = geometry.get_image_limits(img0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "rois, info = trench_detection.find_trenches(\n",
    "    img0,\n",
    "    width_to_pitch_ratio=width_to_pitch_ratio,\n",
    "    join_info=False,\n",
    "    diagnostics=diag,\n",
    "    # pitch=16.173741362290226\n",
    ")\n",
    "angle = info[\"angle\"]\n",
    "pitch = info[\"pitch\"]\n",
    "(angle, pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"set_finding\"][\"image_with_lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"binarize_trench_image\"][\"normalized_image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## Multicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imgs = [get_frame_func(filename, 11, ch, 10) for ch in segmentation_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_composite = np.sum([img / img.max() for img in imgs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = img_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(img_composite, scale=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img = get_frame_func(filename, 11, segmentation_channel, 0, k1=0, center=None)\n",
    "img_corr = get_frame_func(filename, 11, segmentation_channel, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag = util.tree()\n",
    "rois, info = trench_detection.find_trenches(\n",
    "    img,\n",
    "    width_to_pitch_ratio=width_to_pitch_ratio,\n",
    "    join_info=False,\n",
    "    diagnostics=diag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"labeling\"][\"set_finding\"][\"image_with_lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "diag_corr = util.tree()\n",
    "rois_corr, info_corr = trench_detection.find_trenches(\n",
    "    img_corr,\n",
    "    width_to_pitch_ratio=width_to_pitch_ratio,\n",
    "    join_info=False,\n",
    "    diagnostics=diag_corr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag_corr[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag_corr[\"labeling\"][\"set_finding\"][\"image_with_lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag_corr[\"labeling\"][\"set_finding\"][\"reduced_profile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = diag_corr[\"labeling\"][\"set_finding\"][\"reduced_profile\"].Curve.I.data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from paulssonlab.image_analysis.misc.holoborodko_diff import holo_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xd = holo_diff(1, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = np.nanpercentile(x, 99.9) * 0.1\n",
    "plt.plot(x)\n",
    "plt.axhline(threshold);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trim_nans(x):\n",
    "    return x[np.argmax(~np.isnan(x)) : len(x) - np.argmax(~np.isnan(x)[::-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xt = trim_nans(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xdt = trim_nans(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa import stattools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "axt = stattools.acf(xt, nlags=1000)\n",
    "plt.plot(axt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "axdt = stattools.acf(xdt, nlags=1000)\n",
    "plt.plot(axdt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(axdt[10:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(x)\n",
    "plt.plot(x[600:])\n",
    "plt.plot(x[1200:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array_split(xt, 600)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.split(xt, np.arange(0, len(xt), 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in np.split(xt, np.arange(0, len(xt), 600)):\n",
    "    plt.plot(split);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(xdt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peaks, props = scipy.signal.find_peaks(xd, distance=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.nanmax(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peaks, props = scipy.signal.find_peaks(xd, prominence=np.nanmax(xd) / 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(xd)\n",
    "for peak in peaks:\n",
    "    plt.axvline(peak, color=\"r\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peaks[1:] - peaks[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag_corr[\"bboxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rois_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 300\n",
    "top = np.asarray(rois_corr.loc[idx, [\"top_x\", \"top_y\"]])  # [::-1]\n",
    "bottom = np.asarray(rois_corr.loc[idx, [\"bottom_x\", \"bottom_y\"]])  # [::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = trench_detection.profile.profile_line(\n",
    "    img_corr, src=top, dst=bottom, linewidth=20, cval=0, order=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(res);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
