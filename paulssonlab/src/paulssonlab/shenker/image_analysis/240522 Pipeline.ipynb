{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools as it\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import distributed\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import nd2\n",
    "import nd2reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import scipy.signal\n",
    "import skimage.measure\n",
    "import zarr\n",
    "from dask import delayed\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from holoviews.operation.datashader import regrid\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "IDX = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import paulssonlab.image_analysis.mosaic as mosaic\n",
    "import paulssonlab.image_analysis.delayed as delayed\n",
    "import paulssonlab.image_analysis.drift as drift\n",
    "import paulssonlab.image_analysis.geometry as geometry\n",
    "import paulssonlab.image_analysis.image as image\n",
    "import paulssonlab.image_analysis.pipeline as pipeline\n",
    "import paulssonlab.image_analysis.readers as readers\n",
    "import paulssonlab.image_analysis.segmentation.watershed as watershed\n",
    "import paulssonlab.image_analysis.trench_detection as trench_detection\n",
    "import paulssonlab.image_analysis.util as util\n",
    "import paulssonlab.image_analysis.workflow as workflow\n",
    "from paulssonlab.image_analysis.ui import RevImage, display_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")\n",
    "# hv.extension(\"matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd2_filename = \"/home/jqs1/scratch/microscopy/230915/230915_RBS_repressors.nd2\"\n",
    "nd2_filename = workflow.SplitFilename(\n",
    "    sorted(\n",
    "        glob.glob(\n",
    "            # \"/home/jqs1/scratch/jqs1/microscopy/230619/230619_NAO745_repressilators_split.nd2*\"\n",
    "            # \"/home/jqs1/scratch/jqs1/microscopy/230707/230707_repressilators_restart.nd2.split.a*\"\n",
    "            \"/home/jqs1/scratch/microscopy/230830/230830_repressilators.nd2.split.*\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "assert nd2_filename.files\n",
    "# nd2_filename = \"/home/jqs1/scratch/jqs1/microscopy/231101/231101_FP_calibration.nd2\"\n",
    "fish_filename = Path(nd2_filename).parent / \"FISH/real_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(nd2_filename).parent / \"test\"\n",
    "# output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2 = workflow.get_nd2_reader(nd2_filename)\n",
    "t_max = nd2.sizes[\"t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2.metadata[\"channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    # \"CFP-EM\": \"#6fb2e4\",\n",
    "    # \"YFP-EM\": \"#eee461\",\n",
    "    # \"RFP-EM\": \"#c66526\",\n",
    "    \"CFP-EM\": \"#648FFF\",\n",
    "    \"YFP-EM\": \"#FFB000\",\n",
    "    \"RFP-EM\": \"#DC267F\",\n",
    "}\n",
    "\n",
    "fish_colors = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"GFP\": \"#f44336\",\n",
    "    \"Cy5\": \"#03a9f4\",\n",
    "    # \"Cy7\": \"#ffeb3b\"\n",
    "    \"Cy7\": \"#8bc34a\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"02:00:00\",\n",
    "    memory=\"16GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(maximum=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k1 = 1e-9\n",
    "# center = image.center_from_shape(nd2.get_frame_2D().shape) - np.array([0, -500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_frame_func(\n",
    "#     filename, position, channel, t, k1=None, center=None, dark=None, flat=None\n",
    "# ):\n",
    "#     img = np.asarray(\n",
    "#         workflow.get_nd2_frame(\n",
    "#             filename, position=position, channel=channel, t=t, dark=dark, flat=flat\n",
    "#         )\n",
    "#     )\n",
    "#     if k1 is not None:\n",
    "#         img = image.correct_radial_distortion(img, k1=k1, center=center)\n",
    "#     # TODO\n",
    "#     img = img[:, 300 : img.shape[1] - 300]\n",
    "#     return img\n",
    "\n",
    "\n",
    "def preprocess_func(\n",
    "    img, filename, position, channel, t, k1=None, center=None, dark=None, flat=None\n",
    "):\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # \"composite_func\": image.mean_composite,\n",
    "    # \"roi_detection_func\": trench_detection.find_trenches,\n",
    "    # \"track_drift\": True,\n",
    "    # \"segmentation_func\": watershed.watershed_segment,\n",
    "    \"segmentation_channels\": [\"RFP-EM\", \"YFP-EM\", \"CFP-EM\"],\n",
    "    \"trench_detection_channels\": None,  # channel for trench detection, almost always same as segmentation_channel\n",
    "    # \"measure_channels\": = [\"RFP-PENTA\", \"YFP-DUAL\"],\n",
    "    \"crop_channels\": [\"Phase-Fluor\", \"RFP-EM\", \"GFP-EM\", \"YFP-EM\", \"CFP-EM\"],\n",
    "    \"measure_channels\": [\"RFP-EM\", \"GFP-EM\", \"YFP-EM\", \"CFP-EM\"],\n",
    "    # \"fish_probes\": hhh,\n",
    "    \"roi_detection_kwargs\": {\"width_to_pitch_ratio\": 1.4 / 3.5},\n",
    "    # \"preprocess_func\": preprocess_func,\n",
    "    # \"preprocessing_kwargs\": {\"k1\": k1, \"center\": center},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "p._queue._items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed = False\n",
    "\n",
    "p = pipeline.DefaultPipeline(output_dir, config=config, delayed=delayed)\n",
    "\n",
    "for msg in readers.send_nd2(\n",
    "    nd2_filename,\n",
    "    slices=dict(t=[0], v=[8]),\n",
    "    delayed=delayed,\n",
    "):\n",
    "    p.handle_message(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.raw_frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.processed_frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.rois.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.rois[(8, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# diag = util.tree()\n",
    "diag = None\n",
    "img = p.rois[(8, \"RFP-EM\", 0)]\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    img,\n",
    "    # angle=np.deg2rad(0.001),\n",
    "    join_info=False,\n",
    "    width=12,\n",
    "    # width_to_line_width_ratio=2,\n",
    "    # width_to_pitch_ratio=None,\n",
    "    # peak_func=trench_detection.peaks.find_peaks,\n",
    "    diagnostics=diag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.raw_frames[(8, \"RFP-EM\", 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.measurements.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in readers.send_eaton_fish(\n",
    "    fish_filename,\n",
    "    slices=dict(t=None, v=[8]),\n",
    "    delayed=True,\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%pyinstrument\n",
    "ts = np.arange(t_max)\n",
    "# ts = np.arange(2)\n",
    "res = []\n",
    "for position in trange(13, 40):\n",
    "    res.append(\n",
    "        process_fov(\n",
    "            partial(get_frame_func, filename),\n",
    "            position,\n",
    "            ts,\n",
    "            output_dir / \"central_crop2\",\n",
    "            segmentation_channel,\n",
    "            measurement_channels,\n",
    "            image_limits,\n",
    "            find_trenches_kwargs=dict(\n",
    "                angle=angle, pitch=pitch, width_to_pitch_ratio=2.2 / 3.5\n",
    "            ),\n",
    "            delayed=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures = [client.compute(x) for x in tqdm(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "del futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "[fov for fov in futures if any(f.status == \"error\" for f in fov)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "errored = [e for fov in futures if (e := [f for f in fov if f.status == \"error\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_axes(ary, mask):\n",
    "    for i in range(ary.ndim):\n",
    "        axis_mask = np.any(mask, axis=tuple([j for j in range(mask.ndim) if j != i]))\n",
    "        ary = ary[(*[slice(None)] * i, axis_mask)]\n",
    "    return ary\n",
    "\n",
    "\n",
    "# def norm(x, quantile=0.9, min_quantile=0.1, mask_value=None):\n",
    "#     if mask_value is not None:\n",
    "#         x = x[x != mask_value]\n",
    "#     x = x - np.nanquantile(x, min_quantile)\n",
    "#     if quantile is None or quantile == 0:\n",
    "#         return x\n",
    "#     elif quantile == 1:\n",
    "#         return x / np.nanmax(x)\n",
    "#     else:\n",
    "#         if hasattr(x, \"quantile\"):\n",
    "#             return x / x.quantile(quantile)\n",
    "#         else:\n",
    "#             return x / np.nanquantile(x, quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.dataset(\n",
    "    output_dir / \"central_crop2/measurements\", format=\"parquet\", partitioning=\"hive\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = dataset.to_table(filter=ds.field(\"position\") == 14).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "# Manual FISH trench crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nd2.get_frame_2D(v=8, c=0, t=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 8.947368421052635e-10\n",
    "img_t = image.correct_radial_distortion(img, k1=k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# diag = util.tree()\n",
    "diag = None\n",
    "trenches, info = trench_detection.find_trenches(\n",
    "    img_t,\n",
    "    # angle=np.deg2rad(0.001),\n",
    "    join_info=False,\n",
    "    width=12,\n",
    "    # width_to_line_width_ratio=2,\n",
    "    # width_to_pitch_ratio=None,\n",
    "    # peak_func=trench_detection.peaks.find_peaks,\n",
    "    diagnostics=diag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_trenches(img, trenches):\n",
    "    crops = {}\n",
    "    # for i, crop in it.islice(geometry.iter_crops(img, trenches), 10, 13):\n",
    "    for i, crop in geometry.iter_roi_crops(img, trenches):\n",
    "        crops[i] = crop\n",
    "    return crops\n",
    "\n",
    "\n",
    "def stack_crops(crops, channels, timepoints):\n",
    "    stacks = {}\n",
    "    for (t, channel), frame_crops in crops.items():\n",
    "        channel_idx = channels.index(channel)\n",
    "        timepoint_idx = timepoints.index(t)\n",
    "        for trench_idx, trench_slice in frame_crops.items():\n",
    "            if trench_idx not in stacks:\n",
    "                stacks[trench_idx] = zarr.create(\n",
    "                    (len(channels), len(timepoints), *trench_slice.shape),\n",
    "                    dtype=trench_slice.dtype,\n",
    "                    fill_value=np.nan,\n",
    "                )\n",
    "            stacks[trench_idx][channel_idx, timepoint_idx, :, :] = trench_slice\n",
    "    return stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calibrate_image(img, k1=0):\n",
    "    img = skimage.img_as_float32(img)\n",
    "    img = image.correct_radial_distortion(img, k1=k1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "?readers.send_eaton_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed = util.get_delayed(True)\n",
    "fish_frames = {}\n",
    "fish_crops = {}\n",
    "fish_channels = set()\n",
    "fish_timepoints = set()\n",
    "for msg in readers.send_eaton_fish(\n",
    "    fish_filename,\n",
    "    slices=dict(t=None, v=[8]),\n",
    "    delayed=delayed,\n",
    "):\n",
    "    # print(msg[\"metadata\"],msg[\"image\"].shape)\n",
    "    fish_img = msg[\"image\"]\n",
    "    fish_img_corrected = delayed(calibrate_image)(fish_img, k1=k1)\n",
    "    fov = msg[\"metadata\"][\"fov_num\"]\n",
    "    t = msg[\"metadata\"][\"t\"]\n",
    "    channel = msg[\"metadata\"][\"channel\"]\n",
    "    fish_channels.add(channel)\n",
    "    fish_timepoints.add(t)\n",
    "    fish_frames[(t, channel)] = fish_img_corrected\n",
    "    fish_crops[(t, channel)] = delayed(crop_trenches)(fish_img_corrected, trenches)\n",
    "fish_channels = list(sorted(fish_channels))\n",
    "fish_channel_colors = [fish_colors[ch] for ch in fish_channels]\n",
    "fish_timepoints = list(sorted(fish_timepoints))\n",
    "fish_stacks = delayed(stack_crops)(fish_crops, fish_channels, fish_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_frames0, fish_stacks0 = dask.compute(fish_frames, fish_stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_stacks0[10].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in new.readers.send_nd2(\n",
    "    filename,\n",
    "    slices=dict(v=slice(1), t=slice(1)),\n",
    "):\n",
    "    handle_message(pipeline, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = fish_stacks0[13][1:, :9]\n",
    "# x = x - x.min(axis=1)[:,np.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mean(ary):\n",
    "    ary = ary - ary.min(axis=1)[:, np.newaxis, :, :]\n",
    "    # lmbda = (ary.max(axis=1) - ary.min(axis=1))[:,np.newaxis,:,:]\n",
    "    lmbda = ary.max(axis=1)[:, np.newaxis, :, :]\n",
    "    w = (\n",
    "        1\n",
    "        / 3\n",
    "        * (lmbda / lmbda.sum(axis=(2, 3))[:, :, np.newaxis, np.newaxis]).sum(axis=0)[\n",
    "            np.newaxis, :, :, :\n",
    "        ]\n",
    "    )\n",
    "    if w.sum() == 0:\n",
    "        return None\n",
    "    return np.average(ary, axis=(2, 3), weights=np.broadcast_to(w, ary.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics = {\n",
    "    idx: weighted_mean(np.asarray(stack[1:, ...]))\n",
    "    for idx, stack in tqdm(fish_stacks0.items())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(1 for x in fish_metrics.values() if x is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bit_names = [(ch, str(t)) for ch in fish_channels[1:] for t in fish_timepoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        trench_idx: ary.flatten()\n",
    "        for trench_idx, ary in fish_metrics.items()\n",
    "        if ary is not None\n",
    "    },\n",
    "    columns=pd.MultiIndex.from_tuples(bit_names, names=[\"channel\", \"timepoint\"]),\n",
    "    orient=\"index\",\n",
    ").rename_axis(index=\"trench_idx\")\n",
    "fish_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2 = fish_metrics_df.melt(ignore_index=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_thresholds = {\"GFP\": 0.007, \"Cy5\": 0.005, \"Cy7\": 0.002}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2[\"ground_truth\"] = fish_metrics_df2[\"value\"] > fish_metrics_df2[\n",
    "    \"channel\"\n",
    "].map(fish_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(fish_metrics_df2.groupby(\"trench_idx\").sum(\"ground_truth\") == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2.groupby(\"channel\").apply(lambda x: x[\"ground_truth\"].sum() / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(fish_metrics_df2.groupby(\"channel\").sum(\"ground_truth\") == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 200\n",
    "# idx = 3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = fish_stacks0[idx][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df2[fish_metrics_df2[\"trench_idx\"] == idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(image.unstack_multichannel(x), scale=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = x - x.min(axis=1)[:, np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_image(image.unstack_multichannel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(weighted_mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Violin(fish_metrics_df2, [\"channel\", \"timepoint\"], \"value\").opts(\n",
    "    hv.opts(\n",
    "        width=700,\n",
    "        show_legend=True,\n",
    "        violin_color=hv.dim(\"channel\").str(),\n",
    "        inner=None,\n",
    "        # violin_width=1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.Violin(fish_metrics_df2, [\"channel\", \"timepoint\", \"ground_truth\"], \"value\").opts(\n",
    "    hv.opts(\n",
    "        width=700,\n",
    "        show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        split=hv.dim(\"ground_truth\"),\n",
    "        violin_width=3,\n",
    "        inner=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = hv.Dataset(fish_metrics_df2, [\"channel\", \"timepoint\", \"ground_truth\"], \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.to(hv.Violin, [\"timepoint\", \"ground_truth\"]).layout(\"channel\").opts(\n",
    "    hv.opts.Violin(\n",
    "        width=700,\n",
    "        # show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        split=hv.dim(\"ground_truth\"),\n",
    "        violin_width=3,\n",
    "        inner=None,\n",
    "        axiswise=True,\n",
    "    )\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = ds.to(hv.Violin, [\"timepoint\"]).overlay(\"ground_truth\").layout(\"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_stacked_violins = (\n",
    "    ds.to(hv.Violin, [\"timepoint\"]).overlay(\"ground_truth\").layout(\"channel\")\n",
    ")\n",
    "\n",
    "hv.Layout([v.redim(value=k) for k, v in _stacked_violins.items()]).opts(\n",
    "    hv.opts.Violin(\n",
    "        width=700,\n",
    "        # show_legend=True,\n",
    "        # violin_color=hv.dim(\"channel\").str(),\n",
    "        # violin_width=3,\n",
    "        inner=None,\n",
    "        bandwidth=0.2,\n",
    "        cut=0.05,\n",
    "    )\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fish_metrics_df2.groupby(\"channel\").apply(lambda x: hv.Violin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): hv.Distribution(df, \"value\").redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ")  # .opts(hv.opts.Distribution(logy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): hv.Dataset(df, [\"ground_truth\"], \"value\").to(\n",
    "            hv.Distribution\n",
    "        )\n",
    "        # .overlay(\"ground_truth\")\n",
    "        # hv.Distribution(df, \"value\").redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ")  # .opts(hv.opts.Distribution(show_legend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hv.GridSpace(\n",
    "    {\n",
    "        (timepoint, channel): (\n",
    "            hv.Distribution(df[df[\"ground_truth\"]], \"value\", label=\"On\")\n",
    "            * hv.Distribution(df[~df[\"ground_truth\"]], \"value\", label=\"Off\")\n",
    "        ).redim(value=channel)\n",
    "        for (timepoint, channel), df in fish_metrics_df2.groupby(\n",
    "            [\"timepoint\", \"channel\"]\n",
    "        )\n",
    "    },\n",
    "    kdims=[\"timepoint\", \"channel\"],\n",
    ").opts(hv.opts.Distribution(show_legend=True, bandwidth=0.3, cut=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.sampledata.iris import flowers\n",
    "from holoviews.operation import gridmatrix\n",
    "\n",
    "iris_ds = hv.Dataset(flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df3 = fish_metrics_df.set_axis(\n",
    "    [\"_\".join(c) for c in fish_metrics_df.columns], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fish_metrics_df3 = fish_metrics_df3.loc[\n",
    "    :, [*fish_metrics_df3.columns[3:6], *fish_metrics_df3.columns[13:16]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "density_grid = gridmatrix(\n",
    "    hv.Dataset(fish_metrics_df3), diagonal_type=hv.Distribution, chart_type=hv.Bivariate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "density_grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
