{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import holoviews as hv\n",
    "import datashader as ds\n",
    "from holoviews.operation.datashader import (\n",
    "    aggregate,\n",
    "    datashade,\n",
    "    dynspread,\n",
    "    shade,\n",
    "    regrid,\n",
    ")\n",
    "from holoviews.operation import decimate\n",
    "from holoviews.streams import Stream, param\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hex2color\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import skimage\n",
    "import skimage.morphology\n",
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# from sklearn import metrics\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import peakutils\n",
    "import scipy.stats\n",
    "import scipy.interpolate\n",
    "from holoborodko_diff import holo_diff\n",
    "import functools\n",
    "import operator\n",
    "from functools import partial, reduce\n",
    "import itertools\n",
    "from itertools import zip_longest\n",
    "from more_itertools import rstrip\n",
    "from collections import Counter, defaultdict\n",
    "from bokeh.models import WheelZoomTool\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "\n",
    "# from bokeh.layouts import row\n",
    "# from bokeh.plotting import figure\n",
    "import tqdm\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "hv.notebook_extension(\"bokeh\")\n",
    "renderer = hv.renderer(\"bokeh\")\n",
    "%matplotlib inline\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# store = zarr.DirectoryStore('/home/jqs1/scratch/fidelity/171018/171018.zarr')\n",
    "store = zarr.DirectoryStore(\n",
    "    \"/home/jqs1/scratch/fidelity/171214/transcriptionerror_timelapse.zarr\"\n",
    ")\n",
    "root_group = zarr.open_group(store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "channel_to_color = {\n",
    "    \"BF\": \"#ffffff\",\n",
    "    \"MCHERRY\": \"#e22400\",\n",
    "    \"GFP\": \"#76ba40\",\n",
    "    \"CY5\": \"#e292fe\",\n",
    "    \"BFP\": \"#3a87fd\",\n",
    "    \"YFP\": \"#f5eb00\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trench_points = get_image_series_trenches(frame_series, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sharpness = np.array(\n",
    "    [image_sharpness(frame_series[i]) for i in range(frame_series.shape[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image viewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(xs, mask):\n",
    "    if len(xs) != len(mask):\n",
    "        raise ValueError(\"mask length does not match\")\n",
    "    return [xs[i] for i in range(len(xs)) if mask[i]]\n",
    "\n",
    "\n",
    "def composite_channels(imgs, hexcolors, scale=True):\n",
    "    colors = [hex2color(hexcolor) for hexcolor in hexcolors]\n",
    "    return _composite_channels(imgs, colors, scale=scale)\n",
    "\n",
    "\n",
    "def _composite_channels(channel_imgs, colors, scale=True):\n",
    "    if len(channel_imgs) != len(colors):\n",
    "        raise ValueError(\"expecting equal numbers of channels and colors\")\n",
    "    num_channels = len(channel_imgs)\n",
    "    if scale:\n",
    "        scaled_imgs = [\n",
    "            channel_imgs[i][:, :, np.newaxis] / np.percentile(channel_imgs[i], 99.9)\n",
    "            for i in range(num_channels)\n",
    "        ]\n",
    "        for scaled_img in scaled_imgs:\n",
    "            np.clip(scaled_img, 0, 1, scaled_img)  # clip in place\n",
    "    else:\n",
    "        scaled_imgs = channel_imgs\n",
    "    imgs_to_combine = [\n",
    "        scaled_imgs[i] * np.array(colors[i]) for i in range(num_channels)\n",
    "    ]\n",
    "    if not len(imgs_to_combine):\n",
    "        imgs_to_combine = [np.ones(colored_imgs[0].shape)]  # white placeholder\n",
    "    img = imgs_to_combine[0]\n",
    "    for img2 in imgs_to_combine[1:]:\n",
    "        img = 1 - (1 - img) * (1 - img2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def multichannel_selector(frames):\n",
    "    channels = frames.attrs[\"metadata\"][\"channels\"]\n",
    "    num_channels = len(channels)\n",
    "    # colors = [hex2color(channel_colors[channel]) for channel in channels]\n",
    "    channel_boxes = []\n",
    "    channel_widgets = []\n",
    "    channel_enabled = [True] * num_channels\n",
    "    channel_colors = [channel_to_color[channel] for channel in channels]\n",
    "    for i, channel in enumerate(channels):\n",
    "        solo_button = widgets.Button(\n",
    "            description=\"S\", layout=widgets.Layout(width=\"10%\")\n",
    "        )\n",
    "        enabled_button = widgets.ToggleButton(\n",
    "            description=channel, value=channel_enabled[i]\n",
    "        )\n",
    "        solo_button._button_to_enable = enabled_button\n",
    "        color_picker = widgets.ColorPicker(concise=True, value=channel_colors[i])\n",
    "        channel_box = widgets.HBox([solo_button, enabled_button, color_picker])\n",
    "        channel_widgets.append([solo_button, enabled_button, color_picker, channel_box])\n",
    "    solo_buttons, enabled_buttons, color_pickers, channel_boxes = zip(*channel_widgets)\n",
    "    channels_box = widgets.VBox(channel_boxes)\n",
    "    DisplaySettings = Stream.define(\n",
    "        \"DisplaySettings\",\n",
    "        channel_enabled=channel_enabled,\n",
    "        channel_colors=channel_colors,\n",
    "    )\n",
    "    display_settings_stream = DisplaySettings()\n",
    "\n",
    "    def update_enabled_channels(change):\n",
    "        channel_enabled = [button.value for button in enabled_buttons]\n",
    "        display_settings_stream.event(channel_enabled=channel_enabled)\n",
    "\n",
    "    def update_solo(solo_button):\n",
    "        if (\n",
    "            solo_button._button_to_enable.value\n",
    "            and sum([b.value for b in enabled_buttons]) == 1\n",
    "        ):\n",
    "            for enabled_button in enabled_buttons:\n",
    "                enabled_button.value = True\n",
    "        else:\n",
    "            for enabled_button in enabled_buttons:\n",
    "                enabled_button.value = enabled_button == solo_button._button_to_enable\n",
    "        # update_enabled_channels(None)\n",
    "\n",
    "    for solo_button in solo_buttons:\n",
    "        solo_button.on_click(update_solo)\n",
    "    for enabled_button in enabled_buttons:\n",
    "        enabled_button.observe(update_enabled_channels, names=\"value\")\n",
    "\n",
    "    def update_channel_colors(change):\n",
    "        channel_colors = [color_picker.value for color_picker in color_pickers]\n",
    "        display_settings_stream.event(channel_colors=channel_colors)\n",
    "\n",
    "    for color_picker in color_pickers:\n",
    "        color_picker.observe(update_channel_colors, names=\"value\")\n",
    "    return channels_box, display_settings_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameStream = Stream.define(\"Frame\", t=0, v=0)\n",
    "\n",
    "\n",
    "def timepoints_browser(frames, frame_stream):\n",
    "    num_timepoints = len(frames.attrs[\"metadata\"][\"frames\"])\n",
    "    # play_buttons = widgets.Play(interval=10, min=0, max=num_timepoints, step=1)\n",
    "    back_step_button = widgets.Button(\n",
    "        description=\"<\", layout=widgets.Layout(width=\"10%\")\n",
    "    )\n",
    "    forward_step_button = widgets.Button(\n",
    "        description=\">\", layout=widgets.Layout(width=\"10%\")\n",
    "    )\n",
    "    t_slider = widgets.IntSlider(\n",
    "        label=\"t\", min=0, max=num_timepoints, step=1, value=0, continuous_update=False\n",
    "    )\n",
    "    slider_box = widgets.HBox([back_step_button, t_slider, forward_step_button])\n",
    "    t_slider.observe(lambda change: frame_stream.event(t=change[\"new\"]), names=\"value\")\n",
    "    return slider_box\n",
    "\n",
    "\n",
    "def frame_browser(frames, frame_stream):\n",
    "    num_timepoints = len(frames.attrs[\"metadata\"][\"frames\"])\n",
    "    num_fovs = len(frames.attrs[\"metadata\"][\"fields_of_view\"])\n",
    "    t_slider = widgets.IntSlider(\n",
    "        label=\"t\", min=0, max=num_timepoints, step=1, value=0, continuous_update=False\n",
    "    )\n",
    "    v_slider = widgets.IntSlider(\n",
    "        min=0, max=num_fovs, step=1, value=0, continuous_update=False\n",
    "    )\n",
    "    slider_box = widgets.VBox([v_slider, t_slider])\n",
    "    t_slider.observe(lambda change: frame_stream.event(t=change[\"new\"]), names=\"value\")\n",
    "    v_slider.observe(lambda change: frame_stream.event(v=change[\"new\"]), names=\"value\")\n",
    "    return slider_box\n",
    "\n",
    "\n",
    "def big_image_viewer(positions):\n",
    "    num_channels = positions[0].shape[0]  # TODO\n",
    "    frame_stream = FrameStream()\n",
    "    slider_box = frame_browser(positions, frame_stream)\n",
    "    channels_box, display_settings_stream = multichannel_selector(positions)\n",
    "\n",
    "    def image_callback(t, v, channel_enabled, channel_colors):\n",
    "        pos_stack = positions[str(v)]\n",
    "        channel_imgs = [\n",
    "            pos_stack[c, t, :, :] for c in range(num_channels) if channel_enabled[c]\n",
    "        ]\n",
    "        img = composite_channels(channel_imgs, select(channel_colors, channel_enabled))\n",
    "        viewer = hv.RGB(img[::-1], bounds=(0, 0, img.shape[1], img.shape[0])).opts(\n",
    "            plot={\"invert_yaxis\": True}\n",
    "        )\n",
    "        return viewer\n",
    "\n",
    "    image = hv.DynamicMap(\n",
    "        image_callback, streams=[frame_stream, display_settings_stream]\n",
    "    )\n",
    "    image = regrid(image)\n",
    "    image = image.opts(plot={\"width\": 500, \"height\": 500})\n",
    "    output = widgets.Output()\n",
    "    box = widgets.VBox([widgets.HBox([channels_box, slider_box]), output])\n",
    "    display(box)\n",
    "    with output:\n",
    "        display(image)\n",
    "    return None\n",
    "\n",
    "\n",
    "big_image_viewer(root_group[\"quantized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_image_viewer(frames):\n",
    "    frame_stream = FrameStream()\n",
    "    slider_box = frame_browser(frames, frame_stream)\n",
    "    channels_box, display_settings_stream = multichannel_selector(frames)\n",
    "\n",
    "    def image_callback(t, v, channel_enabled, channel_colors):\n",
    "        channel_imgs = [\n",
    "            frames[v, c, t, :, :] for c in range(frames.shape[1]) if channel_enabled[c]\n",
    "        ]\n",
    "        img = composite_channels(channel_imgs, select(channel_colors, channel_enabled))\n",
    "        viewer = hv.RGB(img[::-1], bounds=(0, 0, img.shape[1], img.shape[0]))\n",
    "        return viewer\n",
    "\n",
    "    image = hv.DynamicMap(\n",
    "        image_callback, streams=[frame_stream, display_settings_stream]\n",
    "    )\n",
    "    image = regrid(image)\n",
    "    image = image.opts(plot={\"width\": 500, \"height\": 500})\n",
    "    output = widgets.Output()\n",
    "    box = widgets.VBox([widgets.HBox([channels_box, slider_box]), output])\n",
    "    display(box)\n",
    "    with output:\n",
    "        display(image)\n",
    "    return None\n",
    "\n",
    "\n",
    "overlay_image_viewer(frames_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "%%opts Image (cmap='viridis')\n",
    "def scrubber_callback(t, y):\n",
    "    t = int(t)\n",
    "    v_line = hv.VLine(t + 0.5)(style={\"color\": \"white\", \"alpha\": 0.3, \"line_width\": 2})\n",
    "    t_label = hv.Text(t + kymo.shape[1] / 20, kymo.shape[0] / 20, \"t={:}\".format(t))(\n",
    "        style={\"color\": \"white\", \"text_alpha\": 0.8}\n",
    "    )\n",
    "    h_line = hv.HLine(y)(style={\"color\": \"white\", \"alpha\": 0.3, \"line_width\": 2})\n",
    "    return v_line * t_label * h_line\n",
    "\n",
    "\n",
    "def cross_section_callback(t, y):\n",
    "    y = int(y)\n",
    "    h_line = hv.HLine(y)(style={\"color\": \"white\", \"alpha\": 0.3, \"line_width\": 2})\n",
    "    return h_line\n",
    "\n",
    "\n",
    "def sharpness_scrubber_callback(t):\n",
    "    t = int(t)\n",
    "    v_line = hv.VLine(t + 0.5)(style={\"color\": \"black\", \"alpha\": 0.3, \"line_width\": 2})\n",
    "    return v_line\n",
    "\n",
    "\n",
    "def trench_thumbnail_callback(img_series, t):\n",
    "    t = int(t)\n",
    "    img = get_trench_thumbnail(img_series[t], trench_points, trench_idx)\n",
    "    # TODO: don't know why calling hv.Image.opts(plot={'invert_axes': True}) doesn't work\n",
    "    # also switched HLine to VLine in cross_section, above\n",
    "    thumb = hv.Image(\n",
    "        img[::-1], bounds=(0, 0, img.shape[1], img.shape[0]), kdims=[\"x2\", \"y\"]\n",
    "    )\n",
    "    # return thumb\n",
    "    # return thumb.opts(plot={'invert_axes': False, 'width': max_thumbnail_width})#, 'xaxis': None, 'yaxis': None})\n",
    "    return thumb.opts(\n",
    "        plot={\"invert_axes\": False, \"invert_yaxis\": True, \"width\": 200}\n",
    "    )  # , 'xaxis': None, 'yaxis': None})\n",
    "    # return thumb.opts(plot={'invert_axes': False, 'invert_yaxis': True})\n",
    "\n",
    "\n",
    "pointerx = hv.streams.PointerX(x=0).rename(x=\"t\")\n",
    "pointery = hv.streams.PointerY(y=0)\n",
    "\n",
    "# BOUNDS: (left, bottom, top, right)\n",
    "trench_idx = 15\n",
    "img_series = frame_series_k1\n",
    "bbox_ul, bbox_lr = get_trench_bbox(\n",
    "    trench_points, trench_idx, *get_img_limits(img_series[0])\n",
    ")\n",
    "kymo = extract_kymograph(\n",
    "    img_series, trench_points[0][trench_idx], trench_points[1][trench_idx]\n",
    ")\n",
    "kymo_img = hv.Image(kymo[::-1], bounds=(0, 0, kymo.shape[1], kymo.shape[0])).opts(\n",
    "    plot={\"width\": 700, \"height\": 300, \"invert_yaxis\": True}\n",
    ")\n",
    "# kymo_img = hv.Raster(kymo).opts(plot={'width': 700, 'height': 300, 'yaxis': 'left'})\n",
    "scrubber_line = hv.DynamicMap(scrubber_callback, streams=[pointerx, pointery])\n",
    "cross_section_line = hv.DynamicMap(cross_section_callback, streams=[pointerx, pointery])\n",
    "trench_thumbnail_img = hv.DynamicMap(\n",
    "    partial(trench_thumbnail_callback, img_series), streams=[pointerx]\n",
    ")  # .opts(plot={'invert_axes': True})\n",
    "sharpness_plot = hv.Curve(sharpness, kdims=[\"x\"], vdims=[\"s\"]).opts(\n",
    "    plot={\"width\": 700, \"height\": 100}\n",
    ")\n",
    "sharpness_scrubber = hv.DynamicMap(sharpness_scrubber_callback, streams=[pointerx])\n",
    "# pointery.source = kymo_img\n",
    "# SEE: http://holoviews.org/reference/elements/bokeh/Distribution.html\n",
    "# kymo_img * scrubber_line << (trench_thumbnail_img * cross_section_line) << (sharpness_plot * sharpness_scrubber)\n",
    "\n",
    "KymoOverlayStream = Stream.define(\"KymoOverlayStream\", overlay_enabled=True)\n",
    "kymo_overlay_stream = KymoOverlayStream()\n",
    "kymo_overlay_button = widgets.ToggleButton(description=\"Overlay\", value=True)\n",
    "\n",
    "\n",
    "def update_kymo_overlay(change):\n",
    "    kymo_overlay_stream.event(overlay_enabled=change[\"new\"])\n",
    "\n",
    "\n",
    "kymo_overlay_button.observe(update_kymo_overlay, names=\"value\")\n",
    "\n",
    "\n",
    "def get_thumbnail_overlay(t, overlay_enabled):\n",
    "    # because of https://github.com/ioam/holoviews/issues/1388, overlay_enabled must be True initially\n",
    "    x0 = trench_points[0][trench_idx]\n",
    "    x1 = trench_points[1][trench_idx]\n",
    "    trench_line = hv.Curve([x0 - bbox_ul, x1 - bbox_ul]).opts(\n",
    "        style={\"color\": \"white\", \"alpha\": 0.5, \"line_width\": 1.5},\n",
    "        plot={\"yaxis\": None, \"shared_axes\": True},\n",
    "    )\n",
    "    overlays = []\n",
    "    if overlay_enabled:\n",
    "        overlays.append(trench_line)\n",
    "    else:\n",
    "        pass  # overlays = []#line.opts(style={'alpha': 0.0, 'color': 'red'})\n",
    "    return hv.Overlay(overlays)\n",
    "\n",
    "\n",
    "thumbnail_overlay = hv.DynamicMap(\n",
    "    get_thumbnail_overlay, streams=[pointerx, kymo_overlay_stream]\n",
    ")  # .opts(plot={'invert_yaxis': True})\n",
    "\n",
    "display(kymo_overlay_button)\n",
    "(\n",
    "    kymo_img * scrubber_line\n",
    "    << (trench_thumbnail_img * thumbnail_overlay * cross_section_line)\n",
    "    << (sharpness_plot * sharpness_scrubber)\n",
    ")\n",
    "# kymo_img * scrubber_line << (trench_thumbnail_img * cross_section_line) << (sharpness_plot * sharpness_scrubber)\n",
    "# trench_thumbnail_img * thumbnail_overlay\n",
    "# trench_thumbnail_img * thumbnail_overlay * cross_section_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trench_peaks_callback(t, y):\n",
    "    t = int(t)\n",
    "    overlays = [hv.Curve(kymo[:, t]).opts(plot={\"width\": 500})]\n",
    "    overlays.extend(\n",
    "        [\n",
    "            hv.Points([(x, kymo[int(x), t])]).opts(style={\"size\": 6})\n",
    "            for x in kymo_endpoints[t]\n",
    "        ]\n",
    "    )\n",
    "    return hv.Overlay(overlays)\n",
    "\n",
    "\n",
    "hv.DynamicMap(trench_peaks_callback, streams=[pointerx, pointery])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def find_kymograph_cell_endpoints(kymograph, thresh=0.2, min_dist=3):\n",
    "    endpoints = []\n",
    "    for t in range(kymograph.shape[1]):\n",
    "        idxs = peakutils.indexes(kymograph[:, t], thres=thresh, min_dist=min_dist)\n",
    "        xs = idxs\n",
    "        # xs = peakutils.interpolate(np.arange(kymograph.shape[0]), kymograph[:,t], ind=idxs)\n",
    "        endpoints.append(xs)\n",
    "    return endpoints\n",
    "\n",
    "\n",
    "kymo_endpoints = find_kymograph_cell_endpoints(kymo, thresh=0.2, min_dist=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(kymo.shape[1] // 5):\n",
    "    plt.plot(kymo[220:, t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %%opts Image (cmap='viridis')\n",
    "img_series = frame_series\n",
    "kymo = extract_kymograph(\n",
    "    img_series, trench_points[0][trench_idx], trench_points[1][trench_idx]\n",
    ")\n",
    "kymo_img = hv.Image(kymo, bounds=(0, 0, kymo.shape[1], kymo.shape[0])).opts(\n",
    "    plot={\"width\": 700, \"height\": 300}\n",
    ")\n",
    "trench_thumbnail_img = hv.DynamicMap(\n",
    "    partial(trench_thumbnail, img_series), streams=[pointerx]\n",
    ")\n",
    "(\n",
    "    kymo_img.opts(plot={\"invert_axes\": True}) * scrubber_line\n",
    "    + trench_thumbnail_img * cross_section_line\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# handle out-of-bounds/negative t/x values\n",
    "# focus quality score\n",
    "# show focus quality as a bar above kymograph\n",
    "# accurate horizontal line position on thumbnail\n",
    "# draw cross-section line through thumbnail\n",
    "# synchronize zoom/pan of multiple kymograph viewers\n",
    "# 3-up thumbnail viewer with crosshairs/endpoint correspondences (links) synchronized with kymograph viewer\n",
    "# clicking through a track advances 3-up by one frame\n",
    "# if you press END it finishes track and rewinds to the first unfinished track\n",
    "# automatic tracking: always identify bottom-most endpoint?\n",
    "# can we work out all other correspondences from this? (look at t=14)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
