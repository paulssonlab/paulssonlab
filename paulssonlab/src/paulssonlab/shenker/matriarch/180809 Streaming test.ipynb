{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import dask\n",
    "import distributed\n",
    "from distributed import Client\n",
    "from cytoolz import partial\n",
    "import streamz\n",
    "import asyncio\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(total_size, ncols):\n",
    "    nrows = int(total_size / ncols / np.dtype(\"float64\").itemsize)\n",
    "    return pd.DataFrame({\"c\" + str(i): np.random.randn(nrows) for i in range(ncols)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client = Client(processes=False, diagnostics_port=(\"0.0.0.0\", 9500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mock_stream_async(total_size, ncols, num):\n",
    "    df = generate_data(total_size, ncols)\n",
    "    for i in range(num):\n",
    "        await source.emit((df, df, df))\n",
    "\n",
    "\n",
    "def mock_stream(total_size, ncols, num):\n",
    "    df = generate_data(total_size, ncols)\n",
    "    for i in range(num):\n",
    "        source.emit((df, df, df))\n",
    "\n",
    "\n",
    "def pandas_to_arrow(dfs, sinks, writers):\n",
    "    for i, df in enumerate(dfs):\n",
    "        batch = pa.RecordBatch.from_pandas(df)\n",
    "        if i not in writers:\n",
    "            sinks[i] = pa.BufferOutputStream()\n",
    "            writers[i] = pa.RecordBatchStreamWriter(sinks[i], batch.schema)\n",
    "        writers[i].write_batch(batch)\n",
    "\n",
    "\n",
    "source = streamz.Stream(asynchronous=False)\n",
    "\n",
    "stream_sinks = {}\n",
    "stream_writers = {}\n",
    "\n",
    "source.rate_limit(0.004).timed_window(1).flatten().sink(\n",
    "    partial(pandas_to_arrow, sinks=stream_sinks, writers=stream_writers)\n",
    ")\n",
    "\n",
    "# t = asyncio.get_event_loop().create_task(mock_stream_async(10**3, 10, 10**6))\n",
    "t = asyncio.run_in_(mock_stream_async(10**3, 10, 10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_sinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pa.open_stream(stream_sinks[2].getvalue()).read_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_stream(source, futures):\n",
    "    ac = distributed.as_completed(futures, with_results=False)\n",
    "    async for future in ac:\n",
    "        source.emit(future)\n",
    "\n",
    "\n",
    "from tornado import gen\n",
    "from distributed.client import default_client\n",
    "\n",
    "\n",
    "@streamz.Stream.register_api()\n",
    "class gather_and_cancel(streamz.Stream):\n",
    "    def __init__(self, upstream, stream_name=None, client=None, cancel=True):\n",
    "        if client is None:\n",
    "            client = default_client()\n",
    "        self.client = client\n",
    "        self.cancel = cancel\n",
    "        streamz.Stream.__init__(self, upstream, stream_name=stream_name)\n",
    "\n",
    "    @gen.coroutine\n",
    "    def update(self, x, who=None):\n",
    "        result = yield self.client.gather(x, asynchronous=True)\n",
    "        if self.cancel:\n",
    "            self.client.cancel(x)\n",
    "        result2 = yield self._emit(result)\n",
    "        raise gen.Return(result2)\n",
    "\n",
    "\n",
    "def do_task(pause, seed):\n",
    "    1 / pause\n",
    "    # asyncio.sleep(pause)\n",
    "    time.sleep(pause)\n",
    "    return pause\n",
    "\n",
    "\n",
    "source = streamz.Stream(asynchronous=True)\n",
    "\n",
    "stream_sinks = {}\n",
    "stream_writers = {}\n",
    "\n",
    "# source.rate_limit(0.0004).timed_window(1).map(partial(gather_and_cancel, cancel=True)).flatten().sink(partial(sink_to_arrow, sinks=stream_sinks, writers=stream_writers))\n",
    "# source.rate_limit(0.0004).timed_window(1).gather_and_cancel(client=client, cancel=False).flatten().sink(partial(sink_to_arrow, sinks=stream_sinks, writers=stream_writers))\n",
    "source.gather_and_cancel(cancel=True).sink(print)\n",
    "\n",
    "futures = [\n",
    "    local_client.submit(do_task, np.random.randint(5), np.random.random())\n",
    "    for i in range(100)\n",
    "]\n",
    "\n",
    "t = asyncio.get_event_loop().create_task(gather_stream(source, futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
