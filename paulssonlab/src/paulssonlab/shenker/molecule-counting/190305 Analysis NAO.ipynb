{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"190311photobleaching.pickle\", \"rb\") as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements, regionprops, labels, img = d[\n",
    "    \"/n/scratch2/jqs1/fidelity/190311/190311_mGFPmut2_100ms_laser100pct_006.nd2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regionprops.reset_index(inplace=True)\n",
    "regionprops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=150\n",
    "#%%opts Image {+axiswise}\n",
    "hv.Image(img / img.max()).options(cmap=\"gray\") + hv.Image(labels != 0).options(\n",
    "    cmap=\"blues\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(measurements.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "rp_list = []\n",
    "rp_df = pd.DataFrame()\n",
    "for i in range(7):\n",
    "    print(i)\n",
    "    measurements, regionprops, labels, img = d[\n",
    "        \"/n/scratch2/jqs1/fidelity/190311/190311_mGFPmut2_100ms_laser100pct_00\"\n",
    "        + str(i)\n",
    "        + \".nd2\"\n",
    "    ]\n",
    "    traces.append(measurements[\"mean\"][1:])\n",
    "    rp_list.append(regionprops)\n",
    "    print(measurements[\"mean\"][1:].shape)\n",
    "traces = np.concatenate(traces)\n",
    "rp_df = pd.concat(rp_list, sort=False)\n",
    "rp_df.reset_index(inplace=True)\n",
    "print(traces.shape)\n",
    "data = pd.DataFrame(traces)  # + np.random.normal(0,1,Gsamp.T.shape))\n",
    "\n",
    "bins = np.arange(data[0].min() - 1, data[0].max() + 1, 50)\n",
    "data[\"bin\"] = pd.cut(data[0], bins=bins)\n",
    "data = pd.concat([data, rp_df], axis=1, sort=False)\n",
    "# rp_df['initial_intensity'] = df[0]\n",
    "t_end = traces.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=250\n",
    "# traces = measurements['mean']\n",
    "idxs = np.random.permutation(traces.shape[0])\n",
    "downsample = (\n",
    "    10  # set to 1 to show all traces (instead of 10%); this will make your browser slow\n",
    ")\n",
    "curves = [\n",
    "    {\"x\": np.arange(traces.shape[1]), \"y\": traces[i], \"i\": idxs[i]}\n",
    "    for i in range(traces.shape[0] // downsample)\n",
    "]\n",
    "hv.Contours(curves, vdims=[\"i\"]).options(color_index=\"i\", cmap=\"Category20\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from scipy.integrate import simps\n",
    "\n",
    "\n",
    "def filter_df(df, prop_dict):\n",
    "    processed_df = df.copy()\n",
    "    for prop in prop_dict:\n",
    "        processed_df = processed_df[\n",
    "            (processed_df[prop] > prop_dict[prop][0])\n",
    "            & (processed_df[prop] < prop_dict[prop][1])\n",
    "        ]\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def get_stats(df, thresh):\n",
    "    p = df.iloc[:, :t_end].apply(lambda x: x / x[0], axis=1)\n",
    "    p[\"bin\"] = df[\"bin\"]\n",
    "    pbar = p.groupby(p[\"bin\"]).mean()[p.groupby(p[\"bin\"]).size() > thresh]\n",
    "    mu = (\n",
    "        df.iloc[:, :t_end]\n",
    "        .groupby(df[\"bin\"])\n",
    "        .mean()[df.groupby(df[\"bin\"]).size() > thresh]\n",
    "    )\n",
    "    sigma2 = (\n",
    "        df.iloc[:, :t_end]\n",
    "        .groupby(df[\"bin\"])\n",
    "        .var(ddof=0)[df.groupby(df[\"bin\"]).size() > thresh]\n",
    "    )\n",
    "\n",
    "    return pbar, mu, sigma2\n",
    "\n",
    "\n",
    "def nu_int(pbar, mu, sigma, q=1):\n",
    "    nu_dict = {}  # pd.Series()\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    y = sigma2.div(mu[0].values, axis=\"rows\")\n",
    "    for name, group in pbar.groupby(\"bin\"):\n",
    "        dp = pbar.loc[name].values\n",
    "        dp = dp[pbar.loc[name].values > 1 - q]\n",
    "        f = y.loc[name].values[pbar.loc[name].values > 1 - q]\n",
    "        nu_dict[name] = cq * simps(f, dp)\n",
    "\n",
    "    return pd.Series(nu_dict)\n",
    "\n",
    "\n",
    "def fluct_plot(pbar, mu, sigma2, thresh):\n",
    "    hist_df = df.groupby(df[\"bin\"]).size()\n",
    "    hist_df = hist_df[hist_df.values > thresh]\n",
    "    print(hist_df)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    cmap = cm.get_cmap(\"coolwarm\")\n",
    "\n",
    "    y = sigma2.div(mu[0].values, axis=\"rows\")\n",
    "    imax = pbar.index[-1].left\n",
    "    imin = pbar.index[0].left\n",
    "    q = 1 / 2\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    # plt.vlines(q,0,3)\n",
    "\n",
    "    for name, group in pbar.groupby(\"bin\"):\n",
    "        dp = pbar.loc[name].values\n",
    "        dp = dp[pbar.loc[name].values > 1 - q]\n",
    "        f = y.loc[name].values[pbar.loc[name].values > 1 - q]\n",
    "        c = (name.left - imin) / (imax - imin)\n",
    "        plt.scatter(\n",
    "            1 - pbar.loc[name].values, y.loc[name].values, color=cmap(c), label=name\n",
    "        )\n",
    "        plt.legend()\n",
    "\n",
    "    plt.title(\n",
    "        r\"$\\nu = \"\n",
    "        + str(np.round(-cq))\n",
    "        + r\"\\cdot \\int\\frac{\\hat{\\sigma}^2}{f_{max}}dp$ =\"\n",
    "        + str(np.round(nu_df.mean(), 2)),\n",
    "        fontsize=20,\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.xlabel(r\"$(1-\\hat{p})$\", fontsize=20)\n",
    "    plt.ylabel(r\"$\\frac{\\hat{\\sigma}^2}{f_{max}}$\", fontsize=20)\n",
    "\n",
    "\n",
    "thresh = 40\n",
    "\n",
    "prop_dict = {\n",
    "    \"centroid_x\": [300, 1000],\n",
    "    \"centroid_y\": [750, 1500],\n",
    "    \"area\": [30, 150],\n",
    "    0: [2000, 10000],\n",
    "}\n",
    "# prop_dict = {'area': [30,150],\n",
    "#              0: [2000, 10000]}\n",
    "\n",
    "df = filter_df(data, prop_dict)\n",
    "pbar, mu, sigma2 = get_stats(df, thresh)\n",
    "\n",
    "\n",
    "nu_df = nu_int(pbar, mu, sigma2)\n",
    "print(nu_df)\n",
    "\n",
    "fluct_plot(pbar, mu, sigma2, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=250\n",
    "# traces = measurements['mean']\n",
    "idxs = np.random.permutation(traces.shape[0])\n",
    "downsample = (\n",
    "    10  # set to 1 to show all traces (instead of 10%); this will make your browser slow\n",
    ")\n",
    "curves = [\n",
    "    {\"x\": np.arange(traces.shape[1]), \"y\": df[i], \"i\": idxs[i]}\n",
    "    for i in range(traces.shape[0] // downsample)\n",
    "]\n",
    "hv.Contours(curves, vdims=[\"i\"]).options(color_index=\"i\", cmap=\"Category20\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I0 = traces[:, 0]\n",
    "plt.hist(I0, bins=30)\n",
    "print(np.mean(I0), np.var(I0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "cmap = cm.get_cmap(\"coolwarm\")\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "imax = pbar.index[-1].left\n",
    "imin = pbar.index[0].left\n",
    "for name, group in df.groupby(\"bin\"):\n",
    "    if group.shape[0] > thresh:\n",
    "        c = (name.left - imin) / (imax - imin)\n",
    "        #         c = (nu_dict[name] - min(nu_int))/(max(nu_int) - min(nu_int))\n",
    "        z = name.left * np.ones(group.centroid_x.shape)\n",
    "        plt.scatter(\n",
    "            group.centroid_x, group.centroid_y, color=cmap(c), label=nu_df[name]\n",
    "        )\n",
    "        plt.xlim(data.centroid_x.min(), data.centroid_x.max())\n",
    "        plt.ylim(data.centroid_y.min(), data.centroid_y.max())\n",
    "    else:\n",
    "        plt.scatter(group.centroid_x, group.centroid_y, color=\"k\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
