{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('190311photobleaching.pickle', 'rb') as f:\n",
    "# with open('all_data.pickle', 'rb') as f:\n",
    "with open(\"190313photobleaching_noflatcorr.pickle\", \"rb\") as f:\n",
    "    # with open('190326photobleaching_flatcorr_fluoronly.pickle', 'rb') as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements, regionprops, labels, img = d[\n",
    "    \"/n/scratch2/jqs1/fidelity/190313/fluorescence/190313_mkate_100ms_50pct_laser.nd2\"\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regionprops.reset_index(inplace=True)\n",
    "regionprops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=150\n",
    "#%%opts Image {+axiswise}\n",
    "hv.Image(img / img.max()).options(cmap=\"gray\") + hv.Image(labels != 0).options(\n",
    "    cmap=\"blues\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(measurements.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "rp_list = []\n",
    "rp_df = pd.DataFrame()\n",
    "directory = (\n",
    "    \"/n/scratch2/jqs1/fidelity/190313/fluorescence/190313_mkate_100ms_100pct_laser.nd2\"\n",
    ")\n",
    "for i in [3, 5, 7, 8]:\n",
    "    print(i)\n",
    "    #     measurements, regionprops, labels, img = d['/n/scratch2/jqs1/fidelity/190301/jqs_photobleach_100ms_de32_mkate2_000{:d}.nd2'.format(i)]\n",
    "    regionprops = d[directory][i][\"regionprops\"]\n",
    "    measurements = d[directory][i][\"traces\"]\n",
    "\n",
    "    traces.append(measurements[\"mean\"][1:])\n",
    "    rp_list.append(regionprops)\n",
    "    print(measurements[\"mean\"][1:].shape)\n",
    "traces = np.concatenate(traces)\n",
    "rp_df = pd.concat(rp_list, sort=False)\n",
    "rp_df.reset_index(inplace=True)\n",
    "print(traces.shape)\n",
    "data = pd.DataFrame(traces)  # + np.random.normal(0,1,Gsamp.T.shape))\n",
    "\n",
    "bins = np.arange(data[0].min() - 1, data[0].max() + 1, 30)\n",
    "data[\"bin\"] = pd.cut(data[0], bins=bins)\n",
    "data = pd.concat([data, rp_df], axis=1, sort=False)\n",
    "# rp_df['initial_intensity'] = df[0]\n",
    "t_end = traces.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=250\n",
    "# traces = measurements['mean']\n",
    "idxs = np.random.permutation(traces.shape[0])\n",
    "downsample = (\n",
    "    10  # set to 1 to show all traces (instead of 10%); this will make your browser slow\n",
    ")\n",
    "curves = [\n",
    "    {\"x\": np.arange(traces.shape[1]), \"y\": traces[i], \"i\": idxs[i]}\n",
    "    for i in range(traces.shape[0] // downsample)\n",
    "]\n",
    "hv.Contours(curves, vdims=[\"i\"]).options(color_index=\"i\", cmap=\"Category20\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from scipy.integrate import simps\n",
    "from astropy.stats.biweight import biweight_midvariance\n",
    "\n",
    "\n",
    "def filter_df(df, prop_dict):\n",
    "    processed_df = df.copy()\n",
    "    for prop in prop_dict:\n",
    "        processed_df = processed_df[\n",
    "            (processed_df[prop] > prop_dict[prop][0])\n",
    "            & (processed_df[prop] < prop_dict[prop][1])\n",
    "        ]\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def get_stats(df, thresh):\n",
    "    p = df.iloc[:, :t_end].apply(lambda x: x / x[0], axis=1)\n",
    "    p[\"bin\"] = df[\"bin\"]\n",
    "    pbar = p.groupby(p[\"bin\"]).mean()[p.groupby(p[\"bin\"]).size() > thresh]\n",
    "    mu = (\n",
    "        df.iloc[:, :t_end]\n",
    "        .groupby(df[\"bin\"])\n",
    "        .mean()[df.groupby(df[\"bin\"]).size() > thresh]\n",
    "    )\n",
    "    sigma2 = (\n",
    "        df.iloc[:, :t_end]\n",
    "        .groupby(df[\"bin\"])\n",
    "        .var(ddof=0)[df.groupby(df[\"bin\"]).size() > thresh]\n",
    "    )\n",
    "    #     sigma2 = (1.48*df.iloc[:,:t_end].groupby(df['bin']).mad()[df.groupby(df['bin']).size() > thresh])**2\n",
    "    #     sigma2 = (df.iloc[:,:t_end].groupby(df['bin']).iqr()[df.groupby(df['bin']).size() > thresh]/1.35)**2\n",
    "    #     sigma2 = sigma2 - (pbar**2).multiply(sigma2[0].values,axis=0)\n",
    "    return pbar, mu, sigma2\n",
    "\n",
    "\n",
    "def nu_int(pbar, mu, sigma, q=1):\n",
    "    nu_dict = {}  # pd.Series()\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    y = sigma2.div(mu[0].values, axis=\"rows\")\n",
    "    for name, group in pbar.groupby(\"bin\"):\n",
    "        dp = pbar.loc[name].values\n",
    "        dp = dp[pbar.loc[name].values > 1 - q]\n",
    "        f = y.loc[name].values[pbar.loc[name].values > 1 - q]\n",
    "        nu_dict[name] = cq * simps(f, dp)\n",
    "\n",
    "    return pd.Series(nu_dict)\n",
    "\n",
    "\n",
    "def fluct_plot(pbar, mu, sigma2, thresh, q=1):\n",
    "    hist_df = df.groupby(df[\"bin\"]).size()\n",
    "    hist_df = hist_df[hist_df.values > thresh]\n",
    "    print(hist_df)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cmap = cm.get_cmap(\"coolwarm\")\n",
    "\n",
    "    y = sigma2.div(mu[0].values, axis=\"rows\")\n",
    "    imax = pbar.index[-1].left\n",
    "    imin = pbar.index[0].left\n",
    "    q = 1\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    # plt.vlines(q,0,3)\n",
    "\n",
    "    for name, group in pbar.groupby(\"bin\"):\n",
    "        c = (name.left - imin) / (imax - imin)\n",
    "        plt.scatter(\n",
    "            1 - pbar.loc[name].values, y.loc[name].values, color=cmap(c), label=name\n",
    "        )\n",
    "        plt.legend()\n",
    "\n",
    "    plt.title(\n",
    "        r\"$\\nu =  {0:2.0f} \\cdot \\int\\frac{{\\hat{{\\sigma}}^2}}{{f_{{max}}}}dp$ = {1:2.2f}\".format(\n",
    "            -cq, nu_df.mean()\n",
    "        ),\n",
    "        fontsize=20,\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.xlabel(r\"$(1-\\hat{p})$\", fontsize=20)\n",
    "    plt.ylabel(r\"$\\frac{\\hat{\\sigma}^2}{f_{max}}$\", fontsize=20)\n",
    "\n",
    "\n",
    "thresh = 40\n",
    "\n",
    "prop_dict = {\n",
    "    \"centroid_x\": [300, 1700],\n",
    "    \"centroid_y\": [300, 1700],\n",
    "    \"area\": [30, 150],\n",
    "    0: [1500, 10000],\n",
    "}\n",
    "# prop_dict = {'area': [30,150],\n",
    "#              0: [1500, 10000]}\n",
    "\n",
    "df = filter_df(data, prop_dict)\n",
    "pbar, mu, sigma2 = get_stats(df, thresh)\n",
    "\n",
    "q = 1\n",
    "nu_df = nu_int(pbar, mu, sigma2, q)\n",
    "print(nu_df)\n",
    "\n",
    "fluct_plot(pbar, mu, sigma2, thresh, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=250\n",
    "# traces = measurements['mean']\n",
    "idxs = np.random.permutation(traces.shape[0])\n",
    "downsample = (\n",
    "    10  # set to 1 to show all traces (instead of 10%); this will make your browser slow\n",
    ")\n",
    "curves = [\n",
    "    {\"x\": np.arange(traces.shape[1]), \"y\": df[i], \"i\": idxs[i]}\n",
    "    for i in range(traces.shape[0] // downsample)\n",
    "]\n",
    "hv.Contours(curves, vdims=[\"i\"]).options(color_index=\"i\", cmap=\"Category20\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I0 = traces[:, 0]\n",
    "plt.hist(I0, bins=30)\n",
    "print(np.mean(I0), np.var(I0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap(\"coolwarm\")\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(24, 12))\n",
    "gridfig, gridaxs = plt.subplots(\n",
    "    nrows=int(np.ceil(nu_df.size / 4)), ncols=4, figsize=(24, 30)\n",
    ")\n",
    "imax = pbar.index[-1].left\n",
    "imin = pbar.index[0].left\n",
    "ind = 0\n",
    "for name, group in df.groupby(\"bin\"):\n",
    "    if group.shape[0] > thresh:  # & (np.round(name.left) == 3352):\n",
    "        #         c = (name.left - imin)/(imax - imin)\n",
    "        c = (nu_df[name] - nu_df.min()) / (nu_df.max() - nu_df.min())\n",
    "        #         z = name.left*np.ones(group.centroid_x.shape)\n",
    "\n",
    "        axs[0].scatter(\n",
    "            group.centroid_x,\n",
    "            group.centroid_y,\n",
    "            color=cmap(c),\n",
    "            marker=\"o\",\n",
    "            s=16,\n",
    "            label=nu_df[name],\n",
    "        )\n",
    "        axs[0].set_xlim(data.centroid_x.min(), data.centroid_x.max())\n",
    "        axs[0].set_ylim(data.centroid_y.min(), data.centroid_y.max())\n",
    "        axs[1].semilogy(group.iloc[:, :t_end].T, color=cmap(c))\n",
    "        #         tempfig = plt.figure(figsize=(8,8))\n",
    "        gridaxs.flatten()[ind].semilogy(group.iloc[:, :t_end].T, color=cmap(c))\n",
    "        gridaxs.flatten()[ind].set_title(\n",
    "            r\"Interval = {:s}, $\\nu = $ {:2.2f}\".format(str(name), nu_df[name])\n",
    "        )\n",
    "        ind += 1\n",
    "    else:\n",
    "        axs[0].scatter(\n",
    "            group.centroid_x, group.centroid_y, color=\"k\", marker=\"x\", s=12, alpha=0.3\n",
    "        )\n",
    "gridfig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
