{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import regrid\n",
    "import hvplot.pandas\n",
    "import panel as pn\n",
    "import param\n",
    "import pickle\n",
    "import os\n",
    "from scipy.integrate import simps\n",
    "import segmentation\n",
    "from matriarch_stub import RevImage\n",
    "import astropy.stats\n",
    "from cytoolz import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select file\n",
    "# checkboxes: positions\n",
    "# select: var estimator\n",
    "# select: mean/median/p.095\n",
    "# double-slider: size filtering (on histogram?)\n",
    "# slider: bin size\n",
    "# slider: threshold\n",
    "# plot: downsampled log traces (checkbox: normalized to t0)\n",
    "# plot: var as a function of p\n",
    "# plot: integral as a function of p\n",
    "# plot: spatial (select: color dimension: initial intensity, etc.)\n",
    "# plot: counts per bin\n",
    "# plot: regridded image+seg mask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"/n/groups/paulsson/jqs1/molecule-counting\"\n",
    "filename = \"190304photobleaching.pickle\"\n",
    "# filename = '190328photobleaching_flatcorr.pickle'\n",
    "with open(os.path.join(base_filename, filename), \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyarrow as pa\n",
    "# buf = pa.serialize(data).to_buffer()\n",
    "# with pa.OSFile(os.path.join(base_filename, '190328photobleaching_flatcorr.arrow'), 'wb') as f:\n",
    "#    f.write(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check integral values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trace_plot(traces, downsample=10, normalize=True, colors=None):\n",
    "    if colors is None:\n",
    "        colors = np.random.permutation(traces.shape[0])\n",
    "        cmap = \"Category20\"\n",
    "    else:\n",
    "        cmap = \"bmy\"\n",
    "    y = traces\n",
    "    if normalize:\n",
    "        y = y / y[:, 0, np.newaxis]\n",
    "    curves = [\n",
    "        {\"x\": np.arange(traces.shape[1]), \"y\": y[i], \"i\": colors[i]}\n",
    "        for i in range(0, traces.shape[0], downsample)\n",
    "    ]\n",
    "    plot = hv.Contours(curves, vdims=[\"i\"]).options(\n",
    "        color_index=\"i\", cmap=cmap, logy=True\n",
    "    )\n",
    "    return plot\n",
    "\n",
    "\n",
    "def _fluctuation_plots(pbar, y, qs, nu_qs, colors=None):\n",
    "    if colors is None:\n",
    "        colors = np.random.permutation(y.shape[0])\n",
    "        cmap = \"Category20\"\n",
    "    else:\n",
    "        cmap = \"bmy\"\n",
    "    nus = nu_qs.iloc[:, -1]\n",
    "    fluctuation_curves = [\n",
    "        {\"x\": 1 - pbar.values[i], \"y\": y.values[i], \"i\": colors[i]}\n",
    "        for i in range(y.shape[0])\n",
    "    ]\n",
    "    fluctuation_plot = hv.Contours(fluctuation_curves, vdims=[\"i\"]).options(\n",
    "        color_index=\"i\", cmap=cmap\n",
    "    )\n",
    "    integral_curves = [\n",
    "        {\"x\": qs, \"y\": nu_qs.values[i], \"i\": colors[i]} for i in range(nu_qs.shape[0])\n",
    "    ]\n",
    "    integral_plot = (\n",
    "        hv.Contours(integral_curves, vdims=[\"i\"])\n",
    "        .redim(y=\"integral\")\n",
    "        .options(color_index=\"i\", cmap=cmap)\n",
    "    )\n",
    "    plots = fluctuation_plot, integral_plot\n",
    "    return plots\n",
    "\n",
    "\n",
    "def _spatial_plots(regionprops, labels, img, colors=None):\n",
    "    if colors is None:\n",
    "        colors = np.random.permutation(regionprops.shape[0])\n",
    "        cmap = \"Category20\"\n",
    "    else:\n",
    "        cmap = \"bmy\"\n",
    "    regionprops[\"x\"] = regionprops[\"centroid_x\"]\n",
    "    regionprops[\"y\"] = regionprops[\"centroid_y\"]\n",
    "    regionprops[\"color\"] = colors\n",
    "    xy_plot = hv.Points(regionprops, kdims=[\"x\", \"y\"], vdims=[\"color\"]).options(\n",
    "        color=hv.dim(\"color\"), cmap=cmap\n",
    "    )\n",
    "    image_plot = regrid(RevImage(img))\n",
    "    labels_plot = regrid(\n",
    "        RevImage(segmentation.permute_labels(labels)), aggregator=\"max\"\n",
    "    ).redim(z=\"label\")\n",
    "    spatial_plots = xy_plot + image_plot + labels_plot\n",
    "    return spatial_plots\n",
    "\n",
    "\n",
    "class PhotobleachingViewer(param.Parameterized):\n",
    "    def __init__(self, data, *args, **kwargs):\n",
    "        self._data = data\n",
    "        filenames = list(data.keys())\n",
    "        self.param[\"filename\"].objects = filenames\n",
    "        self.filename = filenames[0]\n",
    "        self.measurement = list(data[self.filename][0].keys())[0]\n",
    "        self._update_measurements()\n",
    "        self._process_traces()\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    filename = param.ObjectSelector()\n",
    "    measurement = param.ObjectSelector()\n",
    "    estimator = param.ObjectSelector(\n",
    "        objects=[\"variance\", \"mad\", \"biweight_midvariance\"],\n",
    "        default=\"biweight_midvariance\",\n",
    "    )\n",
    "    fluctuation_colormap = param.ObjectSelector(\n",
    "        objects=[\"random\", \"bin\", \"gain\"], default=\"bin\"\n",
    "    )\n",
    "    traces_colormap = param.ObjectSelector(\n",
    "        objects=[\"random\", \"fluorescence\", \"bin\", \"area\", \"gain\"], default=\"bin\"\n",
    "    )\n",
    "    downsample = param.ObjectSelector(objects=[1000, 100, 30, 10, 1], default=30)\n",
    "    normalize_traces = param.Boolean(True)\n",
    "\n",
    "    @param.depends(\"filename\", watch=True)\n",
    "    def _update_measurements(self):\n",
    "        old_measurement = self.measurement\n",
    "        measurements = list(self._data[self.filename][0].keys())\n",
    "        self.param[\"measurement\"].objects = measurements\n",
    "        if old_measurement not in measurements:\n",
    "            self.measurement = measurements[0]\n",
    "        traces, regionprops, labels, img = self._data[self.filename]\n",
    "        self._traces = traces[self.measurement][\n",
    "            1:, :\n",
    "        ]  # skip background trace (index 0)\n",
    "        self._regionprops = regionprops\n",
    "        self._labels = labels\n",
    "        self._img = img\n",
    "\n",
    "    @param.depends(\"filename\", \"measurement\", \"estimator\", watch=True)\n",
    "    def _process_traces(self):\n",
    "        thresh = 30  # TODO: parameterize\n",
    "        num_qs = 20\n",
    "        initial_fluorescence_threshold = 3  # in sigma units\n",
    "        traces = self._traces\n",
    "        # FROM: numpy.histogram\n",
    "        traces0 = traces[:, 0]\n",
    "        bin_edges = np.histogram_bin_edges(traces0, bins=\"auto\")\n",
    "        bins = pd.Series(pd.cut(traces0, bin_edges), name=\"bin\")\n",
    "        traces_df = pd.DataFrame(traces)\n",
    "        traces_df = traces_df.fillna(0)  # TODO!!!!!!\n",
    "        bin_counts = bins.groupby(bins).size()\n",
    "        bin_counts.name = \"bin_count\"\n",
    "        trace_info = pd.merge(\n",
    "            bins, bin_counts, left_on=\"bin\", right_index=True, how=\"left\"\n",
    "        )\n",
    "        mask = trace_info[\"bin_count\"] > thresh\n",
    "        if initial_fluorescence_threshold:\n",
    "            traces0_loc = astropy.stats.biweight.biweight_location(traces0)\n",
    "            traces0_scale = astropy.stats.biweight.biweight_scale(\n",
    "                traces0, modify_sample_size=True\n",
    "            )\n",
    "            mask &= (\n",
    "                traces0 <= traces0_loc + initial_fluorescence_threshold * traces0_scale\n",
    "            )\n",
    "            mask &= (\n",
    "                traces0 >= traces0_loc - initial_fluorescence_threshold * traces0_scale\n",
    "            )\n",
    "        traces_df = traces_df[mask]\n",
    "        trace_info = trace_info[mask]\n",
    "        # observed=True is important in these groupbys, otherwise plotting colormaps get messed up by all the NaNs\n",
    "        traces_by_bin = traces_df.groupby(trace_info[\"bin\"], observed=True)\n",
    "        pbar = (\n",
    "            traces_df.div(traces_df.iloc[:, 0], axis=0)\n",
    "            .groupby(trace_info[\"bin\"], observed=True)\n",
    "            .mean()\n",
    "        )\n",
    "        # TODO: nan handling\n",
    "        mu = traces_by_bin.mean()\n",
    "        if self.estimator == \"variance\":\n",
    "            sigma2 = traces_by_bin.var(ddof=0)\n",
    "        elif self.estimator == \"mad\":\n",
    "            # sigma2 = traces_by_bin.agg(partial(astropy.stats.biweight.mad_std, ignore_nan=True))**2\n",
    "            sigma2 = traces_by_bin.agg(partial(astropy.stats.biweight.mad_std)) ** 2\n",
    "        elif self.estimator == \"biweight_midvariance\":\n",
    "            sigma2 = traces_by_bin.agg(\n",
    "                partial(\n",
    "                    astropy.stats.biweight.biweight_midvariance, modify_sample_size=True\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError\n",
    "        y = sigma2.div(mu[0], axis=\"rows\")\n",
    "        qs = np.linspace(0.1, 1, num_qs)  # TODO: make start point adjustable?\n",
    "        # TODO: the following line is slow (because of pandas indexing), following is a faster version\n",
    "        # nu_qs = pd.DataFrame(np.array([-1/(1/2*q**2 - 1/3*q**3)*simps(y[pbar >= 1-q].fillna(0), pbar, axis=1) for q in qs]).T, index=y.index, columns=qs)\n",
    "        nu_qs = []\n",
    "        y_ary = y.values.copy()  # we need an unmodified copy of y to plot\n",
    "        pbar_ary = pbar.values\n",
    "        for q in qs[::-1]:\n",
    "            y_ary[pbar_ary < 1 - q] = 0\n",
    "            nu_q = -1 / (1 / 2 * q**2 - 1 / 3 * q**3) * simps(y_ary, pbar, axis=1)\n",
    "            nu_qs.append(nu_q)\n",
    "        nu_qs = pd.DataFrame(np.array(nu_qs)[::-1, :].T, index=y.index, columns=qs)\n",
    "        self._pbar = pbar\n",
    "        self._y = y\n",
    "        self._qs = qs\n",
    "        self._nu_qs = nu_qs\n",
    "        self._bins = bins\n",
    "\n",
    "    def _colors(self, colormap):\n",
    "        if colormap == \"random\":\n",
    "            colors = None\n",
    "        elif colormap == \"fluorescence\":\n",
    "            colors = np.log(self._traces[:, 0])\n",
    "        elif colormap == \"bin\":\n",
    "            colors = self._bins.values.codes\n",
    "        elif colormap == \"area\":\n",
    "            colors = self._regionprops[\"area\"].values\n",
    "        elif colormap == \"gain\":\n",
    "            # TODO: make cleaner\n",
    "            gain = self._nu_qs.iloc[:, -1]\n",
    "            colors = pd.merge(\n",
    "                self._bins, gain, left_on=\"bin\", right_index=True, how=\"left\"\n",
    "            )[gain.name].values\n",
    "        else:\n",
    "            raise ValueError\n",
    "        return colors\n",
    "\n",
    "    def _bin_colors(self, colormap):\n",
    "        if colormap == \"random\":\n",
    "            colors = None\n",
    "        elif colormap == \"bin\":\n",
    "            colors = self._nu_qs.index.values.codes\n",
    "        elif colormap == \"gain\":\n",
    "            colors = self._nu_qs.iloc[:, -1].values\n",
    "        else:\n",
    "            raise ValueError\n",
    "        return colors\n",
    "\n",
    "    @param.depends(\n",
    "        \"filename\",\n",
    "        \"measurement\",\n",
    "        \"fluctuation_colormap\",\n",
    "        \"traces_colormap\",\n",
    "        \"downsample\",\n",
    "        \"estimator\",\n",
    "        \"normalize_traces\",\n",
    "    )\n",
    "    def view(self):\n",
    "        gs = pn.GridSpec(sizing_mode=\"stretch_both\")\n",
    "        trace_colors = self._colors(self.traces_colormap)\n",
    "        fluctuation_colors = self._bin_colors(self.fluctuation_colormap)\n",
    "        gs[0:1, 0:2] = _trace_plot(\n",
    "            self._traces,\n",
    "            downsample=self.downsample,\n",
    "            normalize=self.normalize_traces,\n",
    "            colors=trace_colors,\n",
    "        )\n",
    "        fluct_plots = _fluctuation_plots(\n",
    "            self._pbar, self._y, self._qs, self._nu_qs, colors=fluctuation_colors\n",
    "        )\n",
    "        gs[1:2, 0:1] = fluct_plots[0]\n",
    "        gs[1:2, 1:2] = fluct_plots[1]\n",
    "        gs[2:3, 0:2] = _spatial_plots(\n",
    "            self._regionprops, self._labels, self._img, colors=trace_colors\n",
    "        )\n",
    "        return gs\n",
    "        # return pn.Row(hv.Curve(np.random.random(10)), hv.Points(np.random.random((10,2))))\n",
    "        # return pn.Column(trace_plots[self.filename], overlay_plots[self.filename])\n",
    "\n",
    "\n",
    "viewer = PhotobleachingViewer(data, name=\"Photobleaching\")\n",
    "pn.Column(viewer.param, viewer.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_qs.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_qs.index.values.codes - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_colors = viewer._regionprops[\"area\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer._traces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_trace_plot(viewer._traces[:], downsample=10, normalize=False, colors=trace_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces, regionprops, _, _ = data[\n",
    "    \"/n/scratch2/jqs1/fidelity/190301/jqs_photobleach_100ms_de32_mkate2_0002.nd2\"\n",
    "]\n",
    "traces = traces[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.arange(data[0].min()-1,data[0].max()+1,50)\n",
    "# FROM: numpy.histogram\n",
    "traces0 = traces[:, 0]\n",
    "bin_edges = np.histogram_bin_edges(traces0, bins=\"auto\")\n",
    "bins = pd.Series(pd.cut(traces0, bin_edges), name=\"bin\")\n",
    "# traces_normed = traces / traces0[:,np.newaxis]\n",
    "traces_df = pd.DataFrame(traces)\n",
    "bin_counts = bins.groupby(bins).size()\n",
    "bin_counts.name = \"bin_count\"\n",
    "pd.merge(bins, bin_counts, left_on=\"bin\", right_index=True, how=\"left\")\n",
    "thresh = 30\n",
    "pbar = (\n",
    "    traces_df.div(traces_df.iloc[:, 0], axis=0).groupby(bins).mean()\n",
    ")  # [bin_count > thresh]\n",
    "mu = traces_df.groupby(bins).mean()[bin_count > thresh]\n",
    "sigma2 = traces_df.groupby(bins).var(ddof=0)[bin_count > thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwise = nu_qs.iloc[:, -1]\n",
    "pd.merge(bins, binwise, left_on=\"bin\", right_index=True, how=\"left\")[\n",
    "    binwise.name\n",
    "].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwise.index.name = \"bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(bins, binwise, left_on=\"bin\", right_index=True, how=\"left\")[\n",
    "    binwise.name\n",
    "].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins.values.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
