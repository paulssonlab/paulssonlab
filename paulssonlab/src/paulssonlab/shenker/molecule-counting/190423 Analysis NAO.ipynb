{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "import pickle\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('190311photobleaching.pickle', 'rb') as f:\n",
    "# with open('all_data.pickle', 'rb') as f:\n",
    "# with open('190313photobleaching_noflatcorr.pickle', 'rb') as f:\n",
    "# with open('190326photobleaching_flatcorr_fluoronly.pickle', 'rb') as f:\n",
    "with open(\"190405photobleaching_noflatcorr.pickle\", \"rb\") as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements, regionprops, labels, img = d[\n",
    "    \"/n/scratch2/jqs1/fidelity/190313/fluorescence/190313_mkate_100ms_50pct_laser.nd2\"\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regionprops.reset_index(inplace=True)\n",
    "regionprops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=150\n",
    "#%%opts Image {+axiswise}\n",
    "hv.Image(img / img.max()).options(cmap=\"gray\") + hv.Image(labels != 0).options(\n",
    "    cmap=\"blues\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(measurements.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "rp_list = []\n",
    "rp_df = pd.DataFrame()\n",
    "directory = \"/n/scratch2/jqs1/fidelity/190326/190326_mkate_nochlor_wateragarpad_100ms_100pct_laser.nd2\"\n",
    "# directory =  '/n/scratch2/jqs1/fidelity/190313/fluorescence/190313_mkate_100ms_100pct_laser.nd2'\n",
    "# directory = '/n/scratch2/jqs1/fidelity/190325/phase/SB1_mcherry_LBagarpad_100ms_100pct_laser/190313_SB1_mcherry_LBagarpad_100ms_100pct_laser.nd2'\n",
    "for i in d[directory].keys():\n",
    "    #     if i == 4:\n",
    "    if i not in np.arange(9, 9).astype(list):\n",
    "        print(i)\n",
    "        #     measurements, regionprops, labels, img = d['/n/scratch2/jqs1/fidelity/190301/jqs_photobleach_100ms_de32_mkate2_000{:d}.nd2'.format(i)]\n",
    "        regionprops = d[directory][i][\"regionprops\"]\n",
    "        measurements = d[directory][i][\"traces\"]\n",
    "        area = d[directory][i][\"regionprops\"][\"area\"]\n",
    "\n",
    "        bg_trace = measurements[\"mean\"][0, :]\n",
    "        bg = np.nanmin(measurements[\"mean\"][1:], axis=1)\n",
    "        #         print(np.nanmin(measurements['mean'][1:],axis=1).shape)\n",
    "\n",
    "        #         traces.append((measurements['mean'][1:] - 0*bg[:,np.newaxis])*area[:,np.newaxis])\n",
    "        #         traces.append(measurements['mean'][1:] - bg_trace)\n",
    "        traces.append(measurements[\"mean\"][1:])\n",
    "\n",
    "        rp_list.append(regionprops)\n",
    "        print(measurements[\"mean\"][1:].shape)\n",
    "traces = np.concatenate(traces)\n",
    "rp_df = pd.concat(rp_list, sort=False)\n",
    "rp_df.reset_index(inplace=True)\n",
    "print(traces.shape)\n",
    "data = pd.DataFrame(traces)  # + np.random.normal(0,1,Gsamp.T.shape))\n",
    "\n",
    "# bins = np.linspace(data[0].min(),data[0].max(),150)\n",
    "data = pd.concat([data, rp_df], axis=1, sort=False)\n",
    "# rp_df['initial_intensity'] = df[0]\n",
    "# data['bin'] = np.zeros(len(traces))\n",
    "x_bin = pd.cut(data[\"centroid_x\"], 40)\n",
    "y_bin = pd.cut(data[\"centroid_y\"], 40)\n",
    "xy_bin_df = pd.DataFrame({\"x\": x_bin.values.codes, \"y\": y_bin.values.codes})\n",
    "data[\"bin\"] = pd.Categorical(xy_bin_df.apply(lambda x: tuple(x.values), axis=1)).codes\n",
    "# data['bin'] = pd.Categorical().values\n",
    "# data['bin'] = np.arange(len(traces))\n",
    "\n",
    "t_end = traces.shape[1] - 6\n",
    "data[\"k\"] = data.apply(\n",
    "    lambda y: (y.values[0] - y.values[t_end - 1])\n",
    "    / np.sum(y[:t_end].values - y.values[t_end - 1]),\n",
    "    axis=1,\n",
    ").values\n",
    "# cfit = data.apply(lambda y: curve_fit(func1, np.arange(0,y[:t_end].shape[0]), y[:t_end],p0=[y[0],.001,0])[0], axis=1).apply(lambda x: pd.Series(x,index=['I0','k','bg']))\n",
    "# data[:t_end] = data[:t_end].values - cfit.bg.values[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=250\n",
    "# traces = measurements['mean']\n",
    "idxs = np.random.permutation(traces.shape[0])\n",
    "downsample = 100  # set to 1 to show all traces (instead odata.k.hist()f 10%); this will make your browser slow\n",
    "curves = [\n",
    "    {\"x\": np.arange(traces.shape[1]), \"y\": traces[i], \"i\": idxs[i]}\n",
    "    for i in range(traces.shape[0] // downsample)\n",
    "]\n",
    "hv.Contours(curves, vdims=[\"i\"]).options(color_index=\"i\", cmap=\"Category20\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpoint = 600\n",
    "blorp = traces[traces[:, tpoint] < 100, tpoint]\n",
    "# blorp = blorp[::10]\n",
    "plt.hist(blorp, bins=30, density=True)\n",
    "x = np.linspace(blorp.min(), blorp.max(), 100)\n",
    "mu, sigma = stats.norm.fit(blorp)\n",
    "print(mu, sigma**2)\n",
    "print(stats.kstest(blorp, \"norm\", args=(mu, sigma)))\n",
    "plt.plot(x, stats.norm.pdf(x, mu, sigma), linewidth=6, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from scipy.integrate import simps, trapz\n",
    "from astropy.stats.biweight import biweight_midvariance\n",
    "\n",
    "\n",
    "def filter_df(df, prop_dict):\n",
    "    processed_df = df.copy()\n",
    "    for prop in prop_dict:\n",
    "        processed_df = processed_df[\n",
    "            (processed_df[prop] > prop_dict[prop][0])\n",
    "            & (processed_df[prop] < prop_dict[prop][1])\n",
    "        ]\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def get_stats(df, thresh):\n",
    "    trajectories = df.iloc[:, :t_end]\n",
    "    p = trajectories.apply(lambda x: x / x[0], axis=1)\n",
    "    #     p['bin'] = df['bin']\n",
    "    pbar = p.mean()\n",
    "    mu = trajectories.mean()\n",
    "    sigma2 = (p - pbar) ** 2\n",
    "    #     sigma2 = (1.48*df.iloc[:,:t_end].groupby(df['bin']).mad()[df.groupby(df['bin']).size() > thresh])**2\n",
    "    #     sigma2 = (df.iloc[:,:t_end].groupby(df['bin']).iqr()[df.groupby(df['bin']).size() > thresh]/1.35)**2\n",
    "    #     sigma2 = sigma2 - (pbar**2).multiply(sigma2[0].values,axis=0)\n",
    "    return pbar, mu, sigma2\n",
    "\n",
    "\n",
    "def nu_int(pbar, mu, sigma, q=1):\n",
    "    nu_dict = {}  # pd.Series()\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    y = sigma2\n",
    "    #     print(y)\n",
    "    dp = pbar.values\n",
    "    dp = dp[pbar.values > 1 - q]\n",
    "    #     print(y.shape, )\n",
    "    f = y.iloc[pbar.values > 1 - q]\n",
    "\n",
    "    nu_dict[name] = cq * simps(f, dp)\n",
    "\n",
    "    return pd.Series(nu_dict)\n",
    "\n",
    "\n",
    "def fluct_plot(pbar, mu, sigma2, thresh, q=1):\n",
    "    hist_df = df.groupby(df[\"bin\"]).size()\n",
    "    hist_df = hist_df[hist_df.values > thresh]\n",
    "    #     print(hist_df)\n",
    "    #     print(f'Total number of cells is {np.sum(hist_df.values)}')\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cmap = cm.get_cmap(\"coolwarm\")\n",
    "\n",
    "    y = sigma2 * mu[0]\n",
    "    y[np.isnan(y)] = 0\n",
    "\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    #     cq = -1/(q*(1/2 - (2/3)*q**2))\n",
    "\n",
    "    nu = np.nanmean(\n",
    "        cq * simps(y.T.iloc[pbar.values > 1 - q].T, pbar.iloc[pbar.values > 1 - q])\n",
    "    )\n",
    "    #     qind = (pbar.values > (1/2 - q)) & (pbar.values < (1/2 + q))\n",
    "    #     print(cq,pbar.iloc[qind],y.T.iloc[qind].T)\n",
    "    #     nu = np.nanmean(cq*simps(y.T.iloc[qind].T,pbar.iloc[qind]))\n",
    "\n",
    "    #     c = (name.left - imin)/(imax - imin)\n",
    "    plt.scatter(1 - pbar, np.nanmean(y, axis=0), color=\"k\", label=\"Single-cell data\")\n",
    "    #     plt.fill_between(1-pbar,np.nanmean(y,axis=0),alpha=.1,color='r')\n",
    "\n",
    "    p = np.linspace(0, 1, 1000)\n",
    "    plt.plot(\n",
    "        p,\n",
    "        nu * p * (1 - p),\n",
    "        linewidth=6,\n",
    "        alpha=0.5,\n",
    "        color=\"g\",\n",
    "        label=\"Theoretical curve\",\n",
    "    )\n",
    "    p_left = np.linspace(0, q, 100)\n",
    "    p_right = np.linspace(q, 1, 100)\n",
    "\n",
    "    plt.fill_between(\n",
    "        p_left,\n",
    "        nu * p_left * (1 - p_left),\n",
    "        alpha=0.3,\n",
    "        color=\"c\",\n",
    "        label=\"Integrated area\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        p_right,\n",
    "        nu * p_right * (1 - p_right),\n",
    "        alpha=0.3,\n",
    "        color=\"r\",\n",
    "        hatch=\"/\",\n",
    "        label=\"Interpolated area\",\n",
    "    )\n",
    "\n",
    "    plt.vlines(\n",
    "        q, 0, nu * q * (1 - q), alpha=0.5, linewidth=5, color=\"m\", label=f\"q = {q}\"\n",
    "    )\n",
    "    plt.title(\n",
    "        rf\"$\\nu =  {-cq:.1f} \\cdot \\int\\frac{{\\hat{{\\sigma}}^2}}{{f_{{max}}}}dp$ = {nu:.6f}\",\n",
    "        fontsize=20,\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.xlabel(r\"$(1-\\hat{p})$\", fontsize=20)\n",
    "    plt.ylabel(r\"$\\frac{\\hat{\\sigma}^2}{f_{max}}$\", fontsize=20)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "#     plt.ylim(bottom=0,top=.0004)\n",
    "thresh = 50\n",
    "\n",
    "prop_dict = {\n",
    "    \"centroid_x\": [500, 1700],\n",
    "    \"centroid_y\": [500, 1700],\n",
    "    \"area\": [\n",
    "        data.area.median() - 2 * data.area.std(),\n",
    "        data.area.median() + 2 * data.area.std(),\n",
    "    ],\n",
    "    0: [500, 3000],\n",
    "}\n",
    "# prop_dict = {'area': [data.area.median() - 2*data.area.std(), data.area.median() + 2*data.area.std()],\n",
    "#               0: [800, 3000]}\n",
    "\n",
    "df = filter_df(data, prop_dict)\n",
    "print(f\"Total number of cells used is {df.shape[0]} out of {data.shape[0]}\")\n",
    "pbar, mu, sigma2 = get_stats(df, thresh)\n",
    "\n",
    "q = 1 / 2\n",
    "# nu_df = nu_int(pbar,mu,sigma2,q)\n",
    "# print(nu_df)\n",
    "\n",
    "fluct_plot(pbar, mu, sigma2, thresh, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from scipy.integrate import simps, trapz\n",
    "from astropy.stats.biweight import biweight_midvariance\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import least_squares\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def func1(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "\n",
    "def func2(x, t, y):\n",
    "    return x[0] * np.exp(-x[1] * t) - y\n",
    "\n",
    "\n",
    "def filter_df(df, prop_dict):\n",
    "    processed_df = df.copy()\n",
    "    for prop in prop_dict:\n",
    "        processed_df = processed_df[\n",
    "            (processed_df[prop] > prop_dict[prop][0])\n",
    "            & (processed_df[prop] < prop_dict[prop][1])\n",
    "        ]\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def tau_interp(y, t, kbar, k):\n",
    "    #     k = curve_fit(func, t, y)[0][1]\n",
    "    #     k = np.polyfit(t[0:600],np.log(y[0:600]),1)[0]\n",
    "    #     k = np.mean((y[:-1] - y[1:])/(y[:-1]))\n",
    "    #     print(k,kbar)\n",
    "\n",
    "    tau = (kbar / k * t).astype(np.int)\n",
    "    tau = tau[tau < y.shape[0]]\n",
    "    #     print(k)\n",
    "    y_tau = y[tau]\n",
    "    if y.shape[0] > tau.shape[0]:\n",
    "        y_tau = np.pad(\n",
    "            y_tau, (0, t.shape[0] - tau.shape[0]), \"constant\", constant_values=np.nan\n",
    "        )\n",
    "\n",
    "    #     print(type(y_tau))\n",
    "    #     y_tau = y*np.exp((k-kbar)*t)\n",
    "    return row\n",
    "\n",
    "\n",
    "def nl_correct(row):\n",
    "    tpoints = np.arange(0, t_end)\n",
    "    p, _ = curve_fit(func1, tpoints, row, p0=[row[0] - row.min(), 0.001, row.min()])\n",
    "    #     return pd.Series(func1(tpoints,p[0],p[1],0))\n",
    "    #     print(p[1])\n",
    "    return (row - p[2]) * p[0] / row.iloc[0]\n",
    "\n",
    "\n",
    "def get_stats(df):\n",
    "\n",
    "    #     df_agg = df.groupby('bin').mean()\n",
    "    #     k_agg = df_agg.apply(lambda y: (y.values[0] - y.values[t_end-1])/np.sum(y[:t_end].values),axis=1)\n",
    "    #     df['k_agg'] = k_agg[df['bin']].values\n",
    "    #     y = df.apply(lambda f: tau_interp(f.values[:t_end],np.arange(t_end),np.nanmean(k_agg),f['k_agg']),axis=1)\n",
    "\n",
    "    y = df.iloc[:, :t_end]\n",
    "    #     y = y - 1.13*y.min(axis=1).mean()#[:,np.newaxis]\n",
    "    y = y.apply(nl_correct, axis=1)\n",
    "    print(y.shape)\n",
    "    p = pd.DataFrame(y.values / y[0].values[:, np.newaxis])\n",
    "\n",
    "    pbar = p.mean()\n",
    "    mu = y.mean()\n",
    "    sigma2 = (p - pbar) ** 2\n",
    "    #     sigma2 -= sigma2[0]*pbar**2\n",
    "    #     sigma2 = y.var() - y[0].var()*pbar**2\n",
    "\n",
    "    #     sigma2 = pd.DataFrame(sigma2.values*y[0].values[:,np.newaxis])\n",
    "    return y, pbar, mu, sigma2\n",
    "\n",
    "\n",
    "def nu_int(pbar, mu, sigma, q=1):\n",
    "    nu_dict = {}  # pd.Series()\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    y = sigma2\n",
    "    #     print(y)\n",
    "    dp = pbar.values\n",
    "    dp = dp[pbar.values > 1 - q]\n",
    "    #     print(y.shape, )\n",
    "    f = y.iloc[pbar.values > 1 - q]\n",
    "\n",
    "    nu_dict[name] = cq * simps(f, dp)\n",
    "\n",
    "    return pd.Series(nu_dict)\n",
    "\n",
    "\n",
    "def fluct_plot(pbar, mu, sigma2, y0, q=1):\n",
    "    #     print(hist_df)\n",
    "    #     print(f'Total number of cells is {np.sum(hist_df.values)}')\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cmap = cm.get_cmap(\"coolwarm\")\n",
    "    y = pd.DataFrame(sigma2.values * y0.values[:, np.newaxis])\n",
    "    #     y -= y.iloc[1]*pbar**2\n",
    "    y = y.iloc[:, 1:]\n",
    "    pbar = pbar.iloc[1:]\n",
    "    ybar = y.mean(axis=0)\n",
    "    ybar -= ybar.iloc[0] * pbar**2\n",
    "    print(y.shape, pbar.shape)\n",
    "    #     y = sigma2*mu[0]\n",
    "    y[np.isnan(y)] = 0\n",
    "\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    #     cq = -1/(q*(1/2 - (2/3)*q**2))\n",
    "\n",
    "    #     nu = np.nanmean(cq*simps(y.T.iloc[pbar.values > 1-q].T,pbar.iloc[pbar.values > 1-q]))\n",
    "    nu = cq * simps(ybar.T.iloc[pbar.values > 1 - q].T, pbar.iloc[pbar.values > 1 - q])\n",
    "    #     qind = (pbar.values > (1/2 - q)) & (pbar.values < (1/2 + q))\n",
    "    #     print(cq,pbar.iloc[qind],y.T.iloc[qind].T)\n",
    "    #     nu = np.nanmean(cq*simps(y.T.iloc[qind].T,pbar.iloc[qind]))\n",
    "\n",
    "    #     c = (name.left - imin)/(imax - imin)\n",
    "    plt.scatter(1 - pbar, ybar, color=\"k\", label=\"Single-cell data\")\n",
    "    #     plt.fill_between(1-pbar,np.nanmean(y,axis=0),alpha=.1,color='r')\n",
    "\n",
    "    p = np.linspace(0, 1, 1000)\n",
    "    plt.plot(\n",
    "        p,\n",
    "        nu * p * (1 - p),\n",
    "        linewidth=6,\n",
    "        alpha=0.5,\n",
    "        color=\"g\",\n",
    "        label=\"Theoretical curve\",\n",
    "    )\n",
    "    p_left = np.linspace(0, q, 100)\n",
    "    p_right = np.linspace(q, 1, 100)\n",
    "\n",
    "    plt.fill_between(\n",
    "        p_left,\n",
    "        nu * p_left * (1 - p_left),\n",
    "        alpha=0.3,\n",
    "        color=\"c\",\n",
    "        label=\"Integrated area\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        p_right,\n",
    "        nu * p_right * (1 - p_right),\n",
    "        alpha=0.3,\n",
    "        color=\"r\",\n",
    "        hatch=\"/\",\n",
    "        label=\"Interpolated area\",\n",
    "    )\n",
    "\n",
    "    plt.vlines(\n",
    "        q, 0, nu * q * (1 - q), alpha=0.5, linewidth=5, color=\"m\", label=f\"q = {q}\"\n",
    "    )\n",
    "    plt.title(\n",
    "        rf\"$\\nu =  {-cq:.1f} \\cdot \\int\\frac{{\\hat{{\\sigma}}^2}}{{f_{{max}}}}dp$ = {nu:.6f}\",\n",
    "        fontsize=20,\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.xlabel(r\"$(1-\\hat{p})$\", fontsize=20)\n",
    "    plt.ylabel(r\"$\\frac{\\hat{\\sigma}^2}{f_{max}}$\", fontsize=20)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "#     plt.ylim(bottom=0,top=.0004)\n",
    "\n",
    "\n",
    "def kmaps(df):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(24, 12))\n",
    "\n",
    "    cmap = cm.get_cmap(\"coolwarm\")\n",
    "\n",
    "    fit_df = df[[\"centroid_x\", \"centroid_y\", \"k\", 0]].copy()\n",
    "    fit_df[\"c_k\"] = (fit_df.k - fit_df.k.min()) / (fit_df.k.max() - fit_df.k.min())\n",
    "    fit_df[\"c_I0\"] = (fit_df[0] - fit_df[0].min()) / (fit_df[0].max() - fit_df[0].min())\n",
    "\n",
    "    sns.regplot(\n",
    "        data=fit_df,\n",
    "        x=\"centroid_x\",\n",
    "        y=\"centroid_y\",\n",
    "        fit_reg=False,\n",
    "        ax=axs[0],\n",
    "        scatter_kws={\"color\": cmap(fit_df[\"c_k\"])},\n",
    "    )\n",
    "    sns.regplot(\n",
    "        data=fit_df,\n",
    "        x=\"centroid_x\",\n",
    "        y=\"centroid_y\",\n",
    "        fit_reg=False,\n",
    "        ax=axs[1],\n",
    "        scatter_kws={\"color\": cmap(fit_df[\"c_I0\"])},\n",
    "    )\n",
    "\n",
    "    axs[0].set_xlim([0, 2000])\n",
    "    axs[0].set_ylim([0, 2000])\n",
    "    axs[1].set_xlim([0, 2000])\n",
    "    axs[1].set_ylim([0, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "prop_dict = {\n",
    "    \"area\": [\n",
    "        data.area.median() - 2 * data.area.std(),\n",
    "        data.area.median() + 2 * data.area.std(),\n",
    "    ],\n",
    "    0: [1000, 2500],\n",
    "    t_end - 1: [0, 400],\n",
    "    \"k\": [0.0075, 0.009],\n",
    "}\n",
    "# prop_dict = {'area': [data.area.median() - 2*data.area.std(), data.area.median() + 2*data.area.std()],\n",
    "#              'k': [.0038,.004],\n",
    "#               0: [4e4,1e5]}\n",
    "# prop_dict = {'area': [data.area.median() - 2*data.area.std(), data.area.median() + 2*data.area.std()],\n",
    "#               0: [1400, 2500], t_end-1: [50,300],\n",
    "#              'k': [.007,.0085]}\n",
    "# prop_dict = {'centroid_x': [850, 1250],\n",
    "#              'centroid_y': [750, 1150],\n",
    "#              'area': [data.area.median() - 2*data.area.std(), data.area.median() + 2*data.area.std()],\n",
    "#              0: [500, 3000]}\n",
    "\n",
    "df = filter_df(data, prop_dict)\n",
    "df.k.hist(bins=30)\n",
    "\n",
    "\n",
    "y, pbar, mu, sigma2 = get_stats(df)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.semilogy(y.T.values[:, ::20] + 1)\n",
    "plt.ylim(bottom=1)\n",
    "\n",
    "q = 0.7\n",
    "\n",
    "\n",
    "fluct_plot(pbar, mu, sigma2, y[0], q)\n",
    "\n",
    "kmaps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.figure(figsize=(12,8))\n",
    "\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(24, 12))\n",
    "\n",
    "cmap = cm.get_cmap(\"coolwarm\")\n",
    "\n",
    "\n",
    "fit_df = df[[\"centroid_x\", \"centroid_y\", \"k\", 0]].copy()\n",
    "# fit_df = fit_df[fit_df[0] > 1000]\n",
    "# fit_df = fit_df[fit_df['k'] < .003]\n",
    "\n",
    "fit_df[\"c_k\"] = (fit_df.k - fit_df.k.min()) / (fit_df.k.max() - fit_df.k.min())\n",
    "fit_df[\"c_I0\"] = (fit_df[0] - fit_df[0].min()) / (fit_df[0].max() - fit_df[0].min())\n",
    "\n",
    "print(\"plotting!\")\n",
    "sns.regplot(\n",
    "    data=fit_df,\n",
    "    x=\"centroid_x\",\n",
    "    y=\"centroid_y\",\n",
    "    fit_reg=False,\n",
    "    ax=axs[0],\n",
    "    scatter_kws={\"color\": cmap(fit_df[\"c_k\"])},\n",
    ")\n",
    "sns.regplot(\n",
    "    data=fit_df,\n",
    "    x=\"centroid_x\",\n",
    "    y=\"centroid_y\",\n",
    "    fit_reg=False,\n",
    "    ax=axs[1],\n",
    "    scatter_kws={\"color\": cmap(fit_df[\"c_I0\"])},\n",
    ")\n",
    "\n",
    "\n",
    "# sns.plt.show()\n",
    "\n",
    "# for x, y, c_k, c_I0 in zip(fit_df.centroid_x, fit_df.centroid_y, fit_df.c_k, fit_df.c_I0):\n",
    "# #     print(x,y,c)\n",
    "#     axs[0].scatter(x,y,color=cmap(c_k))\n",
    "#     axs[1].scatter(x,y,color=cmap(c_I0))\n",
    "\n",
    "axs[0].set_xlim([0, 2000])\n",
    "axs[0].set_ylim([0, 2000])\n",
    "axs[1].set_xlim([0, 2000])\n",
    "axs[1].set_ylim([0, 2000])\n",
    "\n",
    "# m_list = []\n",
    "# for i in range(traces.shape[0]):\n",
    "#     y = np.log10(traces[i]-bg_trace)\n",
    "\n",
    "#     m, b = np.polyfit(x[:-3],y[:-3],1)\n",
    "#     m_list.append(m)\n",
    "# # plt.plot(x,y)\n",
    "# plt.hist(m_list,bins=30)\n",
    "# print(np.mean(m_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from scipy.integrate import simps\n",
    "from astropy.stats.biweight import biweight_midvariance\n",
    "\n",
    "\n",
    "def filter_df(df, prop_dict):\n",
    "    processed_df = df.copy()\n",
    "    for prop in prop_dict:\n",
    "        processed_df = processed_df[\n",
    "            (processed_df[prop] > prop_dict[prop][0])\n",
    "            & (processed_df[prop] < prop_dict[prop][1])\n",
    "        ]\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "def get_stats(df, thresh):\n",
    "    trajectories = df.iloc[:, :t_end]\n",
    "    p = trajectories.apply(lambda x: x / x[0], axis=1)\n",
    "    p[\"bin\"] = df[\"bin\"]\n",
    "    pbar = p.groupby(p[\"bin\"]).mean()[p.groupby(p[\"bin\"]).size() > thresh]\n",
    "    mu = trajectories.groupby(df[\"bin\"]).mean()[df.groupby(df[\"bin\"]).size() > thresh]\n",
    "    sigma2 = trajectories.groupby(df[\"bin\"]).var(ddof=0)[\n",
    "        df.groupby(df[\"bin\"]).size() > thresh\n",
    "    ]\n",
    "    #     sigma2 = (1.48*df.iloc[:,:t_end].groupby(df['bin']).mad()[df.groupby(df['bin']).size() > thresh])**2\n",
    "    #     sigma2 = (df.iloc[:,:t_end].groupby(df['bin']).iqr()[df.groupby(df['bin']).size() > thresh]/1.35)**2\n",
    "    #     sigma2 = sigma2 - (pbar**2).multiply(sigma2[0].values,axis=0)\n",
    "    return pbar, mu, sigma2\n",
    "\n",
    "\n",
    "def nu_int(pbar, mu, sigma, q=1):\n",
    "    nu_dict = {}  # pd.Series()\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    y = sigma2.div(mu[0].values, axis=\"rows\")\n",
    "    for name, group in pbar.groupby(\"bin\"):\n",
    "        dp = pbar.loc[name].values\n",
    "        dp = dp[pbar.loc[name].values > 1 - q]\n",
    "        f = y.loc[name].values[pbar.loc[name].values > 1 - q]\n",
    "        nu_dict[name] = cq * simps(f, dp)\n",
    "\n",
    "    return pd.Series(nu_dict)\n",
    "\n",
    "\n",
    "def fluct_plot(pbar, mu, sigma2, thresh, q=1):\n",
    "    hist_df = df.groupby(df[\"bin\"]).size()\n",
    "    hist_df = hist_df[hist_df.values > thresh]\n",
    "    print(hist_df)\n",
    "    print(f\"Total number of cells is {np.sum(hist_df.values)}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cmap = cm.get_cmap(\"coolwarm\")\n",
    "\n",
    "    y = sigma2.div(mu[0].values, axis=\"rows\")\n",
    "    imax = pbar.index[-1].left\n",
    "    imin = pbar.index[0].left\n",
    "    q = 1\n",
    "    cq = -1 / (1 / 2 * q**2 - 1 / 3 * q**3)\n",
    "    # plt.vlines(q,0,3)\n",
    "\n",
    "    for name, group in pbar.groupby(\"bin\"):\n",
    "        c = (name.left - imin) / (imax - imin)\n",
    "        plt.scatter(\n",
    "            1 - pbar.loc[name].values,\n",
    "            y.loc[name].values,\n",
    "            color=cmap(c),\n",
    "            label=name.left,\n",
    "        )\n",
    "        plt.legend()\n",
    "\n",
    "    p = np.linspace(0, 1, 1000)\n",
    "    plt.plot(p, nu_df.mean() * p * (1 - p), linewidth=6, alpha=0.8, color=\"g\")\n",
    "\n",
    "    plt.title(\n",
    "        rf\"$\\nu =  {-cq:.0f} \\cdot \\int\\frac{{\\hat{{\\sigma}}^2}}{{f_{{max}}}}dp$ = {nu_df.mean():.2f}\",\n",
    "        fontsize=20,\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.xlabel(r\"$(1-\\hat{p})$\", fontsize=20)\n",
    "    plt.ylabel(r\"$\\frac{\\hat{\\sigma}^2}{f_{max}}$\", fontsize=20)\n",
    "\n",
    "\n",
    "#     plt.ylim([0,.0001])\n",
    "thresh = 100\n",
    "\n",
    "# prop_dict = {'centroid_x': [500, 1700],\n",
    "#              'centroid_y': [500, 1700],\n",
    "#              'area': [data.area.median() - 2*data.area.std(), data.area.median() + 2*data.area.std()],\n",
    "#              0: [800, 3000]}\n",
    "prop_dict = {\n",
    "    \"area\": [\n",
    "        data.area.median() - 2 * data.area.std(),\n",
    "        data.area.median() + 2 * data.area.std(),\n",
    "    ],\n",
    "    0: [800, 3000],\n",
    "}\n",
    "\n",
    "df = filter_df(data, prop_dict)\n",
    "pbar, mu, sigma2 = get_stats(df, thresh)\n",
    "\n",
    "q = 1\n",
    "nu_df = nu_int(pbar, mu, sigma2, q)\n",
    "print(nu_df)\n",
    "\n",
    "fluct_plot(pbar, mu, sigma2, thresh, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=250\n",
    "# traces = measurements['mean']\n",
    "idxs = np.random.permutation(traces.shape[0])\n",
    "downsample = (\n",
    "    10  # set to 1 to show all traces (instead of 10%); this will make your browser slow\n",
    ")\n",
    "curves = [\n",
    "    {\"x\": np.arange(traces.shape[1]), \"y\": df[i], \"i\": idxs[i]}\n",
    "    for i in range(traces.shape[0] // downsample)\n",
    "]\n",
    "hv.Contours(curves, vdims=[\"i\"]).options(color_index=\"i\", cmap=\"Category20\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I0 = traces[:, 0]\n",
    "plt.hist(I0, bins=30)\n",
    "print(np.mean(I0), np.std(I0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap(\"coolwarm\")\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(24, 12))\n",
    "gridfig, gridaxs = plt.subplots(\n",
    "    nrows=int(np.ceil(nu_df.size / 4)), ncols=4, figsize=(24, 30)\n",
    ")\n",
    "imax = df.bin.values[-1].left\n",
    "imin = df.bin.values[0].left\n",
    "ind = 0\n",
    "for name, group in df.groupby(\"bin\"):\n",
    "    if group.shape[0] > thresh:  # & (np.round(name.left) == 3352):\n",
    "        #         c = .5\n",
    "        c = (name.left - imin) / (imax - imin)\n",
    "        #         c = (nu_df[name] - nu_df.min())/(nu_df.max() - nu_df.min())\n",
    "        #         z = name.left*np.ones(group.centroid_x.shape)\n",
    "\n",
    "        axs[0].scatter(\n",
    "            group.centroid_x, group.centroid_y, color=cmap(c), marker=\"o\", s=16\n",
    "        )  # , label=nu_df[name])\n",
    "        axs[0].set_xlim(data.centroid_x.min(), data.centroid_x.max())\n",
    "        axs[0].set_ylim(data.centroid_y.min(), data.centroid_y.max())\n",
    "        axs[1].semilogy(group.iloc[:, :t_end].T, color=cmap(c))\n",
    "        axs[1].set_ylim([1, 3000])\n",
    "        #         tempfig = plt.figure(figsize=(8,8))\n",
    "        gridaxs.flatten()[ind].semilogy(group.iloc[:, :t_end].T, color=cmap(c))\n",
    "        #         gridaxs.flatten()[ind].set_title(rf'Interval = {str(name)}, $\\nu = $ {nu_df[name]:.2f}')\n",
    "        gridaxs.flatten()[ind].set_ylim([1, 2000])\n",
    "        ind += 1\n",
    "    else:\n",
    "        axs[0].scatter(\n",
    "            group.centroid_x, group.centroid_y, color=\"k\", marker=\"x\", s=12, alpha=0.3\n",
    "        )\n",
    "gridfig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
