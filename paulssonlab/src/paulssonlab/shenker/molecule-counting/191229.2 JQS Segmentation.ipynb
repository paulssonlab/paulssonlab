{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nd2reader\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import regrid\n",
    "import skimage.filters\n",
    "import skimage.feature\n",
    "import scipy.ndimage\n",
    "import peakutils\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import dask\n",
    "import dask.array as da\n",
    "import distributed\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from cytoolz import partial, compose, juxt\n",
    "from itertools import repeat\n",
    "from glob import glob\n",
    "import cachetools\n",
    "import numpy_indexed\n",
    "import pickle\n",
    "import pyarrow as pa\n",
    "import warnings\n",
    "import os\n",
    "from numbers import Integral\n",
    "from dask.delayed import Delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from segmentation import *\n",
    "# from util import *\n",
    "# from matriarch_stub import *\n",
    "import segmentation\n",
    "import matriarch_stub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask.config.config['distributed']['scheduler']['allowed-failures'] = 20\n",
    "# dask.config.config['distributed']['worker']['memory'] = {'target': 0.4,\n",
    "#                                                         'spill': 0.5,\n",
    "#                                                         'pause': 0.9,\n",
    "#                                                         'terminate': 0.95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"03:00:00\",\n",
    "    memory=\"8GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/projects/molecule-counting/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "# diagnostics_port=('127.0.0.1', 8787),\n",
    "# env_extra=['export PYTHONPATH=\\\"/home/jqs1/projects/matriarch\\\"'])\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogenous cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# filter/debug bad FOVs\n",
    "# reduce churn/transfers\n",
    "# set up benchmarking tool, compare different chunking\n",
    "# arbitrary sequence of traces using initial segmentation (replace sandwich)\n",
    "# dry run without regionprops\n",
    "# fix regionprops memory usage\n",
    "# optimize submission performance\n",
    "\n",
    "# BENCHMARK: try readahead buffering/chunk size\n",
    "# named_funcs_as_juxt: decorator to turn {'func1': func1, ('q0.5', 'q0.7'): partial(np.percentile, q=(0.5,0.7))} into a multiple-valued func\n",
    "# zarrification of labels (skip??)\n",
    "# pin segmentation tasks to high-RAM nodes (in heterogenous dask cluster)\n",
    "\n",
    "# convert dask arrays to delayed before calling short_circuit_none (otherwise we wait until all frames are in RAM)\n",
    "# don't process FOV if too many labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ary = segmentation.nd2_to_dask(\n",
    "    \"/n/scratch2/jqs1/190922/190922_photobleaching_greens/GFP_photobleaching_100pct_100ms_0001.nd2\",\n",
    "    0,\n",
    "    \"GFP-PENTA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = segmentation.segment(ary[0].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_delayed0 = dask.delayed(segmentation.segment)(ary[0].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_delayed = dask.delayed(segmentation.segment)(ary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = ary[:10].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, z = segmentation.aggregate_dask(partial(np.mean, axis=1), labels, stack)\n",
    "z[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, z = segmentation.aggregate_dask(partial(np.mean, axis=1), labels, ary[:10])\n",
    "z[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, z = segmentation.aggregate_dask(partial(np.mean, axis=1), labels_delayed, ary)\n",
    "z  # [0]#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = z.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"/n/scratch2/jqs1\"\n",
    "fluorescence_filenames = glob(\n",
    "    os.path.join(base_filename, \"190922/*/*photobleaching*.nd2\")\n",
    ")\n",
    "phase_filenames = (\n",
    "    []\n",
    ")  # glob(os.path.join(base13_filename, 'phase/*_0001.nd2')) + glob('/n/scratch2/jqs1/fidelity/190325/phase/*/*_0001.nd2')\n",
    "sandwich_filenames = []  # glob(os.path.join(base13_filename, 'sandwich/*_0001.nd2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluorescence_filenames = fluorescence_filenames[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = None  # not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graph = {}\n",
    "for photobleaching_filename in fluorescence_filenames[:]:\n",
    "    data_graph[photobleaching_filename] = segmentation.process_file(\n",
    "        funcs, photobleaching_filename\n",
    "    )\n",
    "\n",
    "# for photobleaching_filename in phase_filenames[:]:\n",
    "#     segmentation_filename = photobleaching_filename.replace('_0001.nd2', '.nd2')\n",
    "#     data_graph[segmentation_filename] = segmentation.process_file(funcs, photobleaching_filename,\n",
    "#                                                                     segmentation_filename=segmentation_filename)\n",
    "\n",
    "# for initial_filename in sandwich_filenames[:]:\n",
    "#     segmentation_filename = initial_filename.replace('_0001.nd2', '.nd2')\n",
    "#     photobleaching_filename = initial_filename.replace('_0001.nd2', '_0002.nd2')\n",
    "#     final_filename = initial_filename.replace('_0001.nd2', '_0003.nd2')\n",
    "#     data_graph[segmentation_filename] = segmentation.process_file(funcs, photobleaching_filename,\n",
    "#                                                                   segmentation_filename=segmentation_filename,\n",
    "#                                                                   initial_filename=initial_filename,\n",
    "#                                                                   final_filename=final_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up computes so we can gather results from multiple workers\n",
    "# (otherwise the single worker assembling the dict will run out of memory)\n",
    "# TODO: use recursive_map(..., levels=?)\n",
    "data_futures = {\n",
    "    k: {k2: client.compute(v2) for k2, v2 in v.items()} for k, v in data_graph.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.gather(data_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/n/groups/paulsson/jqs1/molecule-counting/191229photobleaching.pickle\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    k: {pos: np.asarray(d[\"labels\"]).max() for pos, d in v.items()}\n",
    "    for k, v in data.items()\n",
    "    if k[0] != \"_\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[\n",
    "    \"/n/scratch2/jqs1/190922/CFP_photobleaching/CFP_photobleaching_50pct_100ms.nd2_0054.nd2\"\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(d[\"segmentation_frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(d[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
