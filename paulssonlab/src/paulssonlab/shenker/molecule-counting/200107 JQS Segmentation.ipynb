{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nd2reader\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import regrid\n",
    "import skimage.filters\n",
    "import skimage.feature\n",
    "import scipy.ndimage\n",
    "import peakutils\n",
    "from tqdm.autonotebook import tqdm\n",
    "import dask\n",
    "import dask.array as da\n",
    "import distributed\n",
    "from distributed import Client, LocalCluster, progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from cytoolz import partial, compose, juxt\n",
    "from itertools import repeat\n",
    "from glob import glob\n",
    "import cachetools\n",
    "import numpy_indexed\n",
    "import pickle\n",
    "import pyarrow as pa\n",
    "import warnings\n",
    "import os\n",
    "from numbers import Integral\n",
    "from dask.delayed import Delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from segmentation import *\n",
    "# from util import *\n",
    "# from matriarch_stub import *\n",
    "import segmentation\n",
    "import matriarch_stub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask.config.config['distributed']['scheduler']['allowed-failures'] = 20\n",
    "# dask.config.config['distributed']['worker']['memory'] = {'target': 0.4,\n",
    "#                                                         'spill': 0.5,\n",
    "#                                                         'pause': 0.9,\n",
    "#                                                         'terminate': 0.95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue=\"short\",\n",
    "    walltime=\"03:00:00\",\n",
    "    memory=\"8GB\",\n",
    "    local_directory=\"/tmp\",\n",
    "    log_directory=\"/home/jqs1/projects/molecule-counting/log\",\n",
    "    cores=1,\n",
    "    processes=1,\n",
    ")\n",
    "# diagnostics_port=('127.0.0.1', 8787),\n",
    "# env_extra=['export PYTHONPATH=\\\"/home/jqs1/projects/matriarch\\\"'])\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogenous cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# fix autothresholding\n",
    "# break up segment into sub-functions\n",
    "# handwrite frangi that works with float32, uint16 (github issue for float32 bug)\n",
    "\n",
    "# memory profile regionprops\n",
    "\n",
    "# tree() that records insertion times, utility func to turn into benchmarking for each step (hierarchical inter-step times)\n",
    "# split photobleaching task into multiple sub-tasks (each is a single-threaded .compute() call)\n",
    "# pin segmentation/regionprops tasks to high-RAM nodes (in heterogenous dask cluster)\n",
    "\n",
    "# filter by FOCUS (???)\n",
    "\n",
    "# named_funcs_as_juxt: decorator to turn {'func1': func1, ('q0.5', 'q0.7'): partial(np.percentile, q=(0.5,0.7))} into a multiple-valued func\n",
    "# zarrification of labels (skip??)\n",
    "\n",
    "# pass in frame metadata to filter funcs (requires unified metadata representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_frame_filter(img):\n",
    "    return True\n",
    "\n",
    "\n",
    "def segmentation_labels_filter(labels, img):\n",
    "    return labels.max() < 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"/n/scratch2/jqs1\"\n",
    "# filenames = glob(os.path.join(base_filename, '190922/*/*photobleaching*.nd2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: try segmenting everything in phase (to reduce bias of segmenting in different channels)\n",
    "# G_GR  G_RG  G-R_GR  G-R_RG  R-G_GR  R_GR  R-G_RG  R_RG\n",
    "seg_channel_to_files = {\n",
    "    \"RFP-PENTA\": [\"191312/R_RG/*.nd2\"],\n",
    "    #'191312/R_GR/*.nd2'], # missing GFP-PENTA for all but one\n",
    "    \"GFP-PENTA\": [\n",
    "        \"191312/G_GR/*.nd2\",\n",
    "        \"191312/G_RG/*.nd2\",\n",
    "        \"191312/G-R_GR/GR*.nd2\",  # missing RFP-PENTA for all but two\n",
    "        \"191312/G-R_RG/*.nd2\",\n",
    "        \"191312/R-G_GR/*.nd2\",\n",
    "        \"191312/R-G_RG/*.nd2\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation.cluster_nd2_by_positions(glob(os.path.join(base_filename, '191312/R-G_GR/*.nd2')), ignored_channels=['BF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = None  # not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graph = {}\n",
    "for segmentation_channel, file_patterns in tqdm(seg_channel_to_files.items()):\n",
    "    for file_pattern in file_patterns:\n",
    "        data_graph[file_pattern] = {}\n",
    "        filenames = glob(os.path.join(base_filename, file_pattern))\n",
    "        clustered_filenames = segmentation.cluster_nd2_by_positions(\n",
    "            filenames, ignored_channels=[\"BF\"]\n",
    "        )\n",
    "        for channel_to_file in tqdm(clustered_filenames.values()):\n",
    "            segmentation_filename = channel_to_file[segmentation_channel]\n",
    "            channels = list(set(channel_to_file.keys()) - set([\"BF\"]))\n",
    "            d = {}\n",
    "            for channel in channels:\n",
    "                d[channel] = segmentation.process_photobleaching_file(\n",
    "                    funcs,\n",
    "                    channel_to_file[channel],\n",
    "                    photobleaching_channel=channel,\n",
    "                    segmentation_filename=segmentation_filename,\n",
    "                    segmentation_channel=segmentation_channel,\n",
    "                    time_slice=slice(10),\n",
    "                    rechunk=True,\n",
    "                    segmentation_frame_filter=segmentation_frame_filter,\n",
    "                    segmentation_labels_filter=segmentation_labels_filter,\n",
    "                )\n",
    "            rep = d[channels[0]][0]\n",
    "            seg_data = {\n",
    "                \"segmentation_filename\": segmentation_filename,\n",
    "                \"segmentation_channel\": segmentation_channel,\n",
    "                \"segmentation_frame\": rep[\"segmentation_frame\"],\n",
    "                \"labels\": rep[\"labels\"],\n",
    "                \"traces\": {channel: d[channel][0][\"traces\"] for channel in channels},\n",
    "                \"photobleaching_filenames\": channel_to_file,\n",
    "            }\n",
    "            data_graph[file_pattern][segmentation_filename] = seg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up computes so we can gather results from multiple workers\n",
    "# (otherwise the single worker assembling the dict will run out of memory)\n",
    "# TODO: use recursive_map(..., levels=?)\n",
    "data_futures = {\n",
    "    k: {k2: client.compute(v2) for k2, v2 in v.items()} for k, v in data_graph.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.gather(data_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/n/groups/paulsson/jqs1/molecule-counting/200107photobleaching.pickle\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = pickle.load(\n",
    "    open(\"/n/groups/paulsson/jqs1/molecule-counting/200103photobleaching.pickle\", \"rb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    k: {pos: np.asarray(d[\"labels\"]).max() for pos, d in v.items()}\n",
    "    for k, v in data.items()\n",
    "    if k[0] != \"_\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[\"191312/R-G_RG/*.nd2\"][\n",
    "    \"/n/scratch2/jqs1/191312/R-G_RG/RG_100pct_100ms_100pct_100ms.nd2_0011.nd2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d[\"segmentation_frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(matriarch_stub.permute_labels(d[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(d[\"traces\"][\"GFP-PENTA\"][\"mean\"].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
