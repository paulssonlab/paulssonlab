{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c57f7d-eb34-40e9-b810-10d4c44d68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import operator\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import gfapy\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from pyarrow import csv\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117a156-f6f6-423f-81be-bb5eed890a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d050f91-79f4-491b-a4c4-a208210eff14",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589476b-6033-46ed-9b8f-c4f1d115469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\n",
    "    \"/home/jqs1/scratch/jqs1/sequencing/230818_bcd_rbses/20230818_1343_1A_PAQ97606_f49ab41c\"\n",
    ")\n",
    "gaf_filename = data_dir / \"temp/mapped_t4.gaf\"\n",
    "gfa = gfapy.Gfa.from_file(data_dir / \"references/bcd_rbses.gfa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73add2a-6327-4a1d-a8c5-8d8be4cacd24",
   "metadata": {},
   "source": [
    "# GAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5f3a3-a4a6-4207-a5b3-2cc5e6e4c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEE: http://samtools.github.io/hts-specs/SAMv1.pdf\n",
    "# and https://samtools.github.io/hts-specs/SAMtags.pdf\n",
    "# pyarrow CSV parser only supports pa.dictionary with int32 indices\n",
    "SAM_TAG_TYPES = {\n",
    "    \"A\": pa.dictionary(pa.int32(), pa.string()),\n",
    "    \"f\": pa.float32(),\n",
    "    \"i\": pa.int32(),\n",
    "    \"Z\": pa.string(),\n",
    "}\n",
    "GAF_COLUMN_TYPES = {\n",
    "    \"query_length\": pa.uint64(),\n",
    "    \"query_start\": pa.uint64(),\n",
    "    \"query_end\": pa.uint64(),\n",
    "    \"strand\": pa.dictionary(pa.int32(), pa.string()),\n",
    "    \"path\": pa.string(),\n",
    "    \"path_length\": pa.uint64(),\n",
    "    \"path_start\": pa.uint64(),\n",
    "    \"path_end\": pa.uint64(),\n",
    "    \"residue_matches\": pa.uint64(),\n",
    "    \"block_length\": pa.uint64(),\n",
    "    \"mapping_quality\": pa.uint8(),\n",
    "}\n",
    "SAM_TAG_REGEX = re.compile(\n",
    "    r\"^(?P<tag>[a-zA-Z0-9]+):(?P<tag_value>A:.|f:\\d+(\\.\\d+)?|i:\\d+|Z:.*)$\"\n",
    ")\n",
    "\n",
    "\n",
    "def parse_gaf_types(gaf_filename):\n",
    "    with open(gaf_filename, \"r\") as f:\n",
    "        first_row = f.readline().split(\"\\t\")\n",
    "    columns_to_parse = {}\n",
    "    column_types = []\n",
    "    for idx in reversed(range(len(first_row))):\n",
    "        if match := SAM_TAG_REGEX.match(first_row[idx]):\n",
    "            tag = match.group(\"tag\")\n",
    "            column_types.append((tag, pa.string()))\n",
    "            tag_value = match.group(\"tag_value\")\n",
    "            columns_to_parse[tag] = tag_value[: tag_value.index(\":\")]\n",
    "        else:\n",
    "            break\n",
    "    column_types.extend(reversed(GAF_COLUMN_TYPES.items()))\n",
    "    for idx in reversed(range(idx + 1 - len(GAF_COLUMN_TYPES))):\n",
    "        if match := SAM_TAG_REGEX.match(first_row[idx]):\n",
    "            tag = match.group(\"tag\")\n",
    "            column_types.append((tag, pa.string()))\n",
    "            tag_value = match.group(\"tag_value\")\n",
    "            type_ = tag_value[: tag_value.index(\":\")]\n",
    "            columns_to_parse[tag] = type_\n",
    "        else:\n",
    "            if idx != 0:\n",
    "                raise ValueError(\"expecting SAM tags following FASTQ read name\")\n",
    "            else:\n",
    "                column_types.append((\"name\", pa.string()))\n",
    "    column_types = dict(reversed(column_types))\n",
    "    return column_types, columns_to_parse\n",
    "\n",
    "\n",
    "def parse_gaf_table(table, columns_to_parse):\n",
    "    # TODO: we could convert string read UUIDs (and semicolon-delimited pairs of UUIDs)\n",
    "    # to an extension type to save a small amount of space\n",
    "    # SEE: https://arrow.apache.org/docs/python/extending_types.html#defining-extension-types-user-defined-types\n",
    "    for tag, type_ in columns_to_parse.items():\n",
    "        col_idx = table.column_names.index(tag)\n",
    "        new_column = pc.replace_substring_regex(table[tag], f\"{tag}:{type_}:\", \"\").cast(\n",
    "            SAM_TAG_TYPES[type_]\n",
    "        )\n",
    "        table = table.set_column(col_idx, tag, new_column)\n",
    "    path = pa.array(\n",
    "        [re.split(r\"(?=<|>)\", s.as_py())[1:] for s in table.column(\"path\")],\n",
    "        type=pa.list_(pa.dictionary(pa.int16(), pa.string())),\n",
    "    )\n",
    "    table = table.set_column(table.column_names.index(\"path\"), \"path\", path)\n",
    "    return table\n",
    "\n",
    "\n",
    "def parse_gaf(gaf_filename):\n",
    "    column_types, columns_to_parse = parse_gaf_types(gaf_filename)\n",
    "    read_options = csv.ReadOptions(column_names=column_types.keys())\n",
    "    parse_options = csv.ParseOptions(delimiter=\"\\t\")\n",
    "    convert_options = csv.ConvertOptions(column_types=column_types)\n",
    "    with csv.open_csv(\n",
    "        gaf_filename,\n",
    "        read_options=read_options,\n",
    "        parse_options=parse_options,\n",
    "        convert_options=convert_options,\n",
    "    ) as f:\n",
    "        while True:\n",
    "            try:\n",
    "                table = parse_gaf_table(\n",
    "                    pa.Table.from_batches([f.read_next_batch()]), columns_to_parse\n",
    "                )\n",
    "            except StopIteration:\n",
    "                break\n",
    "            yield table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35736c61-37ce-411e-b859-4539ee95da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd321849-0af8-4423-b51c-0583be13377a",
   "metadata": {},
   "source": [
    "# Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb9871-962f-4db5-83c8-5b8014490e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "segments = Counter()\n",
    "ends = Counter()\n",
    "total_reads = 0\n",
    "for table in tqdm(parse_gaf(gaf_filename)):\n",
    "    path_col = table.column(\"path\")\n",
    "    for idx in range(len(table)):\n",
    "        path = [s[1:] for s in path_col[idx].as_py()]\n",
    "        segments.update(path)\n",
    "        ends[path[0]] += 1\n",
    "        ends[path[-1]] += 1\n",
    "        total_reads += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02cf40-143f-4160-9254-f74acd3518ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sorted(\n",
    "    {k: f\"{v/total_reads*100:.0f}\" for k, v in segments.items()}.items()\n",
    "):\n",
    "    print(f\"{k}: {v}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280303fd-4b87-4a25-9bd1-a365292d0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sorted({k: f\"{v/total_reads*100:.0f}\" for k, v in ends.items()}.items()):\n",
    "    print(f\"{k}: {v}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be42acce-3b4a-466a-ba3f-666370bc8d36",
   "metadata": {},
   "source": [
    "# Duplex barcode mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3190d8-57a9-4518-9464-dabefcd58681",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "total_reads = 0\n",
    "complete_barcodes = 0\n",
    "name_to_barcode = {}\n",
    "for table in tqdm(parse_gaf(gaf_filename)):\n",
    "    name_col = table.column(\"name\")\n",
    "    path_col = table.column(\"path\")\n",
    "    for idx in range(len(table)):\n",
    "        name = name_col[idx].as_py()\n",
    "        path = set([s[1:] for s in path_col[idx].as_py()])\n",
    "        total_reads += 1\n",
    "        if (\"BIT0:0\" in path or \"BIT0:1\" in path) and (\n",
    "            \"BIT29:0\" in path or \"BIT29:1\" in path\n",
    "        ):\n",
    "            complete_barcodes += 1\n",
    "            barcode = tuple(f\"BIT{bit}:1\" in path for bit in range(30))\n",
    "            name_to_barcode[name] = barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8f13a-0979-4c66-ad05-855e3f22ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "(complete_barcodes, total_reads, complete_barcodes / total_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7acd10-93bc-4318-8551-853ba3d05341",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplex_matches = []\n",
    "duplex_mismatches = []\n",
    "duplex_missing = []\n",
    "for name, barcode in tqdm(name_to_barcode.items()):\n",
    "    reads = name.split(\";\")\n",
    "    if len(reads) == 2:\n",
    "        if reads[0] in name_to_barcode and reads[1] in name_to_barcode:\n",
    "            if name_to_barcode[reads[0]] != name_to_barcode[reads[1]]:\n",
    "                duplex_mismatches.append(name)\n",
    "            else:\n",
    "                duplex_matches.append(name)\n",
    "        else:\n",
    "            duplex_missing.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd6f228-0911-43b4-b8a9-8f8bbd4adcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_barcode[\"e7a0f1dc-d947-4265-9dd4-d4cda25a0928\"] == name_to_barcode[\n",
    "    \"50815360-6914-41f9-8da8-1882c8db69e6\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec6701-f08f-4499-a215-9e1582f53832",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplex_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ef203-82bd-4cc5-b109-9a037229603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplex_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf6b9f3-3998-476c-907d-1f51a2d64ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplex_mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c9be1-0a11-4dbf-b7a9-7018b749cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplex_mismatches[10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
